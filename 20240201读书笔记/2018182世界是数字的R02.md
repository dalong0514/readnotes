## 记忆时间

2020-01-22；2020-04-14；2021-08-20

## 目录

0201算法

算法是一系列精准、无歧义的计算步骤，可以执行某项任务，然后停止。算法不依赖于任何实现的计算过程。复杂性是用来度量算法效率的（计算时间与要处理数据量之间的关系）。

0202编程与编程语言

编程语言是能让我们表达完成某个任务所需计算步骤的语言。

0203软件系统

操作系统，是用来控制和分配计算机资源的。操作系统里的文件系统，是计算机逻辑组织和物理实现的集中体现。应用程序，表示所有在操作系统平台上完成某种任务的软件或程序。

0204学习编程

以 JavaScript 为例阐述了编程语言的基本概念，语法、语义等等。

## 0200. 软件

1、算法。算法就是一系列精确、无歧义的步骤，可以执行某种任务，然后停止。算法描述了不依赖于任何实现的计算过程。这些步骤由定义明确的基本操作或原始操作构成。算法有很多，我们只介绍了基本的搜索和排序算法。

2、复杂性。算法的复杂性是对算法要执行的工作量的抽象描述。度量的依据是基本操作（如检测数据项、比较数据项），而表述的是计算次数与数据项数的关系。算法的复杂性可以分为几个层次，就我们介绍的几种算法而言，既有对数级算法（数据量加倍，计算次数只加一）也有线性算法（计算次数与数据量成正比，最常见也最容易表达） ，还有指数级算法（数据量加一，计算次数加倍）。复杂性度量的是最坏情况（实际的问题很可能要简单得多），而且描述的是一种渐近性质（只有数据量很大的时候才适用）。

3、编程。算法是抽象的，而程序是具体的。程序是让计算机完成一个任务的所有步骤的具体描述。程序必须考虑内存和时间的限制、数值的大小和精度，以及偏激和恶意用户。

4、编程语言。编程语言是表达所有计算步骤的记号库，人们可以籍此轻松写出代码来，而且代码可以被翻译成计算机最终可以执行的二进制形式。翻译方式有很多种，但最常见的是使用编译器，有时候还要用汇编器，把用 C 等语言编写的程序转换成二进制形式，以便在计算机上运行。不同的处理器有不同的指令集和指令形式，因此编译器也会有相应的差异。解释器和虚拟机是模拟真正或假想计算机的程序，可以面向它们编译并运行代码。JavaScript 程序就是面向解释器编译运行的。

5、库。编写一个在真正计算机上运行的程序要牵扯很多细节，涉及很多常用操作。库以及类似的机制可以提供预制的组件，供程序员在编程时使用。有了库，程序员就可以在既有工作成果基础上开展新工作。今天的编程工作通常都是组织既有组件与编写原创代码并重。组件可能是库函数（比如 JavaScript 程序中用到的那些函数），也可能是像 Google Maps 一样的大型系统，或者是其他 Web 服务。然而，从底层来看，它们都是由程序员使用我们介绍过的语言或没介绍过的类似语言指令编写的。

6、接口。接口或者 API（应用程序编程接口）是提供服务的软件与使用该服务的软件之间的一种约定。库和组件通过 API 提供服务。操作系统通过自身的系统调用接口让硬件看起来更有章可循，而且可以编程控制。

7、抽象和虚拟化。使用软件可以隐藏实现的细节或者把实现伪装成其他东西，比如虚拟内存、虚拟机和解释器。

8、Bug。计算机不懂宽容，因此容易犯错的程序员必须写出某种程度上没有错误的程序来。所有大型程序都有 bug，也就是说有时候会不听使唤。某些 bug 仅仅只是惹人讨厌，比如设计得不好，并不像真正的错误那么严重。（「这不是 bug，而是一个功能」是程序员中流行的说法。）而有些 bug 只有在极端情况下或者罕见的情境中才会出现，往往很难再现，更不用说修复了。但有些 bug 确实严重，甚至会威胁到人身安全。随着软件在关键系统中的应用越来越广，对计算设备中软件责任的认定也变得越来越重要。过去那种「买不买由你，一旦售出概不负责」的说辞应该改一改了。对待软件也应该像对待硬件一样，厂商必须尽到保护用户的合理责任。根据经验，因为程序是基于既有组件构建的，而原有 bug 都会消灭掉，至少从原理上讲，新程序中的错误应该越来越少。然而，与这些进步因素相对的是随着计算机和语言的发展，系统承载的需求将越来越多样，市场和消费者呼唤新功能带来的压力也会越来越大，于是无法避免的隐患也会层出不穷。总之，bug 将成为我们心中永远的痛。

好消息是，计算机是一种通用机器，能够执行任何计算。虽然它只有很少的指令，但执行这些指令的速度却极快，而且它能够很大程度上控制自己的运行。坏消息是，如果没有人告诉它该做什么，它就什么都不会做，而且得事无巨细一五一十地告诉它。计算机是「魔法师的学徒」，能够不知疲倦、分毫不差地执行指令，但下达给它的任务书也必须高度精确。

能够让计算机完成某种任务的指令序列通称软件。软件的「软」与硬件的「硬」相对，寓意看不见，摸不着。硬件是有形的：如果失手把计算机掉在脚上，你会喊疼。软件则没有这个问题。

在接下来的几章中，我们要讨论软件，即如何告诉计算机做什么。第 4 章会概括地谈谈软件，并着重讨论一下算法，它们实际上是诸多焦点任务的理想化解决方案。第 5 章讨论编程和编程语言，我们用它来表达一系列计算步骤。第 6 章介绍主要的软件系统，无论你知道与否，反正每天都在用。本部分最后一章是第 7 章，讲讲 JavaScript 编程。

在此期间，要把这些牢记于心：现代系统越来越多地采用通用硬件（如处理器、内存，以及与外界相连接的接口），同时靠软件来实现特定的行为。人们普遍认为，软件更便宜、更灵活，比硬件更好修改（特别是跟已经出厂的设备比）。例如，如果用一台计算机来控制汽车的动力和刹车，那么防抱死和电子稳定控制显然应该是软件的功能。

计算机是许多关键系统的核心，并且软件控制着这些系统。MRI（核磁共振）和 CT（电脑断层）扫描等医学成像系统，就是用计算机来控制信号，并生成供医生解读的图像（胶片已经被数字图像取代）。现代汽车都有数十个小型计算机，分别负责管理制动和稳定性控制系统，无论哪个出问题，后果都不堪设想。火车、轮船、飞机也概莫能外。

事实表明，只要软件不可靠不耐用，我们就一定会遇到麻烦。而随着人们对软件越来越依赖，潜在的麻烦也只会越来越大。后面我们还会介绍到，很难写出一点问题都没有的软件。逻辑或实现上的任何一点错误或疏忽，都可能导致程序出问题。即使正常使用中不会发生这些问题，也会给敌人留下可乘之机。

## 0201. 算法

重塑人们对「我们能计算多快」的认识，多年来一直是计算机科学研究的主题。而用数据量来表示运行时间/次数（如 N 、logN 、N^2 或 NlogN ），则是这一领域研究成果的集中体现。它不去纠结于这台计算机是不是比那一台更快，或者你是不是一个比我更优秀的程序员之类的问题，而是抓住了程序或算法背后的复杂性。正因为如此，才非常合适比较或推断出某些计算是否可行。（一个问题固有的复杂性和解决这个问题的算法的复杂性并不是一个概念。比如，排序是一个 NlogN 问题，但快速排序是一个 NlogN 算法，而选择排序则是一个 N^2 算法。）

算法和复杂性的研究是计算机科学的一个重要组成部分，既有理论也有实践。我们感兴趣的是哪些问题可以计算，哪些不可以，以及如何在无需更多内存的情况下计算得更快（或者是同样速度下使用更少的内存）。我们期待全新的、更好的计算方法。快速排序就是一个典型的例子，尽管它已经出现很多年了。

现实生活中，有许多重要的算法比我们这里介绍的简单的搜索和排序更专业更复杂。例如，压缩算法旨在让声音（MP3）、图片（JPEG）和电影（MPEG）占用更少的存储空间。错误检测和校正算法也很重要。数据在存储和传输（例如通过嘈杂的无线信道）过程中可能会受到损害；控制数据冗余的算法可以检测甚至纠正某些错误。密码学高度依赖于算法，它需要发送只让好人看懂而不能让坏人破解的加密消息。

对于必应和谷歌等搜索引擎而言，算法同样至关重要。从原理上讲，搜索引擎所做的大量工作都很简单，无非是收集网页、组织信息，使其便于搜索，所不同之处在于数据规模极大。如果每天有数十亿次查询，要搜索数十亿个网页，那么即使 NlogN 的复杂性也是无法接受的。为了跟上日益增长的 Web 数据量，满足我们通过它进行搜索的需求，人们在改进算法和编程方面投入了大量聪明才智，以确保搜索引擎能够足够快。

什么是软件？一个通俗的比喻是做菜用的菜谱。菜谱会列出做某个菜所需的原材料、烹饪步骤以及预期结果。类似地，程序也要描述待操作的数据，讲清楚要对数据做什么，以及产出什么结果。不过，菜谱与任何程序都不能比，因为它含糊，容易产生歧义。所以这个比喻并不是非常恰当。比如，我家那本《烹饪的快乐》（Joy of Cooking）在说到打鸡蛋时，说要「放在一个小碗里：1 个鸡蛋」，但没说必须先把蛋磕开，把壳去掉。

用纳税申报表来作比喻更准确一些：这些表格极其详尽地说明了你应该做什么（从第 29 行减去第 30 行。如果结果是 0 或更小，则输入 0。给第 31 行乘上 25%，……）。虽然这个比喻也不完美，但与菜谱相比，纳税申报表在说明计算过程方面更胜一筹：数学计算必不可少，数据从一个位置被复制到另一个位置，后续的计算取决于之前计算的结果。

对于纳税来说，这个过程应该是完整的，无论什么情况下都应该得出一个结果，即应纳税额。应该是毫无疑义的，只要开始的数据相同，任何人都应该得到相同的最终结果。而且应该在有限的时间内完成。从我个人经验来看，这几条都是理想化的，因为术语并不总是很明了，计算说明也比税务机关的说法含糊很多，而且要使用什么数据经常也不好确定。

算法，就是保证特定计算过程正确执行的一系列步骤，它是计算机科学中的菜谱或纳税申报表，只不过编制得更仔细、更准确、更清楚。算法的每一步都表达为一种基本操作，其含义都是完全确定的，如「两个数相加」。任何事物都没有歧义，输入数据的性质也是既定的。所有可能的情况都会涵盖，而算法绝不会遇到一种它不知道接下来该做什么的情况。（计算机科学家有时候也不免书生气，因此通常会给算法多加一个限定条件：任何算法最终必须停止。根据这个标准，经典的洗发水使用说明「起泡、冲洗、重复」就不能说是算法了。）

设计、分析和实现高效的算法是学院派计算机科学的工作核心，而在现实世界中也有很多算法意义重大。我没有打算滴水不漏地解释或说明各种算法，但我想让大家了解相关的思想，即详尽地描述一系列操作步骤，不管执行这些步骤的实体有没有智能或创造力，都能对这些步骤是什么意思以及如何执行做到毫无疑义。另外，我还想谈一谈算法的效率，也就是计算时间与要处理的数据量之间存在什么关系。为此，我会分析几个常见且容易理解的基本算法。

假设我们想找出谁是房间里个子最高的人。我们可以四下里看看，然后猜一猜会是谁。然而，算法则必须精确地列出每一个步骤，从而让不会说话的计算机都能遵照执行。最基本的做法就是依次询问每个人的身高，并记住到目前为止谁最高。于是，我们可能会问「约翰，你多高？玛丽，你呢？」等等。如果我们第一个问的是约翰，那么当时他是最高的。如果玛丽更高，则现在她是最高的人，否则，约翰仍然最高。无论如何，我们都会接着问第三个人。在问完每个人之后，我们就会知道究竟谁最高以及到底有多高。类似的方法还可以找出最有钱的人，或者名字在字母表中最靠前的人，或者谁的生日最接近年底，谁在 5 月出生，以及谁叫克里斯。

会遇到一些复杂的情况。比如如何处理重复的数据，或者说要是有两三个人的身高一样怎么办？我们可以决定只记录第一个人、只记录最后一个人，或者随机记录其中某一个人，再或者记录他们所有人。请注意，找出同样身高的所有人是比较困难的。因为必须记住所有这些人的名字，不问完最后一个人，我们是无法知道这些信息的。这个例子涉及数据结构，即如何表示计算过程中所需的信息。数据结构对很多算法而言都是非常重要的，但在这里我们不会谈太多。

2『数据结构对算法非常重要，直觉是个关键知识点。以后找一个例证放到这里来。（2021-08-22）』—— 未完成

但是，如果让计算机来做这件事，就必须多加小心。例如，要考虑到假如纸上没有身高值怎么办？这对人来说不是问题，因为我们知道这意味着什么也不用做。但对计算机来说，我们必须告诉它如何测试这种情况，出现这种情况该怎么办。假如不事先测试，那它就会尝试用零去除 sum，而这个操作是未定义的。算法和计算机必须处理所有可能的情况。如果你看到过「0 美元 00 美分」的支票，或者收到过尚欠余额为 0 元的账单，那就是因为计算机系统没有全面测试所有可能的情况。

如果我们事先不知道有多少个数据项怎么办（这种情况很常见）？那就得重写算法，让它在累计和的同时计算有多少项。

算法的一个关键属性是其效率有多高 —— 对于给定的数据量，它们的处理速度是快还是慢，要花多长时间？对于上面给出的例子，计算机要执行多少步，或者需要花的时间有多长，与它必须处理的数据量成正比：如果房间里的人多出一倍，就要多花一倍时间才能找到最高的人，或者才能计算出平均身高；如果人数是现在的十倍，就要花十倍的时间。如果计算时间与数据量成正比或叫线性比例，那该算法就叫做线性时间算法或线性算法。以数据量为横坐标，以时间为纵坐标画一条线，得到的将是一条向右上方延伸的直线。我们平时遇到的大多数算法都是线性的，因为它们对某些数据所执行的基本操作是相同的，数据越多工作量也会同比例增加。

线性算法的基本形式都一样。可能需要进行一些初始化，如把累计和的初值设置为 0，或者把最大的身高值设置为一个较小的值。然后依次检查每一项，对它完成一次简单的计算，如计数、与上一个值比较，或进行简单的变换。最后，可能需要再做一些计算，如计算平均值、打印累计和或最大的身高值。如果对每一项执行操作所花的时间相同，那么总时间与数据项数就是呈正比的关系。

那我们还可以做得更好一些吗？假设我们面前有一大堆打印出来的人名和电话号码，或者一沓名片。如果名字并没有特定的顺序，而我们想找到迈克·史密斯（Mike Smith）的号码，那就必须一个名字一个名字地找，直至找到他的名字为止（或者没找到，因为根本就没有这个人）。如果名字是以字母顺序排列的，我们就可以做得更好。

想想我们是怎么从老式的电话簿中查人名的。首先，我们会从接近中间的地方开始查。如果要找的名字比中间页上的名字在字母表中靠前，那后半本就不用看了，直接翻到前半本的中间（整本电话簿的四分之一处）；否则，前半本就不用看了，直接翻到后半本的中间（整本电话簿的四分之三处）。由于名字按字母顺序排列，每一步我们都知道接下来到哪一半里去找。最终，我们一定会找到那个名字，或者可以断定电话簿里根本就没有这个人。

这个搜索算法被称为二分搜索，因为每次检查或比较都会把数据项一分为二，而其中一半今后就不会再理会了。这其实也是常见的分而治之策略的一个应用。它的速度有多快？每一步都会舍弃一半数据项，因此所需要的步数就等于在处理最后一项之前，最初的项数被 2 除开的次数。

假设最初有 1024 个名字（这个数容易计算）。一次比较，就可以舍弃 512 个。再比较一次，还剩 256 个，然后是 128 个、64 个、32 个，接着是 16 个、8 个、4 个、2 个，最后剩下 1 个。总共比较了 10 次。显然，2^10 等于 1024 并非巧合。比较次数作为 2 的指数就能得到最初的数，而从 1 到 2 到 4…… 到 1024，每次都是乘以 2。如果你还记得学校里讲过的对数，那你应该知道一个数的对数就是底数（这里是 2）要得到该数需要自乘的次数。1024（以 2 为底）的对数等于 10，就是因为 2^10 等于 1024。

二分搜索的关键是数据量的增长只会带来工作量的微小增长。如果有 1000 个名字按字母顺序排列，那为了找到其中一个必须检查 10 个名字。如果有 2000 个名字，也只要检查 11 个名字，因为看完第一个名字立即就能舍弃 2000 个中的 1000 个，而这又回到了从 1000 个中查找的情形（检查 10 次）。如果有 1 000 000 个名字，也就是 1000 的 1000 倍，那么前 10 次测试就能减少到 1000，另外 10 次测试即可减少到 1，总共 20 次测试。1 000 000 是 10$^6$，约等于 2$^{20}$，因此 1 000 000（以 2 为底）的对数约等于 20。

不过，得先把这些名字按照字母顺序排列起来呀，怎么做到呢？如果没有这个先行步骤，就不能使用二分搜索。这就引出了另一种基本算法 —— 排序，把数据按顺序排好，后续搜索才能更快。

假设我们要把一些名字按照字母顺序排好，以便后面更有效地使用二分搜索。那么可以使用一个叫选择排序的算法，因为它会不断从未经排序的名字中选择下一个名字。这个算法的技巧，就是前面讨论的找出房间里最高的那个人所用的技巧。

选择排序的工作量有多大？它每次都会遍历剩余的数据项，每次都会找到字母顺序中的下一个名字。对于 16 个名字的排序，查找第一个名字要检查 16 个名字，查找第二个名字需要 15 步，查找第三个名字需要 14 步，依此类推，加起来总共要检查 16+15+14+...+3+2+1 个名字。当然，我们也可能很幸运，发现这些名字已经都按字母排好序了。但研究算法的计算机科学家可都是悲观主义者，他们假设的是最坏的情况（即这些名字都是按照字母顺序的反序排列的）。

检查名字的遍数与最初的数据项数成正比（我们例子中的数据项有 16 个，可以用一般化的 N 表示）。而每一遍要处理的项数都比前一遍少一项，所以选择排序算法一般化的工作量是：

这个序列加起来等于 N×(N+1)/2（最简单的办法是把两头的项成对地加起来），也就是 N^2/2+N/2。忽略除数 2，可见选择排序的工作量与 N^2+N 成正比。随着 N 不断增大，N^2 最终会大得让 N 也可以忽略不计（例如，如果 N 是 1000，则 N^2 就是 1 000 000）。因此，结果就是工作量近似地与 N^2 即 N 的平方成正比，而这个增长率叫做二次增长。二次增长不如线性增长，事实上，差得很远。要排序的数据项增加到原来的 2 倍，时间会增加到原来的 4 倍；数据项增加到 10 倍，时间会增加到 100 倍；数据项增加到 1000 倍，时间会增加到 1 000 000 倍！这可不太好。

幸运的是，有办法让排序更快一些。我们简单地介绍一种巧妙的方法 —— 快速排序（Quicksort），这个算法是英国计算机科学家托尼·霍尔在 1962 年前后发明的（霍尔获得了 1980 年的图灵奖，获奖理由是包括快速排序在内的多项贡献）。快速排序也是分而治之的一个绝佳示例。

要使用快速排序算法给这些名字排序，首先要遍历一次所有名字，把介于 A 到 M 之间的名字放到一组里，把介于 N 到 Z 之间的名字放到另一组里。这样就把所有名字分成了两个组，每个组里包含一半名字（假设这些名字的分布不会很不均匀）。

现在，遍历 A-M 组，把 A 到 F 分成一组，G 到 M 分成另一组；遍历 N-Z 组，把 N-S 分成一组，T-Z 分成一组。到现在为止，遍历了所有名字两次，分成了四个组，每个组包含四分之一的名字：

接下来再遍历每个组，把 A-F 分为 ABC 和 DEF，把 G-M 分成 GHIJ 和 KLM；同样，对 N-S 和 T-Z 也如法炮制。这样，就有了 8 个组，每组差不多有 2 个名字：

当然，到最后我们不仅仅要看名字的第一个字母，比如要把 IBM 排到 Intel 前面，把 Skype 排到 Sony 前面，就得继续比较第二个字母。但就这样多排一两遍，即可以得到 16 个组，每组 1 个名字，而且所有名字都按字母顺序排好了。

整个过程的工作量有多大？每一遍排序都要检查 16 个名字。假设每次分割都很完美，则每一遍分成的组分别会包含 8、4、2、1 个名字。而遍数就是 16 反复除以 2 直到等于 1 为止除过的次数。结果就是以 2 为底 16 的对数，也就是 4。因此，排序 16 个名字的工作量就是 16log216。在遍历 4 遍数据的情况下，快速排序总共需要 64 次操作，而选择排序则需要 136 次。

该算法可以对任何数据进行排序，但只有在每次都能把数据项分割成大小相等的组时，它才是最有效的。对于真实的数据，快速排序必须猜测数据的中位值，以便每次都能分割出相同大小的组。好在，只要对少量数据项进行采样，就可以估计出这个值。一般来说（忽略某些细节上的差别），快速排序在对 N 个数据项排序时，要执行 NlogN 次操作，即工作量与 NlogN 成正比。这与线性增长比要差一些，但还不算太坏，在 N 特别大的情况下，它比二次增长即 N^2 增长可以好太多了。

刚才，我们对算法的「复杂性」或运行时间进行了简单的剖析。一个极端是 logN，即二分搜索的复杂性，它表示随着数据量的增加，工作量的增长非常缓慢。最常见的情况是线性增长，或者说简单的 N，此时工作量与数据量是成正比的。然后是快速排序的 NlogN，比 N 差（增长快），但在 N 非常大的情况下仍然特别实用。还有就是 N^2，或者二次增长，增长速度太快了，既让人无法忍受又不切实际。

除了这些之外，还有其他很多种复杂性，有的容易理解（例如三次增长，即 N^3，比二次增长还差，但道理相同），有的则很难懂，只有少数专业人士才会研究。但有一个还是非常值得了解一下，因为它在现实当中很常见，而且从复杂性上说特别糟糕，这就是所谓的指数级增长，用数学方法表示是 2^N（与 N^2 可不一样）。指数级算法的工作量增长极快：增加一个数据项，工作量就会翻一番。从某种意义上讲，指数级算法与 logN 算法是两个极端，后者数据项翻一番，工作量才增加一步。

什么情况下会用到指数级算法呢？那就是除了一个一个地尝试所有可能性，没有更好的办法的情况。谢天谢地，指数级算法总算是有点用武之地的。有些算法，特别是密码学中的算法，都是让特定计算任务具有指数级难度的。对于这样的算法，只要选择了足够大的 N，其他人在不知道某个秘密捷径的情况下，是不可能通过计算直接解决问题的。

现在你只要知道有些问题容易解决，而有些问题则要难得多就可以了。实际上，关于解决问题的难易程度，也可以表达得更加精确一些。所谓「容易」的问题，都具有「多项式」级复杂性。换句话说，解决这些问题的时间可以用 N^2 这样的多项式来表示，其中指数可以大于 2，但都是可能被解决的。计算机科学家称这类问题为「P」（即「Polynomial」，多项式），因为它们可在多项式时间内解决。

现实中大量的问题或者说很多实际的问题似乎都需要指数级算法来解决，也就是说，我们还不知道对这类问题有没有多项式算法。这类问题被称为「NP」问题。NP 问题的特点是，它可以快速验证某个解决方案是否正确，但要想迅速找到一个解决方案却很难。NP 的意思是「非确定性多项式」（nondeterministic polynomial），这个术语大概的意思是：这些问题可以用一个算法在多项式时间内靠猜测来解决，而且该算法必须每次都能猜中。在现实生活中，没有什么能幸运到始终都做出正确的选择，所以这只是理论上的一种设想而已。

1『欣喜，原来 NP 问题是相对于 P 问题来说的，P 问题即多项式问题。』

很多 NP 问题都会牵扯大量技术细节，三言两语也解释不清楚。不过倒是有一个问题很好解释，乍一看还挺有意思的，而且其实际应用也比较广。这就是「旅行推销员问题」（Traveling Salesman Problem）。一个推销员必须从他居住的城市出发，到其他几个城市去推销，然后再回家。目标是每个城市只到一次（不能重复），而且走过的总距离最短。这个问题跟最短校车或者垃圾车路线有异曲同工之妙。很早以前我在研究这个问题的时候，其原理经常被应用于设计电路板上孔洞的位置，或者部署船只到墨西哥湾的特定地点采集水样。

旅行推销员问题已经被仔细推敲了 50 多年，尽管能用它来解决的问题更加多样化了，但解决方案的核心依然是从所有路径中更巧妙地找出最短路径。同样，有许多的其他问题，尽管类型不同，形式各异，也都面临同样的命运：我们没有什么好办法有效地解决它们。

对于研究算法的人来说，这个现实令人沮丧。我们不知道到底是这些问题本质上就很难解决呢，还是因为人类不够聪明，所以至今都没有找到更好的解决办法。当然，不管怎么说，人们更愿意相信它们「本质上就很难解决」。

1970 年，斯蒂芬·库克（Stephen Cook）证明了一个非同小可的数学结论，就是说所有这些问题其实都是等价的，只要我们找到一个多项式时间算法（复杂性类似 N^2）解决其中一个问题，那我们据此就能找到所有问题的多项式时间算法。库克因此获得了 1982 年的图灵奖。

美国克雷数学研究所（Clay Mathematics Institute）公布了 7 个悬而未决的问题，解决其中一个就可以获得 100 万美元奖金。而问题之一是：P 是否等于 NP？换句话说，这些难题到底跟那些简单的问题是不是一类？（7 个问题中的另一个，可以追溯到 20 世纪初的「庞加莱猜想」，已经被俄罗斯数学家格里戈里·佩雷尔曼解决，奖金已经在 2010 年发放。所以，现在还剩下 6 个待解决的问题。）

对于这种复杂性，有几个地方需要特别注意。虽然 P=NP 问题很重要，但它更多的是一个理论问题，而不是一个实际问题。正如计算机科学家所说的，复杂性结果就是「最坏的」结果，有些问题的实例可能需要投入全部时间和精力，但并不是所有实例都那么难解决。这些问题也具有「渐近」的特点，也就是说，只有 N 值特别大的情况下才值得考虑。在现实生活中，或许大多数问题都能找到简单的解决办法，或许从实用角度看，近似的结果也是完全可以接受的，或许 N 很小，考虑不考虑渐近问题根本无关紧要。

举例来说，如果你只需要对几十或者几百个数据项进行排序，那选择排序可能就足够快了，尽管其复杂性是二次方的，而且与快速排序的 NlogN 相比是每况愈下。如果你只需造访五六个城市，要尝试所有可能的路线不是什么难事儿，但如果是 60 个城市，就有点不可行了，而 600 个城市也这么做根本就是不可能的。最后，在大多数情况下，一个近似的解决方案可能就足够好了，完全没有必要追求所谓的绝对最佳方案。而能够给出合理近似答案的算法可能要多少有多少，其中很多可能还更切合实际。

1『很赞同作者的这个观点，够用即可，不必追求完美。』

## 0202. 编程与编程语言

上一章我们讨论了算法。算法是忽略具体实例而对过程进行的一种抽象或理想化的描述，是分毫不差且没有歧义的「菜谱」。算法通过一组确定的基本操作来表达，这些操作的含义是完全已知且明确的。算法描述了应用这些基本操作的一系列步骤，涵盖所有可能的情况，而且保证最终能够停止。另一方面，程序则不是抽象的，它陈述了一台真正的计算机要完成某个任务所必须执行的具体步骤。程序之于算法，犹如建筑之于图纸，一个是实际存在的，一个是理想化的。

1『隐喻：程序之于算法如同建筑之余图纸一般。』

换一个角度看，程序又是以计算机能够直接处理的某种形式表达出的一个或多个算法。程序必须考虑实际的问题，比如内存不足、处理器速度不快、无效或恶意的输入、网络连接中断，以及（看不见摸不着，但却经常会导致其他问题恶化的）人性弱点。因此，如果说算法是理想化的菜谱，那程序就是让烹饪机器人冒着敌人的炮火为军队准备一个月的给养所需的操作说明书。

我们需要或者希望计算机无所不能，如此一来就需要巨大的编程工作量，而世界上却没有那么多程序员。因此，让计算机代替人处理更多的编程细节就成为这个领域永恒的话题。这自然也就引出了编程语言，即让我们能够表达完成某个任务所需计算步骤的语言。同样，管理一台计算机的资源也十分困难，而现代计算机的复杂性更是让这种困难有增无减。因此，我们也需要让计算机来控制自己的操作，而由此就有了所谓的操作系统。

1『这个角度来看，编程语言用来完成人机交互，操作系统用来完成机机交互。』

1949 年，EDSAC 的诞生标志着第一批真正可编程的电子计算机登上了历史舞台。那时候，给这些计算机编程要把表示指令和数据的数值打在穿孔卡片或纸上，然后把这些数值加载到存储器中执行。用这种编程方式哪怕写一个非常小的程序也十分艰难。首先是不可能一次就做对，其次是发现错误以后修改、增删指令或数据也不容易。

20 世纪 50 年代，出现了能代替人处理某些琐事的程序，因而程序员可以使用有意义的单词来表示指令（如用 ADD 代替数字 5），使用名字来指代特定的内存位置（如用 Sum 代替数字 14）。这其中蕴含的用程序操作程序的思想，一直都是软件领域各种重大进步的核心驱动力。这种代替人执行具体操作的程序被称为汇编器（assembler），因为它最初也用来组装（assemble）程序中由其他程序员事先写好的部分。相应的语言叫做汇编语言，而这个层次上的编程叫做汇编语言编程。有了汇编器，给程序添加或删除指令就方便多了，因为汇编器会负责跟踪数据和指令在存储器中的位置，程序员就不必管这些琐碎的事儿了。

不同处理器的汇编语言只能用于为该处理器编写程序。汇编语言通常都与 CPU 的指令一一对应，能够以特定方式将指令编码为二进制格式，也知道信息在存储器中如何存放。这也就意味着，用某种 CPU（如 Mac 或 PC 中的 Intel 处理器）的汇编语言编写的程序，与在不同 CPU（如手机中的 ARM 处理器）上完成相同任务的其他汇编程序差别会很大。把为一种处理器编写的汇编程序移植到其他处理器，实际上接近于重写一遍执行相同任务的程序。

20 世纪 50 年代末到 60 年代初，计算机在代替程序员做更多事方面又前进了一大步，而这无疑也是人类编程史上最重要的一步。那就是独立于任何 CPU 体系结构的「高级」编程语言问世了。高级语言让人类得以用接近自然语言的方式来表达计算过程。

用高级语言编写的代码经过一个翻译程序，可被翻译为目标处理器的汇编指令。这些汇编指令则会进一步被转换为比特，从而能够加载到存储器中并执行。这个翻译程序通常被称作编译器 —— 同样是一个信息量有限的老术语。

一个编译器可能把这个玩具程序转换成三条指令，另一个编译器则可能把它转换为一条指令。而相应的汇编器将负责把各自的汇编语言指令转换为实际的位模式，同时为 X、Y、Z 这几个量在存储器中留出位置。当然啦，针对这两台计算机的位模式也不一样。

在实际当中，编译器在内部可能会被分成一个「前端」和多个「后端」。「前端」负责把高级语言的程序转换为中间形式，而「后端」则负责把中间表现形式转换成不同体系结构的汇编指令。这种做法要比使用多个完全不同的编译器更简单。

相比汇编语言，高级语言拥有很多优势。首先，它让更多的人得以学会编程，而且编程效率也大大提高。用高级语言编程接近人类的思维方式，因此学习和使用的难度都降低了。人们不需要熟悉 CPU 指令表，就可以使用高级语言高效地编程。其次，高级语言程序独立于各种体系结构，通常无需任何修改即可在不同的体系结构上运行，只要像上图所示换个编译器编译一下就行。于是，程序可以只写一次，随处运行了。这也大幅降低了为多种计算机开发程序的成本。而编译环节也为发现各种拼写错误、语法错误（如少写括号或操作未定义的量）等疏漏提供了机会，在生成可执行程序之前必须纠正这些错误。这些错误在汇编语言程序中很难发现，因为必须假设汇编指令的任何序列都合法。（当然，语法正确的程序仍有可能充斥着各种编译器检测不出来的语义错误。）高级语言的重要意义无论怎么强调都不过分。

第一批高级语言专注于特定的领域。其中一门最早的语言叫做 FORTRAN，这个名字源自「Formula Translation」（公式转换）。FORTRAN 由约翰·巴库斯（John Backus）在 IBM 领导的一个小组开发，在表达科学和工程计算方面非常成功。许多科学家和工程师（包括我）学习的第一门编程语言就是 FORTRAN。FORTRAN 到今天仍然有很多用户。自 1958 年以来，FORTRAN 经历了几次大的变革，但其核心没有变过。巴库斯 1977 年获得图灵奖，其中部分原因就是他领导开发了 FORTRAN。

20 世纪 50 年代末的第二个主要的高级语言是 COBOL（Common Business Oriented Language，面向商业的通用语言），格蕾斯·霍普（Grace Hopper）对汇编语言高级替代品的研究对它产生了重大影响。霍普与霍华德·艾肯（Howard Aiken）当时使用的是哈佛 Mark I 和 II（当时的机械计算机），后来又使用过 Univac（Universal Automatic Computer，通用自动计算机）。她是认识到高级语言和编译器具有巨大潜力的先驱之一。COBOL 是专门针对商业数据处理的语言，其功能非常适合表达库存管理、开发票、做工资等方面的计算。COBOL 现在也有人在用，虽然变化较大但仍然有它自己的特点。

BASIC（Beginner's All-purpose Symbolic Instruction Code，初学者通用符号指令代码）也是当时问世的一门语言，是约翰·凯梅尼（John Kemeny）和汤姆·库尔茨（Tom Kurtz）于 1964 年在达特茅斯开发出来的。BASIC 当初的设计目标是要成为学习编程的入门语言。它特别简单，只需要非常有限的计算资源，因此也成为了第一批个人计算机中的第一个高级语言。事实上，微软公司的创始人比尔·盖茨和保罗·艾伦发迹，也是始于为 1975 年的 Altair 微型计算机编写 BASIC 编译器，这个编译器是微软公司的第一个产品。今天，Microsoft Visual Basic 作为 BASIC 的一个主要分支，仍然被微软公司积极地维护着。

在计算机价格昂贵、速度又慢而且资源有限的时期，人们都担心用高级语言写出来的程序效率太低，因为编译器生成的汇编代码远不如一个熟练的汇编程序员写得好。编译器作者付出了很大努力，希望生成的代码能够达到手写代码一样的高质量，而这为高级语言的流行奠定了基础。今天，计算机速度提升了上百万倍，而且有了充足的内存，程序员很少需要担心指令级的效率问题，尽管编译器和编译器作者仍然很关心。

FORTRAN、COBOL 和 BASIC 获得成功的部分原因，是它们都专注于某个特定的领域，而且有意避免大而全的定位。20 世纪 70 年代，出现了专门为「系统编程」开发的语言。所谓系统编程，就是编写汇编器、编译器、编程工具乃至操作系统等程序员使用的工具。迄今为止，这些语言中最成功的是 C，由丹尼斯·里奇（Dennis Ritchie）于 1973 年在贝尔实验室开发，至今仍然有着非常广泛的应用。从那时到现在，C 的变化很小，今天的一段 C 程序与 30 年前的相比，几乎没有多大差别。

20 世纪 80 年代又出现了 C++，是比雅尼·斯特劳斯特鲁普（Bjarne Stroustrup）同样在贝尔实验室开发的，定位是应对大型程序开发过程中的复杂性。C++ 由 C 发展而来，而且看起来也跟 C 相似。多数情况下，C 程序也是有效的 C++ 程序（上面的程序就是），但反之却绝对不行。

今天，我们在计算机中使用的大部分软件都是用 C 或 C++ 编写的。我写这本书所用的 Mac，其中安装的大多数软件都是用 C 和 Objective-C（C 的一种方言）写的。一开始我用 Word（C 和 C++ 程序），备份则放在 Unix 和 Linux（都是 C 程序）操作系统上，而我上网使用的是 Firefox 和 Chrome（都是用 C++ 写的）。

20 世纪 90 年代，随着因特网和万维网的发展，更多语言被开发出来。计算机处理器的速度继续加快，内存容量继续增大，而编程是否高效、是否便捷变得比机器效率更重要，此时诞生的 Java 和 JavaScript 在这方面考虑得比较多。

20 世纪 90 年代初，詹姆斯·高斯林（James Gosling）在 Sun Microsystems 公司开发了 Java。Java 最初的目标是开发小型嵌入式系统，例如家用电器和电子设备中的系统，因此对速度要求不高，但对灵活性的要求很高。Java 的目标后来变成了在网页中运行，虽然没有成功，但它在 Web 服务中的应用却非常广泛：打开 eBay 之类的网站，虽然你的计算机在运行 C++ 和 JavaScript 程序，但 eBay 可能正在用 Java 来生成网页，然后发给你的浏览器。Java 比 C++ 简单（但复杂度有越来越接近的趋势），但比 C 复杂。另外，由于去掉了一些危险的特性，并且内建内存管理等避免出错的机制，因此 Java 也比 C 安全。出于这个原因，Java 普遍成为编程课上要学习的第一门语言。

这也引出了程序和编程方面一个非常重要的共识：针对某个特定的任务，总会有多种写程序的方式。从这个意义上说，编程就像是文学创作。没错，风格以及恰如其分地运用语言对写作至关重要，对写程序同样至关重要，而且还是区分真正伟大的程序员与普通程序员的标志。程序员对特定的计算任务可以有如此丰富的表达方式，也意味着不难识别从他人程序中复制的非原创代码。我每次上编程课的时候都会着重强调这个观点，但还是有学生认为改改名字或者挪挪代码，就可以掩盖剽窃的事实。很抱歉，这是行不通的。

1『万法想通，编程语言最最底层的逻辑都是一样的，精通多个语言并且能够根据具体的场景来选择，是我这辈子的一个目标。』

JavaScript 同样是 C 衍生语言大家族的一员，但它与 C 的差别也非常大。它是布兰登·艾奇（Brendan Eich）1995 年在网景公司开发的。最初，设计 JavaScript 的意图是在浏览器中实现网页的动态效果，而今天，几乎每个网页里或多或少都会包含一些 JavaScript 代码。

从某些方面看，JavaScript 是所有语言中最容易实验的。这门语言本身也简单。你不需要为 JavaScript 程序找编译器，每个浏览器都内置了一个。于是乎，计算结果可以迅速出现在你眼前。后面我们还会介绍，给这个程序添上几行代码，然后把它放到网页中，全世界的任何人就都可以使用它了。

以后的语言将何去何从？我猜想，人们将继续使用更多的计算机资源让编程变得更容易。而且我们还会继续发展那些对程序员来说更安全的语言。比如，C 语言就像一柄双刃剑，用它写出的程序很容易遗留错误，而等到发现的时候却已经为时已晚（或许已经被用到了不法用途上）。使用较新的语言更容易防止或至少能检测到某些错误，但有时代价是运行速度慢或占用内存多。大多数情况下，这种取舍的方向是没错的，然而肯定还是有很多应用（比如汽车、飞机、航天器和武器的控制系统）对代码的效率和速度要求相当高，因此像 C 这样的高效语言仍然会有人用。

虽然所有语言在形式上都是等价的（都可以模拟图灵机），但这绝不是说它们都适用于所有的编程任务。写一个控制复杂网页的 JavaScript 程序，与写一个实现 JavaScript 编译器的 C++ 程序仍有天壤之别。同时擅长这两种编程任务的程序员并不多见，经验丰富的专业程序员也可能熟悉或粗通十几种语言，但他们不会对多种语言都同样熟练。

现在的编程语言多达几千种甚至上万种，但真正广泛使用的恐怕连 100 种都到不了。为什么会这么多？前面也提到过，每种语言都代表了对效率、表达力、安全性和复杂性的取舍。许多语言显然是为了弥补之前语言的不足才被发明的，它们不仅吸取了之前语言的教训，还能利用更多的计算资源，通常也会受到设计者个人偏好的强烈影响。新的应用领域也会催生专门面向该领域的新语言。

不管怎么样，编程语言都是计算机科学的一个重要而迷人的部分。正如美国语言学家本杰明·沃尔夫（Benjamin Whorf）所说：「语言塑造我们的思维方式，决定我们可以思考什么。」这个论断是否适用于自然语言还有争议，但对于我们发明的告诉计算机去做什么的人造语言来说，好像还是挺靠谱的。

现实中的编程往往是大规模的。大规模编程的方法与任何人想写一本书或承担任何大项目时一样：先搞清楚要做什么，然后从大概的规程着手，将其一级一级分解为较小的任务，再分别完成这些小任务，同时保证它们能够组合在一起。在编程中，每个小任务意味着一个人用某种编程语言可以写出来的精确的计算步骤。确保不同的程序员编写的代码能够在一起工作很有挑战性，而做不到这一点则是错误的主要来源。例如，1999 年美国航空航天局发射的火星气象卫星坠毁，就是因为飞行系统软件在计算推动力时使用的是公制单位，但输入的路线校正数据使用的则是英制单位，使得该卫星太过接近火星表面所致。

今天，稍有价值的程序可能都会包含几千甚至几万行代码。参加我的编程实践课的学生，分为几个小组，写两三千行代码通常需要 8 到 10 周时间，包括系统设计和学习一两门新语言的时间。他们的作品通常都是一些 Web 服务，涉及学生间的二手书交易或者为访问某些大学数据库提供便利。

编译器或 Web 浏览器可能有几十万到一百万行代码。大型系统则可能有几百万甚至上千万行代码，由数百或数千人共同开发，开发时间也长达几年乃至几十年。这种规模的软件需要程序员、测试人员、文档编写人员协同工作，还要有开发计划、最终期限，层层管理，历经无穷无尽的会议一步步走下去。（据我的一位同事说，他曾参与过一个重要系统的开发，针对该系统的每一行代码都要开一次会。那个系统有几百万行代码，所以他说得可能太夸张了，但老资格的程序员可能还是会说：「这话说得不过分。」）

今天如果要盖一间房子，你不必自己伐木取材，烧土做砖，你可以去买各种预制件，比如门、窗、卫浴器具、火炉和热水器。盖房起屋仍然是一个艰巨的任务，但却是你完全能够做到的，因为你可以使用其他人的工作成果，还有各种基础设施做保障。实际上是有一个完整的产业链条，从各个方面为你提供帮助。

编程未尝不是如此。所有重要的程序几乎没有从零开始写的，有许许多多别人已经写出来的东西可以拿来就用。举个例子，如果你在为 Windows 或 Mac 写程序，那么有很多库都能提供预制的菜单、按钮、文本编辑器、图形、网络连接、数据库访问功能。实际上，你的大部分时间要用来理解这些组件，然后再以自己的方式把它们「粘」在一块儿。当然，这些组件有很多也依赖其他更简单、更基础的库，经常要分好几层。而在最下层，就是支持所有程序运行的操作系统，它是负责管理硬件并确保一切井然有序的程序。

在最基本的层次上，编程语言提供了一种机制，叫做函数。这样，程序员就可以写出一段执行某个任务的代码，然后以某种形式把它包装起来，提供给别的程序员在其他程序里使用，而这些程序员不必知道那些代码具体如何完成该任务。

这里的代码「调用」（也就是使用）了两个 C 语言内置的函数：scanf 和 printf。其中，scanf 用于从输入源读取数据（类似我们玩具程序中的 GET），而 printf 打印输出（类似 PUT）。函数有函数名，接收完成任务所需的输入数据值，完成计算后把结果返回给调用它的程序。这里的语法及其他细节都是 C 语言特有的，可能会与其他语言不一样，但内在思想是一致的。函数使我们可以基于组件搭建程序，而这些组件则是独立创建、可以由任何程序员按需使用的。把一组相关的函数集合起来，就叫做库。例如，C 有一个标准函数库，用于读写磁盘和其他地方的数据，scanf 和 printf 就是这个库里的函数。

函数库提供的服务是通过 API（Application Programming Interface，应用编程接口）的形式描述给程序员的。API 会罗列出所有函数，说明每个函数的用途、用法、需要的输入数据，以及生成什么值。API 也会描述数据结构，也就是传进来传出去的数据的组织形式，以及为请求服务必须遵守哪些条条框框和计算将返回什么结果。这种说明书必须面面俱到、严谨准确，因为基于它编写的程序最终会由一台不会说话的计算机而不是一个随和友善的人去解读。

API 文档中不仅包含对语法的要求，也包括大量辅助说明，用以帮程序员更有效地使用函数库。今天的大型系统开发通常都会用到 SDK（Software Development Kit，软件开发工具包），以便程序员在极其复杂的软件库里找到有用的函数。

这些缺陷被称为 bug，这个词是因我们前面提到的格蕾斯·霍普而流行起来的。那还是 1947 年，霍普的同事在哈佛 Mark II（他们当时使用的一种机械计算机）中发现了一只虫子（死了的蛾子），结果她就说她们是在给这台机器「除虫」（debug）。那只死虫子后来被保存下来，还做成了标本供后人瞻仰。如果你去华盛顿，可以在史密森尼美国历史博物馆里看到它。

导致 bug 的原因多种多样，甚至可以写出一本书来专门论述（确实有这类书）。其中比较常见的原因包括忘记处理可能发生的情况、在测试某个条件时写错了逻辑或算术表达式、用错了公式、访问了没有分配给程序的存储器、错误地操作了某种数据、没有验证用户输入等等。

软件中的错误如果暴露到网络上，就会成为可能遭受攻击的漏洞。攻击者通常会利用这些漏洞以自己的恶意代码重写内存。正是由于 bug 广泛存在，所以各种重要的软件才会频繁升级，比如浏览器，它已经成为很多网络黑客关注的焦点。就拿我使用的 Firefox 来说吧，短短 18 个月就经历了 19 次修订，共修复近 100 个安全漏洞。这可不是什么特例，但也并不意味着 Firefox 程序员都不够格。这说明编写一个耐用的程序非常难，而坏人始终都在寻找你的弱点。

现实中软件面临的另一个复杂性在于外界环境瞬息万变，因此程序必须不断适应新情况。新的硬件问世后，它所需要的软件可能得进行系统级的改动。新的法律法规出台，程序的逻辑可能就必须调整 —— 众所周知，税法每次有什么变化，相关软件都要升一次级。计算机、工具和语言过了时，就需要有新的替代品问世。数据格式过时的情况更加常见 —— 今天的 Word 软件打不开 20 世纪 90 年代初写就的 Word 文档。自然，存储和处理这些数据的物理设备也一样在代代更替。而随着人的退休、死亡或被公司解雇，专业知识也会消逝。学生在校期间开发的系统随着他们的毕业，也面临相同的遭遇。

必须持续不断地小幅更新，这是软件开发和维护的一大问题，但是不做还不行。如果不那么做，程序就会遭遇「比特腐烂」，一段时间之后，也许就不能用了，或者想更新都更新不了了，因为重新编译无法通过，或者它所依赖的库已经变得太多了。与此同时，无论更新还是修复问题，通常都会产生新的 bug，或者改变用户熟悉的行为。

软件所有权引发了很多棘手的法律问题，我认为比硬件的问题还要多，但作为一个程序员，这也可能是我的偏见。与硬件相比，软件是一个比较新的领域，1950 年之前，还没有软件呢。软件独立成为经济发展的一支力量，还只是近二三十年的事。因此，相关的法律、商业惯例和社会规范等机制还来不及完善。软件是有价值的，但又是无形的。开发和维护相当规模的代码需要投入持续的艰苦劳动。与此同时，又可以没有限制地复制软件或者在全世界范围内分发它，却不发生任何成本。你可以很容易地把它改来改去，而不管怎么改，它都是看不见的。凡此种种，导致软件的所有权问题特别棘手。

标准是对某些产品如何制造或者应该具有什么用途的准确、详细的说明。软件标准的例子涉及编程语言（即语法和语义的定义）、数据格式（如何表示信息）、算法处理（完成某个计算的特定步骤），等等。

某些标准是事实标准，比如 Word 软件的 .doc 格式。事实标准指的是没有正式的名义，但每个人都在用。「标准」这个词最好只用于正式的说明书，通常由政府或协会等中立的团体制定和维护，规定某物如何制造和运作。标准的定义是足够完整和准确的，独立的实体可以反馈意见或提供中立的实现。我们每时每刻都受益于硬件标准，尽管我们根本想象不到有多少个硬件标准。如果我买了一台新电视，我之所以可以把它的电源插头插到我家的插座上，就是因为有标准规定插头的大小和形状以及电视和插座的电压。电视可以接收信号并显示画面，是因为广播和有线电视也有标准。而使用标准的 HDMI、USB、S-Video 数据线和连接器，我还可以把其他设备连接到电视上。然而，每台电视都有它自己的遥控器，每一部手机也都有各自的充电器，则是因为它们都还未实现标准化。

计算机领域也有各种各样的标准，字符集有 ASCII 和 Unicode，编程语言有 C 和 C++，算法有加密的和压缩的，还有通过网络交换信息的各种协议。有时候甚至还有相互竞争的标准，让人觉得有点浪费。（正如计算机科学家安迪·特南鲍姆（Andy Tanenbaum）所说：「多个标准的好处在于让人有多个选择。」）过去的例子有录像带的 Betamax 和 VHS 标准，而最近的例子是高清视频盘的 HD-DVD 和 Blu-ray Disc 标准。对于这两种情况，前者以一种标准最终胜出告终，后者则很可能两种标准共存，就像美国存在两种不兼容的手机技术一样。

标准很重要。有了标准，大家各自制造的东西才能集成到一起，多个供应商才能同台竞技，而专有系统则会把每个人限制死。（专有系统的所有者自然愿意把人们都限制在它的平台上。）标准也有缺点 —— 如果标准本身质量不高或者已经过时，但所有人又都被迫使用它，那它就会阻碍进步。不过，与它的优点相比，这些缺点还是能够接受的。

程序员编写的代码，无论使用的是汇编语言还是（更可能的）某种高级语言，都被称为源代码。而编译源代码得到的适合某种处理器执行的编码，叫做目标码。正如已经介绍的它们之间的其他区别一样，区别源代码和目标码看起来有点迂腐，但却非常重要。源代码是程序员可以读懂的，尽管可能得费点时间和精力。因此源代码是可以仔细研究并加以改编的，它所包含的任何创新和思想也是可见的。相对而言，目标码则经过了很大程度的转换，一般不太可能再恢复为类似源代码的形式，也无法从中提取出什么结构再加以改造，甚至连理解它都是不可能的。正因为如此，大多数商业软件只以目标码的形式分发，而源代码是重要的机密，因此说比喻也好，事实也罢，反正它会被锁得严严实实的。

开放源代码则是指另一种做法，即源代码可以被任何人自由阅读、研究和改进。

早期，大多数软件由公司开发，源代码是一般人看不到的，那是属于开发者所有的商业秘密。在麻省理工学院工作的理查德·斯托曼（Richard Stallman），曾经希望能够修改和加强自己使用的某些程序，但这些程序的源代码是别人私有的，自己根本看不到。为此，斯托曼感到很懊恼。1983 年，他发起了一个叫 GNU（即「GNU's Not Unix」，gnu.org）的项目，致力于开发一些重要软件（比如操作系统和编程语言的编译器）的自由和开放版本。他还创办了一个非营利组织，叫自由软件基金会（Free Software Foundation）。这个组织的目标是开发那些永远「自由」的软件，也就是说这些软件不是私有的、不会受到所有权的限制。为此，自由软件的实现在分发时都必须遵守一个独创的版权许可，叫做 GNU 通用公共许可（GNU General Public License）或简称 GPL。

GPL 的序言如是说：「大多数软件及其他实用作品的许可，目的都是剥夺你分享和修改作品的自由。相比而言，GNU 通用公共许可则意在保证你分享和修改程序各个版本的自由，也就是确保该程序对所有用户来说仍然是自由软件。」GPL 规定，基于该许可的软件可以被自由使用，而如果再把它分发给其他人，则必须公开源代码，并同样遵守「所有用户都可以自由使用」的许可。GPL 是一种强有力的许可，一些违反其条款的公司已经被禁止使用其代码，或者公开了以许可约束的代码为基础的源代码。

GNU 项目由很多公司、组织和个人支持，发布了大量软件开发工具和应用程序，这些软件全部采用 GPL 许可。其他类似的开源软件也采用类似的许可方式。很多时候，开源软件都为专有商业软件设立了标杆。比如，Firefox 和 Chrome 浏览器是开源的，大多数 Web 服务器上运行的 Apache Web 服务器软件也是开源的，Android 手机操作系统也是开源的。所有主要的编程语言都有开源的编译器，大多数程序员工具（包括我用来生成本书的工具）也都有开源版本。

Linux 操作系统或许是最广为人知的开源系统了（虽然它并不属于 GNU 项目），它被个人和大型商业企业广泛使用，比如谷歌的全部基础设施都运行在 Linux 之上。如果你想得到 Linux 内核源代码，访问网站 kernel.org 即可免费下载。下载后既可以自己使用，也可以对它进行任意修改。不过，要是你想以任何形式再次发布（比如，把它作为操作系统放到一个小工具里发布），那必须遵守相同的 GPL 协议开放源代码。

开放源代码是很值得研究的。把源代码送人还怎么赚钱呢？为什么程序员愿意为开源项目做贡献呢？志愿者编写的开源软件比大型专业团队协作开发的专有软件更好吗？源代码可以随便下载会不会威胁到国家安全？

这些问题持续吸引着经济学家和社会学家，也有一些答案慢慢浮出了水面。例如，红帽子（Red Hat）是一家在纽约证券交易所公开上市的公司，该公司 2011 年的年收入近 10 亿美元，市值超过 80 亿美元。他们发布的 Linux 源代码可以在网上免费下载，但公司通过支持、集成和其他收费服务可以获得收入。一些开源程序员本身就在那些使用并支持开源软件的企业工作，IBM 是一个明显的例子，但绝非特例。这些公司通过影响开源软件的发展，通过让其他人修复 bug 和改进功能而获得收益。并不是所有开源软件都能独领风骚，开源版本不如它所模仿的商业版本的情况也比比皆是。但是，对于一些核心的程序员工具和系统来说，开源软件生生不息，的确很难被比下去。

## 0203. 软件系统

两种主要的软件：操作系统和应用程序。操作系统是软件中的基础层，它负责管理计算机硬件，并为其他被称作应用程序的程序运行提供支持。

20 世纪 50 年代初，还没有应用程序与操作系统之分。计算机的能力非常有限，每次只能运行一个程序，这个程序会接管整台机器。而程序员要使用计算机，运行自己的程序，必须事先预约时间段（身份低微的学生只能预约在半夜）。随着计算机变得越来越复杂，再靠非专业人员使用它们效率就会很低。于是，操作计算机的工作就交给了专业操作员。计算机操作员的任务就是把程序输入计算机，然后把计算结果送交相应的程序员。操作系统最初就是为了代替人工操作员完成上述工作才诞生的。

硬件不断发展，控制它们的操作系统也日益完善。而随着硬件越来越强大、越来越复杂，就有必要集中更多的资源来控制它们。第一批广泛使用的操作系统诞生于 20 世纪 50 年代末、60 年代初。这些操作系统通常是由硬件厂商提供的，IBM 和 Univac 都推出过自己的操作系统。后来，就连小一点的公司像 Digital Equipment 和 Data General 也都开发过自有操作系统。

操作系统也是很多大学和业界实验室的研究目标。MIT（麻省理工学院）作为这方面的先驱，在 1961 年开发了一个名为 CTSS（Compatible Time-Sharing System，兼容分时系统）的系统，该系统比同时代与之竞争的其他产品都先进得多，用起来的感觉也非常好。1969 年，贝尔实验室的肯·汤普森（Ken Thompson）和丹尼斯·里奇（Dennis Ritchie），结合他们对 CTSS 以及更完善但却不那么成功的 Multics 系统的第一手经验，开始着手开发 Unix。今天，除了微软开发的那些操作系统之外，大多数操作系统要么源自当初贝尔实验室的 Unix 系统，要么是与 Unix 兼容但独立分发的 Linux 版本。里奇和汤普森因为开发了 Unix 而一起荣获 1983 年图灵奖。

现代的计算机确实是一个复杂的「怪物」。它由很多部件组成，包括处理器、内存、磁盘、显示器、网卡，等等。为了有效地使用这些部件，需要同时运行多个程序，其中一些程序等着某些事件发生（如网页下载），另一些程序则必须实时作出响应（跟踪鼠标移动或在你玩游戏的时候刷新显示器），还有一些会干扰其他程序（启动新程序时需要在已经很拥挤的 RAM 中再腾出空地儿来）。简直就是一片混乱。

要管理如此复杂的局面，唯一的办法就是用程序来管理程序，这也是让计算机自己帮自己的又一个例子。这么一个程序就叫作操作系统。家用和商用计算机中最常见的操作系统是微软开发的各种版本的 Windows。我们日常见到的计算机 90% 都是由 Windows 管理的。苹果电脑运行的是 Mac OS X，它是一种 Unix 变体，也是在消费领域中仅次于 Windows 的第二大操作系统。而很多做幕后工作的计算机（当然也有一些直接面向用户的计算机）运行的是 Unix 或 Linux。手机中也有操作系统，它们是精简版 Windows、Unix、Linux 或其他特殊系统。例如，iPhone 和 iPad 运行的 iOS 就源自 Mac OS X，而我的 Android 手机、电视机、TiVo、亚马逊 Kindle 和巴诺 Nook 运行的都是 Linux 操作系统。我甚至可以登录自己的 Android 手机，在上面运行标准的 Unix 命令。

操作系统控制和分配计算机资源。

首先，它负责管理 CPU，调度和协调当前运行的程序。它控制 CPU 在任意时刻执行的程序，包括应用程序和后台进程（如杀毒软件和检查更新的程序）。它会将一个暂时等待的程序（比如等待用户在上面单击的对话框）挂起。它会阻止个别程序多占资源。如果一个程序占用 CPU 时间太多，操作系统会强行将其中断以便其他任务得以正常执行。操作系统通常都需要管理数十个同时运行的进程或任务。其中有些是由用户启动的程序，但大多数还是一般用户看不到的系统任务。在 Mac OS X 上通过 Activity Monitor，或在 Windows 上通过任务管理器，可以看到系统当前都运行有哪些程序。

其次，操作系统管理 RAM。它把程序加载到内存中以便执行指令。如果 RAM 空间不足，装不下所有程序，它就会将某些程序暂时挪到磁盘上，等有了空间之后再挪回来。它确保不同的程序相互分离、互不干扰，即一个程序不能访问分配给另一个程序或操作系统自身的内存。这样做既是为了保持清晰，同时也是一种安全措施，谁也不想让一个流氓程序或错误百出的程序到处乱窜。（Windows 中常见的「蓝屏死机」现象就是因为这种保护做得不到位造成的。）

为了有效利用 RAM，必须事先进行周密设计。一种思路是在必要时把程序的一部分加载到 RAM，而在程序处于非活动状态时再把它转存回磁盘，这个过程称为交换（swapping）。程序编写得就好像整台计算机都归它自己使用一样，而且也不必考虑 RAM 的限制。这样就大大简化了编程工作。另一方面，操作系统必须支持这种「假象」，方法就是在内存地址转换硬件的帮助下，不断地换入换出程序块，让程序认为它一直都在访问真实内存中的真实地址。这种机制被称为虚拟内存（virtual memory）。所谓「虚拟」，意思就是营造一种假象，而实际上这些内存并不存在。

1『活动监视器里，内存页面里，确实有一个「已使用的交换」的数据。』

第三，操作系统管理存储在磁盘上的信息。文件系统是操作系统中的一个主要组成部分，负责提供我们在计算机中都见过的那种文件夹和文件般的分层机制。

最后，操作系统管理和协调外接设备的活动。它维护屏幕上的多个窗口，确保每个窗口都能显示正确的信息，而且在这些窗口被移动、缩放或隐藏后再次显示时，都能准确地恢复原貌。它把键盘和鼠标的输入送往需要这些输入的程序。它处理通过有线或无线网络连接进进出出的流量。它将数据发送给打印机和 DVD 刻录机，从扫描仪取得数据。

1『这么了解后，操作系统实在是太 NB 了，mac os 给我带来的感触更直接。』

请注意，我说过操作系统也是程序。它跟我们在上一章讲到的其他程序一样，都是用同一类编程语言编写的，最常用的是 C 和 C++。早期的操作系统很小，因为工作比较简单。最早的操作系统每次只运行一个程序，所以程序交换量很小。没有太多内存可供分配（最多也就几百 KB）也决定了内存管理很简单。而且也没有太多外部设备需要管理，跟今天的外设比起来显然要少得多。今天的操作系统已经非常庞大（动辄包含数百万行代码）非常复杂了，因为它们的任务本身就非常复杂。

就以 Unix 操作系统第 6 版为例，它是今天很多操作系统（不包括 Windows）的鼻祖。它在 1975 年的时候是一个包含 9000 行 C 代码的汇编程序，两个人（肯·汤普森和丹尼斯·里奇）就可以把它写出来。如今的 Windows 7 拥有大约 1 亿行代码，Linux 的代码也超过了 1000 万行，它们都是几千人历经几十年工作的成果。当然，就这么直接拿来比也不太合适，毕竟现在的计算机要复杂得多，而且今天的环境和设备也要复杂得多。操作系统包含的组件同样也有差别。

2『各操作系统的代码数量做一张信息卡片。』

既然操作系统也是程序，那么从理论上说你也可以写出自己的操作系统来。事实上，Linux 最早就是由芬兰大学生李纳斯·托沃兹（Linus Torvalds）在 1991 年写出来的，他当时的想法就是从头编写一个自己的 Unix 版本。他在互联网上发布了自己写的一个简陋程序，邀请别人试用和帮忙。自那时起，Linux 就逐渐成为软件业中一支重要的力量，很多大大小小的公司都在使用。上一章提到过，Linux 是开源软件。今天，Linux 除了核心的全职开发人员之外，还有数千名志愿者参与开发，而托沃兹负责总体把控和最终裁决。

2『Linux 创始的时间做一张信息卡片。』

我们甚至可以在一个操作系统的控制下运行另一个虚拟操作系统。使用 VMware、Parallels 和（开源的）Xen 等虚拟操作系统软件，可以在一台 Mac OS X 主机上运行另一个客户操作系统，比如 Windows 或 Linux。主机操作系统会拦截客户操作系统的请求，代替它执行那些需要具备操作系统级权限才能执行的操作，如访问文件系统或网络。主机在执行完操作后，将结果返回给客户机。在主机和客户机系统都是为相同硬件编译的情况下，客户系统大多数时候都得到硬件的全速支持，响应的及时性给人感觉就像在裸机上运行一样。

这里有必要说一说「虚拟」这个词的另一种用法。一个模拟计算机的程序，无论它模拟的是真实的计算机还是想象中的计算机（比如本书前面提到的玩具计算机），经常也被称为虚拟机。换句话说，计算机只以软件形式存在，而这种软件的行为就如同硬件一般。这种虚拟机很常见。浏览器都有一个虚拟机用于解释 JavaScript 程序，所有 Java 程序也都是通过虚拟机来解释的，而每台 Android 手机上同样有一个类似的 Java 虚拟机。

2『虚拟机是一个模拟计算机的程序。这个定义让我对虚拟机的概念清楚一些了。虚拟机的定义做一张术语卡片。』

CPU 的结构是经过特殊设计的。计算机加电后，CPU 会开始执行存放在非易失性存储器中的一些指令。这些指令继而从一小块闪存中读出足以运行某些设备的代码。这些代码在运行过程中再从磁盘、CD、USB 存储器或网络连接的既定位置读出更多指令。这些指令再继续读取更多指令，直到加载了足够完成有效工作的代码为止。这个准备开始的过程叫做启动（booting），源自拉着靴带（bootstrap）给自己穿上靴子的典故。具体细节可能不同，但基本思想是一样的，即少量指令足以找到更多指令，后者依次再找到更多的指令。

计算机启动过程中通常还要检查硬件，以便知道有哪些设备接入了计算机，比如有无打印机或者无线设备。还会检查内存和其他组件，以确保它们都可以正常工作。启动过程还会为接入的设备加载软件（驱动程序），以便操作系统能够使用这些设备。上述过程都需要时间，而我们从开机到计算机能用的这段时间内通常都会等得不耐烦。

操作系统运行起来之后，它就会转而执行一个简单循环，依次把控制权交给准备运行或需要关注的每个应用程序。如果我在字处理程序中输入眼下这些字的时候，顺便收了一下邮件，又到网上逛了逛，同时还在后台播放音乐，那么操作系统会让 CPU 依次处理这些进程，并根据需要在它们之间切换。每个程序会得到一段极短的时间，在程序请求系统服务后或者分配给它的时间用完时结束。

操作系统会响应各种事件，比如音乐结束、邮件或网页到达，或者用户按下了键盘上的按键。对这些事件，操作系统都会作出必要的处理，通常是把相应的事件转发给相关的应用程序。如果我重新排列屏幕上的窗口，操作系统会告诉显示器把窗口放在什么地方，并告诉每个应用程序它们各自窗口的哪一部分可见，以便重新绘制窗口。如果我选择「文件> 退出」或单击窗口右上角的「×」按钮退出应用程序，系统会通知应用程序它马上要「死」了，以便它赶紧「安排后事」（比如，弹出对话框询问用户「您想保存这个文件吗？」）。然后，操作系统会回收该程序占用的所有资源，并告诉那些窗口得见天日的其他程序，必须重绘各自的窗口了。

操作系统提供了硬件和其他软件之间的接口。有了这个接口，硬件就好像能听懂人的话了，而程序员编程因此就会变得简单。用这个圈子里的行话说，操作系统提供了一个平台，在这平台上可以构建应用程序。

操作系统为应用程序定义了一组操作（也叫服务），比如将数据存储至文件或者从文件中取出数据、建立网络连接、获取键盘输入、报告鼠标移动和按钮点击、绘制屏幕，等等。

1『对「服务」的定义：操作系统为应用程序定义的一组操作。』

操作系统以标准化的或者说大家协商一致的方式提供这些服务，而应用程序通过执行一种特殊的指令来请求这些服务，并将控制权移交给操作系统中特定的地址。操作系统根据请求完成计算，然后再将控制权和结果返回给应用程序。操作系统的这些「入口」被称为系统调用（system call），而对这些系统调用的详细说明实际上恰恰解释了操作系统能做什么。系统调用可以直接拿操作系统内部的代码作为入口，也可以是对某个（为相应服务而准备的）库函数的调用。但多数情况下，即便是程序员也不用关心上述区别。正因为如此，谁也说不清楚到底有多少个系统调用，但通常一两百个总是有的。

2『对「系统调用」的概念再去了解一下。原书这个章节里有一张图表达的相当清楚了，可以时常看看。（操作系统、系统调用、驱动程序和应用程序之间的关系图）』

操作系统中的另一个部件 —— 设备驱动程序。设备驱动程序是一种沟通操作系统与特定硬件设备（如打印机和鼠标）的程序。驱动程序的代码知道怎么让特殊的设备履行自己的职责，比如从特定的鼠标得到移动和按钮信息、让磁盘通过旋转的磁表面读取和写入信息、让打印机在纸上留下记号、让特定的无线网卡发送和接收无线电信号。

就说打印机吧。操作系统只会发出标准的请求，比如「在这个位置上打印这段文本」、「绘制这幅图像」、「移到下一页」、「描述你的能力」、「报告你的状态」，等等。而且，还是以适合所有打印机的标准方式发出这些请求。然而，打印机的能力是有差别的，比如支不支持彩色打印、双面打印，或者不同纸张大小。打印机专属的驱动程序，要负责把操作系统请求转换为特定设备完成相应任务必需的指令。一句话，就是操作系统发送通用的请求，而具体的设备驱动程序负责在各自硬件上落实、执行请求。

驱动程序把操作系统与特定设备独有的性质隔离开来（任何设备，比如各种键盘，都有一些操作系统要用到的基本性质和操作），操作系统通过驱动程序的接口以统一的方式访问相应设备，从而方便在设备之间切换。通用的操作系统都包含很多驱动程序。例如，Windows 为满足各种潜在用户的需要，在发行时就已经带有各种各样的设备驱动程序。每个设备的制造商都有自己的网站，提供新版本或更新的驱动程序下载。

启动过程中有一个环节就是把当前可用设备的驱动程序加载到运行的系统中。可用的设备越多，加载要花的时间就越长。新设备随时有可能出现。在把外部磁盘插入 USB 插槽后，Windows 会检测到这个新设备，（根据设备驱动程序接口的某个部分）确认它是一个磁盘，然后加载 USB 磁盘驱动程序与这个磁盘通信。Mac OS X 操作系统也一样。一般来说，没有必要不断升级新的驱动程序，因为所有设备的接口都是标准化的，操作系统本身已经包含了必要的代码，而驱动设备的特殊程序也已经包含在设备自身的处理器中。

总之，这些设备俨然与主流通用计算机一般无二。它们都有强劲的处理器、大容量的内存，以及一些外围设备（比如数码相机上的镜头和显示屏）。它们的用户界面极其精美。它们可以通过网络连接与其他系统通信 （手机使用电话网络和 Wi-Fi，游戏机手柄使用红外线和蓝牙），不少还提供 USB 接口，以支持移动硬盘的临时接入。

随着这种趋势的不断演进，选择市面上现成的操作系统要比自己从头写一个来得更实际。除非用途特殊，否则在 Linux 基础上改一改是成本最低的，关键是 Linux 非常稳定、容易修改、方便移植，而且免费。相对而言，自己开发一个专有系统，或者取得某个商业系统的许可，都会引入巨大开销。当然，改造 Linux 的缺点在于必须把改造后的操作系统部分代码按照 GPL 许可发布，由此可能引发如何保护设备中知识产权的问题。不过，从 Kindle 和 TiVo 的案例来看，似乎也没有什么不能解决的。

文件系统是操作系统的一个组成部分，它能够让硬盘、CD 和 DVD、移动存储设备，以及其他各种存储器等物理存储媒体，变成看起来像是由文件和文件夹组成的层次结构。我们常说计算机有逻辑组织和物理实现两大概念，文件系统就是这两大概念的集中体现。文件系统能够在各种不同的设备上组织和存储信息，但操作系统则为所有这些设备都提供相同的接口。文件系统存储信息的方式以及存储多久，最终甚至会衍生出一些法律问题来。所以说，研究文件系统的另一个目的，就是要理解为什么「删除文件」并不代表其内容会永远消失。

1『文件系统是计算机逻辑组织和物理实现的集中体现。』

几乎所有人都用过 Windows 的资源管理器或者 Mac OS X 的 Finder，这两个工具都能列出自最顶层（比如 Windows 中的 C 盘）开始的文件系统的层次结构。在这个层次结构里，一个文件夹（folder）可以包含其他文件夹和文件。换句话说，点开一个文件夹，就可以看到更多文件夹和文件。（Unix 系统则一直使用目录（directory）而不是文件夹的概念。）这里的文件夹是一个组织结构的概念，而实际的文档内容、图片、音乐、电子表格、网页等，则保存在文件中。在计算机中，所有这些信息都存储在文件系统内，只要用鼠标点击几下就可以找到。文件系统中不光存储数据，还存储着可以执行的程序（比如浏览器）、代码库、设备驱动程序，以及构成操作系统自身的文件。这些文件的数量大得惊人，就说我这个普普通通的 MacBook 吧，其中存储的文件已经超过了九十万个。

文件系统管理所有这些信息，方便其他程序和操作系统的其他部件读写这些信息。它统筹安排所有的读写操作，确保这些操作有效进行，且不会相互干扰。它记录数据的物理位置，确保它们各就各位，不会让你的电子邮件意外地窜到你的电子表格或纳税申报单里面去。在支持多用户的系统中，还要保证信息的隐私权和安全性，不能让一个用户在未经允许的情况下访问另一个用户的文件。另外，可能还需要限制每个用户有权使用的硬盘空间，也就是所谓的配额管理。

在最低级的层次上，文件系统服务是通过系统调用来提供的。程序员通常要借助代码库来使用这些系统调用，以简化编程过程中常见的文件处理操作。

无论什么样的存储设备，在文件系统中一律只表现为文件夹和文件。从这一点来说，文件系统是把物理实现抽象为逻辑组织的绝佳范例。但它又是怎么做到的呢？

一块 100GB 的硬盘可以存储 1000 亿字节的数据，但这块硬盘上的软件可能会将其看成 1 亿个 1000 字节大的块。（现实中，块的大小应该是 2 的幂，而且每个块还会更大。这里使用十进制是为了便于说明其中的关系。）这样，一个 2500 字节大的文件（比如一封普通的邮件），就需要 3 个这样的块来存储。因为 2 个块存不下，而 3 个块有富余。文件系统不会在同一个块内存储不同文件的信息，因而就免不了有一些浪费。因为存储每个文件的最后一个块不会完全用完（在我们举的这个例子中，最后一个块就会闲置 500 字节）。考虑到简化记录工作所节省的工作量，这点代价还是值得的，更何况磁盘存储器已经那么便宜了。

这个文件所在的文件夹条目中会包含文件的名字、2500 字节的文件大小、创建或修改时间，以及其他细节信息（权限、类型等，取决于操作系统）。所有这些信息都可以通过资源管理器或者 Finder 看到。

这个文件夹条目中还会包含文件在磁盘上的位置信息，也就是 1 亿个块中的哪 3 个块存储着这个文件。管理这些位置信息的方法有很多种。比如，文件夹条目可以包含一组块编号，也可以引用一个自身包含一组块编号的块，或者只包含第一个块的编号，第一个块又包含第二个块的编号，依此类推。下面这幅示意图展示了文件夹引用块列表的大致情况：

存储同一个文件的块在磁盘上不一定连续。事实上，这些块一般都不挨着，至少存储大文件的块是这样的。兆字节级别的文件需要占用上千个块，这些块通常会分散在磁盘的各个地方。尽管从这幅图中看不出来，但文件夹及块列表本身也存储在块中。

文件夹也是一个文件，只不过这个文件中包含着文件夹和文件的位置信息。由于涉及文件内容和组织的信息必须精准、一致，所以文件系统保留了自己管理和维护文件夹内容的权限。用户和软件只能请求文件系统来间接地修改文件夹内容。

没错，文件夹也是文件。从存储方式上讲，它们跟文件没有任何区别。只不过文件系统会全权负责管理文件夹内容，任何应用软件都不能直接修改该内容。除此之外，它们都保存在硬盘上的块中，由相同的机制进行管理。

在应用程序要访问已有的某个文件时，文件系统必须从其顶级层次开始搜索该文件，在相应文件夹里查找文件路径中的每一部分。举个例子，假设要在 Mac 中查找 /Users/bwk/book/book.txt。文件系统首先要在其顶层搜索 Users，然后在该文件夹里搜索 bwk，接着在找到的文件夹里搜索 book，最后再在找到的文件夹里搜索 book.txt。这是一种化整为零的思路。也就是说，路径中的层次会逐步缩小要搜索的文件或文件夹的范围，同时把其他不相干的部分过滤掉。正因为如此，不同层次中的文件可以使用相同的名字，唯一的要求是完整的路径必须独一无二。实践中，应用程序和操作系统会记住当前的文件夹，因而文件系统不必每次都从顶层开始搜索。而为了加快处理速度，系统还可能会缓存频繁用到的文件夹。

应用程序在创建新文件时会向文件系统发送请求，文件系统会在相应的文件夹中增加一个新条目，包含文件名、日期等项，还有文件大小为零（因为还没有为这个新文件分配磁盘块）。接下来，应用程序要向文件中写入某些数据时（比如向一封邮件中写几句话），文件系统会找到足够多的当前没有使用的或者「空闲」的块来保存相应内容，并把数据复制过去。然后把这些块插入到文件夹的块列表中，最后返回给应用程序。

不难想象，文件系统还要维护一个磁盘上当前未被使用（也就是还没有成为某些文件一部分）的块的列表。每当应用程序请求新磁盘块，它就可以从这些空闲的块中拿出一些来满足请求。这个空闲块的列表同样也保存在文件系统的块中，但只能由操作系统访问，应用是访问不到的。

删除文件时，过程恰好相反：文件占用的块会回到空闲列表，而文件夹中该文件的条目会被清除，结果就好像文件被删除了一样。现实中的情况并不完全如此，而是加入了一些有意思的比喻。当你在 Windows 和 Mac OS X 中删除一个文件时，这个文件会跑到「回收站」或「垃圾桶」里去。「回收站」和「垃圾桶」不过是另外一个文件夹，但具备某些常规文件夹所不具备的属性。正因为如此，才称其为「回收站」嘛。删除文件时，相应的文件夹条目将从当前文件夹被复制到名叫「回收站」或「垃圾桶」的文件夹里，然后会清除掉原来的文件夹条目。但是，这个文件占用的块以及其中的内容没有丝毫变化！从「回收站」里还原文件的过程正好相反，就是把相应条目恢复到它原来所在的文件夹中。

「清空回收站」倒是跟我们本节一开始描述的过程很相似。此时「回收站」或「垃圾桶」里的文件夹条目会被清除，相应的块会真正再添加到空闲块列表中。不管是明确地执行这个操作，还是文件系统因为空闲空间过少而在后台静默地清空，这个过程都将实实在在地发生。

假设是你明确地执行清空操作。那么这个操作首先清除「回收站」文件夹中的条目，然后把其中文件占用的块回写到空闲块列表。但是，这些文件的内容并没有被删除。换句话说，原始文件占用的每个块中的所有字节都会原封不动地呆在原地。除非相应的块从空闲块列表中被「除名」并奉送给某个应用程序，否则这些字节不会被新内容覆盖。

这意味着什么呢？意味着你认为已经删除的信息实际上还保存在硬盘上。如果有人知道怎么读取它们，仍然可以把它们读出来。任何可以不通过文件系统而能够逐块读取硬盘的程序，都可以看到那些被「删除」的内容。

显然，这样有一个潜在的好处。就是在硬盘出问题的情况下，还有可能恢复其中的信息，尽管文件系统可能已经一团糟了。可是不能保证数据真正被删除也有问题。假如你想删除的文件里包含隐私，甚至一些见不得人的东西，你肯定希望它们被删除后永远销声匿迹。对精于此道的坏蛋或者执法机关的专家来说，恢复磁盘中的内容只是小菜一碟。因此，假如你在文件中记录了自己穷凶极恶的想法，或者在妄想症支配下写了很多胡话，那最好使用能够把这些信息从空闲块中彻底擦干净的程序。比如 Mac 中的「安全擦除」选项在释放磁盘块之前，会先用随机生成的比特重写其中的内容。

现实当中的你还应该知道更加保险的做法。因为即使用新信息重写了原有内容，一名训练有素的敌人仍旧可以凭借他掌握的大量资源发现蛛丝马迹。军事级的文件擦除会用随机的 1 和 0 对要释放的块进行多遍重写。更为保险的做法是把整块硬盘放到强磁场里进行消磁。而最保险的做法则是物理上销毁硬盘，这也是保证其中内容彻底销声匿迹的唯一可靠方法。如果你的磁盘一直都在执行自动备份（就像我在上班时使用的计算机一样），或者你的文件保存在网络文件系统中而不是本地硬盘上，那么这些招数恐怕也都不灵光了。

文件夹条目本身也存在类似的问题。删除一个文件时，文件系统会让相应文件夹条目不再指向有效的文件。为此，它可能只会把一个表示「本条目不再使用」的比特位设置为 1。这样在将来需要恢复该文件的原始信息，包括所有未被重新分配的块的内容时，只要把这个比特位重置为 0 就可以了。事实上，1980 年代微软 MS-DOS 中的文件恢复系统采用的就是这种办法。对于待释放的空闲条目，该系统会把相应文件名的第一个字符设置为一个特殊值。这样，如果用户很快又要恢复文件，那么实现起来会简单很多。

知道了文件在被创建人删除后还可能存在很长时间，有助于我们理解一些法律程序，比如当事人坦白和文档保全的意义。在法庭上，这种案例屡见不鲜。有时候，一封陈年邮件就可能影响对被告的量刑，至少会让犯罪嫌疑人的陈述露出马脚。如果这些记录只存在于纸面上，那么徒手将其撕碎就能轻易销毁证据。但数字化记录是会扩散的，还可能通过移动硬盘等媒体藏匿于很多地方。（维基解密 2010 年得到的大批机密外交文件就保存在很多张 CD 中。）明智的人都应该时刻注意自己在邮件里的措辞，甚至应该注意通过计算机发表的任何言论。

刚才我们讨论的是硬盘驱动器（包括移动硬盘）上的常规文件系统。我们大多数的信息都保存在这些硬盘上，而且我们对它们也非常熟悉。不过，这个文件系统也同样适用于其他媒体。例如，已经退出历史舞台的软盘，在逻辑上具有同样的层次结构，但细节上有所不同。CD-ROM 和 DVD 同样以文件系统的方式提供访问界面，同样由不同层次的文件夹和文件组成，只不过一般为只读，不能写。固态硬盘通过闪存来模拟常规硬盘，但重量更轻，耗电更省。

USB 闪存盘和 SD（Secure Digital，安全数字式）闪存卡已经无处不在。把它们插入到一台 Windows 计算机中，它们就会像一块新硬盘一样。通过资源管理器可以查看其中的内容，并像在普通硬盘上一样执行读写操作。唯一的区别就是它们容量小一些，有时候速度可能也慢一些。

如果把它们插到一台 Mac 上，它们同样表现为分层的文件系统，可以通过 Finder 浏览，文件也可以拷来拷去。把它们插到 Unix 或 Linux 计算机上也一样，它们还是表现为文件系统。让这些硬件在不同操作系统中看起来具有同样的文件系统和同样的文件夹/文件结构的是软件。但在内部，文件组织采用的可能是微软的 FAT 系统，其他文件系统也都模仿该系统。但我们不需要去理会这个，这种抽象是非常完美的。（顺便说一句，FAT 是 File Allocation Table 的简写，即「文件分配表」，不是「肥胖」的意思。所以大家可别误以为微软的实现不好。）

值得一提的是，同样的思想也体现在网络文件系统上。在学校和公司里，把文件保存到服务器上是非常常见的做法。借助相应的软件，我们访问其他计算机上的文件系统时，就如同访问本地的硬盘一样。同样只要使用资源管理器、Finder 或者其他软件就可以。远端的文件系统可能与本地相同（比如两台 Windows 计算机），也可能不同（比如其中一台是 Mac 或 Linux 计算机）。但与闪存设备一样，软件把它们的差异隐藏了起来，我们看到的永远是与自己本地计算机中常规文件系统一样的界面。

网络文件系统经常用于备份，当然也可以作为主文件存储系统。必要时，可以把旧文件复制到便于存档的媒体上，保存到其他地方，以免发生火灾等事故时毁坏重要资料。有些磁盘系统会依赖一种叫 RAID（Redundant Array Of Independent Disks，独立磁盘冗余阵列）的技术，把数据和错误校验码分别写到多个磁盘上，以便某个磁盘损坏时能够从其他磁盘恢复数据。当然，这种系统也会增加彻底销毁数据的难度。

「应用程序」是一种统称，表示所有在操作系统平台上完成某种任务的软件或程序。应用程序可大可小，可以只完成特定的任务，也可以囊括大量功能。可以是花钱买的，也可以是免费送的。它的代码可以高度保密，也可以开放源码，甚至没有任何限制。或许可以把应用程序分成两类。一类是小型独立的应用，通常只帮用户做一件事；另一类是大型软件，包含非常多的操作，比如 Word、iTunes 或 Photoshop。

Unix 系统有一个列出目录中文件和文件夹的命令，它是 Windows 资源管理器和 Mac OS X Finder 的纯文本版。对文件执行复制、移动等操作的程序，在 Finder 和资源管理器中也都有对应的图形用户界面版。同样，这些程序也使用系统调用来提供文件夹包含内容的基本信息，也依赖于库函数去读、写、格式化和显示信息。

Word 之类的应用程序比浏览文件系统的程序要大得多。但很明显，Word 一定包含某种类似的文件系统程序，以便用户能够打开文件、读取文件内容和保存文档。Word 也包含非常完善的算法，随着文本变化持续更新显示界面的算法就是一例。它还提供精心设计的用户界面，用于显示信息和让用户调整字号、字体、颜色、布局等的各种选项。对这种程序而言，用户界面是至关重要的一部分。Word 以及其他具有巨大商业价值的大型程序都经历了不断改进和功能完善。我还真不知道 Word 有多少行代码，但要说它有几百万行 C 和 C++ 代码应该一点都不奇怪。

另一个大型、免费，有时候甚至是开源的应用程序是浏览器。从某种角度说，浏览器的复杂度甚至更高。从外部来看，浏览器会向 Web 服务器发送请求，从那里取得信息后再把它们显示出来。那它复杂在哪里呢？

首先，浏览器必须处理异步事件。所谓异步事件，就是在非预定时间发生、没有特定次序的事件。举个例子，你点击一个链接，浏览器就会发送一个对相应页面的请求。但发送完请求后，它不能就那么一直等着。它还得准备响应你的其他操作，比如滚动当前页面，或者在你点击「后退」按钮或另外一个链接时中断之前的请求，不管请求的页面是否已经到达。在你调整窗口大小时，它必须不断更新窗口中的内容，或许就因为你在等待新页面期间没事儿干，于是就会随手来回缩放起窗口来。如果页面中包含音频和视频，那它还要负责控制它们。编写异步系统一直是非常困难的，而浏览器就涉及很多异步操作。

浏览器必须支持很多种内容，包括静态文本和具有互动性的程序（可以动态改变网页中包含的内容）。对某些内容的支持可以委托给辅助程序（这是处理 PDF 文档和电影的标准做法），但浏览器本身必须提供相应的机制，以便启动这些辅助程序，为它们发送和接收数据以及请求，还要控制它们。

浏览器必须管理多个标签页或窗口，每个标签页和窗口都可能需要执行前述操作。它要为每个标签页和窗口单独保留一份历史记录，还要保存书签、收藏夹等数据库。它要支持访问本地文件系统，以便上传和下载文件。

浏览器自身还是一个平台，要提供不同层次的扩展接口。比如，要支持 Flash 和 Silverlight 插件、JavaScript 和 Java 虚拟机，以及 Firefox、Safari 和 Chrome 所支持的那些扩展程序。

浏览器既然包含那么多实现复杂功能的代码，其自身以及它所支持的插件、扩展程序免不了会存在一些漏洞，面临被攻击的风险。另外，一些无知、愚昧，甚至白痴用户，由于不理解浏览器的原理，不知道可能存在的风险，也会导致浏览器遭受攻击。总之，做浏览器开发确实不容易。

如果现在再回头读一读本节内容，你会不会想到些什么？没错，现在的浏览器非常像操作系统。它要管理资源、控制同时发生的活动，它向多个地方请求和保存资源，并且为其他程序运行提供了一个平台。

多年来的实践表明，把浏览器当成操作系统是可行的。换句话说，浏览器本身就是一个独立的系统，与什么操作系统在控制底层硬件无关。大概十几年前，这种想法已经浮出水面，但当时还存在很多实际的困难。今天，这种可能性已经触手可及。大量服务都可以只通过浏览器界面来访问了（邮件是最明显的例子），而这个趋势还在继续。谷歌已经发布了一个浏览器操作系统，叫 Chrome OS。这个操作系统完全依赖于 Web 服务。为此，谷歌还推出了运行 Chrome OS 的计算机 Chromebook。

与计算领域的很多其他东西一样，软件也是分层组织的。类似于地质学中的分层，软件中的不同层次可以隔离不同的关注点。在程序员的世界里，分层是解决复杂问题的一个核心思想。

通俗地讲，计算机的最底层是硬件。硬件，除了总线支持在系统运行期间添加和删除设备之外，其他方面几乎可以看成不可变的。

再往上就是所谓的操作系统层了。为了突出其核心地位，通常把这一层称为内核（kernel）。操作系统介于硬件和应用程序之间。无论底层是什么硬件，操作系统都要负责隐藏其特殊性，向应用程序提供统一的接口或界面，这个接口或界面不因硬件的种种差别而变化。在接口设计得当的情况下，同一个操作系统的接口完全可以适用于众多制造商生产的不同类型的 CPU。

Unix 操作系统的接口就是这样的。Unix 可以在各种处理器之上运行，但在任何处理器上都能提供相同的核心服务。事实上，操作系统就是一种通用的商品，底层的硬件除了价格和性能之外，其他方面都影响不大。而且，上层的软件也不依赖于它。把为一种处理器编写的程序移植到另一种处理器上，无非就是小心谨慎地用合适的编译器再编译一遍而已。当然，程序与硬件结合得越紧密，这种转换工作就越难做。无论如何，这种转换对很多程序来说都是可行的。举个大规模转换的例子，苹果公司在 2005 年到 2006 年，用了不到一年时间，就把它们的软件从 IBM 的 PowerPC 处理器转换到了 Intel 处理器上。

对 Windows 来说，问题就没有那么简单了。从 1978 年的 Intel 8086 CPU 开始，Windows 的开发就与 Intel 架构紧密结合，包括后来 Intel 发布的每一款 CPU。（处理器系列一般称为「x86」，是因为 Intel 的处理器很多年都以「86」这个编号结尾，包括 80286、80386、80486 等。）Windows 与 Intel 的结合是如此紧密，以至于这样的系统一度被世人称作「Wintel」。

操作系统再往上的一层是函数库。函数库提供通用的服务，这样一来，程序员就不必各自重复实现这些功能。有些库比较靠近底层，能够完成一些基本功能（完成数学计算，比如开方和求对数，或者像前面 date 命令一样计算日期和时间）。另外一些库的功能更强大（涉及加密、图形处理、压缩等）。图形用户界面上的组件，包括菜单、按钮、复选框、滚动条、选项卡面板等等，都需要编写很多代码。为此，只要把这些代码封装成函数库，任何人就都可以使用它们，而且还能保证统一的行为和外观。这就是为什么大多数 Windows 应用（至少它们的基本图形组件）看起来那么相似的原因。同样的情况在 Mac 上更是如此。如果所有软件开发商都重新发明、重新实现这些功能，那不仅会浪费大量资源，而且五花八门的界面也会让用户感到无所适从。

如前所述，典型的应用程序会使用函数库和操作系统服务，把它们集成到一起实现某种功能。不过，库函数与系统调用之间的区别并不十分明显。某个特定的服务可以作为系统调用实现，也可以借助使用了系统调用的库函数来实现。

1『一层层的抽象：硬件 → 操作系统 → 函数库 → 应用程序。』

有时候，内核、函数库和应用程序之间并不像我说的那么泾渭分明。毕竟，编写及连接软件组件的方式多种多样。例如，内核可以提供少量服务，而依赖上层的库来完成大部分工作。或者，它也可以自己承担大部分任务，而较少地依赖于库。操作系统与应用程序之间并没有清晰的界限。

那该如何区分它们呢？一个简单（但可能不够完美）的方法，就是把任何确保 A 应用程序不会干扰 B 应用程序的代码看成是操作系统的职能。比如，内存管理、文件系统、设备管理和 CPU 管理，这些都是操作系统的职能。内存管理需要决定在程序运行的时候把它们放到内存的什么位置，文件系统需要决定把信息保存到磁盘上的什么位置，设备管理需要确保两个应用程序不会同时占用打印机，也不能在没有协商的情况下就向显示器输出内容。最核心的还是 CPU 管理，因为这是操作系统履行前述各项职能的前提条件。

浏览器不属于操作系统，因为你可以运行任意浏览器，甚至同时运行多个浏览器，都不会干扰共享资源或者控制流程。听起来好像是可以做到泾渭分明似的，但要是较起真来，比如打起官司来，那可就难说了。美国司法部从 1994 年开始（到 2011 年结束的）对微软的反垄断诉讼，就涉及微软的 Internet Explorer 浏览器到底是操作系统的一部分，还是一个独立应用程序的问题。如果浏览器是操作系统的一部分（按照微软的主张），那么要求微软删除 IE 就是不合理的，而微软要求用户使用 IE 的做法就是正当的。如果浏览器是一个独立的应用程序，那么微软就涉嫌以非法手段强迫用户在非必要情况下使用 IE。当然，这个官司本身要复杂得多，但如何界定浏览器的归属问题确实非常重要。最终诉讼的结果是，法院认定浏览器是一个独立的应用程序，不属于操作系统。用法官托马斯·杰克逊（Thomas Jackson）的话说：「Web 浏览器和操作系统是相互独立的产品。」

## 0204. 学习编程

很早以前，我用过微软的 Visual Basic。它既是一门语言，也是一个编程环境。通过它可以方便地写出看起来很专业的 Windows 应用程序。而且，微软的 Office 办公套件以及很多其他办公软件里也都内置了某种 VB 的简化版。因此，会用 VB 就可以在日常工作中增强或更好地控制 Word 和 Excel（当然，弄不好也会为病毒入侵打开便利之门）。可惜 Visual Basic 已经不再是最好的选择了。尽管微软提供的免费版几乎没有删减任何功能，但比起十几年前，这门语言及其体系实在复杂得太多了。更重要的是，VB 只能在 Windows 系统上运行。而我需要找一个随便在什么平台上都能跑的语言。

为此，我选择了 JavaScript，因为它具有如下优点。首先，它无处不在，所有浏览器都支持它。几乎每一个网页多多少少都有 JavaScript 程序，而且其代码也很容易向别人展示。要是你用它写了一个程序，把它放在自己的网页里就能博得朋友和家人的赞美。其次，这门语言本身比较简单，对学习者的要求很低。当然，这并不意味着它能力弱。事实上，JavaScript 非常强大，可以完成极为复杂的计算任务。很多网页特效的背后都是 JavaScript，包括谷歌的在线办公程序 Google Docs 和其他类似的应用。最后，Twitter、Facebook、Amazon 等等这些世界级的大网站都提供了 JavaScript 的 API。

JavaScript 当然也有缺点。不同浏览器中的 JavaScript 实现并不像我们想象的那样完全一致。换句话说，在一个浏览器中能运行的程序，换一个浏览器可能就运行得不正常。但就本章的学习目标而言，这根本不是问题。做专业开发的前端工程师都有办法解决这个问题。另外，这门语言的某些特性不太好理解，有时候会显得比较怪异。JavaScript 程序通常只能在网页中运行，很少能独立存在。不过也有一些软件支持 JavaScript 程序，比如 Adobe 的 PDF 阅读器。由于它委身于浏览器，因此要学它，一般都得同时学一点 HTML（HTML 是一种描述网页结构的标记语言）。尽管存在这些缺点，JavaScript 仍然非常值得学习。

编程语言的某些基本概念是相通的，因为这些概念都是为了表达一系列计算步骤而发明的。任何编程语言都会提供一些手段，用于取得赖以完成计算的输入数据、进行算术计算、在计算期间存储和获取中间值并显示结果、根据之前的计算结果决定下一个计算步骤，以及在计算完成时保存结果。

是语言就有语法，而语法就是一系列规则，根据它们可以判断什么符合语法，什么不符合语法。编程语言对语法规则是锱铢必较的，哪怕有一点点地方违反语法，它都会提出抗议。语言还要有语义，语义规定了语言中所有元素的含义。

2『上面有关编程语言的基本概念做一张信息卡片。 —— 已归档「2020普通卡片06」』

理论上讲，一段程序的语法是否正确，以及语法正确的情况下其含义是什么，这些都不应该有歧义。但实际上，就像用自然语言写文章一样，任何歧义都没有的理想状态有时候很难达到。语言的最基本单位通常是字和词，这些字和词本身可能就有歧义，而对它们的不同理解更是司空见惯。因此，实现这些语言规则的时候可能就会有偏差。另外，语言本身也会与时俱进。综上所述，不同浏览器对 JavaScript 的实现多多少少都会存在差异。实际上，即使是同一款浏览器的不同版本，对 JavaScript 的实现也有差异。

JavaScript 这门语言实际上包含三个方面。第一是语言本身，包括让计算机完成算术计算的语句、测试条件，以及重复计算的规则等。第二是 JavaScript 代码库，也就是由别人写好的程序段，你可以在自己的程序里直接使用，而不必再花时间重写。比如数学函数、计算日历的函数，以及搜索和操作文本的函数。第三是访问浏览器和网页的接口，JavaScript 程序通过这些接口可以在其所在的网页中获得用户输入、响应用户动作（如单击按钮或填写表单）、让浏览器显示不同的内容或者切换到其他网页。

1『 JavaScript 的三个核心要点：语言本身、代码库和浏览器接口。』

这个程序的 alert 函数来自辅助与浏览器交互的 JavaScript 库，调用它会弹出一个对话框，对话框将显示位于引号中的文本。顺便说一句，你在写 JavaScript 程序时，必须使用标准的双引号（"），不要使用所谓的「智能引号」（本书后面会介绍）。这也是讲究语法规则的一个例子。另外，也不要使用 Word 等文字处理程序来生成 HTML 文件，而应该使用记事本或 TextEdit 这样的文本编辑器。在保存程序文件时，要把它保存成扩展名为 .html 的纯文本文件（也就是没有任何格式信息的文件）。

这个程序涉及几个新元素和新概念。首先，单词 var 添加或者说声明了一个变量。变量是 RAM 中的一个位置，可以让程序在运行期间存储数据。之所以称它为变量，是因为它的值会随着程序的执行而变化。在高级语言里，声明变量就相当于我们在玩具汇编语言中为一个内存位置起一个名字。打个比方，声明就好比一出戏里的演员表。在这里，我们把这个变量叫做 username。当然也可以给它起别的名字，但 username 让人一看就知道它在程序中扮演什么角色。

其次，这个程序使用了一个 JavaScript 库函数 prompt。prompt 与 alert 类似，都会弹出一个对话框。但不同的是，prompt 能收集用户的输入。用户在对话框中输入的任何内容都会成为 prompt 函数中可以使用的值。这个值通过下面这行代码被赋给了变量 username：

这里等号 = 的意思是：「完成右边的计算，把计算结果保存在左边的变量里。」这个等号也是语义的一个例子。等号执行的操作叫赋值。大多数编程语言都使用等号来表示赋值，而没有顾及等号在数学中表示相等的含义。换句话说，这里的 = 不表示相等，而表示复制值。

再提醒一下，这个程序会不断读取用户输入，而在用户输入「0」的时候，会弹出对话框显示之前输入的所有数值之和。这个程序里的一些特性前面刚刚介绍过，比如声明、赋值，还有 prompt 函数。其中第一行代码声明了两个后面会用到的变量 num 和 sum。第二行代码是一个赋值语句，把变量 sum 的值设为 0。第三行代码把变量 num 的值设为用户在对话框中输入的值。

这里真正值得讲的是 while 循环。计算机最擅长一遍又一遍地反复执行一系列指令，而程序员需要想清楚的则是如何通过编程语言来表达这种反复。在玩具语言里，我们添加了 GOTO 指令，用于跳转到程序中的另一个位置，而不是顺序执行下一条指令。还添加了 IFZERO 指令，用于测试一个条件并根据累加器的值决定是否跳转。

这些概念在大多数高级语言里都有，而且被抽象为一个叫做 while 循环的语句。这个循环语句在反复执行一系列指令时更有规律性，也更加有条理。这个程序里的 while 测试了（写在括号中的）一个条件，如果条件为真，则执行花括号 {...} 中所有语句。然后返回，再次测试同一个条件。这个循环一直反复，直至条件为假。此时，接着执行紧跟在右花括号后面的语句。

我并没有明确指定这个示例程序中数据的类型。但在内部，计算机会帮我们明确区分 123 这样的数值和 Hello 这样的任意字符串。有些语言要求程序员自己谨慎地表达这种区别，另一些语言则试图猜测程序员的意图。JavaScript 差不多就属于后一类，因此有时候明确知道数据类型以及如何处理相应的值是十分必要的。比如 parseInt 函数吧，它可以把文本内容转换成数值，也就是说它的输入数据可以被当成（123 这样的）整数而非三个十进制数字来看待。如果不用 parseInt，那么 prompt 返回的数据就会被当成文本，而 + 运算符就会把它追加到之前的文本后面。结果将是把用户输入的所有数字逐个拼接起来。这听起来似乎还挺有意思，但却不是我们想要的。

接下来的这个例子要完成的任务有点不一样，它要从输入的所有数值中找出最大的一个。而这也正是添加另一个控制流语句 if-else 的原因。所有高级语言都有这个语句（可能形式上稍有差异），用于条件判断。实际上，if-else 就是 IFZERO 的通用版本。JavaScript 中的 if-else 语句跟 C 中的一样。

if-else 语句有两种表现形式。一种就是这里所展示的这样，没有 else 子句。此时，只要括号中的条件为真，那么就会执行后面括号 {...} 中的语句。但不管怎样，都会执行紧跟在右花括号后面的语句。另一种形式就是还有一个 else 子句，它也带有一组语句，会在条件为假时执行。无论条件真假，整个 if-else 语句块后面的语句都会执行。

可能你也注意到了，这个示例程序是通过缩进来表示结构的：while 和 if 语句都缩进了。这是一种标准（值得提倡）的做法，能让人一眼就看出 while 和 if 语句都控制着哪些语句。甚至还有一些编程语言要求遵循一致的缩进规则。

把这段程序放到一个网页里就可以测试了。但专业的程序员不必把它放到网页里也能模拟其行为。他们会像计算机一样，认真地推敲每一条语句。如果你也能做到这样（这是确保理解程序的好办法），就可以推断出输入任意值程序都能得出正确的结果。

真的吗？如果输入中包含正数那没问题，但要是输入的都是负数呢？你会发现程序始终会说最大的数是零。

想一想这是为什么。这个程序把到目前为止发现的最大值保存在变量 max 中（就像找出房间里个子最高的人一样）。为了跟后续的数值进行比较，这个变量必须有一个初始值，因此程序一开始（在用户提供任何值之前）就把它设为零。要是用户真的输入了一个大于零的值固然好，就像输入身高一样。可要是用户输入的都是负值（在录入信用卡账单时有这种可能），程序不会输出最大的负值，而是会输出那个终止输入的值。

通过这个例子还可以学到编程的另一个重要方面：测试。测试远不止是随机地向程序抛出几个数值那么简单。好的测试人员会绞尽脑汁地想象程序会在什么情况下出错，想象那些「边缘」或「边界」情形，比如根本没有数据或者被零除。好的测试人员会想到输入都是负值的可能性。但问题是，随着程序越写越大，想象出所有测试用例的难度也越来越大，因为用户可能会以任意次序、在任意时间输入任意值。没有完美的解决方案，这时候认真地设计和实现程序就显得很关键。比如从一开始就在程序里添加检测和比较代码，以便在出现问题时，程序自己就可以第一时间捕获。

1『又见测试的重要性。但到目前为止自己对「测试」还是没有一个系统的了解以及去重视的觉悟，这块短板一定要补上。（2020-01-05）补充：这块目前已经补上了，习惯性的昨晚开发就把单元测试做掉了。（2021-08-26）』

JavaScript 作为一种扩展机制在高级 Web 应用中扮演着十分重要的角色。Google Maps 就是一个典型的例子，它提供了一个库和一套 API，于是所有地图操作就可以通过 JavaScript 程序（而不仅仅是鼠标点击）来控制了。任何人都可以编写自己的 JavaScript 程序在谷歌提供的地图上显示信息。这套 API 使用起来很方便，比如下面这段代码（当然还得有几行 HTML）。

1『 Chrome 里打开内置编译器的快捷键是「option+command+I」。』

第 11 章还会向大家证明，互联网应用发展的趋势是 JavaScript 应用会越来越多，包括地图这种可以编程控制的接口。在被迫公开源代码的环境下，要保护知识产权很难。如果你在使用 JavaScript 编程，就必须自己想办法。任何人都可以通过在网页上单击右键并选择「查看源代码」看到你的源代码。有些 JavaScript 程序经过了混淆处理，可能是开发者有意为之，也可能是为了加快下载速度而被「瘦身」的结果。经过混淆的程序已经非常难破译了，除非碰上那些顽固的死磕分子。

大家回忆一下第 3 章关于编译器、汇编器和机器指令的内容。JavaScript 程序会以同样的方式被转换成可以执行的形式，但细节方面却有着明显差异。浏览器在遇到网页中的 JavaScript 代码时（比如解析到 `<script>` 标签时），就会把代码文本移交给 JavaScript 编译器 —— 通常是一个独立的程序或者是浏览器的一个库。编译器处理程序、检测错误，然后将其编译为与「玩具」类似的一个假想机器的汇编语言指令。当然，这套指令系统包含的指令要多得多，而实际上它正是我们上一章讲过的一种虚拟机。这个虚拟机接着会像玩具模拟器一样也运行一个模拟器，执行 JavaScript 程序设定的指令。模拟器与浏览器保持着密切交互，比如用户单击按钮，浏览器马上就会通知模拟器哪个按钮被单击了。在模拟器希望做点什么的时候，比如弹出一个对话框，它就会调用 alert 或 prompt 让浏览器照着去做。