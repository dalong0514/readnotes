## 记忆时间

## 目录

0301网络

0302互联网

0303万维网

0304数据、信息和隐私

## 0300. 通信

在我们这个「三足鼎立」的世界里，通信是除硬件、软件之外的第三极。无论从哪方面看，通信才是真正让一切变得有意思的东西（也可理解为「有了通信，这个时代才有意思」）。有了通信，计算机与计算机之间才能对话。这种对话通常都是为我们服务的，但有时候也会为图谋不轨之人提供便利。今天的大多数系统都集硬件、软件和通信于一身，可以说是三位一体。换句话说，本书前面介绍的内容也是不可或缺的。通信也是很多社会问题的根源，它诱发了难解的隐私和安全问题，导致了个人、企业和政府之间的权利之争。

简略回顾一下通信的历史背景，讲一讲网络技术。我们会介绍因特网，这个网络的网络承载着全世界计算机与计算机之间相当可观的通信量。接着就是万维网，即 Web（World Wide Web 的简称）。Web 诞生于 1990 年代中期，它把少数人独享的因特网变成了我们每个人每日的必需品。之后，我们会提到因特网的应用，比如电子邮件、电子商务和社交网络，以及相应的威胁和对策。

现代通信系统中的关键问题甚至早在 1790 年代就被注意到了。最重要的，必须有一套共同遵守的协议来表示、交换信息以及检测和排除错误。而且，尽管当时横跨法国发送一条消息只要几个小时，但是想以最快的速度发送信息始终都是个核心问题。另外，安全和隐私问题也出现了。

视觉发报系统有一个致命的问题，就是只能在视线良好的情况下发报，夜晚或恶劣的天气条件下都不能发报。1830 年代，萨缪尔·摩尔斯发明了电报。1840 年代，电报系统在不到十年时间就取代了视觉发报系统。不久，商业电报服务遍及美国各大城市（第一条电报线路 1844 年架设在巴尔的摩和华盛顿之间）。1858 年，第一条穿越大西洋的电报线缆铺设完工。电报系统也让当时的人们经历了从希望到渴望再到失望的过程，就如同后来因特网早期繁荣和 1990 年代后期泡沫破裂一样。财富得而复失，欺诈随处可见。乐观主义者预言世界和平和相互谅解的日子为期不远，而现实的人则认识到尽管情节不同，但历史将再次重演。「这一次不一样」的说法几乎就没有兑现过。

1876 年，亚历山大·格雷厄姆·贝尔（Alexander Graham Bell）就他发明的电话，以先申报几个小时的优势打败伊莱沙·格雷 （Elisha Gray）获得美国专利局的专利。尽管事实真相到现在依旧扑朔迷离，但电话在接下来百年的发展，确确实实让人类的沟通和通信有了翻天覆地的变化（当然，同样没有导致世界和平和相互谅解）。电话让人们无需专业知识即可直接通话，而电话公司制定的标准和达成的协议也让世界上几乎任何两部电话之间都能传递语音。

电话的优势在于支持较长时间的稳定通话，但它只能传送语音。一般来说，通话交谈的时间会持续三分钟左右，因此在建立连接上花几秒钟时间不是问题。电话号码是独一无二的一串数字，明确指示地理位置。而用户操作界面则非常简洁，就是一个纯黑色的电话机上面带一个旋转拨号盘（这种电话机现在已非常少见，唯一遗留下来的只剩「拨电话」时的回铃音了）。电话系统的全部智能都在电话网上，用户所要做的只是接听电话、拨打电话，或者让人工接线员帮忙转接。

对于电话系统来说，20 世纪的后 25 年是一个快速变化的时期，包括技术、社会和政府政策。1980 年代，传真机的普及让通信方式发生了改变，计算机之间直接通信也变得越来越常见。当时使用的是可以把比特转换成声音（或相反）的调制解调器，俗称「猫」。这种通信方式与传真机的原理相同，都是基于模拟电话网络利用音频来传输数字化的信息。技术的发展让发起呼叫的时间变短了，让能发送的信息量变大了（借助铺设于国内甚至跨越大洋的光纤网络），而且能够将一切都数字化。手机则更为彻底地改变了人们的通信方式，以至于今天的世界完全成了手机的天下。经营有线电话线路的公司每况愈下，后起之秀则层出不穷，各领风骚。

世界范围内的政府政策也发生了巨大变化，曾经是高度管制的行业如今不再受管制。以往，在美国 AT&T 一家独大，其他国家则多由政府部门垄断。现在则实现了开放性的竞争。在美国，AT&T 经历了几次拆分。先是 1984 年被分成长途电话与制造业务（AT&T）和本地电话服务（贝尔电话公司）。之后是 1995 年，新的 AT&T 又自行分为长途通信服务（AT&T）和制造（朗讯）两家公司。AT&T 可谓虎落平阳，最终被它自己在 1984 年分拆出的一家运营商西南贝尔收购。2006 年，朗讯与法国电话设备公司阿尔卡特合并。

今天，传统电话公司仍然在与新兴通信系统殊死搏斗。在这些依托互联网的新兴竞争对手挤压下，他们的收入和市场份额与日俱减。最主要的威胁来自互联网电话，通过互联网发送数字语音是一件轻而易举的事。Skype 之类的服务则更进一步，不仅支持计算机之间的免费通话，而且通过互联网拨打传统电话的收费也不高，至少比现有电话公司的收费便宜得多，尤其是国际通话更加明显。谷歌的服务甚至比这还要便宜（目前在美国和加拿大都免费了），所以说传统电话公司无论如何都在劫难逃。

传统电话公司自然不甘败落，他们正使出浑身解数来保护自己的收入，通过技术、法律，甚至政治手段来维护现有的垄断地位。比如，竞争对手要使用你们家的电话线就必须向电话公司付费。这还说得过去，毕竟线路是电话公司铺设到你们家的，人家通过使用费回收成本理所应当。再比如，对于竞争对手通过互联网提供的电话服务（VoIP，即 Voice over IP）或其他竞争性服务，采取限制带宽或其他降速手段。这就不太合理了。

这里涉及一个所谓的网络中立（net neutrality）的问题了。除了为确保网络正常运行所要采取的纯技术手段之外，服务提供商有权干扰、限制或者屏蔽网络通信吗？是应该要求电话和有线电视公司也向所有用户提供同样的互联网服务，还是应该允许他们把服务和用户区别开来对待？如果可以区别对待，那依据又是什么？比如说，电话公司有没有权利限制或屏蔽来自其竞争对手（比如 VoIP 公司 Vonage）的流量？有线电视公司有没有权利降低 Netflix 等互联网视频公司的网速？服务提供商有没有权利限制或屏蔽与自己的社会主张或政治主张不同的网站？同样，这些问题大家众说纷纭。对网络中立问题的看法将从根本上影响互联网未来的发展。而互联网一直以来最得益于（也让我们受益于）其作为一个中立平台的角色，对所有通信都一视同仁，既不干涉，也不限制。

## 0301. 网络

频段是无线联网系统的关键资源，人们对它的需求远远得不到满足。很多政治和经济组织都在激烈争夺频段空间。与此同时，广播公司和电话公司等既得利益集团则在抗拒变化。一种解决方案是有效地利用现有频段。手机通信最早使用的模拟编码技术已被淘汰，当前使用的是更节省带宽的数字系统。现有频段也可能会改换用途，比如 2009 年美国有线电视网经过数字化改造释放出一大块频段空间，成为很多梦寐以求者竞相争夺的目标。当然还可以使用更高的频率，但频率越高覆盖范围越小。

无线网络是广播媒体，任何人都可以监听。加密是保护无线信息和控制访问的唯一途径。事实证明，最初针对 802.11 网络的无线加密标准（WEP，即 Wired Equivalent Privacy，有线等效保密）存在重大缺陷。后来出现的 WPA（Wi-Fi Protected Access，受保护的 Wi-Fi 接入）等加密标准则要安全得多。有些人的无线网络还是开放的，即没有采取任何加密措施。这样一来，附近的任何人不仅可以监听，还能免费使用其无线服务。「沿街扫描」（war driving）指的是驾车寻找那些有开放网络的地方，享用免费服务。有趣的是，与几年前相比，现在的开放网络似乎少多了，或许是人们已经意识到被窃听和搭便车的风险。

咖啡店、机场等场所的免费 Wi-Fi 服务反而越来越多。咖啡店希望顾客能在自家门店里使用笔记本来消磨时间（顺便也消费几杯昂贵的咖啡）。要是不加密的话，在这些网络上传输的信息也将是公开的，并非所有服务器都会自动加密。当然，知道了有 Firesheep 这种软件存在，那最好就不要使用公共网络发送敏感信息了。

尽管存在这样那样的问题，但无线仍然是未来互联网的趋势。与此同时，有线连接必定也是互联网不可或缺的后台支撑。

这一章，我们介绍几种家庭、办公室或者宿舍里常见的联网技术。我们正是通过这些局域网与互联网连接起来的。所有通信系统都有一些共性。从最根本处说，它们都是把信息转换成物理表现形式，以便通过某种媒介传输。而在传输目的地，它们再把这些物理形式转换回人们能够理解的形式。

带宽是最基本的一个特性，它描述的是系统传输数据的速度。在供电条件不好、环境很差的情况下，某些系统的带宽可能只有每秒几比特。而与之形成鲜明对比的，则是带宽高达每秒数万亿比特的光纤网络；等待或延迟衡量的是特定信息块通过系统所需要的时间，用卡车满载硬盘穿越整个国家，带宽显然是巨大的，但延迟也是极高的；抖动，即延迟的可变性，对某些通信系统（特别是语音通信），同样也很重要；信程指的是某种技术能够在多大地理范围内实现联网。有些网络的范围不过数米，有些网络则可以覆盖全球。

还有一些特性表明发送端口是会向所有接收端口都发送广播消息（跟收音机原理相同），还是会点到点地传输，或者只能在特殊的发送方和接收方之间通信。广播网络固有的问题就是容易被监听，因而遭遇攻击的可能性大，存在安全隐患。为此，必须采取预防措施，以备不测。当然，成本也是要考虑的一个主要因素。

电话网作为一个覆盖全球的大型网络，从一开始只传送语音，到后来同时传输语音和可观的数据，为人类做出了贡献。大约有近 20 年的时间，人们都是通过电话网把家用计算机接入互联网的。

在家庭中，电话系统传送模拟的声音信号，不传输数据。因此，必须有一种设备来实现数字化信息（比特）和模拟的声音之间的转换，才能利用电话网络传输数据。改变要通过声音信号传输的信息的形式叫调制。相反，把这种形式再转换成比特叫解调。而能够完成调制和解调功能的设备就叫调制解调器（modem）。过去的电话调制解调器是一个价格不菲的大型机柜，后来逐步缩小为一个小芯片，成本也极其低廉。不过，通过有线电话上网的方式在今天已经不常见了，因此配备调制解调器的计算机也越来越少。

3『

[什么是模拟信号？数字信号？区别是什么？它们又是如何完成转换的？ - YouTube](https://www.youtube.com/watch?v=IEPXTHNXoBc)

[芯片内部是如何实现加法运算的？模拟信号和数字信号有什么区别？李永乐老师讲解门电路（2018最新） - YouTube](https://www.youtube.com/watch?v=pUwYvJtfbsY)

[傅立叶变换如何理解？美颜和变声都是什么原理？李永乐老师告诉你 - YouTube](https://www.youtube.com/watch?v=0LuyxzqI3Hk)

[模拟信号 - 维基百科，自由的百科全书](https://zh.wikipedia.org/wiki/%E6%A8%A1%E6%93%AC%E4%BF%A1%E8%99%9F)

模拟信号（英语：Analog Signal）是指在时域上数学形式为连续函数的信号。与模拟信号对应的是数字信号，后者采取分立的逻辑值，而前者可以获取连续值。模拟信号利用对象的一些物理属性来表达、传递信息。例如，非液体气压表利用指针螺旋位置来表达压力信息。在电学中，电压是模拟信号最普遍的物理介质，除此之外，频率、电流和电荷也可以被用来表达模拟信号。

任何的信息都可以用模拟信号来表达。这里的信号常常指物理现象中被测量对变化的响应，例如声音、光、温度、位移、压力，这些物理量可以使用传感器测量。模拟信号中，不同的时间点位置的信号值可以是连续变化的；而对于数字信号，不同时间点的信号值总是处于预先设置的离散点，因此如果物理量的真实值不能在这些默认值中被找到，那么这时数字信号就与真实值存在一定的偏差。

理论上，模拟信号的分辨率趋近无穷大。不过在实际情况中，模拟信号的分辨率常常会受噪声和信号摆率（Slew Rate）的限制。因此，现实中的模拟信号和数字信号的分辨率和带宽都有一定的限制。在一些非常复杂的模拟系统中，诸如非线性问题和噪声等效应会降低模拟信号的分辨率，以至于此时它的分辨率甚至低于特定的数字信号系统。类似的，当数字系统变得复杂时，数字数据流里会产生错误。在实际的系统中，往往需要综合应用两种形式的信号，从而使的系统获得最好的工作性能。

模拟信号的主要优点是其精确的分辨率，在理想情况下，它具有无穷大的分辨率。[1] 与数字信号相比，模拟信号的信息密度更高。[2] 由于不存在量化误差，它可以对自然界物理量的真实值进行尽可能逼近的描述。模拟信号的另一个优点是，当达到相同的效果，模拟信号处理比数字信号处理更简单。模拟信号的处理可以直接通过模拟电路组件（例如运算放大器等）实现，[3] 而数字信号处理往往涉及复杂的算法，甚至需要专门的数字信号处理器。

模拟信号的主要缺点是它总是受到噪声（信号中不希望得到的随机变化值）的影响。信号被多次复制，或进行长距离传输之后，这些随机噪声的影响可能会变得十分显著。在电学里，使用接地屏蔽（Shield）、线路良好接触、使用同轴电缆或双绞线，可以在一定程度上缓解这些负面效应。[4] 噪声效应会使信号产生有损。有损后的模拟信号几乎不可能再次被还原，因为对所需信号的放大会同时对噪声信号进行放大。如果噪声频率与所需信号的频率差距较大，可以通过引入电子滤波器，[5] 过滤掉特定频率的噪声，但是这一方案只能尽可能地降低噪声的影响。因此，在噪声在作用下，虽然模拟信号理论上具有无穷分辨率，但并不一定比数字信号更加精确。尽管数字信号处理算法相对复杂，但是现有的数字信号处理器可以快速地完成这一项任务。[6] 另外，电脑等系统的逐渐普及，使得数字信号的传播和处理都变得更加方便。诸如照相机等设备都逐渐实现数字化，尽管它们最初必须以模拟信号的形式接收真实物理量的信息，最后都会通过模拟数字转换器转换为数字信号，以方便电脑进行处理，或通过互联网进行传输。

利用信号的调变技术，可以将信号转换成所需要的不同性质的模拟信号。例如，可以对正弦载波进行调幅、调频来达到特殊的工作目的。

』

使用电话网络传输数据有很多缺点。因为要占用电话线路，所以假如你家里只有一根电话线，那你在上网的同时就不能打电话。不过，对多数人来说，最大的问题还是通过电话线传输数据非常慢。最大带宽不过 56 Kbit/s（即每秒 56 千比特每秒，这里小写的字母 b 代表 bit，一般用大写字母 B 表示 byte），或 6~7 KB/s。那么下载一个 20 KB 的网页，得花 3 秒钟，要是 400 KB 的图片呢，差不多要 60 秒。赶上升级软件，轻而易举就得花几个小时。总之，速度太慢。在普遍使用调制解调器上网的年代，大部分时间内的「长途拨号」（实际上也远不到哪儿去）费用也是相当昂贵的。AOL 等提供拨号上网服务的公司，必须提供一系列的市话号码供用户选择，才能让用户免交长途费。即便如此，电话公司也不情愿，因为用户上网占用线路的时间通常都比打电话长，而这些时间又不会产生额外的收入。如前所述，电话网络是为 3 分钟左右的语音通话而非几个小时的数据通信设计的，因此市话一直都按固定标准收费。

电话线传输信号的速度限制是与生俱来的。因为电话只需传输语音，所以有 3 kHz 的带宽就够了。即使再怎么编码、压缩，或者想其他办法，最终都不可能让速度超过 56 Kbit/s。为此很多人选择了另外两种上网方式，带宽至少是电话线的 10 倍。

首先是使用千家万户都安装的有线电视电缆。这种电缆可以同时传输数百个频道的信号，因此有足够的剩余容量让家庭用户来回传送数据。通常的有线电视网的传输速度都以 Mbit/s 计。来回转换有线信号与比特数据的设备叫有线调制解调器。这个名字显然是因为它与电话调制解调器功能相近，当然其速度快多了。

这里所谓的速度快，某种意义上是一种错觉。无论你看不看电视，同样的电视信号都会广播到千家万户。另一方面，虽然大家共享有线电缆，但进入我家的数据就是我的，它不会同时进入你家成为你的数据。换句话说，用户之间没办法共享内容。而数据带宽必须由有线数据的用户共享，如果我用多了，那留给你的就少了。更可能的情况是我们两家的带宽都会变少。值得庆幸的是，我们相互之间倒是不会干扰。通过有线电缆共享上网与航空公司或者酒店有意安排的超额预订非常相似。他们知道预订的人不会全都如约而至，因此超额出售不会出问题。这种策略也同样适用于通信系统。

说到这，又出现了另一个问题。虽然我们实际上都在接收相同的电视信号，但我不希望自己的数据跑到你家去，而你也不希望你的数据跑到我家来。毕竟，这些数据都是个人隐私，比如电子邮件、在线购物订单、银行卡信息，甚至包括自己绝不想让任何人知道的娱乐癖好。这个问题可以通过加密解决，加密可以防止他人偷看我收到或发出的数据。关于加密的话题，我们将在第 10 章讨论。

这里还有一个小插曲。最早的有线网络是单向传输的，即信号会广播到所有家庭。这种网络容易铺设，但用户却不能向有线公司发送信息。有线公司必须解决这个问题，因为视频点播收费和其他服务需要从用户那里接收信息。于是有线网络就变成了双向的，这就为利用有线网络来实现计算机之间的数据通信提供了条件。有时候，「双向通信」会分别使用不同的通道。比如，某些卫星电视系统使用电话线作为上传通道。虽然上网速度慢得让人无法接受，但对于下订单购买电影来说是够用了。而且，上传速度大大低于下载速度也是惯例，所以我们上传图片和视频才会那么慢。

另一种对家庭来说经济适用的联网技术是 DSL（Digital Subscriber Loop，数字用户环路），有时候也叫 ADSL（其中 A 代表 asymmetric，意为「非对称」，因为下载带宽比上传带宽高）。DSL 利用的也是家庭中原有的基础设施 —— 电话线路，而且提供的服务与有线电缆上网相同。但 DSL 与有线电缆相比还是有几个主要的区别。

DSL 在使用电话线发送数据时不会干扰语音信号，这种技术可以让用户打电话和上网冲浪两不误。但 DSL 有距离限制，一般城市或郊区的居民，房子距离本地电话公司的交换机房不超过 5 公里，可以使用 DSL。如果超过这个距离，就没办法用了。

DSL 的另一个优点是非共享。因为它使用电话线，而且也没有其他数据传输服务会同时占线，所以你不会跟自己的邻居共享带宽，你的数据也不会发送到他们家去。DSL 同样需要一个调制解调器，再配合电话公司机房里对应的设备，才能把信号调制成适合在电话线上传输的形式。除此之外，DSL 和有线电缆再没有什么分别了。而且它们的收费标准也差不多，尤其在二者有市场竞争的地区。

这些系统的容量由硬件决定，到了一定的限度之后，再为用户提供更大的容量就不必再购置新设备或增加新投入了。为此，供应商可以玩一个很讨巧的游戏，他答应你只要多掏钱就可以享用更高的带宽。而实际上，他收了钱之后，什么设备也不用添置，只消改动数据库里的一个字段，把你的带宽设置加大就行了。

这种系统都有这个共同的特点，即任何时候都有可用的资源。你想打电话就打电话，想上网就上网。

在技术不断进步的今天，很多地方已经实现了光纤入户，告别了同轴电缆和铜线上网时代。与同类技术相比，光纤传输数据的速度要快得多。光纤中的信号是以光脉冲形式传输的，传输通道是一条极细又极纯净的玻璃纤维，损耗很低。光纤信号在没有中继器的条件下可以传输数公里远。1990 年代早期，我参加了一个「光纤入户」的试验性研究项目，因此我家有 10 年时间在使用（据说是）160 Mbit/s 的光纤上网。虽然我因此有了雄厚的吹牛资本，但可惜如此之高的带宽在当时却没有什么用武之地。

电话、有线电缆和 DSL 等联网技术都可以把计算机连接到一个大型系统，但通常会有一定的距离限制。回顾历史，另外一个网络发展的分支 —— 以太网，最终成为了今天最常用的系统。

怎么把所有阿尔托连到一起共享资源（比如打印机）就成了一个问题。而解决方案就是 1970 年代早期由鲍伯·梅特卡夫（Bob Metcalfe）和大卫·博格斯（David Boggs）发明的一种联网技术，叫做以太网（Ethernet）。以太网可以在通过同轴电缆相连的计算机之间传送信号。从外观上看，当时的同轴电缆与今天的有线电视使用的同轴电缆很相近。而信号则是基于强度和极性编码比特值的脉冲电压。最简单的情况就是用正电压表示比特 1，用负电压表示比特 0。每台计算机都通过一个设备连接到以太网，而且各有一个独一无二的数字标识符。某台计算机要向另一台计算机发送消息时，它会先通过监听信号来确定没有其他计算机正在向同一台计算机发送消息。然后，它把消息加上接收方的数字标识符广播到电缆中。电缆上连接的所有计算机都可以监听到这条消息，但只有指定的那台计算机才会读取和处理该消息。

每台以太网设备都有一个 48 位的数字标识符，这个标识符独一无二，叫做（以太网）地址。因此，以太网最多可以连接 2^48（约为 2.8×10^14）个设备。你的计算机也有以太网地址，这些地址通常会印刷在机器底部。当然，在 Windows 中使用 ipconfig，在 Mac 上使用 ifconfig 也可以显示这些地址。而且经常会有两个地址，一个是有线网卡地址，一个是无线网卡地址。以太网地址都是以十六进制数字表示的，而且两位数字表示一个字节，因此总共是 12 位十六进制数字。比如，我的笔记本电脑的以太网地址就是 00096BD0E705，这肯定跟你计算机的地址不一样。

了解了前面讨论的有线网络，也就不难想象以太网也存在同样的两个问题：隐私和资源争用。

资源争用可以借助一个很巧妙的办法来处理：如果某个网络接口在发消息时检测到其他接口正在发，它会先停下来，等一小会儿，然后再发。如果等待时间是随机的，而且会随着尝试次数逐渐加长，那么最终所有消息都会发出去。

隐私在最初的时候并不是问题，毕竟所有人都是同一家公司的员工，还都在同一栋楼里工作。不过到了今天，隐私确实是问题了。因为把以太网的接口设定为「混乱模式」后，就可以读取网络上所有消息的内容（不限于发给它的内容），所以很容易就会与一些重要的个人信息（如未经加密的密码）不期而遇。这种被称为「嗅探」的行为曾经是大学宿舍里使用以太网所面临的主要安全问题。好在，可以通过对电缆中的所有内容加密来解决问题，尽管说服人们使用加密软件并非易事。

以太网中的信息以包的形式传输。顾名思义，包（packet）就是包装比特或字节信息的一种容器，其中信息的格式经过了精确的定义，以便发送时打包，接收时拆包。最形象的比喻就是把包想象成一个信封（或者明信片），上面写着寄信人地址、收信人地址、内容摘要以及其他信息，而且格式都是标准的。就跟联邦快递取货送货时使用的包裹一样。

包的格式因网络不同而异。拿以太网来说，每个包最小 64 字节，最大 1518 字节。其中源地址和目标地址各占 6 个字节，还有其他信息。因此每个包最多会有 1500 字节用于保存数据。

以太网出人意料地获得了巨大成功。它最早被集成到了商业产品中（还不是通过施乐，而是通过梅特卡夫创办的 3COM 公司），随着时间的推移，数不清的制造商卖出的以太网设备已达数十亿台。早期以太网设备的带宽是 3 Mbit/s，而今天 100 Mbit/s 乃至 10 Gbit/s 带宽的设备都已经随处可见。与调制解调器一样，第一代以太网设备既笨重又昂贵，现如今的以太网卡呢，不过是一小块便宜的芯片而已。

最早的同轴电缆已经被一种 8 芯电缆取代，电缆两头分别是一个常见的 8 针 RJ45 水晶头。这就是我们今天常说的网线。通过网线，可以把设备连接到集线器或交换机，后者会向相连的其他网络发送收到的数据。你的计算机多半都会有一个网口，可以插上标准的水晶头。这种网口也常见于无线基站、电缆调制解调器和 DSL 调制解调器等模拟以太网的设备。

以太网的传输距离也是有限制的，通常在几百米左右。通过硬件（中继设备）连接不同的网段并转发数据包，可以扩大传输范围。智能中继设备可以自动判断主机位置，只将包发送到它应该去的地方。所有这些细节对最终用户都是隐藏的，只有系统管理员在排除故障时才会关心。

以太网有一个明显的缺点 —— 离不开网线。这些网线要么在墙壁里斗折蛇行，要么在地板下匍匐蜿蜒。无线网络同时解决了上网和移动的问题。无线网络（当然不用网线）通过无线电波传输数据，只要信号强度足够，在任何地方都可以通信。无线信号覆盖的范围从几十米到几百米不等。与电视遥控器使用的红外线不同，无线信号不一定非要直线传播。但是，金属物（比如墙壁和隔断）和混凝土结构（如楼板）会干扰无线信号，导致其实际覆盖的范围要远小于在空旷环境下所能覆盖的范围。

从技术角度讲，无线网络利用电磁波传送信号。电磁波是特定频率的电波，其振动频率以 Hz 来衡量。在发送信号之前，首先要通过调制把数据信号附加到载波上。比如，调幅（AM）就是通过改变载波的振幅或强度来传达信息，而调频（FM）的原理则是围绕一个中心值来改变载波的频率。接收器接收到信号的强度与发射器的功率成正比，与到发射器距离的平方成反比。由于存在这种二次方递减的关系，距离发射器的距离增加一倍，接收器接收到的信号强度就只有原来的四分之一。无线电波穿越各种物质时强度都会衰减，物质不同衰减程度也不同，比如说金属就会屏蔽任何电波。高频比低频更容易被吸收，二者在其他方面都一样。

无线联网对可以使用的频率范围 —— 频段，以及使用多大的功率发送电波都有严格规定。频段分配始终都是一个有争议的话题，因为各种需求总会发生冲突。频段在美国由 FCC（Federal Communications Commission，联邦通信委员会）等政府机构负责分配，联合国下辖的 ITU（International Telecommunications Union，国际电信联盟）负责制定国际协议。

今天，计算机网络使用的无线标准有一个朗朗上口的名字，叫 IEEE 802.11b/g/n。但民间流行的称呼则是 Wi-Fi（音 wai-fai）。IEEE 指的是 Institute of Electrical and Electronics Engineers，即电气与电子工程师协会。这个协会除了开展其他工作之外，还负责制定一系列电子方面的标准，包括无线通信标准。802.11 是无线通信标准的编号，而这个标准由几个部分组成，其中 802.11b 定义的是 11 Mbit/s 标准，802.11g 定义 54 Mbit/s 标准、802.11n 定义 600 Mbit/s 标准。这些带宽都是名义上的，实用条件下没那么高，大约只有名义带宽的一半。

无线设备可以把数字化信息编码为适合通过无线电波传输的形式。802.11 无线网络中的数据包与以太网中的数据包类似，因此可以用无线连接代替以太网连接。两者的传输距离也相近，只不过无线网络少了电缆的羁绊。

无线以太网设备发射的电波频率为 2.4~2.5 GHz，某些 802.11 设备的频率会达到 5 GHz。所有无线设备的频率都局限于这一较窄的范围内，冲突的可能性大大增加。更糟的是，有些无线电话、医疗设备，甚至微波炉也跟着凑热闹，同样使用这一频段。有一次我在使用厨房里那台旧笔记本时无线连接突然断了，后来才发现是我用微波炉加热咖啡的缘故。30 秒钟的加热就足以让笔记本断开无线连接。

接下来我给大家简要介绍三种使用最广泛的无线联网技术。首先就是蓝牙，这个名字源自丹麦国王 Harald Bluetooth（约公元 935-985 年）。蓝牙技术是为近距离临时性连接而发明的，使用与 802.11 相同的 2.4 GHz 频段。蓝牙连接的距离是 1 到 100 米，具体取决于功率大小，数据传输速度为 1 到 3 Mbit/s。使用蓝牙技术的设备主要包括无线麦克风、耳机、键盘、鼠标、游戏手柄，功率相对较低。

第二种技术是 RFID（radio-frequency identification），即无线射频识别，主要用于电子门禁、各种商品的电子标签、自动收费系统、宠物植入芯片，以及护照等身份证明。RFID 标签其实就是一个小型无线信号收发装置，对外广播身份信息。被动式标签不带电源，通过天线接收到的 RFID 读取器广播的信号来驱动。RFID 系统使用多种不同的频率，比较常见的是 13.56 MHz。RFID 芯片让秘密监视物体和人的行踪成为可能。植入宠物体内的芯片就是一种常见的应用，我家的小猫身上就有一颗。你猜得对，已经有人建议也给人植入这种芯片了。至于动机嘛，就不好说了。

最后一种是 GPS（Global Positioning System，全球定位系统），它是一种重要的单向无线系统，常见于汽车和手机导航系统中。GPS 卫星会广播精确的时间信息，而 GPS 接收器会根据它从三四颗卫星接收到信号的时间来计算自己在地面的位置。然而，GPS 只接收信号不发送信号。以前曾有一个关于 GPS 的误解，认为它能悄悄地跟踪用户。要想利用 GPS 跟踪用户，必须得有地面系统（比如手机）转发位置信息。正如下一节所要讨论的，手机与基站之间保持密切通信，因而可以（而且确实会）不断地报告你的位置。只不过有了 GPS 接收器之后，它所报告的信息可以更加精确。

最常用的无线设备就是手机了。这种设备曾被叫作「蜂窝电话」或「移动电话」，在 1980 年代还是个稀罕物。如今，地球上半数以上的人都与它须臾不离了。蜂窝电话是本书介绍的所有主题中最值得好好讨论的一个典型，它不仅涉及硬件、软件、通信，还关乎社交、经济、政治，甚至法律。

第一代蜂窝电话是由 AT&T 在 1980 年代早期研制成功的。当时的电话机又大又笨重，而蜂窝电话的广告中则有一个人手提一个装着电池的小箱子，站在一辆携带着天线的汽车旁边。何谓「蜂窝」？因为频段和无线电的覆盖范围都是有限的，因此就要把整个地区划分为蜂窝状的许多小区。可以将每个这样的小区想象为六边形，然后中央有一个基站，相邻的小区之间通过基站相连。打电话的时候，手机会与最近的基站通信。当用户移动到另一个小区时，进行中的通话就由原来的小区移交给新小区，但这个切换用户一般觉察不到。

由于接收功率会随着距离的二次方衰减，所以位于既定频段中的频带在不相邻的小区内可以重用，而不会相互干扰。这就是可以高效利用有限频段的秘密所在。大家看下面这幅示意图，1 号小区中的基站与 2 到 7 号小区中的基站不会使用相同的频率，但可以跟 8 到 19 号小区中的基站使用相同的频率，因为与它们之间的距离足以避免干扰了。「蜂窝」中小区的实际形状要取决很多因素，比如天线的辐射图形。这张图只是一种理想化的结果。实际上，小区覆盖面积的大小并不相同，从几百米到几十公里的都有。具体取决于通信量、地形、障碍物，等等。

蜂窝手机是常规的电话网络的一部分，只不过连接这个网络不是靠电话线，而是靠基站发射无线电波。蜂窝电话的核心优势就是移动性。手机用户可以长距离（通常也是高速）旅行，中间会穿越很多小区，到了目的地也不一定会收到提醒。比如，我们坐了很长时间的飞机，当飞机降落在目的地之后再打开手机时不会觉得有任何异样。

手机使用的频段很窄，传输信息的能力有限。因为要使用电池，所以打电话时发射的都是低功率无线电波。而且根据法律规定，为了避免与其他无线设备发生干扰，它们的传输功率也受到限制。电池容量越大，待机时间越长，但手机也会更大更沉。这也是一个权衡。

手机在世界的不同地区会使用不同的频带，但一般都在 900 MHz 左右。每个频带被分成多个信道，每次通话时，收发信号各占用一个信道。发送呼叫信号的信道由小区中所有手机共享，在某些系统中这个信道也可以同时用于发送短信和数据。

每个手机都有唯一的识别码（可不是说手机号啊），相当于以太网的地址。启动手机后，它就会广播自己的识别码。距离最近的基站接收到手机信号后，会通过后台系统验证该识别码。随着手机移动，基站实时更新其位置信息，并不断向后台系统报告。如果有人呼叫该手机，后台系统就能通过一直与它保持联系的基站找到它。

手机与基站通信时的信号强度很高。但手机会动态调整功率，在距离基站较近时降低功率。这样不仅可以省电，也可以减少干扰。待机时的耗电量远远比不上一次通话，而这也是为什么待机时间以天为单位，而通话时间以小时为单位的原因。如果手机所在小区信号较弱或根本没有信号，那么它就会因为拼命查找基站而大量耗电。

美国使用了两种完全不同的手机通信技术。AT&T 和 T-Mobile 使用 GSM（Global System for Mobile Communications，全球移动通信系统），这是一种在欧洲使用非常普遍的系统，它把频带分成很窄的信道，在每个信道内依次附加多路通话。GSM 是世界上应用范围最广的系统。Verizon 和 Sprint 使用 CDMA （Code Division Multiple Access，码分多址），这是一种「扩展频段」技术，它把信号扩展到频带之外，但对不同的通话采用不同的编码模式进行调制。这就意味着，虽然所有手机都使用相同的频带，但大多数情况下通话之间不会发生干扰。GSM 和 CDMA 都会利用数据压缩来尽可能减少封装信号的比特量。对于通过嘈杂的无线电信道发送数据时无法避免的错误，再添加错误校验来解决问题。

手机带来了一系列难解的非技术问题，频段的分配显然是其中之一。在美国，政府限制每个频带最多只能有两家公司使用指定频率。因此频段是非常稀缺的资源。手机信号发射塔的位置同样如此。信号发射塔作为户外建筑算不上漂亮，很多地区为此拒绝在自己的地界上搭设这种东西。当然，他们依旧希望得到高品质的手机通话服务。

## 0302. 互联网

互联网背后只有少数几个简单的设计思想，但在大量工程实践的支持下，仅用如此少的机制就实现了非凡的成就。

互联网是基于数据包的网络。在互联网中，信息被封装在一个个标准格式的数据包里发出，动态地在一个巨大的变化无常的网络集合里被路由。这种网络模型和电话系统的电路网络完全不同，后者每次通话都会建立一条专用电路，在概念上可以理解为连接通话双方的私有线路。

互联网给接进来的每台主机分配唯一的 IP 地址，同一个网络内的主机共享同一个 IP 地址前缀。笔记本等移动的主机每次连上网的时候，多半会使用不同的 IP 地址，搬到不同的地方，其 IP 地址可能会变。域名系统是个巨大的分布式数据库，用来把主机名字转换成 IP 地址，或者反之。

网络之间通过网关连接。网关是一种专用计算机，用来把那些奔赴终点的数据包从一个网络路由到下一个网络。网关用路由协议交换路由信息，这样即使网络拓扑发生改变、网络间的连接此去彼从，网关还是知道如何把一个包发送到离它的终点更近的地方。

互联网依靠协议和标准来生生不息。IP 是互联网的通用机制，是交换信息的通用语言。以太网和无线网等专用硬件技术都封装 IP 包，但 IP 层感觉不到某个具体硬件的工作方式，甚至不知道其存在。TCP 用 IP 建立连接到目标主机指定端口的可靠数据流。更高层协议则用 TCP 创建互联网服务。

协议把系统切分成层，每一层为上一层提供服务，并调用下一层的服务。这种把协议分层部署的模型是互联网运行的基础，是组织和控制复杂性并隐藏不相关实现细节的绝好方法。在分层协议中，每层只关注本层知晓如何完成的任务：硬件网络把字节从网络中的一台计算机搬运到另一台、IP 在互联网中传送数据包、TCP 从 IP 合成可靠的数据流、应用协议用数据流来回发送数据。每层都使用其相邻下层提供的服务，并为其相邻上层提供服务。任何一层都不试图大包大揽。显然，每层展现出来的编程接口都是第 5 章讲到的 API 的绝佳范例。

互联网的隐私和安全是个大麻烦，下面几章会深入讲这些。这就像是入侵者和防御者的军备竞赛，大多数时候入侵者魔高一丈。世界各地散布着人们共用的、无人管制的、各色各样的介质和网站，数据从其中穿行而过，在一路上的任何位置都可能被人出于商业或政治目的记录、审查和阻断。而要在途中控制访问、保护信息，则难于上青天。很多网络技术用到了广播，这使它们面对窃听毫无抵抗之力。攻击以太网需要找到其中的线缆并进行物理连接，但攻击无线网却不需要物理接触就能偷听。

互联网始于 1969 年，TCP/IP 的核心协议在 1973 年亮相。其后，虽然经历了网络规模、流量和应用的爆炸式增长，互联网还是一如既往地开放和高效。这真的是非凡无比的成就。

前面的章节描述了以太网和无线网等本地网络技术。我们知道，电话系统把全世界的电话机连在了一起，那么如何通过计算机网络把全世界的计算机连接起来呢？怎样才能扩大网络规模，把不同的本地网络连接在一起？如把一幢大楼里的所有局域网都连通，或者用我家的计算机连接到另一个城市里你家的计算机，或者把分别位于加拿大和欧洲的公司网络连成一体。如果底层网络采用了不同的技术，不同的网络又是怎样互通的？当接入的网络和用户越来越多、距离越来越远、所用的设备和技术变化日新月异时，怎样才能从容地扩展网络来满足这些变化的要求？

我们说，「互联网」就是解答以上所有问题的一个答案。实际上，由于它实在太成功了，所以在大多数情况下，它就是唯一的答案。互联网并不是一个巨型网络，更不是一台巨型计算机。它由定义了网络和其中的计算机相互通信规则的标准连接在一起，是一个松散、非结构化、混乱、自组织的网络集合。

如何才能把光纤网、以太网、无线网等不同物理属性的网络连接起来，甚至在它们之间相隔很远时也能连通？我们需要用名字和地址来识别网络和计算机，就像使用电话号码和电话簿那样。我们需要在间接相连的网络之间找到通信的路径，需要就信息采用何种格式传输达成协议，还需要在错误处理、时延、过载等一些不太容易想到的问题上达成协议。没有这些协议，就很难甚至无法进行通信。

所有的网络，尤其是互联网，都需要按照协议的约定来处理数据格式、谁先发起请求、后续可以跟随什么样的应答、错误如何处理等方面的问题。在这里，「协议」这个词跟生活中的意思差不多，表示用来跟对方交谈的一组规则。但是，网络协议是基于技术考虑而非社会习俗的，所以它要比最严格的社会结构还精确。

互联网必须满足以下这些不是那么显而易见的规则：互联网的所有接入方都要达成同样的协议和标准，如信息按什么格式组织、在计算机之间怎样交换，如何识别计算机身份并授权，以及错误发生了该如何处理。考虑到既得利益者的影响，网络协议和标准的达成可能会相当复杂：公司要制造设备、售卖服务，专利和技术持有者想到处渔利，政府则想要监视和控制国际和国内的网络信息。

还有稀缺资源的分配问题。在这方面，无线服务的频段就是一个显而易见的例子，网站域名的管理也不能放任自流。由谁来分配这些资源，按什么原则分配？要使用这些有限的资源，应该谁向谁支付，支付什么？资源分配中遇到纠纷谁来裁决？裁决时以哪套司法系统为依据？制定所有这些规则的可以是政府、公司、行业协会，也可以是像联合国下属的国际电联这种名义上的非营利性或中立团体。但无论谁制定规则，最终所有的参与者都要达成一致，照章办事。

显然这些问题都是能解决的，毕竟有先例在：遍布全球的电话系统就把散布在各个国家的设备成功地连接了起来。尽管互联网和电话系统并无本质区别，但互联网比电话系统更新潮、规模更大、变化更快，也更杂乱无章。这个行业对所有人都是开放的，而通信业则是由传统电信公司组成的受控环境，其中大部分公司是由国家垄断或者牢牢控制的。

在深入了解互联网的技术细节之前，让我们先看看其概貌。互联网初创于 1960 年代，其初衷在于建造一个网络来连接分散在不同地理位置的计算机。由于项目的大部分资金来自美国国防部的高级研究计划署（Advanced Research Project Agency，缩写为 ARPA），最初建成的网络就叫做 ARPANET。1969 年 10 月 29 日，ARPANET 上的第一条消息从加州大学洛杉矶分校发出，到达 550 公里外的斯坦福大学。这一天可以看成互联网的诞生日。

2『1969 年是互联网的诞生日，以什么事件来说明，这一条事件写成一张信息卡片。』

ARPANET 从设计伊始，就具有能处理网络任何局部错误的健壮性，能在网络出现问题时依然成功路由数据。经过多年发展，原始 ARPANET 中的计算机逐步更新换代，所用的技术也推陈出新。网络覆盖范围也从最初只连接美国部分大学计算机科学系和科研机构，到 1990 年代逐步扩大到商界，最终发展成为互联网。

如今的互联网由成千上万个松散连接的独立网络构成，其中的每个网络都连接到另外一个或多个网络。邻近的计算机通过以以太网为主的局域网连接，然后网络和网络再连起来。网络连接采用的设备叫网关或路由器，其实就是一种专用的计算机，用来把组成信息的数据包从一个网络发送到下一个网络（维基百科上说网关是通用设备，而路由器是专用的，在本书里就不作区分通称为「网关」了）。网关之间互相交换着路由信息，这样它们就至少知道哪些网络与本地网络相连并可以被访问到。

每个网络都可以连接上许多计算机主机（以下简称「主机」），比如家里、办公室里、宿舍里的 PC 和 Mac。家用计算机可以通过无线网卡连接到路由器，然后路由器通过电缆或 DSL 链路连接到互联网服务提供商（Internet Service Provider，缩写为 ISP）。办公室的计算机则可用有线网卡与以太网连接。

上一章已经提到，信息在网络之间游弋的时候，被分作称为包（packet）的小块。一个包就是按特定格式组织起来的一串字节。不同设备使用不同的包格式。包的内容中首先是地址信息，用于标明这个包的发送方和接收方；然后是与这个包本身有关的信息，比如包的长度；最后，通常也是最大的部分，是包输送的信息，即有效载荷。

在互联网上，输送数据的包叫做 IP 包（IP 即 Internet Protocol，互联网协议）。所有的 IP 包都是一样的格式。在具体的物理网络上，IP 包通过一个或多个物理包来传输。比如，由于最大的以太网包是 1500 字节，远小于最大 IP 包的 65 000 字节，所以一个较大的 IP 包会被切分成多个较小的以太网包进行传输。

2『最大以太网包的大小以及常规 IP 包的大小，做一张信息卡片。』

每个 IP 包会经过多个网关，每个网关都把这个包传递给离包的最终目的地更近的下一个网关。一个包在网络中的旅程可能会经过 20 个网关，这些网关很可能是不同国家的公司或研究所拥有和运行的。要让这一切运转起来，我们需要以下机制。

1、地址。就像电话号码一样，每台主机都必须有一个辨识身份的地址，才能跟互联网上的其他主机区分开来。这个辨识号码叫做 IP 地址，长度为 32 位（4 字节）或 128 位（16 字节）。较短的地址用于互联网协议版本 4（IPv4），长的则用于版本 6（IPv6）。IPv4 已使用多年，现在仍占统治地位，但由于大部分 IPv4 地址都已经分配出去了，网络地址迁移到 IPv6 的进程正日益加快。

1『记住，IP4 是 32 位编码，IP6 是 128 位编码。』

IP 地址和以太网地址类似。IPv4 地址通常用其 4 字节的值表示，其中每个字节对应一个十进制数，数与数之间用句点分割，如 128.112.132.86 就是普林斯顿大学网站 www.princeton.edu 的 IPv4 地址。这种奇怪的记法叫点分十进制表示法，相比纯十进制或十六进制数值更好记，因而得到广泛的使用。

IP 地址的分配机制是，先由一个中心权威机构把连续的 IP 地址段分配给某个网络的管理员，再由管理员把单个 IP 地址分配给网络里的主机。这样，每台主机就有一个基于它所在网络的独一无二的地址。对台式机来说，IP 地址可能是固定的；但移动设备往往使用动态地址，其 IP 地址至少在设备每次重新连接到互联网时会改变。

2、名字。由于人们不太擅长记忆无规律的 32 位数字，哪怕写成点分十进制也不好记，因此，要让人们直接访问一台主机，必须给它取个名字才方便。比如，像 www.stanford.edu 和 microsoft.com 这种常见的名字，我们称之为域名。域名系统（Domain Name System，缩写为 DNS）用于将名字转换为地址，是互联网基础设施的重要组成部分。

3、路由。必须有一种机制，能为每个包查找从源地址到目标地址的路径。前文提到的网关就提供了这种功能。网关之间持续交换路由信息，即互联网上网络和设备的相互连接情况，并根据路由信息把收到的每个包转发到下一个离最终目的地更近一些的网关。

4、协议。最后，为了使信息在不同计算机之间成功复制，必须有一些规则和步骤，用来准确描述上述机制和其他互联网组件是如何协作的。互联网的核心协议称为 IP，该协议为信息传输定义了统一的传输机制和通用的格式。不同类型的物理网络用各自的底层协议来输送 IP 包。

在 IP 协议之上是传输控制协议（Transmission Control Protocol，缩写为 TCP），该协议利用 IP 协议来提供可靠的传输机制，以便能从源地址向目标地址发送任意长度的字节序列。在 TCP 协议之上，更高层的协议利用 TCP 协议来提供那些我们看起来是「互联网」的服务，如网页浏览、电子邮件、文件共享等。除此之外，互联网还有很多其他协议。例如，IP 地址的动态分配是通过 DHCP 协议（Dynamic Host Configuration Protocol，动态主机配置协议）来处理的。所有这些协议合起来就定义了互联网。

谁制定规则？谁控制名字和数字地址的分配？谁负责管理互联网？长期以来，互联网由一小群技术专家以松散合作的方式来管理。互联网的大部分核心技术是互联网工程任务组（Internet Engineering Task Force，IETF）开发的。IETF 是一个松散的联盟组织，它设计了构成互联网各要素的运行方式，并将之写成规范的文档。IETF 通过定期召开会议和频繁发布出版物的方式打造互联网的技术规范。这些出版物被称为「征求修正意见书」（Request for Comments，RFC），是互联网的事实规范。

管理互联网其他事务的是一个叫互联网名称与数字地址分配机构（Internet Corporation for Assigned Names and Numbers，缩写为 ICANN，其网址为 icann.org）的非营利组织。ICANN 负责互联网的技术协调，包括分配为让互联网正常运行而不能重复的名字和数字地址，如域名、IP 地址和某些协议信息。ICANN 还负责给域名注册商授权，好让他们给个人和机构分配域名。ICANN 最初是美国商务部管辖的一个署，但现在已经是独立的非营利组织，其主要资金来源是对域名注册商和域名注册收取费用。

域名系统（Domain Name System，DNS）规定了我们熟悉的分层命名方案，因此就有了 berkeley.edu 和 cnn.com 这样的名字。在域名系统中，.com、.edu 等组织机构代码和 .us、.ca 等两个字母的国家代码被称为顶级域。顶级域把管理责任和更多名字委托给下级域。例如，普林斯顿大学负责管理 princeton.edu，在这个域名下可为计算机科学系规定子域名 cs.princeton.edu、为古典文学系规定子域名 classics.princeton.edu，计算机系则可进一步规定域名 www.cs.princeton.edu。这种层次式的命名可以一直扩展下去。

域名只表示逻辑结构，并不受任何地理限制。例如，IBM 的分支机构遍布全球，但公司的全部计算机都在 ibm.com 域名下。一台计算机可以为多个域名服务，这在提供网站托管服务的公司里再平常不过了。也可以用多台计算机为同一个域名服务，比如像 Facebook 和 Amazon 这种大型网站。

域名系统没有地理限制会带来很多有趣的结果。比如，南太平洋上位于夏威夷和澳大利亚之间有个群岛国叫图瓦卢，它在域名系统中的国家代码是 .tv。图瓦卢把国家代码的使用权租给商业公司，后者则兴高采烈地把 .tv 域名卖给客户。如果你要买 news.tv 这种显然有潜在商业价值的域名，可能就要准备掏一大笔钱。反之，kernighan.tv 这种只对姓柯尼汉的人有意义的名字，价格还不到每年 40 美元呢。由于语言上的巧合而受益的其他国家还包括：摩尔多瓦共和国，其 .md 域名对医生很有吸引力；意大利，其 .it 域名可以用于 play.it 这样的网站。域名通常只能使用 26 个英文字母、数字和连字符。但从 2009 年起，ICANN 批准了一些国际化顶级域名，比如中国除了用 .cn 之外也可以用 .中国。

每个网络和每台联网主机都必须有 IP 地址，这样才能互相通信。IPv4 地址是互不重复的 32 位二进制数，在同一时刻任一地址只能给一台主机使用。ICANN 把地址按块分配出去，得到地址块的机构再把它划分成子块分配给下级机构或个人。比如，普林斯顿大学有两个地址块，分别是 128.122.ddd.ddd 和 140.180.ddd.ddd，其中 ddd 是从 0 到 255 的数字。这里的每个地址块最多允许给 65 536（216）台主机分配地址，总共大约有 131 000 个可用地址。

这两个地址块没有数值或地理上的关系，这就像 212 是纽约市的长话区号而 213 却是洛杉矶的一样。没有任何理由认为相邻的 IP 地址块代表物理位置相近的计算机，同样也没办法仅靠 IP 地址本身判断地理位置 —— 尽管通常可以从其他信息推断出一个 IP 地址的来源。例如，DNS 支持从 IP 地址到名字的反向查找，可以从 128.112.132.86 查到 www.princeton.edu，于是就可以合理地猜测网站在新泽西州普林斯顿，尽管实际上服务器可能根本就在别的地方。

简单算一下就会发现，IPv4 地址只有大约 43 亿个，甚至还不够地球上每人分一个。因此，按照人类使用的通信服务数量的增长势头，这些 IPv4 地址迟早会被耗光。实际情况比这种「危言耸听」更糟糕，因为 IP 地址是按块划分的，这样用起来就没有理论上那么有效率。想想吧，普林斯顿大学真的会有 13 万 1 千台计算机吗？IPv4 地址耗尽的可能性是真实存在并且迫在眉睫的，大体上在 2012 年就会分配光［1］。

有一种用单个 IP 地址肩扛手挑多台主机的技术，可以让我们在这个灾难面前获得喘息之机。家用无线路由器一般都提供网络地址转换服务（Network Address Translation，NAT），即用单个外部 IP 地址为多个内部 IP 地址提供连网服务。使用 NAT 之后，家里所有联网设备从外部网络看都具有相同的 IP 地址，内外地址的双向转换完全由 NAT 设备的硬件和软件搞定。

DNS 的关键功能是把名字转换为 IP 地址。顶级域的转换工作由一组根域名服务器负责，它们知道所有顶级域（比如 mit.edu）的 IP 地址。为获取 www.cs.mit.edu 的 IP 地址，需要先向根服务器查询 mit.edu 的 IP 地址，这样就能访问到 MIT 域，然后向 MIT 的域名服务器查询 cs.mit.edu 的 IP 地址，从得到的 MIT 计算机系的域名服务器就可以查到 www.cs.mit.edu 的 IP 地址。

因此可以说，DNS 使用分而治之的策略来搜索：对顶级域的首次查询把那些在下一步查询中不可能的地址排除掉，后面的每次查询也是如法炮制，这样就能逐级定位到目标主机。

在实际查询中，域名服务器会把近期查找到的名字和地址保存在缓存中。当收到一个新的查询时，如果缓存中有结果，本地域名服务器就会不求助于远程服务器而直接返回了。比如，当我访问 kernighan.com 时，由于十有八九最近没人查询过这个小众域名，本地域名服务器只好从根服务器开始查询。但当我再次访问这个域名时，由于 IP 地址已就近缓存，查询就会快很多。经尝试，首次查询耗时 1/3 秒，过了几秒钟之后再次查询同一个域名，只要首次时间的 1/10，过几分钟再查也是如此。

你大概以为只有一台根服务器吧？但对这么关键的系统来说，容忍单点故障的存在显然是个坏主意。因此，共有 13 台根服务器遍布于全世界，其中大约一半在美国。有的根服务器包含了位于天南海北的多台计算机，在功能上和一台计算机一样。它通过某种协议把查询请求分配到这组计算机里最近的那台。根服务器在各种不同硬件上运行不同的软件系统，这样，跟单一环境比起来，遇到系统缺陷或病毒攻击时的系统健壮性就要好很多。尽管如此，根域名服务器一直还是协同攻击的目标。可以想见，在某些特殊条件的组合下，所有根域名服务器也可能会同时宕机。

光有域名不行，你还需要为自己的网站准备主机，也就是存放网站内容以对外提供服务的计算机。这样别人访问你的网站时才可以看到内容。同时还需要找一个域名服务器，当别人查询你的域 IP 地址时，好让它告诉人家你主机的 IP 地址。设置域名解析是一个单独的步骤，而某些域名注册商通常也为用户提供域名解析服务，即使自己没有域名服务器，它也会为你寻找其他域名解析服务商提供方便。

竞争导致价格下降。首次域名注册的价格一般为 10-20 美元一年，后期续费也差不多；租用一个空间和流量配置都较低的主机服务的价格每个月大约 5-10 美元。只是用一个通用页面来「停放」[1] 域名的服务则是免费的。有些主机服务是免费的；当你只想随意做一个小型网站时，有的主机服务仅象征性收取少量费用；还有的主机服务则给你一段免费的试用期。例如，Google 的域名注册和主机服务每年只要 10 美元。

域名归谁所有？发生纠纷如何解决？别人先注册了 kernighan.com，我该怎么办？答案很简单：先买先得。至于有商业价值的域名，比如 mcdonalds.com 和 apple.com，法庭和 ICANN 的纠纷调解政策则偏向于财大气粗的一方。如果你的名字叫麦当劳或者苹果，基本不可能把域名从这些公司手中抢过来，甚至就算是你先注册的也很难保住。

路由解决从源地址到目标地址的路径寻找问题。在任何网络中，路由都是核心所在。

有些网络使用静态路由表，为所有可能的目标地址提供路径的下一条地址。但在互联网中，由于网络规模太大、动态性太强，使静态路由表难以提供正常的路由。为此，互联网网关通过与邻近网关交换信息来刷新自身的路由信息，这样就能保证可能的及所需的路径信息基本跟得上网络的变化。

互联网的庞大规模要求采用分层结构来管理路由信息。在路由系统的最顶层，上万个自治系统提供了它们所包含的网络的路由信息。一个自治系统通常也对应于一个大的互联网服务提供商（ISP）。在自治系统内部，路由信息仅进行本地交换，但整个自治系统对外部系统展现统一的路由信息集。

尽管不正式也不严格，路由系统在物理上也存在某种层次结构。用户通过 ISP 接入互联网，ISP 是个公司或组织，它再连接到其他互联网提供商。有的 ISP 规模很小，有的则很大（比如由电话公司或有线电视公司经营的那些 ISP）。有的 ISP 是由公司、学校、政府部门等机构自己运营，是为本机构提供内部服务的；有的 ISP 则对公众提供收费接入服务，如电话公司和有线电视公司。个人通常通过有线网络（在住宅中很常见）或电话接入 ISP，公司和学校则提供以太网或无线连接。

ISP 之间通过网关相互连接。由于主要运营商之间的网络容量巨大，所以各个公司的网络都汇接到运营商的「对等交汇点」，运营商网络之间则互相建立物理连接。这样，就能使来自一个网络的数据高效传送到另一个网络。有些国家对外连接的网关数量相对较少，这样可以监控和过滤政府认为不宜出现的信息。

协议规定了双方互相沟通时遵守的规则：一方是否主动握手，鞠躬多深，谁先从门口走过，在路的哪一侧行驶，等等。虽然有些协议是法律强制规定的，比如在路的哪一边行驶，但生活中的大多数协议都不太正式。

互联网有很多协议，其中最基础的有两个，一是互联网协议（Internet Protocol，IP），定义了单个包的格式和传输方式，二是传输控制协议（Transmission Control Protocol，TCP），定义了 IP 包如何组合成数据流以及如何连接到服务。两者合起来起就叫 TCP/IP。

由于每种物理网络都使用自己的格式传送 IP 包，网关在接收和转发它们时，必须在特定网络格式和 IP 之间来来回回地转换。

TCP 在 IP 层之上确保可靠通信。这样，用户（实际上是指程序员）就不用考虑分包组包的事，只要面对信息流就可以了。被我们认为属于「互联网」的大部分服务都使用 TCP。

再往上一层是支撑万维网、邮件、文件传输之类服务的应用层协议，它们大多以 TCP 为基础设计。从上面对协议的描述可见，互联网协议是分好几层的，每层都依赖下一层的服务，并为上一层提供服务。这是第 5 章中提到的软件分层理念的极好例子。

和 TCP 处在同一层的协议还有用户数据报协议（User Datagram Protocol，UDP）。UDP 比 TCP 简单得多，如果某些数据交换不要求双向流传输，只要高效率分包投递和少量其他特性，那就是 UDP 的用武之地。DNS、流媒体视频、VoIP 和某些在线游戏就使用了 UDP。

互联网协议（IP）提供的包传递服务是不可靠、无连接的。所谓「无连接」，就是说每个 IP 包都是独立的，和其他 IP 包无关。互联网协议没有状态或记忆力，就是说这个协议一旦把包传给下一个网关，就不再需要保存关于这个包的任何信息。

至于「不可靠」，顾名思义，互联网协议是个「尽力而为」型协议，并不能保证包传送的质量，出错也就出错了。包可能丢失或者损坏，接收到的顺序可能和发送的不一致，也许送达得太快而无法处理，也许送达得太慢而失去作用。当然，实际使用的时候，互联网协议是相当可靠的，但是当包中途丢失或损坏的时候，该协议确实不会尝试修复。这就像是在陌生的地方把明信片丢进邮箱，一般会送达收信人，但可能中途受损，有时会彻底寄丢，有时则比预期时间晚很多到达。互联网协议有一种错误模式倒是在明信片投递上见不到：IP 包可以复制，所以接收方可能会收到多份。

IP 包最大约为 65KB。这样长消息就要拆分成小数据块分别发送，到了远端再组装起来。就像以太网包一样，IP 包也有自己的格式。下图是 IPv4 数据包的格式，IPv6 数据包与之类似，只不过源地址和目标地址都是 128 位的。

IP 包中有个很有趣的部分是 TTL（生存时间，time to live 的缩写）。TTL 是个单字节字段，由包的发送方设置一个初始值，每经过一跳网关就减 1，当减到 0 的时候，就丢弃这个包，并给始发者返回一个报错包。互联网中一次典型的传包过程通常会经过 15 到 20 个网关，所以经过了 255 跳的包显然有问题，很可能是走环路了。TTL 并不能消除环路，但能防止个别包在遇到环路时永远转圈。

这里不准备讨论 TCP 工作原理的细节（实在一言难尽），但其基本原理倒是相当简单。在 TCP 中，字节流切分成片段，放到 TCP 包也就是所谓的报文段里。TCP 报文段不仅包含实际数据，还有控制信息构成的头部，其中包括方便接收方知晓收到的包代表数据流中哪部分的顺序号。通过顺序号，就可以发现丢失的报文段并重传之。TCP 报文段的头部还包括错误检测信息。这样，如果报文段出错，就很容易检测出来。每个 TCP 报文段都放在一个 IP 包里传输。下图展示了 TCP 报文段头部的内容，它们与数据一起封装在 IP 包里：

接收方必须对收到的每个报文段返回确认应答或否认应答。我给你发的每一个报文段，你都要返回一个应答以表明你收到了。如果在适当间隔之后我还没收到应答，那我就认为这个报文段已丢失，然后重新发送。同样，如果你预期会收到某个特定的报文段却没收到，那就得给我发送否认应答（比如「未收到 27 号报文段」），这样我就会重新发送。

显然，如果应答报文本身丢失了，情况就会更复杂。TCP 使用若干计时器来检测此类错误，如果计时器超时，就认为出错。如果某个操作耗时过长，就会启动纠错程序。最终，某个连接可能会因为「超时」而被终止。你也许见过失去响应的网站，那就是遇到了这种情况。这些都是 TCP 协议的一部分。

TCP 协议同样还包含提高传输效率的机制。比如，发送方可以在未收到上个包的应答信息时就继续发送下个包，接收方也可以为接收到的一组包回送一个应答。在通信顺畅的时候，这样做可以降低应答带来的开销。而当网络发生拥塞、开始出现丢包现象时，发送方就迅速回退到低速率，直到慢悠悠地一送一达。

在两台计算机主机之间建立 TCP 连接时，不仅要指定计算机，还要指定计算机上的端口。每个端口表示一个独立的会话。端口用两字节（即 16 位）二进制数表示，于是就有 65 536 个可用端口。这样，在理论上每台主机可以同时承载 65 536 个 TCP 会话。

有一百多个众所周知的端口预留给了标准服务。比如，Web 服务器使用 80 端口，邮件服务器使用 25 端口。这样，用浏览器访问 yahoo.com 网站时，浏览器会建立一个到雅虎服务器 80 端口的 TCP 连接，而邮件程序则使用 25 端口来访问雅虎邮箱 [1]。源端口和目标端口是 TCP 头部的一部分，头部与数据一起构成 TCP 报文段。

TCP 协议实现细节远比这复杂得多，但基本原理就是这些。TCP 和 IP 最初由文特·瑟夫（Vint Cerf）和鲍勃·卡恩（Bob Kahn）于 1973 年设计，他们因此一起获得了 2004 年图灵奖。尽管经历了多次改进，但网络规模和通信速度已经增长了多个数量级，TCP/IP 协议还是能基本保持不变，这充分证明最初的设计是相当棒的。如今，TCP/IP 处理了互联网的大部分流量。

邮件客户端程序访问邮件服务器时，发信和收信使用不同的端口，发信用 25 端口而收信通常用 110 或 143 端口。另外，越来越多的人使用 Webmail，即用浏览器通过邮件服务商的网站收发邮件而不是使用专门的邮件客户端程序，这样使用的端口就和浏览网页一样了。

TCP 提供双向通信方式，可使数据在两台计算机之间可靠地来回传输。互联网服务和应用程序使用 TCP 作为传输机制，但在完成具体任务时还要使用自己特定的协议。例如，超文本传输协议（HyperText Transfer Protocol，HTTP）就是万维网浏览器和服务器使用的非常简单的协议。我在页面中点击亚马逊网站链接的时候，浏览器会打开一个 TCP/IP 连接，连接至服务器 amazon.com 的 80 端口，然后发送一条简短的消息请求某个网页。下图中，左边最顶端的客户端应用程序是浏览器。消息沿着协议链向下层走，跨越互联网（通常是经过更多步传递），到了远端之后回到协议上层，传给相应的服务器应用程序。服务器响应的返回路径不一定和传输客户端请求的路径一样。

亚马逊服务器准备好客户端请求的页面，然后把它和一小段附加数据（比如关于页面编码方式的信息）一起发送回去。浏览器读到返回结果后，据此显示出页面内容。你可以亲自尝试用 Telnet 来摸索这个过程。Telnet 是用来跟别的计算机建立远程登录会话的 TCP 服务，通常使用 23 端口，但也可以指定其他端口。在 Mac 终端或者 Windows 命令提示符窗口里输入下面几行英文：

如果说互联网是信息载体，那我们可以在上面做什么？在本节，我们先看看互联网初期使用的一些最早的程序。这些程序都诞生在 1970 年代初，不过至今仍在使用，主要归功于它们良好的设计和功能。所有这些程序都使用 TCP 来传输字节流。它们都是命令行程序，尽管大多数都很简单，却不是给普通用户而是给那些相对专业的人士使用的。

早期互联网的任务之一是让研究人员能够从别的站点获取各种信息，比如实验数据和测试结果，或者生成和分析这些数据的程序。用来做这件事的工具叫 FTP，即文件传输协议（File Transfer Protocol）。FTP 展示了很多基本理念。其操作过程很简单：打开到一个站点的连接，从那个站点取回文件或者发送文件过去，然后关闭连接。除此之外，FTP 还用一些命令操作远程文件系统里的文件。

在上面的例子中，尽管服务器不认识客户机的 IP 地址，但仍然允许匿名访问，不检查口令。对于非公共的文件，就要先用某个有权限的帐户登录之后才能访问。就像早期大多数协议一样，FTP 有个 help 命令，你完全可以自己摸索它的用法。

第二个早期的工具是 Telnet，该工具用来操作远程机器，其效果就如同直接连在上面一样。本章前面已经演示过一个 Telnet 的例子。Telnet 接受客户端的键盘输入并将其发送到服务器，仿佛是在服务器上直接按键一样；然后 Telnet 拦住服务器的输出，并发回到客户端。有了 Telnet，就可以登录任何一台联网的计算机，并把它当成本地机器来使用。Telnet 的基本用法很简单，但其附加功能还可以进行文件复制、把键盘输入定向到本机而不是远程等。Telnet 最初的用途是远程登录，但也可用来连接到任何端口，因此也用于对其他协议进行简单测试。下面的例子是用 Telnet 在 Google 上进行搜索：

Telnet 和 FTP 协议一样，都是开放的。如果远程系统能接受没有口令的登录，那就不需要口令。如果远程系统向客户端要口令，Telnet 会以明文形式将客户端的口令发送过去。因此，任何监视数据流的人都能看到口令。现在，除了不讲究安全的场合，Telnet 已经很少用了，原因之一就是它毫无安全性可言。而 Telnet 的继任者 SSH（Secure Shell 的缩写）则因为双向加密了全部通信而得到广泛使用，可以用来安全地交换信息。SSH 使用 22 端口。

第三个例子是简单邮件传输协议（SMTP，Simple Mail Transfer Protocol）。我们通常使用浏览器或者独立程序如 Outlook、Mac Mail 来收发邮件。但就像互联网上的诸多其他应用一样，我们所能看到的只是表面，之下还有若干层，每层都靠各自的程序和协议来支撑。邮件的运行涉及两种基本类型的协议。SMTP 用来在不同系统之间交换邮件。具体步骤是，先建立一条连接到收件人的邮件服务器 25 端口的 TCP/IP 连接，使用 SMTP 协议指明发件人和收件人，然后传送邮件内容。SMTP 是基于文本的协议，理论上可以用 Telnet 连接到邮件服务器的 25 端口观察其运行过程。不过，SMTP 做了足够多的安全限制，因而即使把你自己的计算机当成邮件服务器进行本地操作，也会遇到麻烦。

SMTP 要求邮件消息是 ASCII 文本。如果要把其他类型的数据转换成文本，或者把多块数据拼成一条邮件消息，那就要按 MIME 标准来。MIME 的意思是多用途互联网邮件扩展（Multipurpose Internet Mail Extensions），实际上它是 SMTP 之外的另一个协议。当需要在邮件里插入照片、音乐等附件时，就要用到 MIME 机制，在 HTTP 中也用得到它。

虽然 SMTP 也是像 FTP 和 Telnet 那样的端到端协议，但它的 TCP/IP 包从源节点到目的节点常常要经过 15 到 20 跳网关。这就意味着，途中的任何网关都可以检查经过的包，将邮件内容复制下来以从容不迫地审查。而且，SMTP 本身也可以复制邮件内容，邮件系统会跟踪内容和头部的传送。因此，如果不想让发送的邮件内容被别人看到，一定要从一开始就加密。但有一点要记住，加密邮件内容并不会隐藏发件人和收件人的身份。

另外，SMTP 只是把邮件从源主机传送到目的邮件服务器，然后就不管用户怎样收取邮件了。邮件到达目的邮件服务器之后就原地等待，直到收件人取走。广泛使用的邮件接收协议有两个：POP 和 IMAP。

当你把邮件从保存它的邮件服务器系统里移到自己的计算机时，要用到邮局协议（Post Office Protocol，POP）。利用 POP 可以把邮件从服务器上取下来，在自己计算机上保存一份用来阅读，然后把服务器上的那份删掉。

互联网邮件访问协议（Internet Mail Access Protocol，IMAP）则用于与 POP 功能相反的另一种场合：邮件保存在服务器上，你可以从好几个地方访问它。IMAP 确保邮件只存在一个地方，这样任何时候邮箱都是一致状态。由此多个访问者可以同时读取和更新同一个邮箱。因为不需要复制多份消息，也不需要在计算机之间同步，所以，当你需要在好几个地方（比如浏览器和手机）读取邮件的时候，IMAP 就是最佳选择。像 Gmail 和雅虎邮件这样的「云端」邮件系统也很常见。这些系统底层也是通过 SMTP 传输邮件，客户端也像 IMAP 那样访问邮件。第 11 章将会讲到云计算。

1999 年 6 月，美国东北大学一年级新生肖恩·范宁（Shawn Fanning）发布了 Napster 程序，让大家能轻而易举地共享 MP3 格式压缩的音乐。范宁的这事做得可谓恰逢其时：那时的音乐 CD 虽然满大街都是，但价格居高不下，而 MP3 编解码算法已广泛传播开来，个人计算机的运算速度已足以制作并播放 MP3 音乐。网络带宽也足够高，在上面传送歌曲相当快，大学里的宿舍网络就更不用说了。由于范宁的设计和实现做得很棒，Napster 如星火燎原般传播开来。1999 年中期，他组建了一家公司来经营这项服务，据称最火的时候有 8000 万用户。但同年晚些时候，Napster 就遭遇了第一起诉讼，被指控大范围偷窃受版权保护的音乐。2001 年中期，法院判决 Napster 关闭其业务。两年时间，从白手起家，到 8000 万用户，再到一无所有，这正是后来的流行语「互联网时代」的生动写照。

使用 Napster 的方法是首先下载 Napster 客户端并安装到自己计算机上，然后指定一个文件夹以共享其中的文件。随后客户端登录到 Napster 服务器，把想共享给别人的文件的文件名传上去。Napster 维护一个中心目录，里面是可以获取的文件名。这个中心目录一直保持更新，当有新客户端登录上来时，就把它们共享的文件名加进来；现有客户端对系统检测没有响应时，就从列表中去除它们的文件名。

当用户在中心服务器搜索歌名或歌手时，Napster 返回一个列表，里面列出在线而且愿意共享这些文件的其他人。当用户选择了某个共享者时，Naspter 就为双方安排联系：提供 IP 地址和端口号，让用户计算机上的客户端连过去取文件 —— 有点像红娘牵线。供需双方都把状态报告给 Napster，但中心服务器并「不参与」文件共享的过程，从头到尾不碰音乐文件「一个手指头」。

我们已经习惯了客户机 - 服务器模型，比如浏览器（客户机）从网站（服务器）请求页面。作为一个实例，Napster 为我们展示了另外一种模型：中心服务器列出了现在可共享的音乐，但音乐文件本身还是存储在用户自己的计算机上；当文件传输时，文件直接从一个 Naspter 用户传到另一个用户，并不经过中心系统。这样的组织方式就叫点对点，共享者就是其中的对等点（peer）。因为音乐文件本身只存在于对等点计算机上，从来不在中心服务器上，所以 Napster 希望据此规避版权问题，但这些看似合法的技术细节并未得到法庭认可。

Napster 协议使用了 TCP/IP，所以它实际上和 HTTP、SMTP 是同一层的协议。Napster 是个简单的系统，范宁的成功是在互联网基础设施、TCP/IP、MP3 和构建图形用户界面的工具这些条件都具备的情况下吹起的一场东风。

之后文件共享就流行起来，在 Napster 停业之前就兴起了其他一些服务，有的甚至用来共享并无版权保护的资料。这些服务在几个关键方面与 Napster 有所不同。首先，Napster 系统的脆弱之处在于它把当前可下载的文件列表保存在中心服务器；这样，只要关掉服务器，服务就荡然无存。其次，Napster 公司开在加州，就要受美国法律管辖。之后的文件共享程序就没有这些限制，大多数都在美国境外运作；更重要的是，这些系统用了分布式的目录方案，将可共享文件的信息传播到多台计算机上，只关掉一部分机器并不能停掉服务。同时，这些服务也开始共享其他资料，除了音乐之外还有电影、软件和色情作品，从而在更多的圈子里促进了对文件共享服务的需求。

当今的大多数文件共享，不论合法的还是非法的，都使用了一种叫 BitTorrent 的点对点协议 [3]。这个协议是布莱姆·科亨（Bram Cohen）于 2001 年设计的，特别适用于共享很大的热门文件比如电影和电视节目，因为每个用 BitTorrent 下载文件的站点也必须同时上载一部分文件给那些需要的人。BitTorrent 通过搜寻和 Kazaa 类似的分布式目录来找到想要的文件，并用一个很小的「torrent 文件」来标记传输过程的踪迹，其中维护了谁上载和接收了哪些文件分块的记录。BitTorrent 用户很容易被查到，因为协议规定了下载者也必须上载，这样就可以找到那些把自称受版权保护的资料共享出来的行为。

文件共享是研究本书所涉及各种问题的绝佳案例，它综合了本书几乎所有重要话题。在硬件方面，涉及声音和网络连接的外设，都是 1990 年代早期尚未出现或非常昂贵的设备；用数字形式来表示模拟信息是 CD 和 MP3 的核心所在；软件则包括应用程序和操作系统，客户机 - 服务器和点对点模型，目录和本机、远程机上的文件，用户界面，当然还有搜索、排序和压缩的算法；通信部分使用互联网和浏览器，要关心带宽、压缩、错误检测。当你让别人在你的计算机上运行他们的程序时，你的安全和隐私就受到了侵犯。

本节提到的这些高层协议的共同之处，就是它们规定的都是如何在计算机程序之间搬运信息，即把互联网作为一个傻瓜网络，从一台计算机到另一台高效地复制字节流，但不去解释或处理这些数据。这是互联网的重要特性：从数据原样传送的意义来讲，互联网就是个「傻瓜」。说得不那么难听点（同时也是端对端原理）：连同收发数据的程序在内的各个端点是智能的。与此相反的是传统的电话网络，其所有智能都体现在网络上；而端点设备，比如老式电话机，真的是傻瓜，除了连接到网络上传递声音之外，什么多余的功能都没有。

就是这种「傻瓜网络」却激发出了很高的创造力，因为这种模式意味着任何人只要有好的想法都可以创建出灵巧的端点设备或软件，网络可以为它们传送数据。反之，等待电话或有线电视公司来实现或支持类似的好想法恐怕就不靠谱了。不难预料，这些运营商只乐于加强控制，这一点在日新月异的移动领域表现尤为突出。但与此同时，虽然运营商竭力想控制，大多数革新仍然从别处不请自来。

像 iPhone 和 Android 这样的智能手机根本就是通过电话网络而不是互联网通信的计算机。运营商尽管想从这些电话上运行的服务赚钱，但基本上只能收点数据流量费。早期，大多数手机的数据服务都是每月收取固定费用，但现在（至少在美国），已经逐渐变为按使用量计费的模式了。对于高流量服务，比如下载电影，这样做可能是合理的，但对于发送文本短信这样的服务来说就有点说不过去了，毕竟这种服务占带宽极小，几乎不消耗运营商什么资源。

最后请留意一下早期的协议和程序有多信任使用它们的用户。Telnet 和 FTP 用明文发送口令。FTP 支持匿名传输，而且实际上鼓励这么做。长久以来，SMTP 完全不限制发件人和收件人，任何人发送给任何人的邮件都能转寄。这种「开放转寄」服务是垃圾邮件发送者的天堂 —— 如果你不需要收件人直接回复你，甚至可以伪造发件人地址，如此就很容易制造欺诈和拒绝服务攻击。

简而言之，互联网协议和在其上构建的程序都是针对可信任的个体构成的诚实、协作、善意的团队设计的。当今的互联网已远非如此，所以我们要在各方面对信息安全和用户认证进行亡羊补牢。

数据在网络中流动的速度受限于最慢的链路。网络中的很多地方都会减慢流量，链路本身和数据传输路径上计算机对数据的处理过程都是常见的瓶颈。光速也是限制因素之一。信号在真空中的传播速度是每秒 3 亿米（用生活中的尺度说就是每纳秒约 30 厘米），在电路中则慢些，所以就算没有其他延迟，信号从一个地方传到另一个地方也要时间。按照真空中的光速，从美国东海岸到西海岸的 4000 公里要花 13 毫秒时间。相比之下，同样一段路程的互联网，由于经过了十来个路由器，延迟为 40 毫秒。而从美国东海岸到欧洲的互联网延迟是 50 毫秒，到北京是 140 毫秒，到悉尼是 110 毫秒。

生活中，你可能遇到过各种各样的带宽。我的第一只调制解调器每秒钟传输 110 个比特，这速度足以跟上机械打字机。前面章节提到过，现在的调制解调器的速率是 56 Kbit/s。家里的 802.11 无线网络，理论上可以运行在 600 Mbit/s，实际速率则要慢得多。有线以太网的带宽一般是 1 Gbit/s。从家到 ISP 的 DSL 专线或有线宽带连接的速度大概是每秒钟几兆比特，两者的上行速率又比下行速率慢很多。ISP 多半通过光缆连到互联网其他部分，其带宽在理论上有 100 Gbit/s 或更快，但实际则慢得多。

蜂窝电话的带宽跟上面的大部分相比都慢。智能手机的「3G」系统本应该在手机静止时提供 2 Mbit/s 的带宽，运动时的带宽则应为 384 Kbit/s，但 3G 这种不恰当的提法却给不实广告留下了空间。

IP 协议本身并不能保障带宽。实际上，作为「尽力而为」型的服务，它甚至都没有承诺信息一定会送达，更不要说有多么快了。互联网广泛使用缓存来加快数据传输，这在讲域名服务的时候我们都说过了。网页浏览器也缓存信息，所以如果你最近刚访问过某个页面或图像，再次打开它的时候，你所看到的页面或图像很可能来自本机缓存而不是网络。大型的互联网服务器也使用缓存来加快对大量访问者的响应。

数据压缩是更有效利用现有内存和带宽的好方法。压缩的基本思想是避免存储或传输冗余信息。所谓冗余信息，就是那些检索时或在通信链路另一端可以重建、推断出来的信息。压缩的目标是把相同信息编码成更少的比特或位。有些不包含信息的位，可以完全删除；有些位可以从别的位计算出来；有些位对接收者无意义，也可以放心丢弃。

下面以本书的英语文本为例。在所有单词中，字母出现的频率并不相同，e 最常见，其后依次大致是 t、a、o、i 和 n。反过来，z、x 和 q 就非常少见了。用 ASCII（American Standard Code For Information Interchange，美国信息交换标准代码）表示文本时，每个字母占 1 字节也就是 8 位。一种节省 1 位（蚊子腿也是肉啊）的方法，就是只使用 7 位，因为 ASCII 编码的第 8 位（也就是最左一位）永远是 0，不包含信息 [1]。同样，可以用更少位来表示那些常见字母，而必要的情况下用较多位表示那些不常见字母。这样，总的位数就可以显著减少。这就跟莫尔斯电码类似：一点表示 e，一划表示 t，但是 q 这种不常用的字母就是「划－划－点－划」。

3『这就是哈夫曼编码原理，常用的信息用短的编码，详见吴军的「信息论 40 讲」。』

说得再具体点，就以《傲慢与偏见》英文原文为例吧，该书大约有 97 000 个单词，占 550 000 字节。最常见的字符是单词间的空格，有 91 000 个，其次是 e（55 100 个）、t（36 900 个）、a（33 200 个），而最少的 X（大写）只出现 1 次，第二少的 Z（也是大写）则出现了 3 次。只看小写字母，最少的 j 是 469 次，q 是 509 次，z 和 x 都是 700 次左右。如果我们用两位数（二进制，以下同）来表示空格、e、t 和 a，那就会节省很多存储空间，这样就算 q、x、z、j 和其他不常见字符超过 8 位也没关系。有一种技术叫霍夫曼编码（Huffman coding），可以有条不紊地完成上述操作，为每个字母找到实现最佳压缩效果的编码值。用这种技术，可以把《傲慢与偏见》占用的空间压掉 44%，只剩 310 000 字节，即平均每个字母大约只用 4 位。

如果按大块文字而不是单个字母来压缩，可以得到更好的效果。例如，我们可以根据原始文档的属性选择按单词或词组压缩。在这方面，有好几个算法做得很棒。如广泛使用的 Zip 程序，可以将《傲慢与偏见》占用的空间压掉 64%，只剩 202 000 字节；而我所知的最好的算法（在 Unix 程序 bzip2 中），可以将该书压到 145 000 字节，只有原始大小的四分之一。

以上技术都属于无损压缩，即压缩过程中不丢失信息，解压后得到的数据和原始数据一模一样。另外一些情况下，并不需要准确重现原始输入，解压后的结果只要大致差不多就足够了（乍一听似乎有点违背直觉）。这时候，使用有损压缩可以得到更好的效果。有损压缩最常用于处理要给人看或听的内容。比如压缩数码相机拍出来的照片。人眼分辨不出来非常相近的颜色，所以不必保留实际输入的那么多种颜色，颜色少一点没有任何问题，这样就可以减少编码所用的位数。与此类似，某些难以觉察的细节也可以丢弃，这样处理后的图像尽管没有原始画面那么精密，但眼睛看不出来。细微的亮度变化也是如此。以随处可见的 .jpg 图像为例，相应的 JPEG 算法利用前面说的感知编码，能把常见图像压缩到十分之一或更小，但看上去也不会明显失真。生成 JPEG 图像的大多数程序都允许控制压缩率，「较高品质」就意味着较低的压缩率。

用于压缩电影和电视节目的 MPEG 系列算法也是按这个道理设计的。在 MPEG 中，单独一帧可以用 JPEG 压缩，还可以把连续的、变化不大的一系列帧压掉一部分。另外，也可以预测画面运动结果，只编码变化部分，甚至把运动的前景从静止的背景里分离出来，减少背景占用的位数。

MP3 是 MPEG 的音频部分，它是一个用来压缩声音的感知编码方案。除了通常的做法外，MP3 利用了人耳无法听到 20 kHz 以上频率（随着年龄增长，这个数值会有所降低）、明亮的声音会掩盖轻柔声音等事实。MP3 编码通常可以把标准 CD 音频压缩到原来的十分之一大小。

手机音频的压缩由于主要集中于人类语音，压缩率可以更高。语音可以比任意音频压缩得更明显，是因为其频率范围较窄，可以从只为个别扬声器建模的单个声道还原出来。知道了特定扬声器的特性，就可以获得更好的压缩效果。

所有压缩算法的思路都是减少或去掉那些不能物尽其用的位串，采用的主要方法包括把出现频率较高的元素编码成短位串、构造频率字典、用数字代替重复内容等。无损压缩能够完美重现原始数据，有损压缩通过丢弃接收者不需要的信息，来达成数据质量和压缩率的折中。

压缩时也可能需要权衡其他因素，如压缩速度和复杂性与解压速度和复杂性。数字电视画面撕裂成块或者声音断断续续，说明解压缩算法碰到了输入错误，可能是因为数据到达的速度不够快。不管是什么压缩算法，有些输入都是无法被压缩的。想象一下用某个算法压缩其前一次压缩得到的结果，你就会知道，任何压缩都是有限度的。

[1] 由于 ASCII 的这个特性，早期的很多串行通信系统，包括电传打字终端、RS-232 串口以至于互联网的某些协议，都为了节省存储空间而只传输 7 位数据。至今还可以在很多互联网协议里看到为了兼容 7 位传输而设计的安全编码方式。—— 译者注

如果压缩是去除冗余信息的过程，那么错误检测和校正就是加入精心控制的冗余信息以便检测错误甚至修正错误的过程。

有些常见数字没有冗余，这样，一旦出现错误就没法检测到。比如，美国的社会保障号码有 9 位，几乎任何 9 位数字都有可能是合法的社会保障号（如果有人要你填社会保障号码但实际上他们又没用时倒好办了，随便编 9 位数字就行）。如果多加几位数字，或者排除掉某些值，就可以检测出错误了。

这里使用了 IBM 公司的彼得·卢恩（Peter Luhn）于 1954 年设计的一个校验和（checksum）算法，来检测在实际操作中最常见的两种错误：单个数字错误、由于两个数字写错位置而引起的大多数换位错误。这个算法很简单：从最右一位数开始向左，把每个数字交替乘 1 或 2，如果结果大于 9 就减 9。如果把各位数的计算结果加起来，最后得到的总和能被 10 整除，那这个卡号就是有效卡号。你可以用这个方法测试一下自己的银行卡，或者某些银行广告中出现的卡号，如「4417 1234 5678 9112」。由于这个卡号计算的结果是 69，所以不是真卡号；如果把它的最后一个数字换成 3，那就是有效卡号了。10 位或 13 位的 ISBN 书号也采用了类似算法的校验和，用来对付同类错误。条形码和美国的邮政编码也使用了校验和。

这些算法都是用于十进制数字的专用算法。应用于二进制位的最简单的错误检测算法是奇偶校验码。这种算法为每组二进制位上附加一个奇偶校验位，其值的选择要满足如下条件：使该组二进制位中值为 1 的位有偶数个。这样如果出现一位错误，接收者就会看到奇数个 1，从而知道有内容被破坏了。当然，奇偶校验码并不能识别出哪一位有错，也不能检测两位同时出错的情况。

错误检测和校正广泛应用在计算和通信中。虽然针对不同类型的错误要使用不同的算法，但纠错码可以用在任意二进制数据上。比如，内存可以抵御在随机位置上出现的一位错误，CD 和 DVD 用编码防止错误位影响后面的持续播放，手机能抵御短暂的突发噪音。就像压缩一样，错误检测并不是万能的。总会出现这样的情况：一组数据，本来匹配某种合法模式，出错以后却匹配了另一种合法模式。

## 0303. 万维网

1990 年以来，万维网从无到有，发展到如今已然无处不在了。万维网改变了商业，也改变了我们的很多习惯。尤其是在消费行为方面，过去谁能想到搜索、网上商店、评级系统、比价网站和产品试用网站的威力呢。机遇和利益总是与问题和风险相逐又相随。万维网扩展了我们的生存空间，但也前所未有地让我们在陌生人面前暴露无遗，因此伤害也可能不期而至。

互联网最外在的一面就是万维网（World Wide Web），也就是我们常说的「上网」的「网」（简称 Web）。虽然平常我们不怎么区分互联网和万维网，但两者其实并不相同。万维网连接着提供信息和请求信息的计算机（提供信息的叫服务器，请求信息的叫客户端，比如我们的个人计算机），它通过互联网建立连接和传送信息，并为互联网支持的其他服务提供人机界面。

像许多伟大的理念一样，万维网在本质上是简单的。除了无处不在、高效、开放的底层网络必不可少外，万维网主要有以下四个组成要素。1）首先是 URL（Uniform Resource Locator，统一资源定位符），形如 http://www.amazon.com，用于指定要访问信息的名字以及信息所在位置。2）其次是 HTTP（HyperText Transfer Protocol，超文本传输协议），上一章刚刚介绍过这个高层协议。HTTP 的功能很简单，它让客户端能够请求某个 URL，同时让服务器能够返回客户端想要的信息。3）然后是 HTML（HyperText Markup Language，超文本标记语言），描述服务器返回信息的格式（或表现形式）。HTML 同样很简单，不需要什么背景知识就能掌握其基本用法。4）最后是浏览器，即运行在客户端计算机上的 Firefox、Internet Explorer 等程序，它通过 URL 和 HTTP 向服务器发送请求，然后读取并显示服务器返回的 HTML。

1『可以把 HTML 理解成服务器返给客户端信息的一种表现形式，即这个信息的格式。』

万维网的诞生可以追溯到 1989 年。当时，在日内瓦附近的欧洲核子研究中心（CERN）工作的英国物理学家蒂姆·伯纳斯-李（Tim Berners-Lee），为便于通过互联网共享科学文献和研究结果而设计了一套系统，包括 URL、HTTP 和 HTML，以及一个只能用文本模式查看可用资源的客户端。

世界上第一个图形界面的浏览器 Mosaic，是由伊利诺伊大学的一群学生开发的。Mosaic 的首个版本发布于 1993 年 2 月，很快就大获成功。次年，第一个商业浏览器 Netscape Navigator 面世。Netscape Navigator 是早期的成功者，而那时微软对互联网的蓬勃发展毫无意识。但不久，这个软件巨头还是觉醒了，随后很快推出竞争产品 Internet Explorer（IE）。IE 后来居上，成为最常用的浏览器，市场份额遥遥领先。微软在多个领域的市场统治地位引发了反垄断关注，公司也因此遭到了美国司法部的起诉，其中包括对 IE 的指控。据称微软利用其在操作系统领域的统治地位，将竞争对手 Netscape 排挤出了浏览器市场。

Web 技术的发展，由万维网联盟（World Wide Web Consortium，简称 W3C，其网站为 w3.org）这个非营利机构控制着（至少是引导者）。W3C 创始人和现任主席伯纳斯-李没想过靠自己的发明赚钱，而是慷慨地提出让所有人免费使用万维网，反倒是很多投身其中的人都托他的福，成了腰缠万贯的大富翁。2004 年，英国女王伊丽莎白二世授予伯纳斯-李爵士勋章。

假设你打开常用的浏览器，正在看一个简单的网页，页面中有些文字可能是蓝色的并带着下划线。用鼠标点击这些文字，当前页面就会换成蓝色文字指向的新页面。类似这样相互链接的页面就叫超文本（意思是「不光是文本」）。超文本实际上是个老概念，但浏览器把它推到每个人面前。

假设某个链接的内容是「W3C 主页」，把鼠标移到该链接上，浏览器窗口底部的状态栏就会显示链接指向的 URL，如 http://w3.org，域名之后也许还有其他信息。点击链接，浏览器就会打开一个到 w3.org 域的 80 端口的 TCP/IP 连接，然后发送 HTTP 请求，获取 URL 中域名后面部分表示的信息。例如，如果链接是 http://w3.org/index.html，那么请求的就是 w3.org 服务器上的 index.html 文件。收到请求后，w3.org 服务器首先判断接下来该怎么做。如果客户端请求获取的是服务器上的文件，服务器就将该文件发送回去，由客户端（也就是浏览器）显示出来。服务器返回的结果中通常也会包括指明数据长度和类型的额外信息。

以上只是最简单的描述，实际情况往往更复杂一些。HTTP 协议规定，浏览器可以在客户端请求中增加若干附加信息。服务器返回的结果中通常也会包括指明数据长度和类型的额外信息。

URL 自身会对信息进行编码。URL 开头的「http」是协议名，最常见的是 HTTP，占了很大比例。如果留意的话，偶尔也会看到其他协议开头的 URL，比如「file」表示信息来自本机（而不是网上）、「ftp」表示使用 FTP 协议传输文件、「https」表示采用经过加密的安全 HTTP 协议（本章稍后介绍该协议）。

接下来，「://」后面是域名，即服务器的名字。域名后面可以跟着斜线（/）和任何一串字符。这些字符串会原样传递给服务器，由服务器决定如何处置。最简单的情况是域名后什么都没有，连斜线也没有。在这种情况下，服务器将返回默认页面，比如 index.html。如果域名后有文件名，就返回其对应文件的内容。文件名之后如果有问号，一般表示问号前面的部分是程序，服务器会运行该程序并把问号后面部分作为参数传入。这就是服务器处理网页表单信息的一种方式。

URL 中的字符必须在某个字符集中，这个字符集里不包含空格和除字母、数字之外的大多数字符。当需要用到字符集之外的字符时，就要先对这些字符进行编码。例如，用加号来表示空格、用前面冠以百分号（%）的十六进制代码表示其他字符。

2009 年末，ICANN 批准使用以 Unicode 编码的「国际域名」。迄今为止，国际域名还仅限于顶级域，而且只为少数几个国家提供。以埃及为例，该国除了使用传统的 .eg 之外，也可以用阿拉伯文域名。显然，这在拉丁字母不通行的地方很有吸引力。

服务器返回的绝大多数文件都是 HTML 格式的，其中包含了文本内容和格式信息。HTML 其实相当简单，只要用你常用的文本编辑器就能编写 HTML 网页。（如果你用的是 Word 这样的字处理软件，切记用 .txt 纯文本格式保存网页而不要用默认格式。）HTML 文件用标签来表示格式信息，标签不仅可以内嵌文件内容，通常还可以标示页面区域的起始和结束位置。一个简单网页的 HTML 代码如下：

如果图像标签 <img> 里的文件无法访问，浏览器可能会在那个位置显示出一张「破损」的替代图片。在 HTML 中，有些标签是自包含的，比如 <img>；有些则有始有终，比如 <body> 和 </body>；还有些标签，如 <p>，虽然严格定义里要求有闭合标签 </p>，但在实际中并不需要 </p>。缩进和换行并非必需，但加上了会让 HTML 代码更易读。

本节讨论的这一点 HTML 恰好够用来揭开网页制作的神秘面纱。基本网页制作技术就是这么简单，只要再花几分钟时间学习，就能做出比上面例子更像样的页面。如果要制作你在商业站点看到的那些精美页面，就要掌握相当多的技能了。但只要学会十来个标签，应该就能胜任大部分纯文字页面，再学十来个，就能做出让一般用户侧目的东西来了。手工创建页面很简单，文字处理程序也有「创建 HTML」的选项。还有很多用来制作专业网页的软件，但只有在你真想学做网页设计的时候才需要。不过，最重要的还是理解网页背后的工作原理。

HTML 最初只能返回纯文本供浏览器显示。但没过多久，浏览器就得到改进，可以显示图像了，包括简单的 LOGO、GIF 格式的笑脸和 JPEG 格式的照片。此外，用户还可以在浏览器显示的网页里填写表单、按下按钮、弹出新窗口或用新窗口替换当前窗口。随后，当网络带宽足以支撑快速下载、主机性能可以快速处理图像显示时，声音、动画和电影马上又涌入了网页。

HTTP 协议里有一个从客户端（你的浏览器）向服务器传递信息的机制，叫通用网关接口（Common Gateway Interface，CGI）。只看这个名字，很难想象它能用来传递用户名和密码、查询条件、单选按钮和下拉菜单选项。CGI 机制在 HTML 里用 <form> ... </form> 标签来控制。你可以在 <form> 标签里放入文本输入区、按钮等常见界面元素。如果再加上一个「提交」按钮，按下去就会把表单里的数据发送到服务器，服务器用这些数据作为输入，来运行指定的程序。

在网页上输入名字后按下提交按钮，浏览器就把输入的名字（即 username 字段的内容）发送到服务器，服务器以它作为输入，运行 echoname 程序。echoname 程序的功能只有一个，就是返回一个嵌有输入名字的页面：

表单有很多局限，比如：只支持按钮、下拉菜单等少数界面元素；除了编写 JavaScript 代码或把表单数据发送给服务器进行处理外，没办法验证表单数据的正确性；没有对密码输入字段进行任何安全性保护，密码完全以明文的形式发送和存储在日志中。尽管如此，表单仍然是万维网的重要组成部分。

HTTP 协议是「无状态」的。「无状态」的意思是，HTTP 服务器不必记住不同客户端发送的请求信息，只要向客户端返回了请求的页面，它就可丢弃有关这次数据交换的全部记录。

于是，问题就来了：有时候服务器确实需要记住某些东西，如用户已经输入的名字和密码，这样后续的每一次交互就不必让用户反复输入了。怎样才能让 HTTP 记住这些东西呢？难点在于，客户端第一次和第二次访问服务器的时间可能间隔几小时、几星期，也可能访问一次以后再也不会访问，服务器要把信息保留多长时间呢？似乎只能靠瞎猜。

1994 年，Netscape 公司发明了一种叫 cookie 的解决方案。cookie 是在程序之间传递的一小段信息，这个名字虽有卖萌之嫌，但已经为广大程序员接受。向浏览器发送页面时，服务器可以附加若干个浏览器可存储的文本块，每个文本块就是一个 cookie，最大为 4000 字节左右。当浏览器再次访问同一个服务器时，再把 cookie 发送回服务器。没错，服务器就是这样利用客户端的内存来记住之前哪个浏览器曾访问过它的。服务器通常为每个客户端分配一个唯一的识别码，包含在 cookie 里；而和这个识别码相关联的永久信息如登录状态、购物车内容、用户喜好等，则由服务器上的数据库来维护。每当用户再次访问这个网站时，服务器就用 cookie 识别出用户原来之前来过，为其建立或恢复信息。

我通常会禁用 cookie，因此当我访问亚马逊时，起始页面跟我打招呼时通常只说「你好」。但如果我为了用购物车添加商品而启用 cookie，之后我再访问时它就会说「你好，布莱恩」。有人觉得这种表面上人性化的招呼很讨喜，但对我而言，这种做法时时提醒我完事后要删除 cookie 并重新将其禁用，以限制网站对我的跟踪。

每个 cookie 都有名字，一台服务器可以为一次访问存储多个 cookie。cookie 有失效时间，过期了就会被浏览器删除。浏览器只能将 cookie 发送给当初返回它的域，但是否接受或返回 cookie 并没有强制规定。需要指出的是，cookie 只是一串存储在浏览器中供以后返回服务器的字符，它是完全被动的，不会被返回给来源服务器之外的其他域。cookie 不是程序，也不包含动态内容。

理论上，cookie 的功能都是挺善意的，创造这一技术的本意也确实如此。但总会有些有违初衷的坏事发生，cookie 也被用到了人们不太喜欢的用途上。最常见的就是在用户浏览时跟踪其行为，生成用户访问网站的记录，然后令人生厌地向用户投放定向广告。

最初设计万维网的时候并没有考虑在客户端运行程序。第一个浏览器可以帮助用户生成请求、发送表单里的信息，并能在辅助程序的帮助下显示图片、声音等需要特殊处理的内容。不久之后，浏览器就能运行从网上下载的、有时被称为动态内容的代码了。至于如何执行，要取决于代码本身，跟浏览器也有关系，但基本思路就是把用某种语言写的代码下载到客户端计算机来运行。不难看出，这会带来某些影响，有些是有益的，也有些显然不是。

在第 6 章我们讲过，浏览器就像一个专用操作系统，可以通过扩展功能来处理纷繁复杂的内容，以此「增强你的浏览体验」。但是，为达成上述目的，需要你的浏览器运行别人写的程序，而你对这些程序的「品行」却一无所知。

在浏览器里运行程序的好处是可以增强浏览器的功能，而且当计算在本地完成时，交互会快很多。不利的一面在于，在你的计算机上运行未知来源的代码真的存在风险。显然，「我的身家性命全靠陌生人的良心」并不是靠谱的安全策略。微软有篇文章叫「关于安全的 10 个不变法则」（Ten Immutable Laws Of Security），第一条说的就是：如果有坏蛋能说服你在自己的计算机上运行他的程序，那你的计算机就不是你的了。

Netscape Navigator 的早期版本可以运行 Java 程序。那时候 Java 还是相对较新的语言，被设计成能轻松安装到计算能力不是很强的环境中（比如家电），所以在浏览器里包含 Java 解释器在技术上并没什么困难。这使得在浏览器里进行重大计算工作的前途一片光明：浏览器可能代替文字处理和电子表格这样的传统程序，甚至操作系统本身也可以被浏览器替代。这种前景让微软坐立不安，于是接连出手排挤 Java 的扩张。为此，Java 的创始者太阳微系统公司（Sun Microsystems）与微软多次对簿公堂。由于各种原因，Java 最终没有成为扩展浏览器的主要途径。Java 本身是一门功能丰富的语言，但与浏览器集成时受限较多，因此现在已经很少将 Java 用于扩展浏览器了 [1]。

[1] 有个很有趣的例子，兴业银行（http://www.cib.com.cn）的「个人网上银行」登录页面里，有脚本检测浏览器类型，如果是 Internet Explorer，就开启一个用 ActiveX（本节稍后将会讲到）写的密码保护控件；对于不支持 ActiveX 的浏览器，则使用 Java 版本。—— 译者注

1995 年，Netscape 还推出了一种专用于其浏览器的新语言 JavaScript。别看名字里有 Java，其实 JavaScript 跟 Java 没有任何关系，唯一能扯上关系的是两者写出来的程序都长得像 C 语言。选择这个名字只是出于市场宣传的目的。[2] Java 和 JavaScript 的实现都使用了虚拟机，但两者的技术差别很明显。Java 源代码在其创建之处编译，生成的目标代码发送到浏览器解释运行，因此你看不到初始的 Java 源代码是什么样子的；而 JavaScript 发送到浏览器的就是源代码，整个编译过程都在浏览器里进行，从而使接收到 JavaScript 程序的人能看到要执行的代码。由于接收到 JavaScript 源代码的人不但可以运行它，而且也能研究和改写它，因此，没有办法保护 JavaScript 源代码。

[2] 事实上，JavaScript 的语言特性主要来自 Self 和 Scheme 语言，只是使用了类似 C 语言风格的记法。JavaScript 一开始也不叫这名字，而是叫 LiveScript，后来因 Netscape 和 Sun 合作，才把名字改为 JavaScript 以便市场推广。—— 译者注

如今的大多数网页都包含一些 JavaScript 代码，用来展示图形特效、验证表单信息、弹出有用的和讨厌的窗口等等。尽管一方面弹窗拦截器减轻了 JavaScript 弹出广告给人们带来的烦恼，以致连浏览器现在都集成了拦截功能，但另一方面，用 JavaScript 进行的复杂跟踪和监控活动也增长迅猛。虽然像 NoScript 和 Ghostery 这样的浏览器附加程序可以控制 JavaScript 代码的可运行功能，但由于 JavaScript 用得太广，如果不允许或限制浏览器运行 JavaScript，我们上网时就会困难重重。尽管有段时间我很担心 JavaScript 的负面影响，尤其担心网站会用它来跟踪我上网浏览的行为（下一章将会谈到如何跟踪），但权衡下来，我觉得 JavaScript 还是利大于弊。我隔三差五地彻底停用 JavaScript，然后又因为我关注的很多站点用到了这玩意而重新启用。

借助浏览器自己的代码或 Apple QuickTime、Adobe Flash 这样的插件，浏览器也可以处理其他语言和内容。插件是按照需求动态加载到浏览器的程序，一般由第三方开发。如果你访问的页面里有浏览器自己不能处理的内容，浏览器会提示你「获取插件」。意思就是要你下载一个新程序，在你的计算机里配合浏览器一起运行。插件能做什么呢？理论上它可以为所欲为。所以你不得不信任插件的发行者，否则就没法显示那些内容。

插件是编译好的代码，通过调用浏览器提供的 API，作为浏览器的一部分运行。常用的插件包括遍地都是的 Flash 动画播放器和微软的 Silverlight 等，后者是取代 Flash 处理视频和其他服务的另一种选择。对于插件，如果我们长话短说，那就是：如果你信任插件的来源，那在使用它的时候，就跟使用其他有瑕疵和会监控你行为的代码没什么两样。HTML 的新版本 HTML5 为浏览器带来了新功能，可以减少对插件的依赖，尤其是在视频和图形方面。但在很长一段时间内，插件还会继续扮演重要角色。

可控性最差或者说最不可控的浏览器扩展技术是微软的 ActiveX，这种技术能让 Internet Explorer 加载代码并运行。ActiveX 像是搅起了江湖血雨腥风的武林秘籍：代码本身不受限制，可以运行任何 Windows 功能，所以实际上能完全控制你的计算机。显然，这是一把双刃剑：用 ActiveX 组件可以实现任何功能，但出错的风险也大大增加 —— 如果代码来自一个坏蛋，造成真正损害的可能性就更大了。由于你没办法知道 ActiveX 组件到底会做什么，于是只好无奈地信任它的发行者。

为此，微软搞出了一种叫 Authenticode 的数字签名机制，想用这种办法来确保代码至少是来自它所声称的发行者而不是别人假冒的。在 Internet Explorer 的安全模式里，也确实有只允许下载和运行已签名的 ActiveX 代码的选项。当然，这种方法还是不能保证代码只执行正确操作，甚至也不能保证代码来源友善，但总比摸黑运行未知来源的代码要好一些。

除了网页，动态内容也可出现在万维网的其他地方。随着万维网服务的增长（下一章将会提到），这些动态内容中潜在的问题也愈发严重。试想一下电子邮件吧。邮件到达的时候，会显示在邮件阅读程序里。显然，邮件阅读器一定要显示文本内容，而值得关注的是，如果邮件包含了其他内容，应该解析到什么程度为好，因为这是关系到用户隐私和安全的大事。

邮件正文里有 HTML 会怎样？虽然邮件里出现大号红头文字会让收信人不悦，但显示这样的邮件其实并无危害。邮件阅读器应该自动显示图像吗？这样便于收件人查看照片，但也为更多的 cookie 打开了方便之门。我们可以通过立法来禁止这些行为，但又能用什么办法来阻止发件人在邮件里嵌入 1×1 的透明像素并在其 URL 里编入收件人的某些信息呢（这些看不到的图像有时称为网页信标，web beacons [1]）？支持 HTML 的邮件阅读器会按 URL 请求这些图像，从而使存放图像的网站得知你在某个时候读了这封邮件。通过跟踪你阅读邮件的时间，有可能获得你本想保密的信息。

如果邮件阅读器能处理 HTML，那它也要解析 JavaScript 吗？最近我试用了一个新推出的基于网页的邮件阅读器。令人惊讶的是，它不但解析了邮件里的 JavaScript，甚至按其默认设置在不提示我的情况下，就自作主张地执行了这些代码。

如果邮件里包含 Word、Excel、PowerPoint、PDF 文档或 Flash 电影，又会发生什么呢？邮件阅读器应该自动运行这些程序吗？还是退而求其次，但为了方便你使用，仍然允许在邮件某个位置点一下就运行呢？再多想一步，应该让你直接点击邮件里的链接吗？要知道，这可是引诱你上当的好把戏。此外，PDF 文档也可以包含 JavaScript（第一次听说时，我也吃了一惊），如果邮件阅读器自动调用 PDF 阅读器，那后者又是否应该自动执行 PDF 文件里的 JavaScript 代码呢？

在邮件里附加文档、电子表格、幻灯片是非常便利的，这也是商业社会的标准做法。但考虑到这些文档可能携带病毒，我们马上会看到，不分青红皂白地打开附件的做法会助长病毒的蔓延。

还有更糟糕的状况 —— 邮件里包含可执行文件，比如 Windows 的.exe 文件之类的。点击这样的附件就会启动这些程序，极有可能在运行后给你或你的系统带来危害。网上的坏蛋们会用各种伎俩骗你运行这些程序。我曾经收到一封邮件，声称里头有俄罗斯网球运动员安娜·库尔尼科娃的照片，鼓励我打开看看。该文件的名字是 kournikova.jpg.vbs，但是扩展名.vbs 隐藏了起来（Windows 默认隐藏扩展名，这个设计害人不浅），收件人很难发现它并非照片而是 Visual Basic 程序。

病毒和蠕虫。这两个词都指在系统间传播的、通常是恶意的代码。两者在技术上有个细微的差别：病毒的传播需要人工介入，也就是只有你的操作才能催生它的传播；而蠕虫的传播却不需要你的援手。

在互联网广泛使用之前，软盘是在 PC 之间交换程序和数据的标准介质。病毒因此通过受感染的软盘，肆虐传播了多年。当计算机加载受感染的软盘时，隐藏在其中的病毒自动运行，把自己复制到本地计算机，并进一步感染后续插入的新软盘。

随着微软在 Office 程序尤其是 Word 中包含 Visual Basic，病毒的传播更加容易了。由于 Word 中内建 VB 解释器（至今仍在），Word（.doc、.docx 文件）、Excel 和 PowerPoint 文档中可以包含 VB 程序，因此写个程序在文档打开时获取控制易如反掌。而且，由于 VB 能访问 Windows 操作系统的全部功能，这类程序可以在操作系统中恣意妄为，做任何事。一般来说，病毒会首先安装在本机上，然后想方设法传播到别的系统上。一种常见的病毒传播模式是：病毒把自己附在一封写着无害或诱惑言辞的电子邮件里，寄给被攻击邮件地址簿里的每个人。

特洛伊木马（在网络安全的语境中，通常简称木马）是伪装成有益或无害，但实际上有害的程序。因为看起来有一定用处，所以受害者会禁不住诱惑而下载、安装木马。常见的情况是，木马程序自称要对用户的系统进行安全分析，实则是安装恶意软件。

前面提到过，软盘曾是病毒的传播介质。随着存储设备的更新，现在这一角色开始由 USB 闪存驱动器接替。也许有人认为闪存驱动器只有存储功能，是个被动设备，很难传播病毒。然而，以 Windows 为代表的一些系统，都有个「自动运行」的功能：当插入 CD、DVD 或闪存驱动器时，系统会自动从盘上运行某个程序。恶意程序会在没有警告的情况下自动安装，造成令人措手不及的破坏。即便大多数公司规定严格的安全策略，限制在公司计算机插入 USB 驱动器，但还是有相当多的系统通过这种方式遭受感染。个别情况下，甚至新买的驱动器里都会带有病毒。

万维网引发了很多安全难题。一般来说，可以把万维网遇到的安全威胁分成三类：对客户端（也就是使用浏览器的你）的攻击、对服务器（例如网上商店或者银行帐户）的攻击和对传输中信息的攻击（比如窃听无线网络）。

对你的攻击不仅包括垃圾邮件、跟踪等惹人讨厌的攻击，还包括泄露你的信用卡和银行账号等私密信息、假冒你花掉你的钱等更严重的攻击行为。

下一章我们会详细讨论 cookie 和其他跟踪机制如何监控你的上网行为、给你发送看似吸引人从而不是那么烦人的广告。实际上，通过禁用第三方 cookie（也就是从别的网站而不是你正在访问的网站发送过来的 cookie），就可以堵住大部分跟踪攻击。如果再使用其他浏览器插件来禁止跟踪程序运行、关闭 JavaScript、禁用 Flash，采取这些防护手段就能把跟踪和广告的数量限制到可控的程度。也许有时你会嫌这些防护手段麻烦，因为这样披挂上阵会导致有的网站无法访问。遇到这种情况时，就要把防护的级别临时调低一些，但要记得访问完这些网站后再复原。

垃圾邮件是不请自来的邮件，其内容通常是发家致富秘籍、洗髓易筋偏方、职场蹿升宝典和很多没用的其他商品和服务。垃圾邮件业已泛滥成灾，严重影响了电子邮件的正常使用。我自己通常每天收到 50 到 100 封垃圾邮件，远比真正的邮件多得多。据可信调查称，所有电子邮件中的 90% 是垃圾邮件。最近我看到一篇文章则说，万维网上每天发送的垃圾邮件多达 2500 亿封。垃圾邮件之所以如此泛滥，主要原因在于发送成本极低（上面那篇文章里说，发送 100 万封垃圾邮件只要 80 美元成本）。就算几百万收件人里回复的只占个零头，也够那些发件人赚回来了。

这种精确瞄准的攻击方式有时叫做鱼叉式网络钓鱼（spear phishing）。鱼叉式网络钓鱼是一种社会工程方法，即假装是受害人的私交密友，或者冒称同事，诱使受害人犯傻。

间谍软件（spyware）是指运行在你的计算机上、会把你的信息送到别处去的程序。有些间谍软件显然是恶意的，但有些只是为了商业目的而私自收集用户信息。例如，我有几台笔记本预装了包探测器程序 pinger，该程序开机自动运行，然后定期连接到厂家的服务器。至少在我某天发现并将之禁用之前，它一直在这么做。我相信如果质问厂家的话，他们一定会告诉我这个包探测器只是向他们报告我机子持续运行时的健康状态并检查软件更新。问题是：我从没收到关于这个程序的说明，也没见过打开这个功能的选项，更不要说给我机会关掉它了。

攻击者入侵客户端计算机之后，就可以查看其文件系统，或者悄悄安装按键记录器抓取用户输入的口令和其他数据，这样就能从源头窃取信息。按键记录器是在客户机上监控所有按键行为的程序，所以能抓到用户输入的口令。而且在这种情况下，加密也没用 [2]。这种程序也可能开启计算机的话筒和摄像头。

为阻止对服务器的攻击，服务器的编程和配置必须非常仔细，不论客户端发来的请求构造得多么精心，都要确保不泄露未授权信息，不允许未授权访问。但实际上，服务器上运行着的大型复杂程序，使服务器容易出现可能被攻击者利用的编程缺陷和配置错误。SQL 注入（SQL injection）就是一种常见的针对服务器的攻击方式。在万维网上，服务器一般在后台运行数据库，访问数据库时通常使用标准接口 SQL（Structured Query Language，结构化查询语言）。如果没有严格限定访问权限，机灵的攻击者就可以提交精心构造的 SQL 查询指令来检查数据库结构，从而提取未授权的信息，甚至有可能在服务器上运行他们自己写的代码，进而控制整个系统。尽管上述攻击及其防御机制是众所周知的，但服务器被攻击的事件仍然不断发生。

系统一旦沦陷，能制约入侵者恶行的限制就很少了。特别是当入侵者设法获得了 root 权限（也就是系统的最高级别管理权限）时，他们就更会为所欲为。不论是对服务器，还是对你家里的个人计算机，都是如此。获得服务器 root 权限后，入侵者就能摧毁网站，或者在网站上发布令人尴尬的言论以丑化所有者的形象。还可能下载破坏性程序，或者在网站上存储并发布色情图片和盗版软件等违法内容。服务器可能会因此丢失大批数据，个人计算机一样在劫难逃。

服务器还经常遭遇拒绝服务攻击（DoS，Denial of Service）。在这种攻击中，发起者把大量网络流量引导到一个网站，利用密集的访问使其停止响应。拒绝服务攻击是精心策划的，通常用僵尸网络来完成：沦陷的肉鸡接到命令后，会在指定时间访问指定网站，从而导致流量骤增。从多个来源同时发起的拒绝服务攻击通常称为分布式拒绝服务攻击（DDoS，Distributed Denial of Service）。

不幸的是，防御者需要防住所有可能的攻击，而攻击者只要找到木桶的一块短板就行。因此，这场攻防战的双方是不对等的，天平倾向于攻击一方。

尽管对传输中信息的攻击仍然很严重也很常见，但这个问题在万维网安全中往往是放到最后考虑的。无线网络的普及，或许会提高人们对这个问题的重视程度。例如，坏蛋可能会偷听你和银行的对话，窃走你的帐号、口令等信息。但如果你和银行之间的通信是加过密的，偷听者就很难分析出他听到的数据是什么意思了。HTTPS 协议是加强型的 HTTP，对请求和应答双向数据都做了加密。这样，偷听者通常就不能读取信息，也无法伪装成通信中的任何一方。然而，由于 HTTPS 并没有被广泛使用，攻击者仍然可以用 Firesheep 之类的程序在咖啡馆、机场和提供无线上网服务的其他公共场所偷听连接，从而可以让他们假扮成你，而你根本无法察觉到。靠窃听商店里未加密的终端机通信就可以获得信息卡信息：窃贼坐在商店外的车里，一有交易发生，窃听设备就可以捕获信用卡数据。还有一种攻击形式是「中间人攻击」，即攻击者截获消息，并按自身需要加以修改后发出去，该消息看起来是直接来自源头的。

VPN（Virtual Private Network，虚拟专用网）在两台计算机间建立起加密的通道，以保证其间双向通信的安全 [1]。企业通常通过部署 VPN 来让员工在家里办公，或者到国外出差时连回公司。用户登录 VPN 不仅需要输入口令，还需要持有一个物理设备。这种「双因子」认证比只输入口令要安全，因为它不仅需要用户知道某些信息（口令），还需要拥有某些实物（设备）。在实际应用中，这个设备可以是手机里运行的程序，能按某种算法生成动态数码以便跟服务器上用同样算法生成的数码匹配，也可以是一个能显示数码的专用设备，在输口令时把设备显示的数码一起输进去。双因子认证技术不仅用于 VPN，也可用于银行和其他在线账号服务。

[1] 第 9 章曾经提到，网关也是一种专用的计算机。如果两个网络不直接相连，也可以用 VPN 在它们各自的网关之间建立加密通道，从而实现网络到网络的安全通信。—— 译者注

个人计算机用户如何进行自我防御？有人向我征求这个意见时，我会用本节的内容告诉他。我把计算机用户的防御手段分成三类：第一类非常重要，第二类中等重要，第三类则要看你的偏执程度。（如你所料，第三类我就不细讲了，因为大多数人根本不会偏执到这种程度。）

1『细节可以详见原文。』

加密的基本思路是，张三和李四 [2] 想互相交换消息，要求通信内容保密，但并不掩盖他们正在通信的事实。要做到这一点，他们需要共享用来扰乱以及随后恢复要传递消息的同一段密文，这样，别人就看不懂他们写了什么，只有两位当事人自己看得懂。用来加密消息的密文被称为密钥。例如，在凯撒密码里，密钥就是字母移位的距离，3 表示把 A 换成 D。对于恩尼格玛密码机这种复杂的机械加密设备来说，密钥就是若干代码转子设置和一组插头接线方式的组合。基于计算机的现代密码系统则使用巨大的秘密数字作为密钥，把秘密数字作为变换消息中比特流的复杂算法的输入。这样，如果不知道这个数字，就不可能还原消息。

有多种方法用来对加密算法实施攻击。频率分析法统计密码中每个符号出现的频率，可以轻松干掉凯撒密码和报纸上填字游戏所用的简单替换密码。要抵御频率分析，加密算法必须要做到让密文中所有符号都以大致相等的机会出现，以做到没有模式可供分析。但有时候，攻击者可能知道与待破解密钥加密的密文相对应的明文；即使不知道，他们还可能会选取一段明文，诱使被攻击者用待破解密钥加密这段明文，从而两相对照，达到破解的目的。好的算法要能有效抵御所有这些攻击。

现代密码学必须假定攻击者知道并完全理解密码系统的工作原理，从而将所有的安全性都寄托在密钥上。与此相反的做法是假定对手不知道系统用什么加密方案、如何破解，这被称为隐匿式安全，只要时间一长，这种做法肯定要完蛋。苏格兰女王玛丽、山本五十六和德军都没有重视这个至关重要的事实，并为此付出了致命的代价。实际上，如果有人鼓吹他们的加密系统十分安全，却不愿说出其工作原理，那就可以确信它并不安全。

目前使用的加密系统基本可分成两类。一类是历史较长的密钥加密，也称对称密钥加密，因为加密和解密要使用相同的钥匙。「对称」这个词能更好地描述其本质，但「密钥」则让人更容易区分它与另一类加密系统：公钥加密。

1『密钥加密和公钥加密的详细细节详见原文。』

## 0304. 数据、信息和隐私

「举手之劳，无不可及」（Reach out and touch someone）曾是 1980 年代 AT&T 效果很好的一句广告语。今天，Web、电子邮件、社交网站、云计算，以及各种端到端的系统都可以实现这个愿景。有时候，这幅图景很美好。你可以在比以前大得多的圈子里交朋友，分享自己的兴趣爱好。然而，举手之劳也可以让你在世界面前暴露无遗，此时可不是人人都会只念你的好。垃圾邮件、欺诈、间谍软件、病毒、监视、冒名顶替、泄漏隐私信息，甚至遗失财产，种种不幸都会接踵而来。小心谨慎才是明智之举。

数字技术为人类带来了无数便利，少了它，我们的生活会平淡乏味很多。与此同时，数字技术也给每个人的隐私带来了空前的威胁。而且，（用本书责任编辑的话来说）这种情况只会越来越糟糕。对个人隐私的这种侵害，有些是因为互联网及其应用，有些则是数字设备变得越来越小、越来越便宜、越来越快带来的副作用。与日俱增的处理能力、存储容量和通信带宽，使采集和保留各种信息、高效地分析数据，然后无远弗届地传播变得易如反掌，而且成本几乎可以忽略不计。