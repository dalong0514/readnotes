## 记忆时间

## 目录

0401面向业务交易的信息架构建设

0501面向联接共享的数据底座建设

0601面向自助消费的数据服务建设

## 0401. 面向业务交易的信息架构建设

### 本章小结

在企业数字化转型过程中，企业信息架构的定位、内涵和管理方式都在不断地演进。信息架构的定位发生了根本性的变化，不再是对准 IT 功能或实现，而是对准整个企业的业务管理目标；信息架构的内涵也进行了极大的扩展，不再只是聚焦于进入类似 ERP 系统的结构化数据，而是对准整个企业在业务中产生的各种结构化数据、非结构化数据、内外部数据、过程类数据、规则类数据、IoT 数据等；信息架构的管理方式也发生了颠覆性的改变，不再是抽象化的、预先定义好的、一次定义覆盖所有场景的标准，而是全量的、实时产生的、满足差异化要求的，甚至是随需定义的标准。

在这样的背景下，需要对原有信息架构框架和方法论不断进行审视和优化，可能两年前刚刚确定的框架已经不能满足要求，甚至一年前发布的架构规则就要重新修订。在企业实现数字化转型的过程中，信息架构管理的结构、技术、组件、标准可能永远不会稳定，永远在进化。

1-2『有感触，之前的是更多的是面向「管理」，其实应该更多的面向「作业」，即业务。面向业务的信息架构管理，做一张主题卡片。（2021-07-24）』—— 已完成

### 4.0

华为过去的信息架构建设主要是为了实现「信息化」或「业务上 ERP」，信息架构往往隐藏在系统中、隐藏在 IT 功能下。对于大部分业务作业人员和管理者而言，他们的关注点更多聚焦在「功能是否完善」或「业务是在系统中完成还是手工完成」上。此时，对信息架构的要求仅限于支撑好各类 IT 系统的落地，或在一定范围内对 IT 建设提供指导。

随着企业数字化转型的推进，华为公司越来越认识到信息架构的价值并不应局限于「支撑 IT 建设落地」，而是更好地管理企业数据资产，更好地提升整个业务交易链条的效率，甚至基于信息架构重新审视业务边界的划分和整合。

### 4.1 信息架构的四个组件

企业在运作过程中，首先需要管理好人和物等「资源」，然后管理好各类资源之间的联系，即各类业务交易「事件」，再对各类事件的执行效果进行「整体描述和评估」，最终实现组织目标和价值。

以一个通用的工业企业运营为例（如图 4-1 所示），企业要管理关键的「员工、组织、产品、客户、供应商」等资源。在企业价值实现的过程中，企业会与客户签订销售合同，与供应商签订采购合同，组建各种交付项目，制定供应计划，财务部门会对成本、费用、收入进行核算，记录客户的应收、供应商的应付，建立合法合规的会计记账体系。然后，通过报告体系按月度、季度、年度发布各种经营、考核报告用于企业决策。

图 4-1 信息架构视图示例

信息架构的目的就是定义好整个运作过程中涉及的各种人、事、物资源，并实施有效的治理，从而确保各类数据在企业各业务单元间高效、准确地传递，上下游流程快速地执行和运作。

华为在实践中构建了一套对业务运作数据进行有效管理的信息架构方法论，用于指导企业内部各部门的信息架构建设工作，让管理者、专家和员工之间有共同语言。

华为的企业级信息架构（Information Architecture）是指以结构化的方式描述在业务运作和管理决策中所需要的各类信息及其关系的一套整体组件规范，包括数据资产目录、数据标准、企业级数据模型和数据分布四个组件，如图 4-2 所示。

图 4-2 华为企业级信息架构的四个组件

#### 4.1.1 数据资产目录

数据资产目录形成完善的企业资产地图，也在一定程度上为企业数据治理、业务变革提供了指引。基于数据资产目录可以识别数据管理责任，解决数据问题争议，帮助企业更好地对业务变革进行规划设计，避免重复建设。

数据资产目录分为 5 层，涵盖华为公司的所有业务数据资产，如图 4-3 所示。

L1 为主题域分组：主题域分组是公司顶层信息分类，通过数据视角体现公司最高层面关注的业务领域。

L2 为主题域：主题域是互不重叠数据的高层面的分类，用于管理其下一级的业务对象。

L3 为业务对象：业务对象是业务领域重要的人、事、物，承载了业务运作和管理涉及的重要信息。

L4 是逻辑数据实体：逻辑数据实体是具有一定逻辑关系的数据属性的集合。

L5 为属性：属性是描述所属业务对象的性质和特征，反映信息管理最小粒度。

1『上面的信息是图 4-3 的文本化，看原图更形象，还有举例。（2021-07-24）』

图 4-3 数据资产的 5 层结构

L1 为主题域分组，是描述公司数据管理的最高层级分类。业界通常有两种数据资产分类方式：基于数据自身特征边界进行分类和基于业务管理边界进行分类。华为公司为了强化企业内业务部门的数据管理责任，更好地推进数据资产建设、数据治理和数据消费建设，采用业务管理边界划分方式，即将 L1 主题域分组与流程架构 L1 相匹配，数据资产和华为业务 GPO（全球流程责任人）相匹配，有利于更好地推进各项数据工作。

L2 为主题域，是互不重叠的数据分类，管辖一组密切相关的业务对象，通常同一个主题域有相同的数据 Owner。

L3 为业务对象，是信息架构的核心层，用于定义业务领域重要的人、事、物，架构建设和治理主要围绕业务对象开展。同时，在企业架构（EA）的范畴内，信息架构（IA）也主要通过业务对象实现与业务架构（BA）、应用架构（AA）、技术架构（TA）的架构集成。

L4 是逻辑数据实体，是指描述一个业务对象在某方面特征的一组属性集合。

L5 为属性，是信息架构的最小颗粒，用于客观描述业务对象在某方面的性质和特征。

#### 4.1.2 数据标准

数据标准是在企业范围内确保数据一致的关键，因此有必要多花一些篇幅来详细介绍。

数据标准定义公司层面需共同遵守的属性层数据含义和业务规则，是公司层面对某个数据的共同理解，这些理解一旦确定下来，就应作为企业层面的标准在企业内被共同遵守。

例如，合同是公司最重要的数据之一，因此有必要对合同编号制订统一的数据标准，包括编号的位数、具体的编码规则等，一旦合同编号数据标准制订下来，那么整个公司所有业务部门都必须共同遵守，除了数据 Owner 以外，任何部门都不允许自定义合同编号。如果随着业务发展需要对合同编号进行变更，那么相关需求也应该统一由数据 Owner 受理，统一制订变更方案。一旦不同业务环节各自定义，那么数据就无法在上下游业务之间快速流转，往往需要额外的人工转换和翻译，这会极大地增加不必要的人工成本、延长业务执行周期、降低业务效率。

表 4-1 展示了华为在数据治理早期阶段，各个 BG 的分类定义不统一问题。

表 4-1 数据定义不一致问题示例

以基础数据「运营商 BG」为例，有的系统叫「carrier network」，有的系统叫「operator」，还有的系统叫「CNBG」，那么在统计「运营商 BG」视角的财务报告时，数据处理人员需要将标识为「carrier network」「operator」「CNBG」的数据进行分类清洗和处理，而不能直接卷积得到结果，增加了额外的处理时间和投入。如果数据处理人员不清楚「运营商 BG」这个数据在诸多系统中的名称不一致的情况，那么很可能在统计时丢失部分数据，导致最终报告的失真，最终可能误导决策。

华为公司对业务数据标准有严格的限定，每个数据标准应该覆盖以下三方面。

1、业务视角要求：用于统一业务侧语言和理解，明确定义每个属性所遵从的业务定义和用途、业务规则、同义词，并对名称进行统一定义，避免重复。

2、技术视角要求：对 IT 实施形成必要的指引和约束，包括数据类型、长度，如果存在多个允许值，则应对每个允许值进行明确的限定。

3、管理视角要求：明确各业务部门在贯彻数据标准管理方面应承担的责任，包括业务规则责任主体、数据维护责任主体、数据监控责任主体，因为很多情况下这些责任并不是由同一个业务部门来负责，所以必须在标准制订时就约定清楚。例如，「客户合同」中某些条款的规则制订者可能是财经部门，负责与客户达成约定并在系统中录入的可能是销售业务部门，而对整个客户合同数据质量进行跟踪、监控的可能是数据专业部门。

但是，企业的每个业务数据标准的定义和维护都需要一定的成本，很多大型企业的 IT 系统中可能存在上百万、上千万属性，即使去掉冗余、重复的部分，数据量也相当大，因此其实并不需要对 IT 系统内所有字段都进行定义。为了实现在统一定义的必要性和成本之间取得平衡，华为公司制订了数据标准规范，明确了在不同情况下哪些数据应该制订统一的标准。

1、描述业务对象的特有属性应作为本业务对象的属性进行定义，并明确业务数据标准。

2、引用其他业务对象的属性，如果属性值可随本业务对象确定和更改，就应作为本业务对象的属性进行定义，并明确业务数据标准。

3、引用其他业务对象的属性，如果属性值取自引用业务对象相应时点的数值且后续不变更，就应纳入本业务对象的数据标准范围，并明确相应取值规则。

4、引用其他业务对象的属性，如果属性值与引用业务对象同步，就不需要重新定义数据标准。

5、引用其他业务对象 / 逻辑数据实体的身份标识属性，应作为本业务对象的属性进行定义，但只能在业务数据标准中定义出处及引用规则，而不允许修改或重新定义该属性本身的业务含义及业务规则。

#### 4.1.3 数据模型

数据模型是从数据视角对现实世界特征的模拟和抽象，根据业务需求抽取信息的主要特征，反映业务信息（对象）之间的关联关系。

数据模型不仅能比较真实地模拟业务（场景），同时也是对重要业务模式和规则的固化。例如在某个物流业务数据模型中，「运输申付单」与「运输委托」建立一对一关系，而「运输委托」与「派送任务」建立多对多关系，那么这意味着业务部门可以根据发货效率和成本的考虑将「运输委托」拆成分多个「派送任务」，但「派送任务」必须在将一个运输委托完整执行后，才能申请向供应商付款。

#### 4.1.4 数据分布

如果说前三个组件主要是从静态角度对数据、数据关系进行定义，那么数据分布则定义了数据产生的源头及在各流程和 IT 系统间的流动情况。数据分布组件的核心是数据源，指业务上首次正式发布某项数据的应用系统，并经过数据管理专业组织认证，作为企业范围内唯一数据源头被周边系统调用。

华为公司规定所有业务数据必须认证数据源，并在公司范围内统一发布。为了更好地识别、管理数据在流程和 IT 系统间的流动，可以通过信息链、数据流来进行描述，体现某一数据在流程或应用系统中是如何被创建（Create）、读取（Read）、更新（Update）、删除（Delete）的。

### 4.2 信息架构原则：建立企业层面的共同行为准则

信息架构承载了企业如何管理数据资产的方法，需要从整个企业层面制订统一的原则，这些原则不仅是对数据专业人员的要求，也是对业务的要求，因为业务才是真正的数据 Owner。所以，公司所有业务部门都应该共同遵从信息架构原则。

华为首先确定了「数据同源一致」的治理目标，围绕目标的实现，制定了五条架构原则。各业务领域和变革项目应按照架构原则设计其信息架构，并由 EAC（企业架构委员会）、IA-SAG（信息架构专家组）指导和监督各领域落实企业架构原则，在一套规则的约束下，共同建设一个企业级的信息架构。

原则一：数据按对象管理，明确数据 Owner。

数据要发挥作用，必然会在多个 IT 系统和流程中流转，并且越是重要的数据资产，所流经的业务环节就越多。例如，产品、人员、客户的数据几乎在所有流程中都会涉及，客户合同数据也会在整个业务交易链条中流转，因此不应该以 IT 系统、业务流程边界来管理数据，而应该从数据本身出发，按对象进行数据全生命周期管理。

1-2『很受启发，不从 IT 系统、业主流程的视角管理数据，直接从数据本身的视角管理数据，即数据按对象管理（数据 Owner）。这里的信息也补充进主题卡片「面向业务的信息架构管理」。（2021-07-24）』—— 已完成

几乎所有的企业数据都是由业务产生的，IT 人员无法对数据的定义、质量负责，因此需要在公司层面确定数据 Owner。华为公司按照业务对象任命数据 Owner，并且每个数据都只能有唯一的数据 Owner。数据 Owner 要负责所辖领域的信息架构建设和维护，负责保障所辖领域的数据质量，承接公司各个部门对本领域数据的需求，并有责任建立数据问题回溯和奖惩机制，对所辖领域的数据问题及争议进行裁决，公司有权对不遵从信息架构或存在严重数据质量问题的责任人进行问责。

原则二：从企业视角定义信息架构。

任何一个数据 Owner 都不只代表自己所辖业务范围的数据管理诉求，而是代表公司对数据进行管理。华为在数据治理实践中，为了拉通各部门所产生的数据结构和流转路径，实现数据在企业内共享和流通的目标，明确要求各业务领域都需站在企业的视角定义信息架构，充分考虑数据的应用场景、范围和用户群体，参考业界实践和主流软件包，平衡和兼顾 AS-IS（现状）和 TO-BE（未来）诉求，在流程设计和 IT 实现中得到落实。

以前面的合同编号为例，销售部门作为数据 Owner 有责任定义合同信息架构，但不应只考虑销售环节对合同编号的管理诉求，而是应该综合考虑供应、交付、财经等各个环节对合同的诉求，合同在整个交易链条中延伸的范围就是相应数据 Owner 所综合覆盖的范围。在这个链条中，任何业务部门对合同编号的诉求，都可以提交给数据 Owner；同时，合同数据 Owner 对所辖数据在整个企业范围内的架构的合理性和一致性负责，如果某个业务环节私自定义了合同信息架构，那么数据 Owner 有责任对该架构进行统一和整改。

原则三：遵从公司的数据分类管理框架。

为了协同企业内各业务领域的数据治理，华为在实践中总结了各类数据的内在特性，制定了统一的数据分类管理框架，公司所有业务领域按照统一的分类框架进行数据治理。

原则四：业务对象结构化、数字化。

华为在长期的数据治理过程中，制定了业务对象结构化、数字化的架构设计原则，实现数据处理效率的提升，构建数据的处理和应用能力，支撑业务管理。

业务对象内容包括业务结果、业务规则、业务过程，并应打造相应的数字化能力。

原则五：数据服务化，同源共享。

随着企业业务规模的不断扩大，往往会随之产生大量的 IT 系统，这样很容易出现数据多源头的情况，导致数据不可信、不可管。为了有效地避免这些问题，华为制定了数据同源共享的架构原则，每一个数据有且只有单一数据源，数据使用方应从数据源获取数据，数据更改应在数据源进行。为了克服企业业务和 IT 的复杂性这一客观现实，华为公司持续推进数据服务建设，要求各数据 Owner 通过数据服务向各业务环节提供数据，各业务环节也有责任通过服务来合理获取数据，从而在整个企业层面实现数据的「一点定义、全局共享」。

### 4.3 信息架构建设核心要素：基于业务对象进行设计和落地

#### 4.3.1 按业务对象进行架构设计

业务对象是指业务领域中重要的人、事、物对象。业务对象承载了业务运作和管理涉及的重要信息，是信息架构中最重要的管理要素。

2『业务对象的定义，做一张术语卡片。（2021-07-24）』—— 已完成

业务对象同时还是业务和 IT 的关键连接点，也是实现 IA（信息架构）、BA（业务架构）、AA（应用架构）、TA（技术架构）集成的关键要素。

以一个简化的交易场景为例（如图 4-4 所示），要完成一个交易，实现商业价值的兑现，企业内的某个子公司，需要与法人客户签订客户合同，在客户合同中，要明确交易的产品。在这个场景中，子公司、法人客户、客户合同、产品是企业需要管理和控制的核心对象，要作为业务对象进行管理。

图 4-4 业务对象和属性示例

在进行信息架构设计时，架构师、业务代表、数据 Owner 通常会对业务对象的判定存在理解上的偏差，从而产生争议。数据治理部门需要制定一套确定性的规则，通过确定性的规则促进形成稳定的架构。华为通过以下四条原则来判定业务对象。

原则一：业务对象是指企业运作和管理中不可缺少的重要人、事、物。

企业在设计业务对象时，围绕支持企业运作和管理的重要的人、事、物去识别。通常，一个业务对象会有相应的管理流程、管理组织，以及支持运作的 IT 系统。比如「客户」这个对象，企业通常会建立类似客户管理部这样的组织，会采购或者开发 CRM 客户管理系统来支撑客户管理，会建立客户信息管理的一系列流程和规范来确保客户信息的准确、合理、合规。为了避免管理上的冲突，业务对象通常在企业内只能有一个唯一的数据 Owner，由数据 Owner 制定相关的架构、标准和管理规则，用于监控和提升数据质量。

原则二：业务对象有唯一身份标识信息。

企业要对业务对象进行管理，需要对所有业务对象的实例进行编码，确保每个对象的实例在企业范围内都有唯一的标识。比如员工，企业需要为每个员工分配一个唯一的工号，如果工号出现重复，则可能引起管理上的混乱，比如工资错发，任务指令接收不到等。又比如产品，企业需要给每一种产品分配精确的分类编号，确保在研发组织内部、制造工厂、物流运输、销售回款各个部门和阶段，相同的产品使用唯一相同的编号，不同的产品绝不出现相同编号。企业的研发、生产、销售、核算各环节均采用产品的唯一编码进行标识和处理。

原则三：业务对象相对独立并有属性描述。

业务对象需要通过大量属性来描述其各个方面的性质和特征，因此属性必定依附于某个业务对象而不可独立存在。比如「名称」是个属性，单纯地记录「名称」这个属性，无任何业务含义，因为「客户」有「名称」属性，「供应商」也有「名称」属性，「员工」也有「名称」属性。业务对象可以独立地存储、传输、使用，业务对象之间可以有关联、依赖关系，但不应有包含或从属关系。

以「销售订单」为例（如图 4-5 所示），「销售订单」通常包含两个方面的信息。一方面是销售订单中所销售产品的公共信息，比如归属的订单编号、订单名称、订单总价等，这类信息集中起来形成一个叫「订单头」的逻辑数据实体。另一方面是销售订单中某个产品的个性化信息，一个销售订单通常会销售多种产品，每种产品的价格和数量可能不一样，这些信息需要用另一个逻辑数据实体来记录，并用一个「订单编码」属性来表示这些明细的销售产品归属于该销售订单里，同时不同产品按不同「订单行号」展示。而「订单行号」是无法独立存在的，企业能够确保所有「订单编码」不会重复，但无法确保所有「订单行号」不会重复，并且这也没有必要，因为任何订单行都是隶属于某个订单的。因此从这个例子可以看出，订单行是无法作为一个独立的业务对象而存在的，必须归属于「销售订单」这个业务对象。

图 4-5 业务对象示例：销售订单

原则四：业务对象可实例化。

在现实世界中，业务对象有大量的实例存在，并可感知、可获取。以员工为例，就算是规模很小的企业，通常至少会有经理、业务员、会计等不同岗位的人员，每个员工的信息都可以视为一个实例；而「员工入职类型」是对员工入职信息的一种分类，其本身是无法实例化的，因此「员工入职类型」这一基础数据应从属于员工业务对象下，而不能独立存在，员工业务对象 Owner 也应该同时负责「员工入职类型」数据的生命周期管理。

#### 4.3.2 按业务对象进行架构落地

信息架构向 IT 侧落地的主要交付件是数据模型。数据模型本身有相对比较成熟的方法体系支撑，不同企业之间可能名称存在差异，但本质差别不大。华为公司将数据模型分为三层：概念数据模型、逻辑数据模型、物理数据模型，如图 4-6 所示。

图 4-6 数据模型分层框架

概念数据模型是通过业务对象及业务对象之间的关系，从宏观角度分析和设计的企业核心数据结构。逻辑数据模型是利用逻辑数据实体及实体之间的关系，准确描述业务规则的逻辑实体关系。物理数据模型是按照一定规则和方法，将逻辑数据模型中定义的逻辑数据实体、属性、属性约束、关系等内容，如实转换为数据库软件能识别的物理数据实体关系。

为了确保架构在落地过程中「不走形」，要控制好两个关键点：一个是概念模型与逻辑模型的一致性，主要通过逻辑数据实体的设计管理来实现；另一个是逻辑模型与物理模型的一致性，主要通过一体化建模管理来实现。

1、逻辑数据实体设计。

逻辑数据实体本质上是对描述业务对象的众多属性的归类，业务对象无法直接指导 IT 系统的物理实现，也无法基于业务对象来审视物理设计是否满足业务需求，因此需要通过逻辑数据实体及相应的逻辑数据模型来指导 IT 系统层面的数据设计。在设计逻辑数据实体时，可参考如下几条主要规则。

1）逻辑数据实体不能脱离业务对象独立存在，因此某个逻辑数据实体一定是用来描述一个特定的业务对象的，业务对象与逻辑数据实体的关系是一对一或一对多，不允许多对一的情况出现。

2）描述业务对象不同业务特征的密切相关的一组属性集合，可以设计为一个逻辑数据实体。

3）逻辑数据实体设计要遵循第三范式。在设计一个业务对象的逻辑数据实体时，每个逻辑数据实体的属性不要重复定义，不应包含其他逻辑数据实体中的非关键字类型的属性。

4）提供数据服务或跨业务领域使用的基础数据，要单独设计逻辑数据实体。描述业务对象的若干属性，如果能够组合起来形成独特价值的数据服务，满足下游的数据消费需求，可以设计成一个逻辑数据实体。

5）两个业务对象间的关系也可以设计成关系型逻辑数据实体，在数据资产目录中，可按业务发生的时间先后顺序，归属于后出现的业务对象。

2、一体化建模管理。

华为公司过去长期存在信息架构与 IT 开发实施「两张皮」的现象，数据人员和 IT 开发实施人员缺乏统一和协同，数据架构遵从无法进行实质、有效管理，信息架构资产和产品实现的物理表割裂、不匹配，同时各种数据模型资产缺失。

1）针对应用系统设计应遵从信息架构设计的政策要求，在相关项目、产品的流程中，缺乏显性化的且有实操指导的角色和活动。

2）信息架构设计大多集中在变革项目层的设计输出和领域层的例行刷新，未与系统落地有效拉通。

3）IT 产品聚焦在版本交付，产品级的数据模型与数据字典缺少有效看护和及时维护。

为了解决这个问题，华为推行了一体化模型设计（如图 4-7 所示），不仅在工具上实现了一体化设计和开发，而且在机制上形成了信息架构设计与 IT 开发实施的有效协同。通过一体化设计不仅确保了元数据验证、发布和注册的一致性，而且实现了产品数据模型管理和资产可视。同时，由于促成了产品元数据的持续运营，进而能够持续对物理模型进行规范，如整改、清理各类作废表等。

仅确保了元数据验证、发布和注册的一致性，而且实现了产品数据模型管理和资产可视。同时，由于促成了产品元数据的持续运营，进而能够持续对物理模型进行规范，如整改、清理各类作废表等。

图 4-7 一体化建模架构

基于良好的一体化建模架构，不仅可以打通设计和物理实现，而且能够对设计、发布、管理运营等完整生命周期进行融合管理，包括：1）产品逻辑模型和物理模型一体化设计，元数据管理和数据模型管理融合；2）构建数据标准池，实体属性只能从数据标准池选择；3）产品元数据和数据库自动比对和验证；4）产品元数据发布认证和信息资产打通；5）基于交易侧产品元数据自助入湖。

### 4.4 传统信息架构向业务数字化扩展：对象、过程、规则

本章前面提到，华为公司的信息架构最初是为了满足「信息化」和「业务上 ERP」过程中提出的数据管理要求，但随着数字化转型的深入，发现既有信息架构已经无法满足自身业务需要，主要体现在以下几个方面。

1、大量业务和作业所产生的数据并没有完整地被管理。

很多情况下，并不是所有业务和作业所产生的数据都在系统中承载，因为大量 IT 系统中已经承载的数据，往往都是为了满足流程的标准化需要而存在的。例如，每个与客户签订的合同都非常复杂，包括诸多的条款，华为公司签订的合同通常会有上百页内容，但信息架构往往只定义了数百个数据属性，IT 系统中也只承载了这部分内容，而大量的数据是以文档的形式存在的。当要对某个合同进行签订前的评审时，如果想基于过去已签订的合同的条款进行基线参考和验证，那么是无法通过自动化手段高效实现的，只能通过人工翻阅历史合同来实现，完整性和准确性都无法保障，而且效率很低。

2、大量业务过程没有形成可视、可管理的数据。

业务在执行某个具体活动时是有大量作业过程的，但这部分数据往往并没有得到管理。例如，过去只记录了物流各个节点的实际到达信息，但缺乏过程信息记录，假如想实时了解具体的物流状态，只能通过电话、邮件一次次询问，增加大量沟通成本，并且信息的及时性也得不到保障。

3、大量业务规则缺乏管理、无法灵活使用。

在业务执行中存在大量规则，但绝大部分规则都缺乏有效管理，往往只能通过文件和文档管理，即使有部分规则固化到了 IT 系统中，也是无法灵活调整的。例如，有业务人员经常抱怨，由于每年都会发布一些文件来制订业务规范，因此自己不知道哪些是最新的，以及多个历史规范之间是否有重叠和矛盾；另外，如果想基于业务变化对规则进行刷新，但这些规则都固定在 IT 代码中，IT 系统动辄需要数个月才能完成修改，而此时业务可能又发生了新的变化。

因此，华为公司在传统信息架构的基础上，提出了面向数字化转型的扩展：对象数字化、过程数字化、规则数字化，并打造与之相应的能力。

1、对象数字化。

对象数字化的目标是建立对象本体在数字世界的映射。这种映射不是传统意义上基于流程要求的少量数据的管理，而是管理某个对象的全量数据，如图 4-8 所示。

『

图 4-8 信息文本化：

业务对象：企业重要的人、事、物，承载了业务运作和管理涉及的重要信息。

』

图 4-8 业务对象数字化

以产品研发和设计为例，信息架构过去只管理产品数据进入 ERP 管道所必需的少量内容，如产品编码、描述、BOM 清单等，而基于对象数字化则需要建立完整的数字孪生（Digital Twin），也要管理与之相应的完整信息架构。过去，供应部门经常抱怨产品研发部门所提供的「重量」「体积」信息不准确，而研发部门又没有足够的人力在产品进入生产环节前精准测量每个产品、部件、元器件。但是，实际上研发在设计过程中会多次产生并使用这些重量和体积信息，因为这对研发设计也同样重要。在推行对象数字化后，就可以通过数据感知等手段在设计的各个环节记录上述这些数据，并按项目编码进行更新，这样就可以向供应环节提供准确并且全量的数据。

2、过程数字化。

仅仅管理好结果还不够，有时我们需要把作业过程记录下来，了解过程进度或者反过来改进结果。这种记录首先是不干预业务活动的，并且能够自动记录（例如，车辆行驶中自动监控是否存在交通违规）。

过程数字化要实现业务活动线上化，并记录业务活动的执行或操作轨迹，一般通过观测数据来实现轨迹记录，如图 4-9 所示。

『

图 4-9 信息文本化：

业务过程：利用传感器等 lT 技术，对业务对象的行为过程进行观测，形成观测数据，并结合业务场景优化作业效率。

样例 1 —— 设备 GPS 数据：供应链通过采集货物的 GPS 数据及模型建设，实时计算动态到港时间，解決发货后需要多次沟通到货情况的问题，大幅缩减沟通成本。

样例 2 —— 网络访日志：通过使用员工访问当地办公室网络的日志数据，实时统计机关人员出差情况，解决人工统计周期长与数据不准的痛点。

』

图 4-9 业务过程数字化

以前面举过的物流场景为例，华为公司通过推进业务过程数字化，实现供应链对各类物流状态的实时感知和可视，大幅缩减了发货后反复人工沟通的成本。

3、规则数字化。

规则数字化的目的是把复杂场景下的复杂规则用数字化手段进行管理。良好的规则数字化管理，应该能实现业务规则与 IT 应用解耦，所有关键业务规则数据要实现可配置，能够根据业务的变化灵活调整，如图 4-10 所示。

『

图 4-10 信息文本化：

业务规则：在业务管辖范围内，为业务行为提供指引且可落地执行的条例和章程。

定义类规则举例 —— 出差住宿标准：根据出差员工的职级，出差住宿的酒店标准相应地分为 A、B、C 三类。

行为类规则举例 —— 出差费用报销：如如因出差计划改变导致预定取消或变更，员工需要及时知会酒店管理员。

』

图 4-10 业务规则数字化

同样以物流场景为例，通常业务希望基于计划对各个环节的物流任务进行监控和预警，这需要大量的预警规则。例如，某个部件的物流周期是 1 周，当 5 天后要交付而对应物流还未发货，则应该预警。但是，不同物料、不同场景、不同国家的供应能力往往是有差异的，并且随着环境经常动态变化，这就需要将对应的规则数据从 IT 应用中解耦出来，单独定义这类数据资产的信息架构，从而使之能够灵活调整。这样，不同国家的业务人员就可以根据需要随时调整规则，而不用对现有 IT 系统进行大的改动，最大程度地满足业务灵活性的要求。

## 0501. 面向联接共享的数据底座建设

### 本章小结

企业数据治理的最终目的是让数据更有效地服务于业务目标，创造价值。对于数字原生企业而言，原生入口提供的大规模、高质量的数据，可以快速地封装成企业级的 API，满足业务侧的应用。华为作为非数字原生企业，在实践探索中发现，数字化转型的关键在于打通数据供应链，通过理解业务、识别数据资产、建设数据架构来推动组织间的共享和协作，标识安全隐私标签，从源头提升数据质量，并通过数据底座建设构建数据湖和数据主题联接两层，形成数据的逻辑集合，为业务可视化、分析、决策等数据消费提供数据服务，让企业数据成为能为业务带来价值的数据资产。

### 5.0

在从信息化向数字化转型的过程中，企业积累了海量的数据，并且还在爆发式地增长。数据很多，但真正能产生价值的数据却很少。数据普遍存在分散、不拉通的问题，缺乏统一的定义和架构，找到想要的、能用的数据越来越难。本章将讲述华为数据底座的总体架构和建设策略，详细说明华为如何通过数据湖和数据主题联接的建设，实现数据的汇聚和联接，打破数据孤岛和垄断，重建数据获取方式和次序。数据底座在华为数字化转型中起着关键作用。

### 5.1 支撑非数字原生企业数字化转型的数据底座建设框架

华为通过建设数据底座，将公司内外部的数据汇聚在一起，对数据进行重新组织和联接，让数据有清晰的定义和统一的结构，并在尊重数据安全与隐私的前提下，让数据更易获取，最终打破数据孤岛和垄断。通过数据底座，主要可以实现如下目标。

1、统一管理结构化、非结构化数据。将数据视为资产，能够追溯数据的产生者、业务源头以及数据的需求方和消费者等。

2、打通数据供应通道，为数据消费提供丰富的数据原材料、半成品以及成品，满足公司自助分析、数字化运营等不同场景的数据消费需求。

3、确保公司数据完整、一致、共享。监控数据全链路下的各个环节的数据情况，从底层数据存储的角度，诊断数据冗余、重复以及「僵尸」问题，降低数据维护和使用成本。

4、保障数据安全可控。基于数据安全管理策略，利用数据权限控制，通过数据服务封装等技术手段，实现对涉密数据和隐私数据的合法、合规地消费。

#### 5.1.1 数据底座的总体架构

华为数据底座由数据湖、数据主题联接两层组成，将公司内外部的数据汇聚到一起，并对数据进行重新的组织和联接，为业务可视化、分析、决策等提供数据服务，如图 5-1 所示。

图 5-1 华为数据底座总体架构

数据湖是逻辑上各种原始数据的集合，除了「原始」这一特征外，还具有「海量」和「多样」（包含结构化、非结构化数据）的特征。数据湖保留数据的原格式，原则上不对数据进行清洗、加工，但对于数据资产多源异构的场景需要整合处理，并进行数据资产注册。

数据入湖必须要遵循 6 项标准，共同满足数据联接和用户数据消费需求。

数据主题联接是对数据湖的数据按业务流 / 事件、对象 / 主体进行联接和规则计算等处理，形成面向数据消费的主题数据，具有多角度、多层次、多粒度等特征，支撑业务分析、决策与执行。基于不同的数据消费诉求，主要有多维模型、图模型、指标、标签、算法模型 5 种数据联接方式。

#### 5.1.2 数据底座的建设策略

数据底座建设不能一蹴而就，要从业务出发，因势利导，持续进行。具体来说，华为数据底座采取「统筹推动、以用促建、急用先行」的建设策略，

根据公司数字化运营的需要，由公司数据管理部统一规划，各领域分别建设，以满足本领域和跨领域的数据需求。其中，数据 Owner 是各领域数据底座建设的第一责任人，各领域数据部负责执行。数据底座资产建设遵从下面四项原则。

1、数据安全原则。数据底座数据资产应遵循用户权限、数据密级、隐私级别等管理要求，以确保数据在存储、传输、消费等全过程中的数据安全。技术手段包括但不限于授权管理、权限控制、数据加密、数据脱敏。

2、需求、规划双轮驱动原则。数据底座数据资产基于业务规划和需求触发双驱动的原则进行建设，对核心数据资产优先建设。

3、数据供应多场景原则。数据底座资产供应需根据业务需求提供离线 / 实时、物理 / 虚拟等不同的数据供应通道，满足不同的数据消费场景。

4、信息架构遵从原则。数据底座数据资产应遵从公司的信息架构，必须经 IA-SAG（信息架构专家组）发布并完成注册。

### 5.2 数据湖：实现企业数据的「逻辑汇聚」

#### 5.2.1 华为数据湖的 3 个特点

华为数据湖（如图 5-2 所示）是逻辑上对内外部的结构化、非结构化的原始数据的逻辑汇聚。数据入湖要遵从 6 项入湖标准，基于 6 项标准保证入湖的质量，同时面向不同的消费场景提供两种入湖方式，满足数据消费的要求。经过近两年的数据湖建设，目前已经完成 1.2 万个逻辑数据实体、28 万个业务属性的入湖，同时数据入湖在华为公司也形成了标准的流程规范，每个数据资产都要入湖成为数据工作的重要标准。

图 5-2 数据湖总体视图

华为数据湖主要有以下几个特点。

1、逻辑统一。华为数据湖不是一个单一的物理存储，而是根据数据类型、业务区域等由多个不同的物理存储构成，并通过统一的元数据语义层进行定义、拉通和管理。

2、类型多样。数据湖存放所有不同类型的数据，包括企业内部 IT 系统产生的结构化数据、业务交易和内部管理的非结构化的文本数据、公司内部园区各种传感器检测到的设备运行数据，以及外部的媒体数据等。

3、原始记录。华为数据湖是对原始数据的汇聚，不对数据做任何的转换、清洗、加工等处理，保留数据最原始特征，为数据的加工和消费提供丰富的可能。

#### 5.2.2 数据入湖的 6 个标准

数据入湖是数据消费的基础，需要严格满足入湖的 6 项标准，包括明确数据 Owner、发布数据标准、定义数据密级、明确数据源、数据质量评估、元数据注册。通过这 6 项标准保证入湖的数据都有明确的业务责任人，各项数据都可理解，同时都能在相应的信息安全保障下进行消费。

1、明确数据 Owner。数据 Owner 由数据产生对应的流程 Owner 担任，是所辖数据端到端管理的责任人，负责对入湖的数据定义数据标准和密级，承接数据消费中的数据质量问题，并制定数据管理工作路标，持续提升数据质量。

2、发布数据标准。入湖数据要有相应的业务数据标准。业务数据标准描述公司层面需共同遵守的「属性层」数据的含义和业务规则，是公司层面对某个数据的共同理解，这些理解一旦明确并发布，就需要作为标准在企业内被共同遵守。数据标准的信息如表 5-1 所示。

表 5-1 数据标准说明

3、认证数据源。通过认证数据源，能够确保数据从正确的数据源头入湖。认证数据源应遵循公司数据源管理的要求，一般数据源是指业务上首次正式发布某项数据的应用系统，并经过数据管理专业组织认证。认证过的数据源作为唯一数据源头被数据湖调用。当承载数据源的应用系统出现合并、分拆、下线情况时，应及时对数据源进行失效处理，并启动新数据源认证。

4、定义数据密级。定义数据密级是数据入湖的必要条件，为了确保数据湖中的数据能充分地共享，同时又不发生信息安全问题，入湖的数据必须要定密。数据定密的责任主体是数据 Owner，数据管家有责任审视入湖数据密级的完整性，并推动、协调数据定密工作。数据定级密度在属性层级，根据资产的重要程度，定义不同等级。不同密级的数据有相应的数据消费要求，为了促进公司数据的消费，数据湖中的数据有相应的降密机制，到降密期或满足降密条件的数据应及时降密，并刷新密级信息。

5、数据质量评估。数据质量是数据消费结果的保证，数据入湖不需要对数据进行清洗，但需要对数据质量进行评估，让数据的消费人员了解数据的质量情况，并了解消费该数据的质量风险。同时数据 Owner 和数据管家可以根据数据质量评估的情况，推动源头数据质量的提升，满足数据质量的消费要求。

6、元数据注册。元数据注册是指将入湖数据的业务元数据和技术元数据进行关联，包括逻辑实体与物理表的对应关系，以及业务属性和表字段的对应关系。通过联接业务元数据和技术元数据的关系，能够支撑数据消费人员通过业务语义快速地搜索到数据湖中的数据，降低数据湖中数据消费的门槛，能让更多的业务分析人员理解和消费数据。

#### 5.2.3 数据入湖方式

数据入湖遵循华为信息架构，以逻辑数据实体为粒度入湖，逻辑数据实体在首次入湖时应该考虑信息的完整性。原则上，一个逻辑数据实体的所有属性应该一次性进湖，避免一个逻辑实体多次入湖，增加入湖工作量。

数据入湖的方式主要有物理入湖和虚拟入湖两种，根据数据消费的场景和需求，一个逻辑实体可以有不同的入湖方式。两种入湖方式相互协同，共同满足数据联接和用户数据消费的需求，数据管家有责任根据消费场景的不同，提供相应方式的入湖数据。

物理入湖是指将原始数据复制到数据湖中，包括批量处理、数据复制同步、消息和流集成等方式。虚拟入湖是指原始数据不在数据湖中进行物理存储，而是通过建立对应虚拟表的集成方式实现入湖，实时性强，一般面向小数据量应用，大批量的数据操作可能会影响源系统。

数据入湖有以下 5 种主要技术手段。

1、批量集成（Bulk/Batch Data Movement）。对于需要进行复杂数据清理和转换且数据量较大的场景，批量集成是首选。通常，调度作业每小时或每天执行，主要包含 ETL、ELT 和 FTP 等工具。批量集成不适合低数据延迟和高灵活性的场景。

2、数据复制同步（Data Replication/Data Synchronization）。适用于需要高可用性和对数据源影响小的场景。使用基于日志的 CDC 捕获数据变更，实时获取数据。数据复制同步不适合处理各种数据结构以及需要清理和转换复杂数据的场景。

3、消息集成（Message-Oriented Movement of Data）。通常通过 API 捕获或提取数据，适用于处理不同数据结构以及需要高可靠性和复杂转换的场景。尤其对于许多遗留系统、ERP 和 SaaS 来说，消息集成是唯一的选择。消息集成不适合处理大量数据的场景。

4、流集成（Stream Data Integration）。主要关注流数据的采集和处理，满足数据实时集成需求，处理每秒数万甚至数十万个事件流，有时甚至数以百万计的事件流。流集成不适合需要复杂数据清理和转换的场景。

5、数据虚拟化（Data Virtualization）。对于需要低数据延迟、高灵活性和临时模式（不断变化下的模式）的消费场景，数据虚拟化是一个很好的选择。在数据虚拟化的基础上，通过共享数据访问层，分离数据源和数据湖，减少数据源变更带来的影响，同时支持数据实时消费。数据虚拟化不适合需要处理大量数据的场景。

5 种数据入湖方式的对比可以参考表 5-2。

表 5-2 数据入湖方式对比

可以通过数据湖主动从数据源 PULL（拉）的方式入湖，也可以通过数据源主动向数据湖 PUSH（推）的方式入湖。数据复制同步、数据虚拟化以及传统 ETL 批量集成都属于数据湖主动拉的方式；流集成、消息集成属于数据源主动推送的方式（如表 5-3 所示）。在特定的批量集成场景下，数据会以 CSV、XML 等格式，通过 FTP 推送给数据湖。

表 5-3 PULL（拉）& PUSH（推）方式入湖

#### 5.2.4 结构化数据入湖

结构化数据是指由二维表结构来逻辑表达和实现的数据，严格遵循数据格式与长度规范，主要通过关系型数据库进行存储和管理。

触发结构化数据入湖的场景有两种：第一，企业数据管理组织基于业务需求主动规划和统筹；第二，响应数据消费方的需求。

结构化数据入湖过程包括：数据入湖需求分析及管理、检查数据入湖条件和评估入湖标准、实施数据入湖、注册元数据（如图 5-3 所示）。

图 5-3 结构化数据入湖流程

5.2.4.1 数据入湖需求分析及管理

对于规划驱动入湖场景而言，由对应的数据代表基于数据湖的建设规划，输出入湖规划清单，清单包含主题域分组、主题域、业务对象、逻辑实体、业务属性、源系统物理表和物理字段等信息。

对于需求驱动入湖场景而言，由数据消费方的业务代表提出入湖需求，并提供数据需求的业务元数据和技术元数据的信息，包括业务对象、逻辑实体、业务属性对应界面的截图。

无论是主动规划还是被动响应需求，入湖需求清单必须通过业务代表和数据代表的联合评审。当业务代表和数据代表就评审结论发生争议时，可到专业评审组织申请仲裁。

5.2.4.2 检查数据入湖条件和评估入湖标准

在数据入湖前要检查数据源准备度和评估数据入湖标准。

1、检查数据源准备度。数据有源是数据入湖的基本前提，数据源准备度检查不仅需要源系统的 IT 团队提供源系统的数据字典和数据模型并检查源系统的物理表规范度，而且需要数据代表评估源系统的数据质量。

2、评估入湖标准。入湖标准包括以下几点。

明确数据 Owner：为保证入湖数据的管理责任清晰，在数据入湖前应明确数据 Owner。

发布数据标准：入湖数据应有数据标准，数据标准定义了数据属性的业务含义、业务规则等，是正确理解和使用数据的重要依据，也是业务元数据的重要组成部分。

认证数据源：原则上以初始源进湖，数据源认证是保证数据湖数据一致性和唯一性的重要措施。

定义数据密级：定义完整、明确的数据密级是数据湖数据共享、权限控制等的关键依据。信息安全管理专员向业务 Owner 提出定密需求，并与业务 Owner 确定定密规则，确定数据密级、定密时间、降密期 / 降密条件等，然后由信息安全管理专员在信息架构管理平台注册密级信息。

评估入湖数据质量：对入湖数据做质量评估，给入湖数据打质量标签。

如果不满足上述任意一条入湖标准，就应推动源系统数据代表完成整改，满足要求后方可实施数据入湖。

5.2.4.3 实施数据入湖

数据代表依据消费场景合理选择入湖方式，在不要求历史数据、小批量数据且实时性要求高的场景，建议虚拟入湖；在要求历史数据、大批量数据且实时性要求不高的场景，可以物理入湖。

虚拟入湖由数据代表实施，数据代表负责设计和部署虚拟表。

物理入湖由对应数据湖的 IT 代表承接 IT 实施需求，设计集成方案和数据质量监测方案，实施数据入湖。数据代表组织 UAT 测试、上线验证。

5.2.4.4 注册元数据

元数据是公司的重要资产，是数据共享和消费的前提，为数据导航和数据地图建设提供关键输入。对元数据进行有效注册是实现上述目的的前提。虚拟表部署完成后或 IT 实施完成后，由数据代表检查并注册元数据，元数据注册应遵循企业元数据注册规范。

#### 5.2.5 非结构化数据入湖

5.2.5.1 非结构化数据管理的范围

非结构化数据包括无格式的文本、各类格式的文档、图像、音频、视频等多样异构的格式文件。相较于结构化数据，非结构化数据更难以标准化和理解，因而非结构化数据的管理不仅包括文件本身，而且包括对文件的描述属性，也就是非结构化的元数据信息。

这些元数据信息包括文件对象的标题、格式、Owner 等基本特征，还包括对数据内容的客观理解信息，如标签、相似性检索、相似性连接等。这些元数据信息便于用户对非结构化数据进行搜索和消费。非结构化数据的元数据实体如图 5-4 所示。

图 5-4 非结构化数据的元数据实体

都柏林核心元数据是一个致力于规范 Web 资源体系结构的国际性元数据解决方案，它定义了一个所有 Web 资源都应遵循的通用核心标准。

基本特征类属性由公司进行统一管理，内容增强类属性由承担数据分析工作的项目组自行设计，但其分析结果都应由公司元数据管理平台自动采集后进行统一存储。

5.2.5.2 非结构化数据入湖的 4 种方式

非结构化数据入湖包括基本特征元数据入湖、文件解析内容入湖、文件关系入湖和原始文件入湖 4 种方式，其中基本特征元数据入湖是必选内容，后面三项内容可以根据分析诉求选择性入湖和延后入湖，如图 5-5 所示。

图 5-5 非结构化数据入湖

1、基本特征元数据入湖。主要通过从源端集成的文档本身的基本信息入湖。入湖的过程中，数据内容仍存储在源系统，数据湖中仅存储非结构化数据的基本特征元数据。基本特征元数据入湖需同时满足如下条件。

已经设计了包含基本特征元数据的索引表。

已经设计了信息架构，如业务对象和逻辑实体。

已经定义了索引表中每笔记录对应文件的 Owner、标准、密级，认证了数据源并满足质量要求。

参考都柏林核心元数据，非结构化数据的基本特征类属性元数据规范如表 5-4 所示。

表 5-4 非结构化数据的基本特征类属性

2、文件解析内容入湖。

对数据源的文件内容进行文本解析、拆分后入湖。入湖的过程中，原始文件仍存储在源系统，数据湖中仅存储解析后的内容增强元数据。内容解析入湖需同时满足如下条件。

已经确定解析后的内容对应的 Owner、密级和使用的范围。

已经获取了解析前对应原始文件的基本特征元数据。

已经确定了内容解析后的存储位置，并保证至少一年内不会迁移。

3、文件关系入湖。

根据知识图谱等应用案例在源端提取的文件上下文关系入湖。入湖的过程中，原始文件仍存储在源系统，数据湖中仅存储文件的关系等内容增强元数据。文件关系入湖需同时满足如下条件：

已经确定文件对应的 Owner、密级和使用的范围。

已经获取了文件的基本特征元数据。

已经确定了关系实体的存储位置，并保证至少一年内不会迁移。

4、原始文件入湖。

根据消费应用案例从源端把原始文件搬入湖。数据湖中存储原始文件并进行全生命周期管理。原始文件入湖需同时满足如下条件。

已经确定原始文件对应的 Owner、密级和使用的范围。

已经获取了基本特征元数据。

已经确定了存储位置，并保证至少一年内不会迁移。

### 5.3 数据主题联接：将数据转换为「信息」

#### 5.3.1 5 类数据主题联接的应用场景

在数字化转型的背景下，华为的数据消费已经不再局限于传统的报表分析，还要支持用户的自助分析、实时分析，通过数据的关联，支持业务的关联影响分析以及对目标对象做特征识别，进行特定业务范围圈定、差异化管理与决策等。这些分析需求也不再是对单一数据的分析，往往需要对跨领域的数据进行联接后再进行综合分析。

目前，数据湖汇聚了大量的原始数据，用户不再需要到各个源系统调用数据，而是统一从数据湖调用。由于数据湖中的数据零散且数据结构都与源系统一致，严格遵从三范式，即使每个数据都有详细的定义和解释，用户也很难知道数据之间的关联关系。例如，消费者 BG 做设备收入预测需要的数据有产品、订单、计划等超过 150 个物理表信息，这些表没有进行联接，没有形成有用信息，是很难支撑用户进行分析的。

华为在数据湖的基础上通过建立数据联接层，基于不同的分析场景，通过 5 类联接方式将跨域的数据联接起来，将数据由「原材料」加工成「半成品」和「成品」，支撑不同场景的数据消费需求，如图 5-6 所示。

图 5-6 5 类数据主题联接

1、多维模型是面向业务的多视角、多维度的分析，通过明确的业务关系，建立基于事实表、维度表以及相互间联接关系，实现多维数据查询和分析。例如，对订货数据从时间、区域、产品、客户等维度进行多视角、不同粒度的查询和分析。

2、图模型面向数据间的关联影响分析，通过建立数据对象以及数据实例之间的关系，帮助业务快速定位关联影响。例如，查看某国家原产地的项目的数据具体关联到哪个客户以及合同、订单、产品的详细信息时，可以通过图模型快速分析关联影响，支撑业务决策。

3、标签是对特定业务范围的圈定。在业务场景的上下文背景中，运用抽象、归纳、推理等算法计算并生成目标对象特征的表示符号，是用户主观观察、认识和描述对象的一个角度。例如，对用户进行画像，识别不同的用户群，为产品设计和营销提供策略支持。

4、指标是对业务结果、效率和质量的度量。依据明确的业务规则，通过数据计算得到衡量目标总体特征的统计数值，能客观表征企业某一业务活动中业务状况。例如，促销员门店覆盖率指标就是衡量一线销售门店促销员的覆盖程度。

5、算法模型是面向智能分析的场景，通过数学建模对现实世界进行抽象、模拟和仿真，提供支撑业务判断和决策的高级分析方法。例如，预测未来 18 个月的销售量，需要数据科学家根据数据湖中的历史订单、发货等数据通过决策树和基因算法进行数据建模，支持业务决策。

#### 5.3.2 多维模型设计

多维模型是依据明确的业务关系，建立基于维度、事实表以及相互间连接关系的模型，实现多角度、多层次的数据查询和分析。如何设计出稳定、易扩展、高可用的数据模型来支持用户消费对数据主题联接至关重要。

多维模型设计有 4 个主要步骤，包括确定业务场景、声明粒度、维度设计和事实表设计。

1、确定业务场景。分析业务需求，识别需求中所涉及的业务流及其对应的逻辑数据实体和关联关系。如业务负责人（PO）履行全流程可视，首先需要识别监控的具体业务环节（如发货、开票等），再根据这些业务环节识别其对应的逻辑数据实体及关联关系，如图 5-7 所示。

图 5-7 PO 履行全流程可视的数据范围

2、声明粒度。粒度表示数据单元的细节程度或综合程度，细节程度越高，粒度越细；细节程度越低，粒度越粗。声明粒度是维度和事实表设计的重要步骤，声明粒度意味着精确定义事实表的每一行表示什么。针对监控 PO 履行这个场景，在做设计时首先要确认是监控 PO 的履行，还是具体到每个 PO 行的履行，不同的粒度会对应不同的事实表。

3、维度设计。维度是用于观察和分析业务数据的视角，支持对数据进行汇聚、钻取、切片分析，如图 5-8 所示。维度由层次结构（关系）、层级、成员、属性组成。维度可以分为基础树和组合树，维度基础树提供统一定义的、完整的层级结构和成员；维度组合树根据业务使用场景进行定制。

图 5-8 维度示例

维度设计需要满足单一性、单向性和正交性。

1、单一性。有且仅有一个视角，在同一个维度中不能穿插其他经营分析的视角，例如，区域维不含客户视角，产品维不含客户视角等。图 5-9 中区域维度客户视角不满足单一性要求。

图 5-9 不满足单一性示例

2、单向性。「上大下小」，维度只能支撑自上而下的分解和自下而上的收敛，每个成员只能存在向上的收敛路径，不能具备向上和向下两个方向的收敛逻辑。图 5-10 中代表处维度低于国家维度，不满足单向性要求。

图 5-10 不满足单向性示例

3、正交性。成员两两不相交，同一成员不能同时拥有多个上级成员，以产品维为例，华为向客户提供的设备或服务都只能被准确地分配到唯一叶子（最底层）节点，并以此路径进行收敛。图 5-11 中最小粒度成员「无线专业服务」同时归属不同的上层节点，不满足正交性要求。

图 5-11 不满足正交性示例

4、事实表设计。事实表存储业务过程事件的性能度量结果，由粒度属性、维度属性、事实属性和其他描述属性组成，如图 5-12 所示。

图 5-12 事实表示例

粒度属性是事实表的主键，通常由原始数据的主键或一组维度属性生成。

维度属性是从维度中继承的属性，可以只继承主键作为事实表的外键，也可以继承维度中全部或其他部分的属性。在上述例子中，事实表中除了有币种 ID，还可以带有币种编码和币种名称等属性。

事实属性是可以对该颗粒度的事实进行定量的属性，大多数的事实表包括一个或多个事实字段。

同一事实表中不能存在多种不同粒度的事实，比如 PO 行明细事实表中不应该包含 PO 总金额，否则 PO 总金额累加时会出现错误。

尽可能包含所有与业务过程相关的事实，不包含与业务过程无关的事实，比如在设计「订单下单」这个业务过程的事实表时，不应该存在「支付金额」这个支付业务过程的事实。

对于不可相加的事实，需要分解为可加的事实。比如比率，需要分解为分子和分母。

事实的数值单位要保持一致。

其他属性主要包括创建人、创建时间、最后修改人、最后修改时间等审计字段。

#### 5.3.3 图模型设计

图模型作为当前流行的信息处理加工技术，自提出以来，迅速在学术界和工业界得到了普及，在智能推荐、决策分析等方面有着广泛的应用。

图模型由节点和边组成。节点表示实体或概念，边则由属性或关系构成。实体指的是具有可区别性且独立存在的某种事物，如某一个人、某一个城市、某一种植物、某一种商品等，是图模型中的最基本元素；概念是对特征的组合而形成的知识单元，主要指集合、类别、对象类型、事物的种类，例如人物、地理等；属性主要指描述实体或概念的特征或特性，例如人员的国籍、生日等。我们以「哲学家」为例设计图模型，如图 5-13 所示。

图 5-13 图模型示例

图模型构建包含几个关键步骤，如图 5-14 所示。

图 5-14 企业图模型构建步骤

第一步：业务场景定义。

业务场景决定信息涵盖范围，以及信息颗粒度的表示。以支撑业务连续性为例，因为不可抗力的影响，部分区域的供应商工厂无法正常生产和发货，涉及的信息包括供应商的信息、产能、元器件及内部物料、合同和客户信息，要求能够根据用户输入的当前物料储备和合同状态，获取影响内部物料、产品、合同交付和客户的清单和范围。这种应用涉及对产品目录和配置的解读，需要对收集的信息进行最小采购器件的抽取。

信息颗粒度在图模型建设中是个不可忽视的问题，根据应用场景决定信息颗粒度以及图模型的精确性与有效性。比如手机，有品牌、型号、批次，直至手机整机。同样的信息范围，颗粒度越细，图模型应用越广泛，关系越丰富，但冗余越多，知识消费越低效。信息颗粒度的原则是「能满足业务应用的最粗颗粒度」。

第二步：信息收集。

信息的选取要考虑两个方面的内容。1）与应用场景直接相关的信息。例如，判断不可抗力供应中断影响的范围，直接相关的信息有物料信息、产品配置、合同信息等。2）与应用场景间接相关，但可辅助理解问题的信息。这包括企业信息、专业领域信息、行业信息以及开放域信息。

第三步：图建模。

相同的数据可以有若干种模式的定义，良好的模式可以减少数据冗余，提高实体识别的准确率，在建模的过程中，要结合数据特点与应用场景来完成。同样的数据从不同的视角可以得出不同的图模型。

第四步：实体、概念、属性、关系的标注。

企业图模型中涉及的实体和概念可分为三类：公共类，如人名、机构名、地名、公司名、时间等；企业类，如业务术语、企业部门等；行业类，如金融行业、通信行业等。

第五步：实体和概念的识别。

企业图模型中实体、概念的识别可将业务输入与数据资产中已有的信息作为种子，运用命名实体识别（NER）的方法扩展出新实体概念，经业务确认后，列入实体、概念库。

第六步：属性识别与关系识别。

企业图模型中的属性与关系一般是根据业务知识在模式层设计时定义，属性与关系相对稳定，其扩展场景不是很多。

企业图模型的存储技术要综合考虑应用场景、图模型中节点和联接的数量、逻辑的复杂度、属性的复杂度，以及性能要求。一般建议采用混合存储方式，用图数据库存储关系，关系型数据库或键值对存储属性。偏重逻辑推理的应用场景用 RDF 的存储方式，偏重图计算的应用场景选择属性图的存储方式。发挥两类数据存储和读写的各自优势。

知识计算主要是根据图谱提供的信息得到更多隐含的知识，如通过模式层以及规则推理技术可以获取数据中存在的隐含信息。知识计算涉及三大关键技术：图挖掘计算、基于本体的推理、基于规则的推理。图挖掘计算是基于图论的相关算法，实现对图谱的探索和挖掘。图挖掘计算主要分为如下 6 类。

1、图遍历：知识图谱构建完之后可以理解为是一张很大的图，可以去查询和遍历这个图，要根据图的特点和应用场景进行遍历。

2、图里面经典的算法，如最短路径。

3、路径的探寻，即根据给定两个实体或多个实体去发现它们之间的关系。

4、权威节点的分析，这在社交网络分析中使用较多。

5、族群分析。

6、相似节点的发现。

图挖掘计算如图 5-15 所示。

图 5-15 图模型示例

图挖掘计算在当前的应用场景中，基于业务连续性，通过查询遍历图模型，识别影响节点和影响范围，基于最短路径，辅助决策物流线路，在企业中的应用较为普遍。

图模型在企业中的价值，很大程度上取决于企业基于对象节点可以构建多完善的关系，这个关系的构建是一个逐步完善的过程，基于业务场景不断补充和完善关系，这就是图模型的优势。当形成一个足够完善的企业级图模型后，领域分段的业务场景应用只需要裁剪部分节点和关系，就可以满足业务的需求，达到快速响应业务需求、降低开发成本的目的。

#### 5.3.4 标签设计

标签是根据业务场景的需求，通过对目标对象（含静态、动态特性）运用抽象、归纳、推理等算法得到的高度精练的特征标识，用于差异化管理与决策。标签由标签和标签值组成，打在目标对象上，如图 5-16 所示。

图 5-16 打标签示例

标签由互联网领域逐步推广到其他领域，打标签的对象也由用户、产品等扩展到渠道、营销活动等。在互联网领域，标签有助于实现精准营销、定向推送、提升用户差异化体验等；在行业领域，标签更多助力于战略分级、智能搜索、优化运营、精准营销、优化服务、智慧经营等。

标签分为事实标签、规则标签和模型标签，如图 5-17 所示。

图 5-17 三种类型的标签

1、事实标签是描述实体的客观事实，关注实体的属性特征，如一个部件是采购件还是非采购件，一名员工是男性还是女性等，标签来源于实体的属性，是客观和静态的。

2、规则标签是对数据加工处理后的标签，是属性与度量结合的统计结果，如货物是否是超重货物，产品是否是热销产品等，标签是通过属性结合一些判断规则生成的，是相对客观和静态的。

3、模型标签则是洞察业务价值导向的不同特征，是对于实体的评估和预测，如消费者的换机消费潜力是旺盛、普通还是低等，标签是通过属性结合算法生成的，是主观和动态的。

标签管理分为标签体系建设和打标签。

5.3.4.1 标签体系建设

1、选定目标对象，根据业务需求确定标签所打的业务对象，业务对象范围参考公司发布的信息架构中的业务对象。

2、根据标签的复杂程度进行标签层级设计。

3、进行详细的标签和标签值设计，包括标签定义、适用范围、标签的生成逻辑等：1）事实标签应与业务对象中的属性和属性值保持一致，不允许新增和修改；2）规则标签按照业务部门的规则进行相关设计；3）模型标签根据算法模型生成。

5.3.4.2 打标签

1、打标签数据存储结构。打标签是建立标签值与实例数据的关系，可以对一个业务对象、一个逻辑数据实体、一个物理表或一条记录打标签。

为了方便从「用户」视角查找、关联、消费标签，可增加用户表，将标签归属到该「用户」下，这里的「用户」是泛指，可以是具体的人，也可以是一个组织、一个部门、一个项目等。

2、打标签的实现方法。

事实标签：根据标签值和属性允许值的关系由系统自动打标签。

规则标签：设计打标签逻辑由系统自动打标签。

模型标签：设计打标签算法模型由系统自动打标签。

#### 5.3.5 指标设计

指标是衡量目标总体特征的统计数值，是能表征企业某一业务活动中业务状况的数值指示器。指标一般由指标名称和指标数值两部分组成，指标名称及其含义体现了指标在质的规定性和量的规定性两个方面的特点；指标数值反映了指标在具体时间、地点、条件下的数量表现。

根据指标计算逻辑是否含有叠加公式，可以把指标分为原子指标和复合指标两种类型。

原子指标是指标数据通过添加口径 / 修饰词、维度卷积而成，口径 / 修饰词、维度均来源于指标数据中的属性。

复合指标由一个或多个原子指标叠加计算而成，其中维度、口径 / 修饰词均继承于原子指标，不能脱离原子指标维度和口径 / 修饰词的范围去产生新的维度和口径 / 修饰词。指标和数据的关系如图 5-18 所示。

图 5-18 指标和数据关系样例

1、指标数据：承载原子指标的数据表，例如门店明细表，其中度量为门店数量，通过「门店编码」卷积；属性包括门店等级、门店状态、门店形象等级、组织等级等。

2、维度：从属性中选取组织、渠道、门店形象等级。

3、口径 / 修饰词：「门店状态」等于「有效」，「有无促销员」等于「1」。

4、原子指标：由指标数据通过添加口径 / 修饰词、维度卷积而成，包括促销员覆盖门店数量、有效门店数量。

5、复合指标：由 2 个或 2 个以上指标叠加计算而成，包括：

促销员门店覆盖率 = 促销员覆盖门店数量 ÷ 有效门店数量

如何按需求进行指标拆解，是将指标对应到数据资产并进行结构化管理，支持指标服务化与自助需求的关键。指标的拆解过程主要包括指标拆解需求澄清、指标拆解设计、指标数据与数据资产匹配 3 个阶段，如图 5-19 所示。

图 5-19 指标拆解过程

6、解读指标定义，识别指标：通过与指标定义的业务管理部门沟通（通常为指标解释部门的业务人员），从业务角度了解指标基本信息、所需统计维度、指标度量场景以及各场景下的计算逻辑和口径（包括剔除规则）、指标发布信息等。

7、基于指标叠加公式拆解指标：根据指标计算逻辑识别原子指标，明确原子指标中需要的口径 / 修饰词、维度信息，以及原子指标与复合指标间的支撑关系。

8、基于指标拆解结果，识别指标数据：识别原子指标的度量属性和支撑属性，并根据原子指标中的维度、口径修饰词匹配已发布业务对象的属性，形成指标数据。

9、数据匹配落地：补充指标、指标数据中的标准属性名称以及对应的落地物理表，支持用户自助实现指标计算，拉通指标设计和落地。

#### 5.3.6 算法模型设计

算法是指训练、学习模型的具体计算方法，也就是如何求解全局最优解，并使得这个过程高效且准确，其本质上是求数学问题的最优化解，即算法是利用样本数据生成模型的方法。算法模型是根据业务需求，运用数学方法对数据进行建模，得到业务最优解，主要用于业务智能分析。

算法模型在数据分析流程中产生，算法模型管理框架包括建模、模型资产管理和模型消费。公司各领域已相继开发出大量基于算法模型的分析应用，通过对算法模型资产注册逐步打造公司级的算法模型地图。

算法模型的设计步骤主要有需求评估、数据准备、方案设计和建模与验证。

1、需求评估。

1）业务驱动的分析需求识别。如果要识别与业务运营优化相关的分析需求，就需要梳理业务需求的背景、现状与目标。若由战略或变革提出可能的分析需求，则应进行战略目标解耦，识别分析需求，了解业务现状与制定目标；初步识别分析结果的应用场景。

2）数据驱动的分析需求识别。在集成的数据环境中进行数据挖掘，探索可能的分析应用；识别分析需求和确认应用领域。初步识别分析结果的应用场景。

3）价值与可行性评估。确定数据分析主题；分析需求的业务价值评估，包括业务基线、分析主题的业务影响与可增进的效益；分析前提与可行性，包括识别目前业务流程与可能的影响因素，探讨业务现状因素，并制定对应的分析解決方案，呈现出对应解决方案可提升的效益，对方案所需资源和数据的可行性进行评估；根据相关的历史数据，进行假设和分析，并明确业务范围。

2、数据准备。

深入探索数据资产目录，识别与分析主题可能相关的数据。

提供数据源、数据标准、数据流等信息。

收集与整合原始数据，生成分析数据集。

根据分析需求进行数据筛选和质量分析。

3、方案设计。

明确要分析的业务目标与相关假设。

定义数据集中的分析目标、样本与筛选条件。

设计所需变量、指标、可能的分析方法和产出。

规划分析的应用场景。

4、建模与验证。

1）决定是否需要分析建模：根据技术复杂度、业务效益和资源评估该分析需求是否需要分析建模。若需要分析建模且通过项目评审，则应进行高阶分析；若不需要建模分析，则运用 BI 分析。

2）建模与验证：根据数据分析方案创建模型，对模型的参数和变量进行调整，根据应用场景选择适用的模型，并与业务分析师确认模型成效与应用，并进行优化，进行模型相关验证（如准确度和稳定度评估）及效益评估。

3）试算分析：对数据分析方案中不需分析建模的场景和应用，根据数据分析方案进行分析结果的计算，并选择合适的展示方式。

4）编写数据分析线下验证报告：记录分析结果与发现；根据洞察发现，建议业务应用场景；建议模型监测方式。

5）决定是否需要 IT 开发：根据模型验证成果（分析建模）、预估业务效益、IT 开发所需的成本和资源来评估分析结果是否需要 IT 开发。若需要，则通过评审后转入 IT 开发流程；若不需要，则进入业务应用并结束流程

6）模型线上验证：设定线上验证范围与场景；进行线上验证，制定模型监控机制（含监控频次和监控要素），生成分析模型线上验证报告；进行业务试运行与推广。

7）转运营：与数据分析模型所属领域的业务代表确认转正式运营计划，启动业务正式运营。