## 记忆时间

## 目录

0501 The Dueling Laws of Large and Small Numbers

0601 False Positives and Positive Fallacies

## 0501. The Dueling Laws of Large and Small Numbers

IN THEIR WORK, Cardano, Galileo, and Pascal assumed that the probabilities relevant to the problems they tackled were known. Galileo, for example, assumed that a die has an equal chance of landing on any of its six faces. But how solid is such「knowledge」? The grand duke's dice were probably designed not to favor any face, but that doesn't mean fairness was actually achieved. Galileo could have tested his assumption by observing a number of tosses and recording how often each face came up. If he had repeated the test several times, however, he would probably have found a slightly different distribution each time, and even small deviations might have mattered, given the tiny differential he was asked to explain. In order to make the early work on randomness applicable to the real world, that issue had to be addressed: What is the connection between underlying probabilities and observed results? What does it mean, from a practical point of view, when we say the chances are 1 in 6 a die will land on 2? If it doesn't mean that in any series of tosses the die will land on the 2 exactly 1 time in 6, then on what do we base our belief that the chances of throwing a 2 really are 1 in 6? And what does it mean when a doctor says that a drug is 70 percent effective or has serious side effects in 1 percent of the cases or when a poll finds that a candidate has support of 36 percent of voters? These are deep questions, related to the very meaning of the concept of randomness, a concept mathematicians still like to debate.

I recently engaged in such a discussion one warm spring day with a statistician visiting from Hebrew University, Moshe, who sat across the lunch table from me at Caltech. Between spoonfuls of nonfat yogurt, Moshe espoused the opinion that truly random numbers do not exist.「There is no such thing,」he said.「Oh, they publish charts and write computer programs, but they are just fooling themselves. No one has ever found a method of producing randomness that's any better than throwing a die, and throwing a die just won't do it.」

Moshe waved his white plastic spoon at me. He was agitated now. I felt a connection between his feelings about randomness and his religious convictions. Moshe is an Orthodox Jew, and I know that many religious people have problems thinking God can allow randomness to exist.「Suppose you want a string of N random numbers between 1 and 6,」he told me.「You throw a die N times and record the string of N numbers that comes up. Is that a random string?」

No, he claimed, because no one can make a perfect die. There will always be some faces that are favored and some that are disfavored. It might take 1,000 throws to notice the difference, or 1 billion, but eventually you will notice it. You'll see more 4s than 6s or maybe fewer. Any artificial device is bound to suffer from that flaw, he said, because human beings do not have access to perfection. That may be, but Nature does, and truly random events do occur on the atomic level. In fact, that is the very basis of quantum theory, and so we spent the rest of our lunch in a discussion of quantum optics.

Today cutting-edge quantum generators produce truly random numbers from the toss of Nature's perfect quantum dice. In the past the perfection necessary for randomness was indeed an elusive goal. One of the most creative approaches came from New York City's Harlem crime syndicates around 1920.1 Needing a daily supply of five-digit random numbers for an illegal lottery, the racketeers thumbed their noses at the authorities by employing the last five digits of the U.S. Treasury balance. (At this writing the U.S. government is in debt by `$`8,995,800,515,946.50, or `$`29,679.02 per person, so today the racketeers could have obtained their five digits from the per capita debt!) Their so-called Treasury lottery ran afoul of not only criminal law, however, but also scientific law, for according to a rule called Benford's law, numbers arising in this cumulative fashion are not random but rather are biased in favor of the lower digits.

Benford's law was discovered not by a fellow named Benford but by the American astronomer Simon Newcomb. Around 1881, Newcomb noticed that the pages of books of logarithms that dealt with numbers beginning with the numeral 1 were dirtier and more frayed than the pages corresponding to numbers beginning with the numeral 2, and so on, down to the numeral 9, whose pages, in comparison, looked clean and new. Assuming that in the long run, wear was proportional to amount of use, Newcomb concluded from his observations that the scientists with whom he shared the book were working with data that reflected that distribution of digits. The law's current name arose after Frank Benford noticed the same thing, in 1938, when scrutinizing the log tables at the General Electric Research Laboratory in Schenectady, New York. But neither man proved the law. That didn't happen until 1995, in work by Ted Hill, a mathematician at the Georgia Institute of Technology.

According to Benford's law, rather than all nine digits' appearing with equal frequency, the number 1 should appear as the first digit in data about 30 percent of the time; the digit 2, about 18 percent of the time; and so on, down to the digit 9, which should appear as the first digit about 5 percent of the time. A similar law, though less pronounced, applies to later digits. Many types of data obey Benford's law, in particular, financial data. In fact, the law seems tailor-made for mining large amounts of financial data in search of fraud.

One famous application involved a young entrepreneur named Kevin Lawrence, who raised `$`91 million to create a chain of high-tech health clubs.2 Engorged with cash, Lawrence raced into action, hiring a bevy of executives and spending his investors' money as quickly as he had raised it. That would have been fine except for one detail: he and his cohorts were spending most of the money not on the business but on personal items. And since several homes, twenty personal watercraft, forty-seven cars (including five Hummers, four Ferraris, three Dodge Vipers, two DeTomaso Panteras, and a Lamborghini Diablo), two Rolex watches, a twenty-one-carat diamond bracelet, a `$`200,000 samurai sword, and a commercial-grade cotton candy machine would have been difficult to explain as necessary business expenditures, Lawrence and his pals tried to cover their tracks by moving investors' money through a complex web of bank accounts and shell companies to give the appearance of a bustling and growing business. Unfortunately for them, a suspicious forensic accountant named Darrell Dorrell compiled a list of over 70,000 numbers representing their various checks and wire transfers and compared the distribution of digits with Benford's law. The numbers failed the test.3 That, of course, was only the beginning of the investigation, but from there the saga unfolded predictably, ending the day before Thanksgiving 2003, when, flanked by his attorneys and clad in light blue prison garb, Kevin Lawrence was sentenced to twenty years without possibility of parole. The IRS has also studied Benford's law as a way to identify tax cheats. One researcher even applied the law to thirteen years of Bill Clinton's tax returns. They passed the test.4

Presumably neither the Harlem syndicate nor its customers noticed these regularities in their lottery numbers. But had people like Newcomb, Benford, or Hill played their lottery, in principle they could have used Benford's law to make favorable bets, earning a nice supplement to their scholar's salary.

In 1947, scientists at the Rand Corporation needed a large table of random digits for a more admirable purpose: to help find approximate solutions to certain mathematical equations employing a technique aptly named the Monte Carlo method. To generate the digits, they employed electronically generated noise, a kind of electronic roulette wheel. Is electronic noise random? That is a question as subtle as the definition of randomness itself.

In 1896 the American philosopher Charles Sanders Peirce wrote that a random sample is one「taken according to a precept or method which, being applied over and over again indefinitely, would in the long run result in the drawing of any one of a set of instances as often as any other set of the same number.」5 That is called the frequency interpretation of randomness. The main alternative to it is called the subjective interpretation. Whereas in the frequency interpretation you judge a sample by the way it turned out, in the subjective interpretation you judge a sample by the way it is produced. According to the subjective interpretation, a number or set of numbers is considered random if we either don't know or cannot predict how the process that produces it will turn out.

The difference between the two interpretations is more nuanced than it may seem. For example, in a perfect world a throw of a die would be random by the first definition but not by the second, since all faces would be equally probable but we could (in a perfect world) employ our exact knowledge of the physical conditions and the laws of physics to determine before each throw exactly how the die will land. In the imperfect real world, however, a throw of a die is random according to the second definition but not the first. That's because, as Moshe pointed out, owing to its imperfections, a die will not land on each face with equal frequency; nevertheless, because of our limitations we have no prior knowledge about any face being favored over any other.

In order to decide whether their table was random, the Rand scientists subjected it to various tests. Upon closer inspection, their system was shown to have biases, just like Moshe's archetypally imperfect dice.6 The Rand scientists made some refinements to their system but never managed to completely banish the regularities. As Moshe said, complete chaos is ironically a kind of perfection. Still, the Rand numbers proved random enough to be useful, and the company published them in 1955 under the catchy title A Million Random Digits.

In their research the Rand scientists ran into a roulette-wheel problem that had been discovered, in some abstract way, almost a century earlier by an Englishman named Joseph Jagger.7 Jagger was an engineer and a mechanic in a cotton factory in Yorkshire, and so he had an intuitive feel for the capabilities — and the shortcomings — of machinery and one day in 1873 turned his intuition and fertile mind from cotton to cash. How perfectly, he wondered, can the roulette wheels in Monte Carlo really work?

The roulette wheel — invented, at least according to legend, by Blaise Pascal as he was tinkering with an idea for a perpetual-motion machine — is basically a large bowl with partitions (called frets) that are shaped like thin slices of pie. When the wheel is spun, a marble first bounces along the rim of the bowl but eventually comes to rest in one of the compartments, which are numbered 1 through 36, plus 0 (and 00 on American roulette wheels). The bettor's job is simple: to guess in which compartment the marble will land. The existence of roulette wheels is pretty good evidence that legitimate psychics don't exist, for in Monte Carlo if you bet `$`1 on a compartment and the marble lands there, the house pays you `$`35 (plus your initial dollar). If psychics really existed, you'd see them in places like that, hooting and dancing and pushing wheelbarrows of cash down the street, and not on Web sites calling themselves Zelda Who Knows All and Sees All and offering twenty-four-hour free online love advice in competition with about 1.2 million other Web psychics (according to Google). For me both the future and, increasingly, the past unfortunately appear obscured by a thick fog. But I do know one thing: my chances of losing at European roulette are 36 out of 37; my chances of winning, 1 out of 37. That means that for every `$`1 I bet, the casino stands to win (36/37 × `$`1) – (1/37 × `$`35). That comes to 1/37 of a dollar, or about 2.7¢. Depending on my state of mind, it's either the price I pay for the enjoyment of watching a little marble bounce around a big shiny wheel or else the price I pay for the opportunity of having lightning strike me (in a good way). At least that is how it is supposed to work.

But does it? Only if the roulette wheels are perfectly balanced, thought Jagger, and he had worked with enough machines to share Moshe's point of view. He was willing to bet they weren't. So he gathered his savings, traveled to Monte Carlo, and hired six assistants, one for each of the casino's six roulette wheels. Every day his assistants observed the wheels, writing down every number that came up in the twelve hours the casino was open. Every night, back in his hotel room, Jagger analyzed the numbers. After six days, he had not detected any bias in five of the wheels, but on the sixth wheel nine numbers came up noticeably more often than the others. And so on the seventh day he headed to the casino and started to bet heavily on the nine favored numbers: 7, 8, 9, 17, 18, 19, 22, 28, and 29.

When the casino shut that night, Jagger was up `$`70,000. His winnings did not go without notice. Other patrons swarmed his table, tossing down their own cash to get in on a good thing. And casino inspectors were all over him, trying to decipher his system or, better, catch him cheating. By the fourth day of betting, Jagger had amassed `$`300,000, and the casino's managers were desperate to get rid of the mystery guy, or at least thwart his scheme. One imagines this being accomplished by a burly fellow from Brooklyn. Actually the casino employees did something far more clever.

On the fifth day, Jagger began to lose. His losing, like his winning, was not something you could spot immediately. Both before and after the casino's trick, he would win some and lose some, only now he lost more often than he won instead of the other way around. With the casino's small margin, it would take some pretty diligent betting to drain Jagger's funds, but after four days of sucking in casino money, he wasn't about to let up on the straw. By the time his change of luck deterred him, Jagger had lost half his fortune. One may imagine that by then his mood — not to mention the mood of his hangers-on — was sour. How could his scheme have suddenly failed?

Jagger at last made an astute observation. In the dozens of hours he had spent winning, he had come to notice a tiny scratch on the roulette wheel. This scratch was now absent. Had the casino kindly touched it up so that he could drive them to bankruptcy in style? Jagger guessed not and checked the other roulette wheels. One of them had a scratch. The casino managers had correctly guessed that Jagger's days of success were somehow related to the wheel he was playing, and so overnight they had switched wheels. Jagger relocated and again began to win. Soon he had pumped his winnings past where they had been, to almost half a million.

Unfortunately for Jagger, the casino's managers, finally zeroing in on his scheme, found a new way to thwart him. They decided to move the frets each night after closing, turning them along the wheel so that each day the wheel's imbalance would favor different numbers, numbers unknown to Jagger. Jagger started losing again and finally quit. His gambling career over, he left Monte Carlo with `$`325,000 in hand, about `$`5 million in today's dollars. Back home, he left his job at the mill and invested his money in real estate.

It may appear that Jagger's scheme had been a sure thing, but it wasn't. For even a perfectly balanced wheel will not come up on 0, 1, 2, 3, and so on, with exactly equal frequencies, as if the numbers in the lead would politely wait for the laggards to catch up. Instead, some numbers are bound to come up more often than average and others less often. And so even after six days of observations, there remained a chance that Jagger was wrong. The higher frequencies he observed for certain numbers may have arisen by chance and may not have reflected higher probabilities. That means that Jagger, too, had to face the question we raised at the start of this chapter: given a set of underlying probabilities, how closely can you expect your observations of a system to conform to those probabilities? Just as Pascal's work was done in the new climate of (the scientific) revolution, so this question would be answered in the midst of a revolution, this one in mathematics — the invention of calculus.

IN 1680 a great comet sailed through our neighborhood of the solar system, close enough that the tiny fraction of sunlight it reflected was sufficient to make it prominent in the night sky of our own planet. It was in that part of earth's orbit called November that the comet was first spotted, and for months afterward it remained an object of intense scrutiny, its path recorded in great detail. In 1687, Isaac Newton would use these data as an example of his inverse square law of gravity at work. And on one clear night in that parcel of land called Basel, Switzerland, another man destined for greatness was also paying attention. He was a young theologian who, gazing at the bright, hazy light of the comet, realized that it was mathematics, not the church, with which he wanted to occupy his life.8 With that realization sprouted not just Jakob Bernoulli's own career change but also what would become the greatest family tree in the history of mathematics: in the century and a half between Jakob's birth and 1800 the Bernoulli family produced a great many offspring, about half of whom were gifted, including eight noted mathematicians, and three (Jakob, his younger brother Johann, and Johann's son Daniel) who are today counted as among the greatest mathematicians of all times.

Comets at the time were considered by theologians and the general public alike as a sign of divine anger, and God must have seemed pretty pissed off to create this one — it occupied more than half the visible sky. One preacher called it a「heavenly warning of the Allpowerful and Holy God written and placed before the powerless and unholy children of men.」It portended, he wrote,「a noteworthy change in spirit or in worldly matters」for their country or town.9 Jakob Bernoulli had another point of view. In 1681 he published a pamphlet titled Newly Discovered Method of How the Path of a Comet or Tailed Star Can Be Reduced to Certain Fundamental Laws, and Its Appearance Predicted.

Bernoulli had scooped Newton on the comet by six years. At least he would have scooped him had his theory been correct. It wasn't, but claiming publicly that comets follow natural law and not God's whim was a gutsy thing to do, especially given that the prior year — almost fifty years after Galileo's condemnation — the professor of mathematics at the University of Basel, Peter Megerlin, had been roundly attacked by theologians for accepting the Copernican system and had been banned from teaching it at the university. A forbidding schism lay between the mathematician-scientists and the theologians in Basel, and Bernoulli was parking himself squarely on the side of the scientists.

Bernoulli's talent soon brought the embrace of the mathematics community, and when Megerlin died, in late 1686, Bernoulli succeeded him as professor of mathematics. By then Bernoulli was working on problems connected with games of chance. One of his major influences was a Dutch mathematician and scientist, Christiaan Huygens, who in addition to improving the telescope, being the first to understand Saturn's rings, creating the first pendulum clock (based on Galileo's ideas), and helping to develop the wave theory of light, had written a mathematical primer on probability inspired by the ideas of Pascal and Fermat.

For Bernoulli, Huygens's book was an inspiration. And yet he saw in the theory Huygens presented severe limitations. It might be sufficient for games of chance, but what about aspects of life that are more subjective? How can you assign a definite probability to the credibility of legal testimony? Or to who was the better golfer, Charles I of England or Mary, Queen of Scots? (Both were keen golfers.) Bernoulli believed that for rational decision making to be possible, there must be a reliable and mathematical way to determine probabilities. His view reflected the culture of the times, in which to conduct one's affairs in a manner that was consistent with probabilistic expectation was considered the mark of a reasonable person. But it was not just subjectivity that, in Bernoulli's opinion, limited the old theory of randomness. He also recognized that the theory was not designed for situations of ignorance, in which the probabilities of various outcomes could be defined in principle but in practice were not known. It is the issue I discussed with Moshe and that Jagger had to address: What are the odds that an imperfect die will come up with a 6? What are your chances of contracting the plague? What is the probability that your breastplate can withstand a thrust from your opponent's long sword? In both subjective and uncertain situations, Bernoulli believed it would be「insanity」to expect to have the sort of prior, or a priori, knowledge of probabilities envisioned in Huygens's book.10

Bernoulli saw the answer in the same terms that Jagger later would: instead of depending on probabilities being handed to us, we should discern them through observation. Being a mathematician, he sought to make the idea precise. Given that you view a certain number of roulette spins, how closely can you nail down the underlying probabilities, and with what level of confidence? We'll return to those questions in the next chapter, but they are not quite the questions Bernoulli was able to answer. Instead, he answered a closely related question: how well are underlying probabilities reflected in actual results? Bernoulli considered it obvious that we are justified in expecting that as we increase the number of trials, the observed frequencies will reflect — more and more accurately — their underlying probabilities. He certainly wasn't the first to believe that. But he was the first to give the issue a formal treatment, to turn the idea into a proof, and to quantify it, asking how many trials are necessary, and how sure can we be. He was also among the first to appreciate the importance of the new subject of calculus in addressing these issues.

THE YEAR Bernoulli was named professor in Basel proved to be a milestone year in the history of mathematics: it was the year in which Gottfried Leibniz published his revolutionary paper laying out the principles of integral calculus, the complement to his 1684 paper on differential calculus. Newton would publish his own version of the subject in 1687, in his Philosophiae Naturalis Principia Mathematica, or Mathematical Principles of Natural Philosophy, often referred to simply as Principia. These advances would hold the key to Bernoulli's work on randomness.

By the time they published, both Leibniz and Newton had worked on the subject for years, but their almost simultaneous publications begged for controversy over who should be credited for the idea. The great mathematician Karl Pearson (whom we shall encounter again in chapter 8) said that the reputation of mathematicians「stands for posterity largely not on what they did, but on what their contemporaries attributed to them.」11 Perhaps Newton and Leibniz would have agreed with that. In any case neither was above a good fight, and the one that ensued was famously bitter. At the time the outcome was mixed. The Germans and Swiss learned their calculus from Leibniz's work, and the English and many of the French from Newton's. From the modern standpoint there is very little difference between the two, but in the long run Newton's contribution is often emphasized because he appears to have truly had the idea earlier and because in Principia he employed his invention in the creation of modern physics, making Principia probably the greatest scientific book ever written. Leibniz, though, had developed a better notation, and it is his symbols that are often used in calculus today.

Neither man's publications were easy to follow. In addition to being the greatest book on science, Newton's Principia has also been called「one of the most inaccessible books ever written.」12 And Leibniz's work, according to one of Jakob Bernoulli's biographers, was「understood by no one」it was not only unclear but also full of misprints. Jakob's brother Johann called it「an enigma rather than an explanation.」13 In fact, so incomprehensible were both works that scholars have speculated that both authors might have intentionally made their works difficult to understand to keep amateurs from dabbling. This enigmatic quality was an advantage for Jakob Bernoulli, though, for it did separate the wheat from the chaff, and his intellect fell into the former category. Hence once he had deciphered Leibniz's ideas, he possessed a weapon shared by only a handful of others in the entire world, and with it he could easily solve problems that were exceedingly difficult for others to attempt.

The set of concepts central to both calculus and Bernoulli's work is that of sequence, series, and limit. The term sequence means much the same thing to a mathematician as it does to anybody else: an ordered succession of elements, such as points or numbers. A series is simply the sum of a sequence of numbers. And loosely speaking, if the elements of a sequence seem to be heading somewhere — toward a particular endpoint or a particular number — then that is called the limit of the sequence.

Though calculus represents a new sophistication in the understanding of sequences, that idea, like so many others, had already been familiar to the Greeks. In the fifth century B.C., in fact, the Greek philosopher Zeno employed a curious sequence to formulate a paradox that is still debated among college philosophy students today, especially after a few beers. Zeno's paradox goes like this: Suppose a student wishes to step to the door, which is 1 meter away. (We choose a meter here for convenience, but the same argument holds for a mile or any other measure.) Before she arrives there, she first must arrive at the halfway point. But in order to reach the halfway point, she must first arrive halfway to the halfway point — that is, at the one-quarter-way point. And so on, ad infinitum. In other words, in order to reach her destination, she must travel this sequence of distances: 1/2 meter, 1/4 meter, 1/8 meter, 1/16 meter, and so on. Zeno argued that because the sequence goes on forever, she has to traverse an infinite number of finite distances. That, Zeno said, must take an infinite amount of time. Zeno's conclusion: you can never get anywhere.

Over the centuries, philosophers from Aristotle to Kant have debated this quandary. Diogenes the Cynic took the empirical approach: he simply walked a few steps, then pointed out that things in fact do move. To those of us who aren't students of philosophy, that probably sounds like a pretty good answer. But it wouldn't have impressed Zeno. Zeno was aware of the clash between his logical proof and the evidence of his senses; it's just that, unlike Diogenes, what Zeno trusted was logic. And Zeno wasn't just spinning his wheels. Even Diogenes would have had to admit that his response leaves us facing a puzzling (and, it turns out, deep) question: if our sensory evidence is correct, then what is wrong with Zeno's logic?

Consider the sequence of distances in Zeno's paradox: 1/2 meter, 1/4 meter, 1/8 meter, 1/16 meter, and so on (the increments growing ever smaller). This sequence has an infinite number of terms, so we cannot compute its sum by simply adding them all up. But we can notice that although the number of terms is infinite, those terms get successively smaller. Might there be a finite balance between the endless stream of terms and their endlessly diminishing size? That is precisely the kind of question we can address by employing the concepts of sequence, series, and limit. To see how it works, instead of trying to calculate how far the student went after the entire infinity of Zeno's intervals, let's take one interval at a time. Here are the student's distances after the first few intervals:

After the first interval: 1/2 meter

After the second interval: 1/2 meter + 1/4 meter = 3/4 meter

After the third interval: 1/2 meter + 1/4 meter + 1/8 meter = 7/8 meter

After the fourth interval: 1/2 meter + 1/4 meter + 1/8 meter + 1/16 meter = 15/16 meter

There is a pattern in these numbers: 1/2 meter, 3/4 meter, 7/8 meter, 15/16 meter…The denominator is a power of two, and the numerator is one less than the denominator. We might guess from this pattern that after 10 intervals the student would have traveled 1,023/1,024 meter; after 20 intervals, 1,048,575/1,048,576 meter; and so on. The pattern makes it clear that Zeno is correct that the more intervals we include, the greater the sum of distances we obtain. But Zeno is not correct when he says that the sum is headed for infinity. Instead, the numbers seem to be approaching 1; or as a mathematician would say, 1 meter is the limit of this sequence of distances. That makes sense, because although Zeno chopped her trip into an infinite number of intervals, she had, after all, set out to travel just 1 meter.

Zeno's paradox concerns the amount of time it takes to make the journey, not the distance covered. If the student were forced to take individual steps to cover each of Zeno's intervals, she would indeed be in some time trouble (not to mention her having to overcome the difficulty of taking submillimeter steps)! But if she is allowed to move at constant speed without pausing at Zeno's imaginary checkpoints — and why not? — then the time it takes to travel each of Zeno's intervals is proportional to the distance covered in that interval, and so since the total distance is finite, as is the total time — and fortunately for all of us — motion is possible after all.

Though the modern concept of limits wasn't worked out until long after Zeno's life, and even Bernoulli's — it came in the nineteenth century14 — it is this concept that informs the spirit of calculus, and it is in this spirit that Jakob Bernoulli attacked the relationship between probabilities and observation. In particular, Bernoulli investigated what happens in the limit of an arbitrarily large number of repeated observations. Toss a (balanced) coin 10 times and you might observe 7 heads, but toss it 1 zillion times and you'll most likely get very near 50 percent. In the 1940s a South African mathematician named John Kerrich decided to test this out in a practical experiment, tossing a coin what must have seemed like 1 zillion times — actually it was 10,000 — and recording the results of each toss.15 You might think Kerrich would have had better things to do, but he was a war prisoner at the time, having had the bad luck of being a visitor in Copenhagen when the Germans invaded Denmark in April 1940. According to Kerrich's data, after 100 throws he had only 44 percent heads, but by the time he reached 10,000, the number was much closer to half: 50.67 percent. How do you quantify this phenomenon? The answer to that question was Bernoulli's accomplishment.

According to the historian and philosopher of science Ian Hacking, Bernoulli's work「came before the public with a brilliant portent of all the things we know about it now; its mathematical profundity, its unbounded practical applications, its squirming duality and its constant invitation for philosophizing. Probability had fully emerged.」In Bernoulli's more modest words, his study proved to be one of「novelty, as well as…high utility.」It was also an effort, Bernoulli wrote, of「grave difficulty.」16 He worked on it for twenty years.

JAKOB BERNOULLI called the high point of his twenty-year effort his「golden theorem.」Modern versions of it that differ in their technical nuance go by various names: Bernoulli's theorem, the law of large numbers, and the weak law of large numbers. The phrase law of large numbers is employed because, as we've said, Bernoulli's theorem concerns the way results reflect underlying probabilities when we make a large number of observations. But we'll stick with Bernoulli's terminology and call his theorem the golden theorem because we will be discussing it in its original form.17

Although Bernoulli's interest lay in real-world applications, some of his favorite examples involved an item not found in most households: an urn filled with colored pebbles. In one scenario, he envisioned the urn holding 3,000 white pebbles and 2,000 black ones, a ratio of 60 percent white to 40 percent black. In this example you conduct a series of blind drawings from the urn「with replacement」 — that is, replacing each pebble before drawing the next in order not to alter the 3:2 ratio. The a priori chances of drawing a white pebble are then 3 out of 5, or 60 percent, and so in this example Bernoulli's central question becomes, how strictly should you expect the proportion of white pebbles drawn to hew to the 60 percent ratio, and with what probability?

The urn example is a good one because the same mathematics that describes drawing pebbles from an urn can be employed to describe any series of trials in which each trial has two possible outcomes, as long as those outcomes are random and the trials are independent of each other. Today such trials are called Bernoulli trials, and a series of Bernoulli trials is a Bernoulli process. When a random trial has two possible outcomes, one is often arbitrarily labeled「success」and the other「failure.」The labeling is not meant to be literal and sometimes has nothing to do with the everyday meaning of the words — say, in the sense that if you can't wait to read on, this book is a success, and if you are using this book to keep yourself and your sweetheart warm after the logs burned down, it is a failure. Flipping a coin, deciding to vote for candidate A or candidate B, giving birth to a boy or girl, buying or not buying a product, being cured or not being cured, even dying or living are examples of Bernoulli trials. Actions that have multiple outcomes can also be modeled as Bernoulli trials if the question you are asking can be phrased in a way that has a yes or no answer, such as「Did the die land on the number 4?」or「Is there any ice left on the North Pole?」And so, although Bernoulli wrote about pebbles and urns, all his examples apply equally to these and many other analogous situations.

With that understanding we return to the urn, 60 percent of whose pebbles are white. If you draw 100 pebbles from the urn (with replacement), you might find that exactly 60 of them are white, but you might also draw just 50 white pebbles or 59. What are the chances that you will draw between 58 percent and 62 percent white pebbles? What are the chances you'll draw between 59 percent and 61 percent? How much more confident can you be if instead of 100, you draw 1,000 pebbles or 1 million? You can never be 100 percent certain, but can you draw enough pebbles to make the chances 99.9999 percent certain that you will draw, say, between 59.9 percent and 60.1 percent white pebbles? Bernoulli's golden theorem addresses questions such as these.

In order to apply the golden theorem, you must make two choices. First, you must specify your tolerance of error. How near to the underlying proportion of 60 percent are you demanding that your series of trials come? You must choose an interval, such as plus or minus 1 percent or 2 percent or 0.00001 percent. Second, you must specify your tolerance of uncertainty. You can never be 100 percent sure a trial will yield the result you are aiming for, but you can ensure that you will get a satisfactory result 99 times out of 100 or 999 out of 1,000.

The golden theorem tells you that it is always possible to draw enough pebbles to be almost certain that the percentage of white pebbles you draw will be near 60 percent no matter how demanding you want to be in your personal definition of almost certain and near. It also gives a numerical formula for calculating the number of trials that are「enough,」given those definitions.

The first part of the law was a conceptual triumph, and it is the only part that survives in modern versions of the theorem. Concerning the second part — Bernoulli's formula — it is important to understand that although the golden theorem specifies a number of trials that is sufficient to meet your goals of confidence and accuracy, it does not say you can't accomplish those goals with fewer trials. That doesn't affect the first part of the theorem, for which it is enough to know simply that the number of trials specified is finite. But Bernoulli also intended the number given by his formula to be of practical use. Unfortunately, in most practical applications it isn't. For instance, here is a numerical example Bernoulli worked out himself, although I have changed the context: Suppose 60 percent of the voters in Basel support the mayor. How many people must you poll for the chances to be 99.9 percent that you will find the mayor's support to be between 58 percent and 62 percent — that is, for the result to be accurate within plus or minus 2 percent? (Assume, in order to be consistent with Bernoulli, that the people polled are chosen at random, but with replacement. In other words, it is possible that you poll a person more than once.) The answer is 25,550, which in Bernoulli's time was roughly the entire population of Basel. That this number was impractical wasn't lost on Bernoulli. He also knew that accomplished gamblers can intuitively guess their chances of success at a new game based on a sample of far fewer than thousands of trial games.

One reason Bernoulli's numerical estimate was so far from optimal was that his proof was based on many approximations. Another reason was that he chose 99.9 percent as his standard of certainty — that is, he required that he get the wrong answer (an answer that differed more than 2 percent from the true one) less than 1 time in 1,000. That is a very demanding standard. Bernoulli called it moral certainty, meaning the degree of certainty he thought a reasonable person would require in order to make a rational decision. It is perhaps a measure of how much the times have changed that today we've abandoned the notion of moral certainty in favor of the one we encountered in the last chapter, statistical significance, meaning that your answer will be wrong less than 1 time in 20.

With today's mathematical methods, statisticians have shown that in a poll like the one I described, you can achieve a statistically significant result with an accuracy of plus or minus 5 percent by polling only 370 subjects. And if you poll 1,000, you can achieve a 90 percent chance of coming within 2 percent of the true result (60 percent approval of Basel's mayor). But despite its limitations, Bernoulli's golden theorem was a milestone because it showed, at least in principle, that a large enough sample will almost certainly reflect the underlying makeup of the population being sampled.

IN REAL LIFE we don't often get to observe anyone's or anything's performance over thousands of trials. And so if Bernoulli required an overly strict standard of certainty, in real-life situations we often make the opposite error: we assume that a sample or a series of trials is representative of the underlying situation when it is actually far too small to be reliable. For instance, if you polled exactly 5 residents of Basel in Bernoulli's day, a calculation like the ones we discussed in chapter 4 shows that the chances are only about 1 in 3 that you will find that 60 percent of the sample (3 people) supported the mayor.

Only 1 in 3? Shouldn't the true percentage of the mayor's supporters be the most probable outcome when you poll a sample of voters? In fact, 1 in 3 is the most probable outcome: the odds of finding 0, 1, 2, 4, or 5 supporters are lower than the odds of finding 3. Nevertheless, finding 3 supporters is not likely: because there are so many of those nonrepresentative possibilities, their combined odds add up to twice the odds that your poll accurately reflects the population. And so in a poll of 5 voters, 2 times out of 3 you will observe the「wrong」percentage. In fact, about 1 in 10 times you'll find that all the voters you polled agree on whether they like or dislike the mayor. And so if you paid any attention to a sample of 5, you'd probably severely over- or underestimate the mayor's true popularity.

The misconception — or the mistaken intuition — that a small sample accurately reflects underlying probabilities is so widespread that Kahneman and Tversky gave it a name: the law of small numbers.18 The law of small numbers is not really a law. It is a sarcastic name describing the misguided attempt to apply the law of large numbers when the numbers aren't large.

If people applied the (untrue) law of small numbers only to urns, there wouldn't be much impact, but as we've said, many events in life are Bernoulli processes, and so our intuition often leads us to misinterpret what we observe. That is why, as I described in chapter 1, when people observe the handful of more successful or less successful years achieved by the Sherry Lansings and Mark Cantons of the world, they assume that their past performance accurately predicts their future performance.

Let's apply these ideas to an example I mentioned briefly in chapter 4: the situation in which two companies compete head-to-head or two employees within a company compete. Think now of the CEOs of the Fortune 500 companies. Let's assume that, based on their knowledge and abilities, each CEO has a certain probability of success each year (however his or her company may define that). And to make things simple, let's assume that for these CEOs successful years occur with the same frequency as the white pebbles or the mayor's supporters: 60 percent. (Whether the true number is a little higher or a little lower doesn't affect the thrust of this argument.) Does that mean we should expect, in a given five-year period, that a CEO will have precisely three good years?

No. As the earlier analysis showed, even if the CEOs all have a nice cut-and-dried 60 percent success rate, the chances that in a given five-year period a particular CEO's performance will reflect that underlying rate are only 1 in 3! Translated to the Fortune 500, that means that over the past five years about 333 of the CEOs would have exhibited performance that did not reflect their true ability. Moreover, we should expect, by chance alone, about 1 in 10 of the CEOs to have five winning or losing years in a row. What does this tell us? It is more reliable to judge people by analyzing their abilities than by glancing at the scoreboard. Or as Bernoulli put it,「One should not appraise human action on the basis of its results.」19

Going against the law of small numbers requires character. For while anyone can sit back and point to the bottom line as justification, assessing instead a person's actual knowledge and actual ability takes confidence, thought, good judgment, and, well, guts. You can't just stand up in a meeting with your colleagues and yell,「Don't fire her. She was just on the wrong end of a Bernoulli series.」Nor is it likely to win you friends if you stand up and say of the gloating fellow who just sold more Toyota Camrys than anyone else in the history of the dealership,「It was just a random fluctuation.」And so it rarely happens. Executives' winning years are attributed to their brilliance, explained retroactively through incisive hindsight. And when people don't succeed, we often assume the failure accurately reflects the proportion with which their talents and their abilities fill the urn.

Another mistaken notion connected with the law of large numbers is the idea that an event is more or less likely to occur because it has or has not happened recently. The idea that the odds of an event with a fixed probability increase or decrease depending on recent occurrences of the event is called the gambler's fallacy. For example, if Kerrich landed, say, 44 heads in the first 100 tosses, the coin would not develop a bias toward tails in order to catch up! That's what is at the root of such ideas as「her luck has run out」and「He is due.」That does not happen. For what it's worth, a good streak doesn't jinx you, and a bad one, unfortunately, does not mean better luck is in store. Still, the gambler's fallacy affects more people than you might think, if not on a conscious level then on an unconscious one. People expect good luck to follow bad luck, or they worry that bad will follow good.

I remember, on a cruise a few years back, watching an intense pudgy man sweating as he frantically fed dollars into a slot machine as fast as it would take them. His companion, seeing me eye them, remarked simply,「He is due.」Although tempted to point out that, no, he isn't due, I instead walked on. After several steps I halted my progress owing to a sudden flashing of lights, ringing of bells, not a little hooting on the couple's part, and the sound of, for what seemed like minutes, a fast stream of dollar coins flying out of the machine's chute. Now I know that a modern slot machine is computerized, its payoffs driven by a random-number generator, which by both law and regulation must truly generate, as advertised, random numbers, making each pull of the handle completely independent of the history of previous pulls. And yet…Well, let's just say the gambler's fallacy is a powerful illusion.

THE MANUSCRIPT in which Bernoulli presented his golden theorem ends abruptly even though he promises earlier in the work that he will provide applications to various issues in civic affairs and economics. It is as if「Bernoulli literally quit when he saw the number 25,550,」wrote the historian of statistics Stephen Stigler.20 In fact, Bernoulli was in the process of publishing his manuscript when he died「of a slow fever」in August 1705, at the age of fifty. His publishers asked Johann Bernoulli to complete it, but Johann refused, saying he was too busy. That may appear odd, but the Bernoullis were an odd family. If you were asked to choose the most unpleasant mathematician who ever lived, you wouldn't be too far off if you fingered Johann Bernoulli. He has been variously described in historical texts as jealous, vain, thin-skinned, stubborn, bilious, boastful, dishonest, and a consummate liar. He accomplished much in mathematics, but he is also known for having his son Daniel tossed out of the Académie des Sciences after Daniel won a prize for which Johann himself had competed, for attempting to steal both his brother's and Leibniz's ideas, and for plagiarizing Daniel's book on hydrodynamics and then faking the publication date so that his book would appear to have been published first.

When he was asked to complete his late brother's manuscript, he had recently relocated to Basel from the University of Groningen, in the Netherlands, obtaining a post not in mathematics but as a professor of Greek. Jakob had found this career change suspicious, especially since in his estimation Johann did not know Greek. What Jakob suspected, he wrote Leibniz, was that Johann had come to Basel to usurp Jakob's position. And, indeed, upon Jakob's death, Johann did obtain it.

Johann and Jakob had not gotten along for most of their adult lives. They would regularly trade insults in mathematics publications and in letters that, one mathematician wrote,「bristle with strong language that is usually reserved for horse thieves.」21 And so when the need arose to edit Jakob's posthumous manuscript, the task fell further down the food chain, to Jakob's nephew Nikolaus, the son of one of Jakob's other brothers, also named Nikolaus. The younger Nikolaus was only eighteen at the time, but he had been one of Jakob's pupils. Unfortunately he didn't feel up to the task, possibly in part because he was aware of Leibniz's opposition to his uncle's ideas about applications of the theory. And so the manuscript lay dormant for eight years. The book was finally published in 1713 under the title Ars conjectandi, or The Art of Conjecture. Like Pascal's Pensées, it is still in print.

Jakob Bernoulli had shown that through mathematical analysis one could learn how the inner hidden probabilities that underlie natural systems are reflected in the data those systems produce. As for the question that Bernoulli did not answer — the question of how to infer, from the data produced, the underlying probability of events — the answer would not come for several decades more.

### Notes

1 Tijms, Understanding Probability, p. 53.

2 Scott Kinney,「Judge Sentences Kevin L. Lawrence to 20 Years Prison in Znetix/HMC Stock Scam,」Washington State Department of Financial Institutions, press release, November 25, 2003; http://www.dfi.wa.gov/sd/kevin_laurence_sentence.htm.

3 Interview with Darrell Dorrell, August 1, 2005.

4 Lee Berton,「He's Got Their Number: Scholar Uses Math to Foil Financial Fraud,」Wall Street Journal, July 10, 1995.

5 Charles Sanders Peirce, Max Harold Fisch, and Christian J. W. Kloesel, Writings of Charles S. Peirce: A Chronological Edition (Bloomington: Indiana University Press, 1982), p. 427.

6 Rand Corporation, A Million Random Digits with 100,000 Normal Deviates (1955; repr., Santa Monica, Calif.: Rand, 2001), pp. ix–x. See also Lola L. Lopes,「Doing the Impossible: A Note on Induction and the Experience of Randomness,」Journal of Experimental Psychology: Learning, Memory, and Cognition 8, no. 6 (November 1982): 626–36.

7 The account of Joseph Jagger (sometimes spelled Jaggers) is from John Grochowski,「House Has a Built-in Edge When Roulette Wheel Spins,」Chicago Sun-Times, February 21, 1997.

8 For details about the Bernoulli family and Jakob's life, see E. S. Pearson, ed., The History of Statistics in the 17th and 18th Centuries against the Changing Background of Intellectual, Scientific and Religious Thought: Lectures by Karl Pearson Given at University College, London, during the Academic Sessions 1921–1933 (New York: Macmillan, 1978), pp. 221–37; J. O. Fleckenstein,「Johann und Jakob Bernoulli,」in Elemente der Mathematik, Beihefte zur Zeitschrift, no. 6 (Basel, 1949); and Stephen Stigler,「The Bernoullis of Basel,」Journal of Econometrics 75, no. 1 (1996): 7–13.

9 Quoted in Pearson, The History of Statistics in the 17th and 18th Centuries, p. 224.

10 Stephen Stigler, The History of Statistics: The Measurement of Uncertainty before 1900 (Cambridge, Mass.: Harvard University Press, 1986), p. 65.

11 Pearson, The History of Statistics in the 17th and 18th Centuries, p. 226.

12 William H. Cropper, The Great Physicists: The Life and Times of Leading Physicists from Galileo to Hawking (London: Oxford University Press, 2001), p. 31.

13 Johann Bernoulli, quoted in Pearson, The History of Statistics in the 17th and 18th Centuries, p. 232.

14 This depends, of course, on what you identify as「the modern concept.」I am using the definition employed by Hankel's 1871 history of the topic, described in great detail in Gert Schubring, Conflicts between Generalization, Rigor, and Intuition: Number Concepts Underlying the Development of Analysis in 17th–19th Century France and Germany (New York: Springer, 2005), pp. 22–32.

15 David Freedman, Robert Pisani, and Roger Purves, Statistics, 3rd ed. (New York: W. W. Norton, 1998), pp. 274–75.

16 The Hacking quote is from Ian Hacking, The Emergence of Probability (Cambridge: Cambridge University Press, 1975), p. 143. The Bernoulli quote is from David, Gods, Games and Gambling, p. 136.

17 For a discussion of what Bernoulli actually proved, see Stigler, The History of Statistics, pp. 63–78, and Ian Hacking, The Emergence of Probability, pp. 155–65.

18 Amos Tversky and Daniel Kahneman,「Belief in the Law of Small Numbers,」Psychological Bulletin 76, no. 2 (1971): 105–10.

19 Jakob Bernoulli, quoted in L. E. Maistrov, Probability Theory: A Historical Sketch, trans. Samuel Kotz (New York: Academic Press, 1974), p. 68.

20 Stigler, The History of Statistics, p. 77.

21 E. T. Bell, Men of Mathematics (New York: Simon & Schuster, 1937), p. 134.

0501针锋相对的大数定律与小数定律

卡尔达诺、伽利略和帕斯卡都做了一个假设，那就是问题中的概率是已知的。伽利略就假设骰子的 6 个面出现的可能性都相等。但这种「知识」有多可靠呢？大公的骰子很可能是按各面平等的原则设计的，但这并不意味着这个期望中的公平就能成为现实。也许伽利略观察了若干次投掷的结果，并记下各面出现的频度来检验他的假设。但是，如果把这个检验重复几次，那么他很可能会发现，频率分布每次都会稍有出入。对于他需要解释的那个 8% 的微小差异，分布中的任何出入都可能对结论造成显著的影响。要想把随机性的早期研究成果真正应用于真实情况，就必须面对如下的问题：那些隐藏着的概率和观测结果之间的联系究竟是怎样的？在实际应用的时候，如果我们说骰子扔出 2 点的可能性是 1/6，这个说法到底是要表达什么意思？如果这句话并不是指在任一系列的投掷中，每 6 次就会严格地出现一次 2 点，那么我们对于扔出 2 点的概率为 1/6 的这种信念，到底从何而来？如果医生说一种药的有效率是 70%，但还有 1% 的可能性会出现严重的副作用，那么他又是什么意思？或者一次民意调查发现某候选人的选民支持率为 36%，这句话到底有什么含义？这些问题都十分深刻，而且与随机性的定义本身有关，而这也是一个时至今日数学家仍然乐此不疲地为之争辩的概念。

最近，我就在一个温暖的春日里，与一名来我校访问的希伯来大学统计学家进行了一次这样的讨论。莫希，这位统计学家当时就坐在加州理工学院我餐桌的对面。趁着吞下一口脱脂酸奶的空当，莫希表明了一个观点，即并不存在所谓真正的随机数。「根本没这种事儿。」他说，「对，他们出版了很多随机数表，写了很多计算机程序，但都只是在自己骗自己。从来就没有人找到过比扔骰子更好的产生随机性的方法，而扔骰子同样做不到真正的随机。」

莫希朝我挥舞着他的白色塑料勺子。他的情绪有些激动。我察觉到他对随机性的信念和他的宗教信仰之间有某种联系。莫希是一名犹太东正教徒，而就我所知，许多有宗教信仰的人，会比较难以想象上帝竟然能够允许随机性的存在。「假设你想得到 N 个由 1 到 6 的数字构成的一串随机数，」他告诉我，「那么把骰子扔上 N 次，再记录下所得的点数。不过这是一个随机数串吗？」

然后他说，不是的，因为没人能做出一个完美的骰子。总会有某些点数出现得比其他点数更频繁。也许要扔上 1000 次或 10 亿次这一点才会显示出来，但你迟早总会注意到这样的偏向。他说，只要是由人制造出来的东西，就注定会受到这类缺陷的影响，因为人类无法做到完美。这句话也许没错。不过大自然却可以做到完美，真正随机的事件确确实实在原子层面上发生着。实际上，这正是量子理论的基础。因此，我们就把剩下的午餐时间都用来讨论量子光学了。

现在，我们通过投掷大自然完美的量子骰子，可以用最尖端的量子发生器产生真正的随机数。不过在以前，产生随机性所必需的完美性，的确是一个不容易达到的目标。1920 年前后，纽约哈莱姆区的犯罪集团在这个问题上，倒是想出一种非常有创造性的方法。他们每天都需要找到 5 位数字构成的随机数，好用来进行非法彩票活动。这些骗子对当局嗤之以鼻，他们以美国国债余额的最后 5 位数字作为他们需要的随机数。（在撰写本书时，美国政府已负债 8995800515946.50 美元，或者平均每人负债 29679.02 美元。因此，如果是在今天，骗子们就可以直接利用人均负债来获得他们要的 5 个数字！）不过骗子们组织的所谓「财富」彩票，不但违反了刑法，还违反了科学规律。根据一条被称为本福特定律的规则，像国债那样的累积方式所产生的数字并不是随机的，实际上，这些数字更倾向于出现较小的值。

2『本福特定律，做一张术语卡片。（2021-02-20）』——已完成

本福特定律并不是哪个叫本福特的家伙发现的。它的发现者是美国天文学家西蒙·纽科姆。纽科姆在 1881 年前后注意到一种现象：那些对数表书中，用来处理 1 开头的数字的那几页，相比于处理 2 开头一直到 9 开头的数字的那些书页，看起来更脏一些，磨损得也更厉害。特别是 9 开头的数字对应的那几页，看上去干净崭新。纽科姆假定对数表书在长期的使用过程中，其磨损度与使用次数成正比。根据这个假设，他得出一个结论，就是跟他共用这本对数表的那些科学家，他们日常所处理的数据的分布，决定了这些书页的新旧分布。在纽约州斯克内克塔迪的通用电气研究实验室工作的弗兰克·本福特，1938 年也在对数表书中发现了同样的情况。之后，这条规律就获得了它今天的那个名字。不过这两人都未能给出证明。这个证明要到 1995 年才由佐治亚理工学院的数学家特德·希尔完成。

根据本福特定律，1 到 9 这 9 个数字的出现频率并不相等。相反，数位最高位为 1 的情况约占 30%，为 2 的情况约占 18%，如此一直到数字 9，它出现在最高位的情况大概是 5%。另外还有一个类似但人们较少提到的定律，里面考察的则是数位最低位的数字。许多类型的数据都遵循本福特定律，特别是财务数据。实际上，这条定律简直就是为在大量财务数据中发现欺诈行径而量身定做的。

本福特定律的一个著名应用，跟凯文·劳伦斯这位年轻企业家有关。劳伦斯集资 9100 万美元，说要办一个高科技保健连锁俱乐部。大把钞票到手后，劳伦斯迅速行动起来。他雇了一帮人坐办公室，很快就花光了投资人的钱，花钱的速度跟他筹钱的速度一样快。如果不在意一些小细节的话，这本来也没什么。不过几栋私人住宅，20 艘私人游艇，47 辆汽车（包括 5 辆悍马、4 辆法拉利、2 辆道奇蝰蛇、2 辆德托马索 Pantera 跑车以及 1 辆兰博基尼迪亚波罗），2 块劳力士表，1 个 21 克拉的钻石手镯，1 把 20 万美元的日本武士刀，以及 1 台商用棉花糖机，这些小细节可很难被说成是业务方面的必要开支。为了掩饰这些贪污公款的痕迹，劳伦斯和同伙们想用一个复杂的银行账户与皮包公司网络，来制造业务欣欣向荣的假象。不幸的是，他们碰到一位名叫达雷尔·多雷尔的生性多疑的法务会计师。多雷尔把他们的支票与转账单编成了一张有着 7 万个数据的表，然后把表中数字的分布情况与本福特定律进行了对比。这些数据没能通过定律的检验。这当然只是调查的开始，不过后来这个商业传奇的真相大白也就没有什么出乎意料的地方了。2003 年感恩节的前一天，穿着浅蓝色囚服、被律师簇拥着的劳伦斯被判 20 年徒刑，不得假释，这个故事就此画上了句号。美国国家税务局（IRS）也研究了本福特定律，以便用它来识别纳税中的骗局。甚至还有研究者把该定律用到了克林顿 13 年的退税款上。不过这些款项通过了定律的检验。

可想而知，哈莱姆区的犯罪集团和它的彩票顾客都没有注意到中奖号码中存在的这种规律性，但如果纽科姆、本福特或希尔这类人也来玩这个彩票，原则上他们就可以利用本福特定律，对赢面更大的数字投注，这样他们就能在学者职位的薪水之外，赚上一笔颇为不错的外快。

1947 年，兰德公司的科学家迫切需要一个巨大的随机数表。当然，他们的目的要高尚得多：用这些随机数，以一种被很恰当地称为蒙特卡罗方法的数学方法，求取某些方程的近似解。他们用电子噪声产生这些随机数。实际上，我们可以把电子噪声看成一种电子轮盘赌。那么，电子噪声是随机的吗？这个问题就如随机性的定义本身一样微妙。

美国哲学家查尔斯·桑德斯·皮尔斯在 1896 年写道，随机采样是「根据某种规则或方法进行的抽样方法，当这种规则或方法被重复无限次，那么从长远来看，它从某组实例中抽取任一元素的次数，跟它从其他任何一个元素数目相同的集合中抽取任一元素的次数，频率相同」。这被称为随机数的频率解释。另一个主流解释叫作主观解释。频率解释根据采样结果进行判断，而主观解释根据采样值的产生方式进行判断。根据主观解释，如果我们既不知道也无法预测产生某个或某些数字的过程会给出怎样的结果，那么这个或这些数字就被认为是随机的。

这两种解释之间的差别要比看上去的更大。打个比方，在一个完美的世界中，根据第一种定义，扔骰子是随机的，但按照第二种定义就不是那样了，因为尽管扔出各个点数的机会都相等，但我们可以（在一个完美的世界中）根据所掌握的精确的物理条件，在每次投出骰子前就确定将得到的点数。但在我们不完美的真实世界中，扔骰子在第二种定义下是随机的，而在第一种定义下又不是了，原因就是莫希指出的那一点，即骰子本身并非完美，它的各个点数不会以相同的频率出现。能力所限，我们没有任何先验知识知道某个点数会比另一个点数出现得更频繁。

兰德公司的科学家们为了搞清楚他们的随机数表是不是真的随机，进行了许多不同的检验。更细致的分析显示，正如莫希那个从原则上来说不完美的骰子一样，这个随机数生成系统似乎是有偏差的。兰德公司的科学家对系统进行了一些改进，但还是没有办法完全消除这种规律性。正如莫希所言，颇具讽刺意味的是，彻底的混沌本身其实也是一种完美。不过兰德公司的这些随机数已经被证明具有足够的随机性，因此可以满足使用要求。1955 年，兰德公司用一个挺好记的名字出版了这些随机数表：《百万乱数表》（ A Million Random Digits ）。

其实在差不多一个世纪之前，兰德公司的科学家在研究中碰到的这个问题，已经有一名英国人约瑟夫·贾格尔以某种形式遭遇到了。他所碰到的问题叫轮盘赌问题。贾格尔是约克郡一个棉花厂的工程师和机修师，因此，他对于机械的能力及缺陷有一种直觉。在 1873 年的某一天，他把自己对机械的直觉和创造性思维从棉纺车间转向了金钱。他考虑的问题是，蒙特卡洛赌场的轮盘赌到底有多完美？

根据传说，轮盘赌是帕斯卡在瞎想着永动机时发明出来的。基本上，轮盘赌就是把一个很大的碗，隔成许多形如从馅饼上切下的窄窄的扇形部分（称为槽）；当轮子转动时，一颗石弹珠先在碗沿上跳来跳去，并最终落入这些以数字 1 到 36 再加一个 0（美国的轮盘上还有一个 00）作为标记的槽中的某一个。轮盘赌存在的本身，就是所谓靠谱的灵媒根本不存在的一个极好的证据，因为在蒙特卡洛，你如果把 1 美元押在某个编号的槽上，而弹珠恰好掉到了这个槽里，那么赌场会付你 35 美元（再加上你下注的那 1 美元）。如果我们认为的那种灵媒确实存在，那么我们本该在赌场这类地方，看着他们一个个吵吵嚷嚷、手舞足蹈地推走一车又一车的钞票。但实际上，我们碰到的灵媒大都出没于网络，给自己起个「啥都知道也啥都看到的泽尔塔」之类的名字，一边提供 24 小时免费在线情感咨询，一边和大概 120 万（据谷歌）名其他网络灵媒激烈竞争。对我来说，未来有如身处浓雾之中，模糊不清，实际上，甚至连以前的事情也一天天都变成这样。但我起码知道这么一件事：如果赌欧式轮盘赌，我输钱的机会将是 36/37，而赢钱的机会只有 1/37。这就意味着我们每下 1 美元赌注，赌场就会赚（36/37×1 美元）-（1/37×35 美元）= 1/37 美元，大约 2.7 美分。当然，我可以把这 2.7 美分当成欣赏石弹珠在闪亮锃亮的大轮子上弹来蹦去的门票钱，也可以把它当成购买一次试图（以一种好的方式）被闪电击中的机会所付的价钱。至于到底是哪种看法，就取决于我当时的精神状态了。上面这种方式，就是我们所期望的轮盘赌机的行为方式。

但轮盘赌机真的就是如此行事的吗？贾格尔认为，只有当轮盘的各个部分都处于一种完美的平衡状态时，机器才能做到这一点。不过贾格尔跟机器厮混的时间太长了，因此他的观点跟莫希一致：他很愿意去赌一赌，这些轮盘赌机其实并不完美。于是他带着全部积蓄来到蒙特卡洛，雇了 6 名助手，赌场里面有 6 台轮盘赌机，这些助手每人负责盯一台。助手们每天都要观察所负责的机器，并记录下赌场开门后 12 个小时内，每次轮盘赌中获胜的数字。晚上回到旅馆后，贾格尔就对这些数字进行分析。经过 6 天的观察，有 5 台机器并没有表现出任何不均匀的数字分布，但在第 6 台机器上，有 9 个数字明显比其他数字出现得更频繁。第 7 天，他开赴赌场，并在这 9 个出现得更频繁的数字 ——7、8、9、17、18、19、22、28 和 29—— 上投以重注。

当晚赌场关门时，贾格尔赢了 7 万美元。这个胜利没有逃脱其他人的眼睛。别的赌徒围到他的桌旁，扔下钞票一同分享好运。赌场所有的巡查都紧盯着贾格尔，想要找出他如此走运的原因，当然，如果能在他出老千的时候抓个现行就更棒了。大赌 4 天之后，贾格尔堆起了 30 万美元，而赌场经理能做的只是绝望地祈求摆脱这个神秘的家伙，或者至少能够阻止他继续推进他的计划。也许你会以为赌场经理是请某个布鲁克林的壮汉来帮助达到这个目的的，不过赌场的人的做法可要聪明得多。

在第五天，贾格尔开始输钱了。他现在的失败一如之前的成功，并不是马上就能察觉到的。在赌场搞小动作的之前或之后，贾格尔一直都有输有赢，只不过现在他输多赢少，而之前输少赢多。照着赌场在每一注上赚到的那点儿小钱，如果贾格尔想把他的钱都输光，就得加倍勤勉地在赌桌上大干很多天；但 4 天中鲸吞了赌场金钱的贾格尔，可不想因为一点儿风声鹤唳就收手不干了。从开始转霉运到他终于收手，贾格尔输掉了一半的家产。我们不难想象他 —— 更不用说他的跟随者们 —— 是多么失落和难过。好好的一个计划怎么突然就不行了呢？

贾格尔终于精明地发现，他赢钱的时候曾经瞥到机器上有一条细微的划痕，但现在划痕不见了。难道赌场会好心地给机器补个漆，好让贾格尔把它搞破产的过程看起来更加有范儿？贾格尔可不觉得赌场会有这份好心。因此，他仔细地检查了其他几台机器。划痕在其中一台上。赌场经理没有猜错，贾格尔的成功，肯定跟他赌的那台机器存在某种联系。因此他们连夜调换了机器。发现这一点之后，贾格尔换到这台有划痕的机器上，钱再次流向他的钱包。没多久，他就赚到比之前更多的钱，这次有将近 50 万美元。

后来的事情对贾格尔来说就很不幸了。赌场经理终于忍无可忍，于是集中全力来对付他。为了阻止贾格尔，赌场想出一个新方法：每晚赌场关门后，他们就把轮盘槽全部转离原先的位置。这样一来，机器的不平衡性每一天都会偏爱不同的数字，而贾格尔现在可没法知道到底哪些数字才能赢钱了。于是钱又开始溜出贾格尔的钱包，而这一轮输钱，最终让贾格尔离开了赌场。贾格尔带着 32.5 万美元离开了蒙特卡洛，就此结束了他的赌徒生涯。以现值计算，这笔钱大约有 500 万美元。回到家乡后，他辞去厂里的工作，开始投资房地产。

贾格尔的方法看似稳妥可靠，实际上却并不那么简单。哪怕一个轮盘赌机达到了所谓完美的平衡性，0、1、2、3 等这些点数也不会以绝对相等的频率出现。那些出现频率较高的数字可不会出于礼貌而留步，以便让掉队的家伙们赶上来。实际上，肯定会有某些数字出现得比平均水平更频繁，而另一些则达不到平均水平。所以，即使进行了 6 天的观察，贾格尔仍然有可能出错。他发现的某些数字的更高出现频率，其实也有可能还是一个随机的结果，而并非说明这些数字的出现概率确实更高。换言之，贾格尔也需要面对本章开头的问题：对于一系列未知概率，如果我们通过由此产生的结果进行观察，那么这个观测结果与未知概率的吻合程度到底有多高呢？我们已经看到，帕斯卡的工作是在（科学）革命的新氛围中才得以完成的。同样，现在这个问题也是在一次新的革命期间才获得答案的，不过这回是一次数学革命，而这个革命就是微积分的发明。

1680 年，一颗巨大的彗星掠过我们附近的太空。它离地球非常近，因此哪怕仅凭它反射的那微不足道的阳光，就足以让它成为夜空中引人注目的主角。人们第一次发现这颗彗星时，它正处在被我们称为 11 月的那一段地球轨道中。在之后的几个月中，它成为人们充满热情、细致入微的调查对象，人们对它的运行轨迹不厌其烦地做着记录。1687 年，牛顿用这些数据作为他平方反比定律的例子。在瑞士巴塞尔这片土地上，另一个注定要成就伟大功业的人，同样在一个晴朗的夜晚注视着这颗彗星。这名年轻的神学家凝视着彗星那明亮而弥漫的光芒，突然意识到他希望为之奉献一生的，不是教会，而是数学。这个意识不仅带来了雅各布·伯努利个人职业生涯的改变，也诞生了数学史上最伟大的一棵家族树：从雅各布出生到 1800 年的一个半世纪里，伯努利家族产生了许多后人，其中约半数都颇具天分，贡献了 8 位知名的数学家，而其中 3 位（雅各布，他的弟弟约翰，以及约翰的儿子丹尼尔）更是成为历史上最伟大的数学家这一群体的成员。

当时的神学家跟普罗大众一样，都认为彗星是神愤怒的标志。按照这个说法，1680 年这颗彗星出现时，上帝肯定快被气疯了，因为它竟然占据了大半个肉眼可见的天空。一个牧师称它为「由全能而神圣之上帝书写并呈现于无力而不洁的凡人之子眼前的天国之警告」。他还写道，这颗彗星预示着国家或城市在「精神或俗事中将出现值得关注的变化」。雅各布·伯努利对此却另有看法。1681 年，他出版了一本小册子，书名是冗长的《一种新发现的方法：如何将彗星或扫帚星的路径简化为某些基本定律，并预测它的出现》。

在预测这颗彗星轨道的问题上，伯努利可比牛顿早了整整 6 年。或者我们应该说，如果他的理论没错的话，可就确确实实抢在了牛顿的前面。不过他的理论不正确。尽管如此，这个理论仍然成了一份公开的宣告，即彗星所遵循的是自然规律，而非上帝的什么奇思怪想。做这件事需要极大的勇气，特别是在一年前，也就是伽利略被宣判有罪之后差不多 50 年，巴塞尔大学的数学教授彼得·梅格林刚刚因为接受了哥白尼的科学体系，而遭到神学家的全面攻击。他因此被禁止在这所大学任教。一道无法跨越的鸿沟横亘在巴塞尔的数学家、科学家与神学家之间，而伯努利坚定地站在科学家的一方。

由于伯努利的出众天分，他很快被数学家团体接纳。当梅格林在 1686 年晚些时候去世之后，伯努利继承了他的数学教授职位。伯努利当时正在研究随机博弈的问题。在那些对他影响最大的人中，就有荷兰数学家与科学家克里斯蒂安·惠更斯。惠更斯改进了望远镜，成为了解土星光环的第一人，（基于伽利略的思路）创造了第一台摆钟，并对光的波动学说做出贡献。除此之外，他还受到帕斯卡与费马观点的启发，写了一本关于概率的初级数学读本。

惠更斯的书确实为伯努利带来了灵感，但他同样在惠更斯的理论中看到了严重的局限性。对于随机博弈而言，这个理论也许够用了，但是对于那些更具主观性的生活中的方方面面来说，这个理论的适用性又如何呢？我们应当怎样做，才能给法庭证言的可信度赋予一个确定的合理概率呢？而英格兰的查理一世和苏格兰女王玛丽，哪个才是更棒的高尔夫球手（这两个人都热衷于打高尔夫球）？伯努利相信，如果想要让理性的决策成为可能，就必须有一个可靠的数学方法来确定概率。他的这种观点实际上反映了他所处时代的文化氛围。在当时的氛围中，一个人被大家认为具备理性的一个标志，就是他能按照符合概率期望的方式行事。但在伯努利看来，主观性并非禁锢旧的随机理论的唯一因素。他也认识到，这个理论不是为无知的情况设计的，在这种情况下，虽然我们原则上能够定义每种可能结果的发生概率，但这些概率的值实际上是未知的。这就是我与莫希谈论的问题，也是贾格尔需要解决的问题：一个不完美的骰子扔出 6 点的机会有多大？你感染上瘟疫的可能性有多大？你的胸甲能挡住对手长剑一刺的可能性又有多大？在主观和不确定的情况下指望我们能掌握惠更斯书中所预设的那些先验概率，这种念头在伯努利看来，简直就是一种「精神错乱」。

正如贾格尔所做的，伯努利认识到这个问题的答案就是：我们不应该依靠那些硬塞到我们手中的概率，而应该通过观测找出这些概率。作为一名数学家，他努力将这个思路精确化。假定我们对一台轮盘赌机进行了若干次观察，那么我们由此估计得到的每个槽获胜的概率，跟隐含的真实获胜概率相比，两者有多接近呢？对于这样估计得到的概率，我们对其正确性又该抱有多强的信念呢？我们将在下一章回顾这些问题，因为它们并不是伯努利能解决的问题。伯努利回答的实际上是与之紧密相关的另外一个问题：我们的观测结果能以多高的准确度，来体现造成这些结果的隐含概率？伯努利认为，随着实验次数的增加，我们显然有理由期望，实际观测到的各种结果的出现频率，应该能越来越精确地体现真实的概率。他肯定不是最早有这种念头人，不过他是把问题进行形式化处理，将思路转化为证明并利用量化的方式进行处理的第一人。他提出的问题具体一点儿说，是这样的：要通过观测结果估计概率，我们至少需要做多少次实验？对于这样得到的结果，我们对它的正确性又有多大把握？在解决这些问题的过程中，他同时认识到微积分这个新学科的重要性，并成为最早认识到这一点的人群中的一员。

2『伯努利回答的问题：想到要通过观测结果估计概率，我们至少需要做多少次实验？对于这样得到的结果，我们对它的正确性又有多大的把握？这就是大数定理解决的问题。做一张主题卡片。（2021-02-20）』

事后看来，伯努利在巴塞尔被提名为教授的那一年，在数学史上具有里程碑式的意义：正是在那一年，戈特弗里德·莱布尼兹发表了一篇革命性的论文。作为 1684 年发表的关于微积分的论文的补充，在新论文中，他阐述了微积分运算的原理。而在 1687 年，牛顿在常被简称为《原理》的《自然哲学的数学原理》一书中，对同样的问题给出他自己的处理方法。这些进展将是伯努利解决之前那个随机性问题的关键。

在莱布尼兹和牛顿各自发表他们的论文时，他们都已经在微积分问题上研究了很多年。但是，由于他们的成果几乎是同时发表的，这就引起了一番争论：到底是谁最早提出这个想法的？伟大的数学家卡尔·皮尔逊（我们将在第 8 章提到他）认为，数学家「流传后世（的声望），很大程度上并不在于他们做了什么，而在于同时代的人认为他们做了什么」。牛顿和莱布尼兹应该会赞同这种观点。无论如何，这两个人都免不了一场激烈的争论，而随后发生的那场争论非常激烈，最终的结果好坏参半。德国人和瑞士人学习微积分时，用的是莱布尼兹的著作，而英国人与许多法国人读的是牛顿的书。从现代观点来看，这两种微积分之间的差别十分微小，但长期以来，人们往往更强调牛顿的贡献，因为看起来确实是他更早一点儿提出这个想法的。当牛顿在《原理》一书中建立起现代物理学的时候，他应用了这一想法。正是现代物理学的建立，使《原理》成为或许是有史以来最伟大的科学著作。不过莱布尼兹建立了一套更好的表示方法，而我们经常使用的，就是这套表示方法。

两位的著作都不容易读懂。《原理》一书除了被认为是最伟大的科学著作，同时获得了「有史以来最难理解的图书之一」的称号。而按照雅各布·伯努利的一位传记作者的话来说，「根本没有人能看懂」莱布尼兹的著作，因为这本书不仅言语晦涩难懂，而且满是印刷错误。雅各布的弟弟约翰则称它为「谜题而非解答」。实际上，两部著作都相当晦涩难懂，因此有学者猜测这两位是不是有意而为之，以便劝退各路业余爱好者。不过这谜题一般的风格确实能够把天分的高低区分得清清楚楚，对雅各布·伯努利而言，这种风格倒不失为一个优点，因为他的智力明显高于常人。当他参透了莱布尼兹的思想时，他就拥有了一件有力的武器，而这件武器的拥有者的人数，在全世界来说是屈指可数的。有了这件武器，伯努利就能轻而易举地解决足以令他人望而却步的难题。

跟伯努利的工作一样，微积分的核心概念就是序列、级数和极限。对数学家或其他人来说，序列这个词表达的意思几乎是一样的：按顺序排列的若干元素（如点或数字）。级数则是一系列数字的和。而极限，不那么严密地说，如果某序列的组成元素似乎指向某个地方，比如某个特定的端点或数字，那么该处就被称为该序列的极限。

尽管微积分把对序列的理解提升到一个新高度，但与许多其他概念一样，古希腊人其实早已熟知。实际上，公元前 5 世纪的古希腊哲学家芝诺，就通过一个令人惊讶的序列，创造出一个至今仍然让哲学专业的大学生们争论不休的悖论，特别是当他们在几杯啤酒下肚之后。芝诺悖论的描述大体如下：设想有一个学生想朝 1 米外的门口走去（1 米只不过是为了叙述方便，但下面的说法对于 1 英里或其他任何距离而言都是一样的）。在这名学生到达门口之前，她首先必须到达这段距离的中点；而为了到达这个中点，她必须到达这一半距离的中点，也就是 1/4 距离点；如此下去，直至无穷。换句话说，为了到达目的地，她必须走过下面这个序列中的这些距离：1/2 米、1/4 米、1/8 米、1/16 米等等。芝诺因此说，由于这个序列无穷无尽，所以这个学生必须越过无穷多的有限距离，而这将耗费无穷多的时间。芝诺由此得出结论：她其实根本动弹不得。

千百年来，从亚里士多德到康德的哲学家们，都在这个困境上争来辩去。犬儒学派的创始人第欧根尼用一种经验主义的方式来解决这个问题：他不过就是起身走了几步，然后说明物体确实是在运动的。对于我们这些并非哲学专业的人而言，这个答案听起来挺不错。可是这个回答打动不了芝诺。芝诺当然清楚他的逻辑与我们感受的运动之间的矛盾，只不过跟第欧根尼不同，芝诺更相信逻辑。而且他的努力也并非毫无效果。即使第欧根尼本人大概也不得不承认，他的那个回答把我们带入另一个令人困惑（而且最终被证明是十分深刻）的问题中：如果我们的感觉是正确的，那么芝诺的逻辑错在何处？

让我们看看芝诺悖论中的这个距离序列：1/2 米、1/4 米、1/8 米、1/16 米……（距离越来越短。）这个序列有无穷多项，因此，我们无法通过直接相加得到整个序列的总和。但我们注意到，尽管这些距离的项数有无穷多，每项的值却一个比一个小。在这个序列中，无穷无尽的项数，和无休无止缩短的每项距离，这两者会不会相互抵消而给出一个有限的总和呢？序列、级数和极限等概念所解释的正是这类问题。现在我们看看具体是怎么做的。我们不再试图去实际计算芝诺那无穷多的间隔累加起来后，所给出的学生行走过的距离，而是考虑每次多加一个间隔，那么得到的结果是怎样的？下面就是经过最初几个间隔后学生走过的距离：

第一个间隔后：1/2 米

第二个间隔后：1/2 米 + 1/4 米 = 3/4 米

第三个间隔后：1/2 米 + 1/4 米 + 1/8 米 = 7/8 米

第四个间隔后：1/2 米 + 1/4 米 + 1/8 米 + 1/16 米 = 15/16 米

1/2 米，3/4 米，7/8 米，15/16 米…… 我们可以在这些数字中发现一种模式：它们的分母是 2 的幂，而分子总比分母小 1。根据这个模式，我们可以猜出，在经过头 10 个间隔后，这名学生将走过 1023/1024 米的距离；而在头 20 个间隔后走过的距离是 1048575/1048576 米；等等。从这个模式可以看出，间隔越多，走过的距离越长，在这一点上，芝诺越对。不过他说因此总距离就是无穷大 —— 错了。从上面这些数字来看，它们好像越来越接近 1，或者用数学家的话来说，1 米就是这个距离序列的极限。这么一来，一切都说得通了：尽管芝诺把学生到门之间的这段旅程剪成了无穷多个间隔，但学生终归还是只需要越过 1 米的距离。

芝诺悖论说的倒不是这段旅程的长度，而是走完这段旅程需要的时间。如果我们的学生得一步一个间隔地走，那么时间确实会成为一个问题（我们就不说她得怎样才能迈出那些比 1 毫米还要小得多的小碎步了）！但如果她可以按正常速度行走，而不必在每个芝诺想象出来的检查站停顿一下（为什么要停呢？），那么跨过每个芝诺间隔的时间，就跟间隔长度成正比了。既然现在总的距离是有限的，那么需要的总时间自然也有限。我们确实挺走运的，毕竟运动对我们而言还是可能的。

虽然现代的极限概念要到芝诺甚至伯努利过世很久之后的 19 世纪才会出现，但正是这个概念，蕴涵了微积分的核心思想。雅各布·伯努利也正是用这个思想，来处理概率与观察结果之间的关系的。更具体点儿说，伯努利研究的是任意大数量的重复实验所给出的极限情况。将一枚（均匀的）硬币扔上 10 次，也许有 7 次是正面朝上；但如果这个扔硬币的次数是一个无限大的数目，那么最可能得到的正面朝上的比例将非常接近 50%。20 世纪 40 年代，南非数学家约翰·克里奇决定用实验来验证一下这个结论。他把一枚硬币扔了又扔，扔的次数肯定赶得上恒河里沙子的数量了（好吧，其实是扔了 1 万次），然后记录下每次扔出的结果。你肯定会奇怪，这位克里奇老兄就没啥别的更紧要的事情好做了？不过还真没有，他当时是一名战囚，德国人在 1940 年 4 月侵入丹麦时，不走运的他正好在哥本哈根访问。根据克里奇得到的数据，在前 100 次中，得到正面朝上的比例只有 44%；但到了 1 万次的时候，得到的结果就很接近对半开了：正面的比例为 50.67%。但我们应该用什么样的定量公式来描述这个结果呢？这正是伯努利取得的成就。

按科学史学家和哲学家伊恩·哈金的话来说，伯努利的工作被「公之于众时，就夺目地预示着我们如今所知的这个理论的所有成就；它的数学深度，它无限的实际应用，它不断转换的二元视角，让我们不断从哲学层面上去思考。概率论至此完全显现出来」。伯努利自己倒是更谦虚一些，他称自己的研究被证明具有「创新性，以及…… 高度实用性」。他还写道，这个研究过程充满了「令人殚精竭虑的困难」。他在这项研究上投入了整整 20 年。

这个耗费了 20 年努力才达到的巅峰，被雅各布·伯努利称为「黄金定理」。不过这个定理的各个（相互间仅有些微技术性差别的）现代版本有好几个名字：伯努利定理，大数定律，以及弱大数定律。正如我们已经看到的，使用大数定律这个术语，是因为伯努利定理所说明的，就是大量观测的结果是如何体现隐含概率的。不过我们在这里还是继续沿用伯努利「黄金定理」的叫法，因为我们下面的讨论，将在这条定理最原始的形式上展开。

尽管伯努利对定理在实际中的应用很感兴趣，但他在举例的时候，却最喜欢用一样恐怕我们大多数人家里都找不到的东西：一个装满了各色鹅卵石的瓮。在一个例子中，他这个瓮里装了 3000 颗白鹅卵石和 2000 颗黑鹅卵石，也就是 60∶40 的白黑比例。然后我们蒙上眼睛，从这个瓮里「返还式地」摸出一系列鹅卵石。这里的「返还式」的含义，是指我们在取出下一枚鹅卵石之前，要把上次取出的石子放回瓮里，以保证 3∶2 的白黑比不会发生改变。这样一来，我们每次摸到白色石子的先验概率就是 3/5，或者 60%。在这个例子里，伯努利所关心的问题是：按照这种方式摸出一系列石子后，其中白色石子的数量跟这个 60% 的比例吻合的程度有多好？而发生这种吻合程度的概率又是多少？

这个瓮是个好例子，因为用来描述从瓮里摸取鹅卵石的那些数学内容，也能用来描述任何一系列具有两种可能结果的试验，只要这些结果的出现是随机的，且各次试验结果相互独立。我们现在称此类试验为伯努利试验，而一系列伯努利试验就构成了一个伯努利过程。如果一个随机试验有两种可能的结果，我们常常认为其中一个结果表示「成功」，另一个自然就表示「失败」了。当然，这样的记号并不严格表示它们的字面意义，实际上，这两种记号有时根本与这两个词的日常含义无关。以我们平时说的成功或失败为例，如果这本书让你迫不及待地想往下读，它就是成功的；如果它唯一的用处，是你在壁炉里的木柴都被烧完之后，用它来给自己和心上人取暖，这本书就失败了。不过更多地，我们扔硬币得到正面或反面朝上，投票给候选人 A 或 B，生男或生女，买或不买某件商品，病愈或未愈，甚至是死亡或生存，这些也都是伯努利试验用到的例子，我们也用「成功」和「失败」来描述这些可能的结果。哪怕一些行为有超过两种的可能结果，但如果我们针对结果提出的问题可以用「是」或「不是」来回答，那么这样的问题同样可以用伯努利试验来描述，比如「骰子是不是扔出了 4 点？」或「北极还有没有冰？」之类的问题。因此，伯努利写的虽然是石子和瓮，但他所有的例子都能原封不动地用于许多其他类似的场合。

理解了这一点之后，让我们再回到那个 60% 的鹅卵石是白色的瓮上。如果你从瓮里（返还式地）取出 100 颗鹅卵石，你也许会发现其中恰好有 60% 是白色的。不过你同样有可能只抽到 50 颗或 59 颗白色石子。那么，你取出的石子中，58% 到 62% 的石子是白色的机会有多大？如果是 59% 到 61% 呢？如果你不是取 100 颗，而是取 1000 颗或 100 万颗鹅卵石，那么这时我们对结果的信任又能增加多少？我们当然永远没办法百分之百地确信这样做得到的结果，但是我们能不能抽取足够多的鹅卵石，从而有 99.9999% 的把握，保证取到白色石子的比例在 59.9% 到 60.1% 之间？伯努利的黄金定理要解决的，就是诸如此类的问题。

在应用黄金定理之前，你需要首先进行两个选择。首先，你要给定一个可容忍的误差范围。大量试验的结果与真实的 60% 的比例，两者之间应该有多接近呢？你必须就此指定一个接近的范围，比如 60%±1% 或 60%±2% 或 60%±0.00001%。其次，你必须明确你对不确定性的容忍度。你永远无法 100% 地确定试验会给出你想要的结果，但你能够有把握做到比如在 100 次试验中获得 99 次满意的结果，或者在 1000 次试验中有 999 次是满意的。

黄金定理指出，你总能通过取出足够多的鹅卵石，保证你能几乎确定所得的白色鹅卵石比例很接近 60%，而不论几乎确定和接近的定义是何等严苛。而且，在给定了这个几乎确定和接近的具体数值后，定理还给出用来计算这个「足够」次数的数学公式。

定理的第一部分是一次理念上的胜利，也是定理中唯一能幸存到各个现代版本中的部分。而关于伯努利公式，这个定理的第二部分，重要的是我们要知道，尽管黄金定理给出一个足以满足你要求的置信度与准确度的试验次数，但这并不意味着我们不能通过更少的试验来达到同样的目标。但这并不影响定理的第一部分，因为第一部分只是说这个特定的试验次数总是有限的。伯努利希望他的公式能给出实际可行的答案，但不幸的是，在大多数实际应用中，这个公式很难实现这一点。这里有一个伯努利自己解出的数值例子，我稍微改动一下文字的先后顺序：假设巴塞尔市长在选民中的实际支持率为 60%；现在我们希望对选民进行民意调查，要使调查显示对市长的支持率在 58% 到 62% 之间（即在真实支持率的正负 2 个百分点区间内）的概率为 99.9%，那么至少需要调查多少位选民？（为了与伯努利的问题保持一致，我们假定采用返还式的采样方式随机选取被调查者。换句话说，同一名被调查者有可能被询问不止一次。）这个问题的答案是 25550 人。这也差不多就是伯努利那个年代巴塞尔城的人口。伯努利并没有将这个不实用的结果扔到一边，因为他知道，老练的赌徒根本用不着几千次试验，就能凭直觉猜出一种新的赌博方式中获胜的概率。

伯努利的公式给出的估计值如此不理想的一个原因，是他的证明基于许多近似值。还有一个原因是，他选择的置信度标准是 99.9%，也就是说结果出错（与真实概率偏差超过 2 个百分点）的概率小于 1/1000。这实在是一个非常苛刻的标准。伯努利称它为道德确定性，是指他认为一个理性的人在进行理性的决策时所应具有的确定性程度。我们现在已经抛弃了道德确定性这种提法，更多地使用在上一章中提到的统计显著性，这意味着你的答案在 20 次中只有不到一次出错的可能。这也许是一种衡量时代变化的方式。

统计学家利用现在的数学方法已经证明，对上面那个民意调查，我们只需要抽查区区 370 名被调查者，就能得到一个具有统计显著性的结果，其准确度在正负 5% 之间。如果调查人数上升到 1000 人，那么调查结果落在真实答案（巴赛尔市长 60% 的真实支持度）2 个百分点的误差范围内的可能性是 90%。尽管伯努利的黄金定理存在各种局限，但是它仍然是数学史上的一座里程碑，因为它至少从原则上证明了，足够大的样本几乎能肯定地反映出被采样群体的真实构成。

在现实生活中，我们通常不会靠几千次的试验来观察人或事物的表现。因此，如果说伯努利错在把确定性标准定得过于严格了，那么在实际生活中，我们常常又会犯下相反的错误：我们假设一个样本或一系列试验的结果体现了潜在情况，但实际上它太小了，并不可靠。举例来说，如果在伯努利那个年代，我们恰好调查了 5 位巴塞尔居民，根据第 4 章中的计算，这个调查能够得到正确的结果，也就是被调查者中的 60%（或 3 人）支持市长，这种情况出现的可能性仅为 1/3。

仅仅 1/3？在对某选民样本进行调查时，市长支持者在人群中的真实比例，难道不应该是最可能的结果吗？事实上，1/3 的确是最可能的结果：调查中碰到 0 个、1 个、2 个、4 个或 5 个支持者的可能性，都比碰到 3 个支持者的可能性小。即使是这个最大的碰到 3 个支持者的可能性，也不太可能：因为有太多非代表性的可能性存在，它们的总和比得到正确结果的可能性大了两倍。所以，对 5 名选民进行调查，每 3 次中就会有 2 次得到「错误」的支持率。事实上，每 10 次这样的调查中，就差不多有 1 次会得出 5 名选民都支持或都不支持市长的结果。如果我们只关注 5 个样本，那么市长真实的支持率很可能被严重高估或低估。

小样本准确反映潜在概率的错误观念（或错误直觉）如此普遍，以至卡尼曼和特沃斯基给它专门起了个名字：小数定律。小数定律并不是一条正儿八经的定律，它只是一个带有讽刺性的名字，用来描述在数字不大的情况下，试图应用大数定律的错误做法。

如果人们只把这个（不正确的）小数定律用在那些鸡毛蒜皮的事情上，倒也没什么大不了的后果。不过我们之前已经提到过，我们生活中的许多事情都可以被看成伯努利过程，因此这个小数定律的直觉，经常让我们对我们看到的事物做出错误的解释。这也就是为什么在第一章中，当人们看到兰辛或坎顿们那屈指可数的几个成功或不够成功的年头时，会认为他们的这些表现能准确预测他们将来的表现。

现在，我们把上面的解决思路用到第 4 章提到过的一个例子上，就是两个公司之间或公司内部两个员工之间的竞争。现在让我们考察一下《财富》500 强公司的首席执行官们。我们假设，这些首席执行官每人都因其学识和能力有一定的概率获得成功（不管他 / 她的公司是如何定义成功的）。同时，为了简化问题，我们假设年终总结时这些首席执行官的成功概率，就跟瓮里的白鹅卵石或市长支持者的比例一样，也是 60%（具体的值高一点儿或低一点儿，都不影响我们论证的核心）。这是不是意味着，我们应该预期，在某个给定的 5 年内，一位首席执行官恰好会有 3 年的好时光？

并非如此。之前的分析表明，即使这些首席执行官都有一个还算过得去的 60% 的先验成功率，但在某个给定的 5 年期间，某特定的首席执行官的职场表现准确符合这一成功率的可能性，仅仅是 1/3！套用到《财富》500 强的例子里，这就意味着在过去的 5 年中，大约有 333 名首席执行官的实际表现并没有反映出他们真正的能力。我们还可以进一步指出，很可能有约 1/10 的首席执行官在这 5 年中会连赢或连输，而造成这种结果的不过是偶然因素。这个事实告诉了我们怎样的道理？它告诉我们，评价一个人更可靠的方法，应该是具体分析他具备的能力，而不是仅仅看业绩表上的分数。或者用伯努利的话来说：「我们不应该以成败论英雄。」

要摆脱小数定律的控制，我们需要一些特殊的能力。躺在沙发里，看着业绩表的最下一行，然后指点一番，这是任何人都能做到的。但评判一个人的真才实学，需要信心、思考、良好的判断以及勇气。开会的时候，你可不能就这么不管不顾地跳出来，对着同事一通大吼：「不要解雇她！她只不过是碰巧处于伯努利序列错误的一端！」当然，如果你跳出来冲着那个志得意满、刚成为销售史上卖出最多丰田凯美瑞的家伙说「你不过就是碰到个随机波动而已」，那么这种做法也不太可能让你赢得朋友。但用后一种方式去评价他人的事情很少发生。高管们的成功总会被归功于他们的聪明才智，而且这些才智是通过深刻的后见之明得来的。而当他们失败时，我们又常常认为这些失败准确地反映了他们的天分与能力的高低。

另一个与大数定律有关的错误的思维方式，就是仅根据事情在最近的发生情况，认定它更可能或更不可能发生。认为某一事件的概率的增加或减少取决于该事件最近一段时间内的出现情况，这种错误叫作赌徒谬论。拿克里奇扔硬币的事儿来说，哪怕他在最开始的 100 次中只扔出 44 次正面朝上，这枚硬币也不会变得更偏向正面朝上，好让正面朝上的次数赶上反面朝上的次数。这个赌徒谬论，就是诸如「她的运气用光了」或「轮也该轮到他了」之类想法的根本所在，而这种事情其实根本不会发生。不管你信不信，好运连连本身并不会给你带来霉运；而一个接一个的坏消息，也并不代表转运的曙光就在前方等着你。不过被赌徒谬论有意无意影响的人，可比你想象的多得多。人们总是期待着倒霉后面会有好运紧随，或者担心顺风顺水的下一刻就是狂风巨浪。

我还记得几年前，我曾在一艘游轮上看到过一个矮胖男人，他满头大汗，充满激情，疯狂地把手中的硬币接二连三地塞到老虎机里，老虎机吞得有多快，他就塞得有多快。他的同伴发现我正盯着他们看，就简单地跟我解释了一句：「他走运的时候就快到了。」尽管我很想对他说：「不，他走运的时候可还没到。」但终于我还是没说出口就走开了。结果刚走出没几步，突然闪动的灯光，响个不停的铃声，这对儿好友发出的不小的喊叫声，以及那哗啦啦肯定响了好几分钟的硬币从老虎机流泻而出的声音，让我停下了脚步。现代的老虎机是由计算机控制的，它的输赢是由随机数生成器驱动的，而且根据法律和法规，这个随机数生成器产生的必须是名副其实真正的随机数，以保证每次搬下手柄时的结果都完全独立于之前的输出。然而…… 好吧，我们还能说什么呢？赌徒谬论实在是一种强大的错觉。

伯努利提出黄金定理的手稿结束得十分突兀，而在手稿的开头，他还许诺会给出定理在公众事务及经济问题等若干不同方面的应用。统计史学家斯蒂芬·施蒂格勒写道，大概是「伯努利在看到 25550 这个数字后，就死心塌地地放弃了」。事实上，当 1705 年 8 月时年 50 岁的伯努利死于「慢性发热」时，他正在准备手稿的出版。出版商请求约翰·伯努利续完手稿，但他以事情太多为由拒绝了。这听起来可能很奇怪，不过这本来就是个奇怪的家族。如果要评选史上最不开心的数学家，你就选约翰·伯努利吧，估计不会错。许多历史文献将他描述成一个嫉妒、虚荣、敏感、固执、脾气糟糕、自卖自夸、毫无诚信的登峰造极的骗子。他在数学方面颇有成就，但下面这件事为人熟知的程度，并不亚于他的数学成就。当时他跟儿子丹尼尔都参加了一场竞赛，丹尼尔在竞赛中胜出。约翰试图窃取他的哥哥和莱布尼茨的观点，并抄袭丹尼尔《流体动力学》一书，篡改了出版日期，让他的书看起来出版时间更早，最终把丹尼尔踢出了法国科学院。

在收到续写过世兄长的手稿这个请求时，约翰刚好从荷兰的格罗宁根大学来到巴塞尔大学，获得了一个希腊语教授而非数学教授的职位。雅各布本人也觉得这个职业变动颇为可疑，特别是他觉得约翰并不懂希腊语。在写给莱布尼兹的信中，雅各布怀疑约翰来到巴塞尔大学是为了篡夺自己数学教授的位子。的确，雅各布一去世，约翰就获得了这个职位。

约翰和雅各布两人在成人之后的大部分岁月中，相处得都不算融洽。在数学著作和书信中，他们颇为常态化地相互羞辱对方，一位数学家就此事曾经写道：「他们那些愤怒又激烈的言辞，在别人那儿通常是为偷马贼保留的。」因此，编辑雅各布遗稿这个任务，就落到了更下一层雅各布的侄子尼古拉 —— 雅各布另一位同样名叫尼古拉的兄弟的儿子 —— 的身上。小尼古拉当时只有 18 岁，不过他也曾是雅各布的学生之一。不幸的是，他感到自己不能胜任这项任务，另外也可能有部分原因是，他清楚地知道，莱布尼兹并不赞同他伯父应用这个理论的那些想法。手稿因此又沉睡了 8 年。最终，手稿以《猜度术》为名于 1713 年出版。和帕斯卡的《思想录》一样，该书至今仍在不断被印刷出版。

1-2『猜度术的电子版目前没找到，已下载书籍「2021072思想录」。（2021-02-20）』

雅各布·伯努利已经表明，我们可以通过数学分析，了解自然系统内部的隐含概率是如何在这些系统产生的数据中被反映出来的。至于伯努利没有回答的那个如何根据观测数据推断事件的隐含概率的问题，它的答案在几十年后才会被揭晓。

## 0601. False Positives and Positive Fallacies

In the 1970s a psychology professor at Harvard had an odd-looking middle-aged student in his class. After the first few class meetings the student approached the professor to explain why he had enrolled in the class.1 In my experience teaching, though I have had some polite students come up to me to explain why they were dropping my course, I have never had a student feel the need to explain why he was taking it. That's probably why I can get away with happily assuming that if asked, such a student would respond,「Because I am fascinated by the subject, and you are a fine lecturer.」But this student had other reasons. He said he needed help because strange things were happening to him: his wife spoke the words he was thinking before he could say them, and now she was divorcing him; a co-worker casually mentioned layoffs over drinks, and two days later the student lost his job. Over time, he reported, he had experienced dozens of misfortunes and what he considered to be disturbing coincidences.

At first the happenings confused him. Then, as most of us would, he formed a mental model to reconcile the events with the way he believed the world behaves. The theory he came up with, however, was unlike anything most of us would devise: he was the subject of an elaborate secret scientific experiment. He believed the experiment was staged by a large group of conspirators led by the famous psychologist B. F. Skinner. He also believed that when it was over, he would become famous and perhaps be elected to a high public office. That, he said, was why he was taking the course. He wanted to learn how to test his hypothesis in light of the many instances of evidence he had accumulated.

A few months after the course had run its course, the student again called on the professor. The experiment was still in progress, he reported, and now he was suing his former employer, who had produced a psychiatrist willing to testify that he suffered from paranoia.

One of the paranoid delusions the former employer's psychiatrist pointed to was the student's alleged invention of a fictitious eighteenth-century minister. In particular, the psychiatrist scoffed at the student's claim that this minister was an amateur mathematician who had created in his spare moments a bizarre theory of probability. The minister's name, according to the student, was Thomas Bayes. His theory, the student asserted, described how to assess the chances that some event would occur if some other event also occurred. What are the chances that a particular student would be the subject of a vast secret conspiracy of experimental psychologists? Admittedly not huge. But what if one's wife speaks one's thoughts before one can utter them and co-workers foretell your professional fate over drinks in casual conversation? The student claimed that Bayes's theory showed how you should alter your initial estimation in light of that new evidence. And he presented the court with a mumbo jumbo of formulas and calculations regarding his hypothesis, concluding that the additional evidence meant that the probability was 999,999 in 1 million that he was right about the conspiracy. The enemy psychiatrist claimed that this mathematician-minister and his theory were figments of the student's schizophrenic imagination.

The student asked the professor to help him refute that claim. The professor agreed. He had good reason, for Thomas Bayes, born in London in 1701, really was a minister, with a parish at Tunbridge Wells. He died in 1761 and was buried in a park in London called Bunhill Fields, in the same grave as his father, Joshua, also a minister. And he indeed did invent a theory of「conditional probability」to show how the theory of probability can be extended from independent events to events whose outcomes are connected. For example, the probability that a randomly chosen person is mentally ill and the probability that a randomly chosen person believes his spouse can read his mind are both very low, but the probability that a person is mentally ill if he believes his spouse can read his mind is much higher, as is the probability that a person believes his spouse can read his mind if he is mentally ill. How are all these probabilities related? That question is the subject of conditional probability.

The professor supplied a deposition explaining Bayes's existence and his theory, though not supporting the specific and dubious calculations that his former student claimed proved his sanity. The sad part of this story is not just the middle-aged schizophrenic himself, but the medical and legal team on the other side. It is unfortunate that some people suffer from schizophrenia, but even though drugs can help to mediate the illness, they cannot battle ignorance. And ignorance of the ideas of Thomas Bayes, as we shall see, resides at the heart of many serious mistakes in both medical diagnosis and legal judgment. It is an ignorance that is rarely addressed during a doctor's or a lawyer's professional training.

We also make Bayesian judgments in our daily lives. A film tells the story of an attorney who has a great job, a charming wife, and a wonderful family. He loves his wife and daughter, but still he feels that something is missing in his life. One night as he returns home on the train he spots a beautiful woman gazing with a pensive expression out the window of a dance studio. He looks for her again the next night, and the night after that. Each night as his train passes her studio, he falls further under her spell. Finally one evening he impulsively rushes off the train and signs up for dance lessons, hoping to meet the woman. He finds that her haunting attraction withers once his gaze from afar gives way to face-to-face encounters. He does fall in love, however, not with her but with dancing.

He keeps his new obsession from his family and colleagues, making excuses for spending more and more evenings away from home. His wife eventually discovers that he is not working late as often as he says he is. She figures the chances of his lying about his after-work activities are far greater if he is having an affair than if he isn't, and so she concludes that he is. But the wife was mistaken not just in her conclusion but in her reasoning: she confused the probability that her husband would sneak around if he were having an affair with the probability that he was having an affair if he was sneaking around.

It's a common mistake. Say your boss has been taking longer than usual to respond to your e-mails. Many people would take that as a sign that their star is falling because if your star is falling, the chances are high that your boss will respond to your e-mails more slowly than before. But your boss might be slower in responding because she is unusually busy or her mother is ill. And so the chances that your star is falling if she is taking longer to respond are much lower than the chances that your boss will respond more slowly if your star is falling. The appeal of many conspiracy theories depends on the misunderstanding of this logic. That is, it depends on confusing the probability that a series of events would happen if it were the product of a huge conspiracy with the probability that a huge conspiracy exists if a series of events occurs.

The effect on the probability that an event will occur if or given that other events occur is what Bayes's theory is all about. To see in detail how it works, we'll turn to another problem, one that is related to the two-daughter problem we encountered in chapter 3. Let us now suppose that a distant cousin has two children. Recall that in the two-daughter problem you know that one or both are girls, and you are trying to remember which it is — one or both? In a family with two children, what are the chances, if one of the children is a girl, that both children are girls? We didn't discuss the question in those terms in chapter 3, but the if makes this a problem in conditional probability. If that if clause were not present, the chances that both children were girls would be 1 in 4, the 4 possible birth orders being (boy, boy), (boy, girl), (girl, boy), and (girl, girl). But given the additional information that the family has a girl, the chances are 1 in 3. That is because if one of the children is a girl, there are just 3 possible scenarios for this family — (boy, girl), (girl, boy), and (girl, girl) — and exactly 1 of the 3 corresponds to the outcome that both children are girls. That's probably the simplest way to look at Bayes's ideas — they are just a matter of accounting. First write down the sample space — that is, the list of all the possibilities — along with their probabilities if they are not all equal (that is actually a good idea in analyzing any confusing probability issue). Next, cross off the possibilities that the condition (in this case,「at least one girl」) eliminates. What is left are the remaining possibilities and their relative probabilities.

That might all seem obvious. Feeling cocky, you may think you could have figured it out without the help of dear Reverend Bayes and vow to grab a different book to read the next time you step into the bathtub. So before we proceed, let's try a slight variant on the two-daughter problem, one whose resolution may be a bit more shocking.2

The variant is this: in a family with two children, what are the chances, if one of the children is a girl named Florida, that both children are girls? Yes, I said a girl named Florida. The name might sound random, but it is not, for in addition to being the name of a state known for Cuban immigrants, oranges, and old people who traded their large homes up north for the joys of palm trees and organized bingo, it is a real name. In fact, it was in the top 1,000 female American names for the first thirty or so years of the last century. I picked it rather carefully, because part of the riddle is the question, what, if anything, about the name Florida affects the odds? But I am getting ahead of myself. Before we move on, please consider this question: in the girl-named-Florida problem, are the chances of two girls still 1 in 3 (as they are in the two-daughter problem)?

I will shortly show that the answer is no. The fact that one of the girls is named Florida changes the chances to 1 in 2: Don't worry if that is difficult to imagine. The key to understanding randomness and all of mathematics is not being able to intuit the answer to every problem immediately but merely having the tools to figure out the answer.

THOSE WHO DOUBTED Bayes's existence were right about one thing: he never published a single scientific paper. We know little of his life, but he probably pursued his work for his own pleasure and did not feel much need to communicate it. In that and other respects he and Jakob Bernoulli were opposites. For Bernoulli resisted the study of theology, whereas Bayes embraced it. And Bernoulli sought fame, whereas Bayes showed no interest in it. Finally, Bernoulli's theorem concerns how many heads to expect if, say, you plan to conduct many tosses of a balanced coin, whereas Bayes investigated Bernoulli's original goal, the issue of how certain you can be that a coin is balanced if you observe a certain number of heads.

The theory for which Bayes is known today came to light on December 23, 1763, when another chaplain and mathematician, Richard Price, read a paper to the Royal Society, Britain's national academy of science. The paper, by Bayes, was titled「An Essay toward Solving a Problem in the Doctrine of Chances」and was published in the Royal Society's Philosophical Transactions in 1764. Bayes had left Price the article in his will, along with £100. Referring to Price as「I suppose a preacher at Newington Green,」Bayes died four months after writing his will.3

Despite Bayes's casual reference, Richard Price was not just another obscure preacher. He was a well-known advocate of freedom of religion, a friend of Benjamin Franklin's, a man entrusted by Adam Smith to critique parts of a draft of The Wealth of Nations, and a well-known mathematician. He is also credited with founding actuary science, a field he developed when, in 1765, three men from an insurance company, the Equitable Society, requested his assistance. Six years after that encounter he published his work in a book titled Observations on Reversionary Payments. Though the book served as a bible for actuaries well into the nineteenth century, because of some poor data and estimation methods, he appears to have underestimated life expectancies. The resulting inflated life insurance premiums enriched his pals at the Equitable Society. The hapless British government, on the other hand, based annuity payments on Price's tables and took a bath when the pensioners did not proceed to keel over at the predicted rate.

As I mentioned, Bayes developed conditional probability in an attempt to answer the same question that inspired Bernoulli: how can we infer underlying probability from observation? If a drug just cured 45 out of 60 patients in a clinical trial, what does that tell you about the chances the drug will work on the next patient? If it worked for 600,000 out of 1 million patients, the odds are obviously good that its chances of working are close to 60 percent. But what can you conclude from a smaller trial? Bayes also asked another question: if, before the trial, you had reason to believe that the drug was only 50 percent effective, how much weight should the new data carry in your future assessments? Most of our life experiences are like that: we observe a relatively small sample of outcomes, from which we infer information and make judgments about the qualities that produced those outcomes. How should we make those inferences?

Bayes approached the problem via a metaphor.4 Imagine we are supplied with a square table and two balls. We roll the first ball onto the table in a manner that makes it equally probable that the ball will come to rest at any point. Our job is to determine, without looking, where along the left-right axis the ball stopped. Our tool in this is the second ball, which we may repeatedly roll onto the table in the same manner as the first. With each roll a collaborator notes whether that ball comes to rest to the right or the left of the place where the first ball landed. At the end he informs us of the total number of times the second ball landed in each of the two general locations. The first ball represents the unknown that we wish to gain information about, and the second ball represents the evidence we manage to obtain. If the second ball lands consistently to the right of the first, we can be pretty confident that the first ball rests toward the far left side of the table. If it lands less consistently to the right, we might be less confident of that conclusion, or we might guess that the first ball is situated farther to the right. Bayes showed how to determine, based on the data of the second ball, the precise probability that the first ball is at any given point on the left-right axis. And he showed how, given additional data, one should revise one's initial estimate. In Bayesian terminology the initial estimates are called prior probabilities and the new guesses, posterior probabilities.

Bayes concocted this game because it models many of the decisions we make in life. In the drug-trial example the position of the first ball represents the drug's true effectiveness, and the reports regarding the second ball represent the patient data. The position of the first ball could also represent a film's appeal, product quality, driving skill, hard work, stubbornness, talent, ability, or whatever it is that determines the success or failure of a certain endeavor. The reports on the second ball would then represent our observations or the data we collect. Bayes's theory shows how to make assessments and then adjust them in the face of new data.

Today Bayesian analysis is widely employed throughout science and industry. For instance, models employed to determine car insurance rates include a mathematical function describing, per unit of driving time, your personal probability of having zero, one, or more accidents. Consider, for our purposes, a simplified model that places everyone in one of two categories: high risk, which includes drivers who average at least one accident each year, and low risk, which includes drivers who average less than one. If, when you apply for insurance, you have a driving record that stretches back twenty years without an accident or one that goes back twenty years with thirty-seven accidents, the insurance company can be pretty sure which category to place you in. But if you are a new driver, should you be classified as low risk (a kid who obeys the speed limit and volunteers to be the designated driver) or high risk (a kid who races down Main Street swigging from a half-empty $2 bottle of Boone's Farm apple wine)? Since the company has no data on you — no idea of the「position of the first ball」 — it might assign you an equal prior probability of being in either group, or it might use what it knows about the general population of new drivers and start you off by guessing that the chances you are a high risk are, say, 1 in 3. In that case the company would model you as a hybrid — one-third high risk and two-thirds low risk — and charge you one-third the price it charges high-risk drivers plus two-thirds the price it charges low-risk drivers. Then, after a year of observation — that is, after one of Bayes's second balls has been thrown — the company can employ the new datum to reevaluate its model, adjust the one-third and two-third proportions it previously assigned, and recalculate what it ought to charge. If you have had no accidents, the proportion of low risk and low price it assigns you will increase; if you have had two accidents, it will decrease. The precise size of the adjustment is given by Bayes's theory. In the same manner the insurance company can periodically adjust its assessments in later years to reflect the fact that you were accident-free or that you twice had an accident while driving the wrong way down a one-way street, holding a cell phone with your left hand and a doughnut with your right. That is why insurance companies can give out「good driver」discounts: the absence of accidents elevates the posterior probability that a driver belongs in a low-risk group.

Obviously many of the details of Bayes's theory are rather complex. But as I mentioned when I analyzed the two-daughter problem, the key to his approach is to use new information to prune the sample space and adjust probabilities accordingly. In the two-daughter problem the sample space was initially (boy, boy), (boy, girl), (girl, boy), and (girl, girl) but reduces to (boy, girl), (girl, boy), and (girl, girl) if you learn that one of the children is a girl, making the chances of a two-girl family 1 in 3. Let's apply that same simple strategy to see what happens if you learn that one of the children is a girl named Florida.

In the girl-named-Florida problem our information concerns not just the gender of the children, but also, for the girls, the name. Since our original sample space should be a list of all the possibilities, in this case it is a list of both gender and name. Denoting「girl-named-Florida」by girl-F and「girl-not-named-Florida」by girl-NF, we write the sample space this way: (boy, boy), (boy, girl-F), (boy, girl-NF), (girl-F, boy), (girl-NF, boy), (girl-NF, girl-F), (girl-F, girl-NF), (girl-NF, girl-NF), and (girl-F, girl-F).

Now, the pruning. Since we know that one of the children is a girl named Florida, we can reduce the sample space to (boy, girl-F), (girl-F, boy), (girl-NF, girl-F), (girl-F, girl-NF), and (girl-F, girl-F). That brings us to another way in which this problem differs from the two-daughter problem. Here, because it is not equally probable that a girl's name is or is not Florida, not all the elements of the sample space are equally probable.

In 1935, the last year for which the Social Security Administration provided statistics on the name, about 1 in 30,000 girls were christened Florida.5 Since the name has been dying out, for the sake of argument let's say that today the probability of a girl's being named Florida is 1 in 1 million. That means that if we learn that a particular girl's name is not Florida, it's no big deal, but if we learn that a particular girl's name is Florida, in a sense we've hit the jackpot. The chances of both girls' being named Florida (even if we ignore the fact that parents tend to shy away from giving their children identical names) are therefore so small we are justified in ignoring that possibility. That leaves us with just (boy, girl-F), (girl-F, boy), (girl-NF, girl-F), and (girl-F, girl-NF), which are, to a very good approximation, equally likely.

Since 2 of the 4, or half, of the elements in the sample space are families with two girls, the answer is not 1 in 3 — as it was in the two-daughter problem — but 1 in 2. The added information — your knowledge of the girl's name — makes a difference.

One way to understand this, if it still seems puzzling, is to imagine that we gather into a very large room 75 million families that have two children, at least one of whom is a girl. As the two-daughter problem taught us, there will be about 25 million two-girl families in that room and 50 million one-girl families (25 million in which the girl is the older child and an equal number in which she is the younger). Next comes the pruning: we ask that only the families that include a girl named Florida remain. Since Florida is a 1 in 1 million name, about 50 of the 50 million one-girl families will remain. And of the 25 million two-girl families, 50 of them will also get to stay, 25 because their firstborn is named Florida and another 25 because their younger girl has that name. It's as if the girls are lottery tickets and the girls named Florida are the winning tickets. Although there are twice as many one-girl families as two-girl families, the two-girl families each have two tickets, so the one-girl families and the two-girl families will be about equally represented among the winners.

I have described the girl-named-Florida problem in potentially annoying detail, the kind of detail that sometimes lands me on the do-not-invite list for my neighbors' parties. I did this not because I expect you to run into this situation. I did it because the context is simple, and the same kind of reasoning will bring clarity to many situations that really are encountered in life. Now let's talk about a few of those.

MY MOST MEMORABLE ENCOUNTER with the Reverend Bayes came one Friday afternoon in 1989, when my doctor told me by telephone that the chances were 999 out of 1,000 that I'd be dead within a decade. He added,「I'm really sorry,」as if he had some patients to whom he would say he is sorry but not mean it. Then he answered a few questions about the course of the disease and hung up, presumably to offer another patient his or her Friday-afternoon news flash. It is hard to describe or even remember exactly how the weekend went for me, but let's just say I did not go to Disneyland. Given my death sentence, why am I still here, able to write about it?

The adventure started when my wife and I applied for life insurance. The application procedure involved a blood test. A week or two later we were turned down. The ever economical insurance company sent the news in two brief letters that were identical, except for a single additional word in the letter to my wife. My letter stated that the company was denying me insurance because of the「results of your blood test.」My wife's letter stated that the company was turning her down because of the「results of your husband's blood test.」When the added word husband's proved to be the extent of the clues the kindhearted insurance company was willing to provide about our uninsurability, I went to my doctor on a hunch and took an HIV test. It came back positive. Though I was too shocked initially to quiz him about the odds he quoted, I later learned that he had derived my 1-in-1,000 chance of being healthy from the following statistic: the HIV test produced a positive result when the blood was not infected with the AIDS virus in only 1 in 1,000 blood samples. That might sound like the same message he passed on, but it wasn't. My doctor had confused the chances that I would test positive if I was not HIV-positive with the chances that I would not be HIV-positive if I tested positive.

To understand my doctor's error, let's employ Bayes's method. The first step is to define the sample space. We could include everyone who has ever taken an HIV test, but we'll get a more accurate result if we employ a bit of additional relevant information about me and consider only heterosexual non-IV-drug-abusing white male Americans who have taken the test. (We'll see later what kind of difference this makes.)

Now that we know whom to include in the sample space, let's classify the members of the space. Instead of boy and girl, here the relevant classes are those who tested positive and are HIV-positive (true positives), those who tested positive but are not positive (false positives), those who tested negative and are HIV-negative (true negatives), and those who tested negative but are HIV-positive (false negatives).

Finally, we ask, how many people are there in each of these classes? Suppose we consider an initial population of 10,000. We can estimate, employing statistics from the Centers for Disease Control and Prevention, that in 1989 about 1 in those 10,000 heterosexual non-IV-drug-abusing white male Americans who got tested were infected with HIV.6 Assuming that the false-negative rate is near 0, that means that about 1 person out of every 10,000 will test positive due to the presence of the infection. In addition, since the rate of false positives is, as my doctor had quoted, 1 in 1,000, there will be about 10 others who are not infected with HIV but will test positive anyway. The other 9,989 of the 10,000 men in the sample space will test negative.

Now let's prune the sample space to include only those who tested positive. We end up with 10 people who are false positives and 1 true positive. In other words, only 1 in 11 people who test positive are really infected with HIV. My doctor told me that the probability that the test was wrong — and I was in fact healthy — was 1 in 1,000. He should have said,「Don't worry, the chances are better than 10 out of 11 that you are not infected.」In my case the screening test was apparently fooled by certain markers that were present in my blood even though the virus this test was screening for was not present.

It is important to know the false positive rate when assessing any diagnostic test. For example, a test that identifies 99 percent of all malignant tumors sounds very impressive, but I can easily devise a test that identifies 100 percent of all tumors. All I have to do is report that everyone I examine has a tumor. The key statistic that differentiates my test from a useful one is that my test would produce a high rate of false positives. But the above incident illustrates that knowledge of the false positive rate is not sufficient to determine the usefulness of a test — you must also know how the false-positive rate compares with the true prevalence of the disease. If the disease is rare, even a low false-positive rate does not mean that a positive test implies you have the disease. If a disease is common, a positive result is much more likely to be meaningful. To see how the true prevalence affects the implications of a positive test, let's suppose now that I had been homosexual and tested positive. Assume that in the male gay community the chance of infection among those being tested in 1989 was about 1 percent. That means that in the results of 10,000 tests, we would find not 1 (as before), but 100 true positives to go with the 10 false positives. So in this case the chances that a positive test meant I was infected would have been 10 out of 11. That's why, when assessing test results, it is good to know whether you are in a high-risk group.

BAYES'S THEORY shows that the probability that A will occur if B occurs will generally differ from the probability that B will occur if A occurs.7 To not account for this is a common mistake in the medical profession. For instance, in studies in Germany and the United States, researchers asked physicians to estimate the probability that an asymptomatic woman between the ages of 40 and 50 who has a positive mammogram actually has breast cancer if 7 percent of mammograms show cancer when there is none.8 In addition, the doctors were told that the actual incidence was about 0.8 percent and that the false-negative rate about 10 percent. Putting that all together, one can use Bayes's methods to determine that a positive mammogram is due to cancer in only about 9 percent of the cases. In the German group, however, one-third of the physicians concluded that the probability was about 90 percent, and the median estimate was 70 percent. In the American group, 95 out of 100 physicians estimated the probability to be around 75 percent.

Similar issues arise in drug testing in athletes. Here again, the oft-quoted but not directly relevant number is the false positive rate. This gives a distorted view of the probability that an athlete is guilty. For example, Mary Decker Slaney, a world-class runner and 1983 world champion in the 1,500 and 3,000 meter race, was trying to make a comeback when, at the U.S. Olympic Trials in Atlanta in 1996, she was accused of doping violations consistent with testosterone use. After various deliberations, the IAAF (known officially since 2001 as the International Association of Athletics Federations) ruled that Slaney「was guilty of a doping offense,」effectively ending her career. According to some of the testimony in the Slaney case the false-positive rate for the test to which her urine was subjected could have been as high as 1 percent. This probably made many people comfortable that her chance of guilt was 99 percent, but as we have seen that is not true. Suppose, for example, 1,000 athletes were tested, 1 in 10 was guilty, and the test, when given to a guilty athlete, had a 50 percent chance of revealing the doping violation. Then for every thousand athletes tested, 100 would have been guilty and the test would have fingered 50 of those. Meanwhile, of the 900 athletes who are innocent, the test would have fingered 9. So what a positive-doping test really meant was not that the probability she was guilty was 99 percent, but rather 50/59 = 84.7 percent. Put another way, you should have about as much confidence that Slaney was guilty based on that evidence as you would that the number 1 won't turn up when she tossed a die. That certainly leaves room for reasonable doubt, and, more important, indicates that to perform mass testing (90,000 athletes have their urine tested annually) and make judgments based on such a procedure means to condemn a large number of innocent people.9

In legal circles the mistake of inversion is sometimes called the prosecutor's fallacy because prosecutors often employ that type of fallacious argument to lead juries to convicting suspects on thin evidence. Consider, for example, the case in Britain of Sally Clark.10 Clark's first child died at 11 weeks. The death was reported as due to sudden infant death syndrome, or SIDS, a diagnosis that is made when the death of a baby is unexpected and a postmortem does not reveal a cause of death. Clark conceived again, and this time her baby died at 8 weeks, again reportedly of SIDS. When that happened, she was arrested and accused of smothering both children. At the trial the prosecution called in an expert pediatrician, Sir Roy Meadow, to testify that based on the rarity of SIDS, the odds of both children's dying from it was 73 million to 1. The prosecution offered no other substantive evidence against her. Should that have been enough to convict? The jury thought so, and in November 1999, Mrs. Clark was sent to prison.

Sir Meadow had estimated that the odds that a child will die of SIDS are 1 in 8,543. He calculated his estimate of 73 million to 1 by multiplying two such factors, one for each child. But this calculation assumes that the deaths are independent — that is, that no environmental or genetic effects play a role that might increase a second child's risk once an older sibling has died of SIDS. In fact, in an editorial in the British Medical Journal a few weeks after the trial, the chances of two siblings' dying of SIDS were estimated at 2.75 million to 1.11 Those are still very long odds.

The key to understanding why Sally Clark was wrongly imprisoned is again to consider the inversion error: it is not the probability that two children will die of SIDS that we seek but the probability that the two children who died, died of SIDS. Two years after Clark was imprisoned, the Royal Statistical Society weighed in on this subject with a press release, declaring that the jury's decision was based on「a serious error of logic known as the Prosecutor's Fallacy. The jury needs to weigh up two competing explanations for the babies' deaths: SIDS or murder. Two deaths by SIDS or two murders are each quite unlikely, but one has apparently happened in this case. What matters is the relative likelihood of the deaths…, not just how unlikely…[the SIDS explanation is].」12 A mathematician later estimated the relative likelihood of a family's losing two babies by SIDS or by murder. He concluded, based on the available data, that two infants are 9 times more likely to be SIDS victims than murder victims.13

The Clarks appealed the case and, for the appeal, hired their own statisticians as expert witnesses. They lost the appeal, but they continued to seek medical explanations for the deaths and in the process uncovered the fact that the pathologist working for the prosecution had withheld the fact that the second child had been suffering from a bacterial infection at the time of death, an infection that might have caused the infant's death. Based on that discovery, a judge quashed the conviction, and after nearly three and a half years, Sally Clark was released from prison.

The renowned attorney and Harvard Law School professor Alan Dershowitz also successfully employed the prosecutor's fallacy — to help defend O. J. Simpson in his trial for the murder of Simpson's ex-wife, Nicole Brown Simpson, and a male companion. The trial of Simpson, a former football star, was one of the biggest media events of 1994–95. The police had plenty of evidence against him. They found a bloody glove at his estate that seemed to match one found at the murder scene. Bloodstains matching Nicole's blood were found on the gloves, in his white Ford Bronco, on a pair of socks in his bedroom, and in his driveway and house. Moreover, DNA samples taken from blood at the crime scene matched O. J.'s. The defense could do little more than accuse the Los Angeles Police Department of racism — O. J. is African American — and criticize the integrity of the police and the authenticity of their evidence.

The prosecution made a decision to focus the opening of its case on O. J.'s propensity toward violence against Nicole. Prosecutors spent the first ten days of the trial entering evidence of his history of abusing her and claimed that this alone was a good reason to suspect him of her murder. As they put it,「a slap is a prelude to homicide.」14 The defense attorneys used this strategy as a launchpad for their accusations of duplicity, arguing that the prosecution had spent two weeks trying to mislead the jury and that the evidence that O. J. had battered Nicole on previous occasions meant nothing. Here is Dershowitz's reasoning: 4 million women are battered annually by husbands and boyfriends in the United States, yet in 1992, according to the FBI Uniform Crime Reports, a total of 1,432, or 1 in 2,500, were killed by their husbands or boyfriends.15 Therefore, the defense retorted, few men who slap or beat their domestic partners go on to murder them. True? Yes. Convincing? Yes. Relevant? No. The relevant number is not the probability that a man who batters his wife will go on to kill her (1 in 2,500) but rather the probability that a battered wife who was murdered was murdered by her abuser. According to the Uniform Crime Reports for the United States and Its Possessions in 1993, the probability Dershowitz (or the prosecution) should have reported was this one: of all the battered women murdered in the United States in 1993, some 90 percent were killed by their abuser. That statistic was not mentioned at the trial.

As the hour of the verdict's announcement approached, long-distance call volume dropped by half, trading volume on the New York Stock Exchange fell by 40 percent, and an estimated 100 million people turned to their televisions and radios to hear the verdict: not guilty. Dershowitz may have felt justified in misleading the jury because, in his words,「the courtroom oath — ‘to tell the truth, the whole truth and nothing but the truth' — is applicable only to witnesses. Defense attorneys, prosecutors, and judges don't take this oath…indeed, it is fair to say the American justice system is built on a foundation of not telling the whole truth.」16

THOUGH CONDITIONAL PROBABILITY represented a revolution in ideas about randomness, Thomas Bayes was no revolutionary, and his work languished unattended despite its publication in the prestigious Philosophical Transactions in 1764. And so it fell to another man, the French scientist and mathematician Pierre-Simon de Laplace, to bring Bayes's ideas to scientists' attention and fulfill the goal of revealing to the world how the probabilities that underlie real-world situations could be inferred from the outcomes we observe.

You may remember that Bernoulli's golden theorem will tell you before you conduct a series of coin tosses how certain you can be, if the coin is fair, that you will observe some given outcome. You may also remember that it will not tell you after you've made a given series of tosses the chances that the coin was a fair one. Along the same lines, if you know that the chances that an eighty-five-year-old will survive to ninety are 50/50, the golden theorem tells you the probability that half the eighty-five-year-olds in a group of 1,000 will die in the next five years, but if half the people in some group died in the five years after their eighty-fifth birthday, it cannot tell you how likely it is that the underlying chances of survival for the people in that group were 50/50. Or if Ford knows that 1 in 100 of its automobiles has a defective transmission, the golden theorem can tell Ford the chances that, in a batch of 1,000 autos, 10 or more of the transmissions will be defective, but if Ford finds 10 defective transmissions in a sample of 1,000 autos, it does not tell the automaker the likelihood that the average number of defective transmissions is 1 in 100. In these cases it is the latter scenario that is more often useful in life: outside situations involving gambling, we are not normally provided with theoretical knowledge of the odds but rather must estimate them after making a series of observations. Scientists, too, find themselves in this position: they do not generally seek to know, given the value of a physical quantity, the probability that a measurement will come out one way or another but instead seek to discern the true value of a physical quantity, given a set of measurements.

I have stressed this distinction because it is an important one. It defines the fundamental difference between probability and statistics: the former concerns predictions based on fixed probabilities; the latter concerns the inference of those probabilities based on observed data.

It is the latter set of issues that was addressed by Laplace. He was not aware of Bayes's theory and therefore had to reinvent it. As he framed it, the issue was this: given a series of measurements, what is the best guess you can make of the true value of the measured quantity, and what are the chances that this guess will be「near」the true value, however demanding you are in your definition of near?

Laplace's analysis began with a paper in 1774 but spread over four decades. A brilliant and sometimes generous man, he also occasionally borrowed without acknowledgment from the works of others and was a tireless self-promoter. Most important, though, Laplace was a flexible reed that bent with the breeze, a characteristic that allowed him to continue his groundbreaking work virtually undisturbed by the turbulent events transpiring around him. Prior to the French Revolution, Laplace obtained the lucrative post of examiner to the royal artillery, in which he had the luck to examine a promising sixteen-year-old candidate named Napoléon Bonaparte. When the revolution came, in 1789, he fell briefly under suspicion but unlike many others emerged unscathed, declaring his「inextinguishable hatred to royalty」and eventually winning new honors from the republic. Then, when his acquaintance Napoléon crowned himself emperor in 1804, he immediately shed his republicanism and in 1806 was given the title count. After the Bourbons returned, Laplace slammed Napoléon in the 1814 edition of his treatise Théorie analytique des probabilités, writing that「the fall of empires which aspired to universal dominion could be predicted with very high probability by one versed in the calculus of chance.」17 The previous, 1812, edition had been dedicated to「Napoleon the Great.」

Laplace's political dexterity was fortunate for mathematics, for in the end his analysis was richer and more complete than Bayes's. With the foundation provided by Laplace's work, in the next chapter we shall leave the realm of probability and enter that of statistics. Their joining point is one of the most important curves in all of mathematics and science, the bell curve, otherwise known as the normal distribution. That, and the new theory of measurement that came with it, are the subjects of the following chapter.

### Notes

1 The account of the Harvard student is from Hastie and Dawes, Rational Choice in an Uncertain World, pp. 320–21.

2 I was told a variant of this problem by Mark Hillery of the Physics Department at Hunter College, City University of New York, who heard it while on a trip to Bratislava, Slovakia.

3 Quoted in Stigler, The History of Statistics, p. 123.

4 Ibid., pp. 121–31.

5 U.S. Social Security Administration,「Popular Baby Names: Popular Names by Birth Year; Popularity in 1935,」http://www.ssa.gov/cgi-bin/popularnames.cgi.

6 Division of HIV/AIDS, Center for Infectious Diseases, HIV/AIDS Surveillance Report (Atlanta: Centers for Disease Control, January 1990). I calculated the statistic quoted from the data given but also had to use some estimates. In particular, the data quoted refers to AIDS cases, not HIV infection, but that suffices for the purpose of illustrating the concept.

7 To be precise, the probability that A will occur if B occurs is equal to the probability that B will occur if A occurs multiplied by a correction factor that equals the ratio of the probability of A to the probability of B.

8 Gerd Gigerenzer, Calculated Risks: How to Know When Numbers Deceive You (New York: Simon & Schuster, 2002), pp. 40–44.

9 Donald A. Barry and LeeAnn Chastain,「Inferences About Testosterone Abuse Among Athletes,」Chance 17, no. 2 (2004): 5–8.

10 John Batt, Stolen Innocence (London: Ebury Press, 2005).

11 Stephen J. Watkins,「Conviction by Mathematical Error? Doctors and Lawyers Should Get Probability Theory Right,」BMJ 320 (January 1, 2000): 2–3.

12.「Royal Statistical Society Concerned by Issues Raised in Sally Clark Case,」Royal Statistical Society, London, news release, October 23, 2001; www.rss.org.uk/PDF/RSS%20Statement%20regarding%20statistical%20issues%20in%20the%20Sally%20Clark%20case,%20October%2023rd%202001.pdf.

13 Ray Hill,「Multiple Sudden Infant Deaths — Coincidence or beyond Coincidence?」Paediatric and Perinatal Epidemiology 18, no. 5 (September 2004): 320–26.

14 Quoted in Alan Dershowitz, Reasonable Doubts: The Criminal Justice System and the O. J. Simpson Case (New York: Simon & Schuster, 1996), p. 101.

15 Federal Bureau of Investigation,「Uniform Crime Reports,」http://www.fbi.gov/ucr/ucr.htm.

16 Alan Dershowitz, The Best Defense (New York: Vintage, 1983), p. xix.

17 Pierre-Simon de Laplace, quoted in James Newman, ed., The World of Mathematics (Mineola, N.Y.: Dover Publications, 1956): 2:1323.

0601假阳性与好错误

20 世纪 70 年代，哈佛大学某位心理学教授的课堂上，来了一个外表奇特的中年学生。上过几堂课之后，学生主动找上教授，解释他选这门课的原因。在我自己的从教经历中，虽然也碰到过一些有礼貌的学生来跟我说为什么选我的课，却从来没有人把这当成一件不得不做的事情。我窃喜不已地以为大概是：「因为这门课令人着迷，而且老师你也很棒！」不过他的原因并非如此，他上这门课，是因为他需要帮助。他身上发生了一系列离奇的事情 —— 他的妻子甚至不用他开口就知道他的心思，可现在却吵嚷着要跟他离婚；一个同事在喝酒时提了一句解雇的话，而两天后他就丢了工作。不仅如此，他说他遭遇这类倒霉的事情和各种令他不快的巧合，已经有相当长的时间了。

一开始，这些事情带给他的只有困惑；渐渐地，他建立起一个模型，能够让这些事情的发生与他所相信的万物之道协调起来，一如大多数人的做法那样。不过他最后建立的理论跟普通人的想法相去甚远：他相信自己是一个精心策划的秘密科学实验中的小白鼠。根据他的理论，一大帮阴谋家实施了这项实验，他们的头头就是著名心理学家斯金纳。他还相信，等到实验结束，他将名满天下，说不定还能得到一个政府部门的高位。而他之所以来上课，是因为他想知道怎样利用长期积累的证据，来检验这个假设是否成立。

课程结束之后的几个月，这名学生再次来找教授寻求帮助。按他这次的说法，实验还在进行。他把他的前老板告上法庭，而前老板找来一名精神病医生，想证明他有妄想症。

这位医生用来证明这个学生有妄想症的证据之一，就是他创造了一个虚构的 18 世纪神父，还到处宣扬这位神父的种种言论。医生更是对这个学生下面的说法大加嘲笑：学生告诉大家，这名神父是个业余数学家，他利用自己的空余时间，建立了一个十分怪异的概率理论。学生声称，这位神父的名字是托马斯·贝叶斯，而贝叶斯的理论所解决的问题，就是如何在某事件已经发生的前提下，估计另一事件发生的可能性。一个特别的学生成为实验心理学家庞大阴谋的被试对象的可能性有多大？不可否认，这个可能性不怎么大。不过如果这个学生的妻子能直接道破老公的心思，并且同事们能在觥筹交错中不经意间点破他职业生涯的前途，在这样的附加证据下，之前那个可能性又有多大呢？按照这名学生的说法，用贝叶斯的理论就能根据新出现的证据，调整某概率的初始估计值。在法庭上，他还列出一堆莫名其妙的公式和算式，而最后得出的结论是，附加证据使得他那个阴谋论的假设成立的可能性达到 999999/1000000。而官司的另一方，精神病医生则断言，这位神父数学家和他的理论，纯粹是这个学生精神分裂的臆造产物。

这个学生希望教授能帮他驳倒精神病医生。教授同意了。要反驳精神病医生，教授的理由十分充分，因为 1702 年出生于伦敦的贝叶斯，的确是坦布里奇韦尔斯的一名神父。他于 1761 年去世，在伦敦一个名叫本希尔菲尔兹的公园中，与他那同为神父的父亲乔舒亚葬在一起。而且，贝叶斯也确实创造了「条件概率」理论，将之前仅能处理独立事件的概率理论，扩展到存在相关性的事件之上。举例来说，随便挑一个人他是精神病的概率，或者随便挑一个人他会相信他妻子有读心术的概率，两者都非常小。但是，如果有人相信妻子会读心术，那么他同时患有精神疾病的概率要高得多。不仅如此，如果一个人是精神病患者，那么他相信妻子会读心术的概率也会高很多。那这些概率相互之间是如何联系起来的？这就是条件概率要研究的内容。

于是，教授为法庭提供了一份证言，解释了贝叶斯的存在及其理论。不过他并未支持那位前学生声称的、可以证明其神志正常的可疑计算。作为原告方的中年精神分裂者，并不是这个故事中唯一让人感到悲哀的对象，和他针锋相对的被告方的医学和法律团队其实也一样。遭受精神分裂的痛苦是很不幸，但毕竟还有药物可以对抗这种疾病。但是药物虽然可以治病，却不能治疗无知。我们马上就会看到，正是出于对贝叶斯思想的无知，许多医学诊断和法律判决出现了严重错误。但在医生和律师们接受职业训练的过程中，没有人告诉他们这个无知的存在。

在日常生活中，我们也经常使用贝叶斯推理。有这么一部电影，说的是一名律师，有着体面高薪的工作、迷人的妻子和幸福的家庭。他爱他的妻子和女儿，但仍然觉得生活中似乎缺少些什么。某晚他乘火车回家，途中无意瞥见一位美人，她若有所思地从一个舞蹈班的窗户朝外凝望着。第二天晚上，他用目光追随着这名女子。第三天晚上也是如此。他乘坐的火车每经过一次这个舞蹈班，他在爱情魔咒中的沉沦就更深一步。终于有一天，他再也抑制不住这股冲动，跳下车去舞蹈班报了名，希望能邂逅这名女子。但当那无法触及的对望变成触手可及的面对面之后，她那令人难忘的魅力却慢慢褪去了。他确实恋爱了，不过不是和那位美人，而是和舞蹈堕入了爱河。

为了对家人和同事保密，让他们不知道这份不理智的情感，他不得不寻找种种借口解释那越来越多的不回家的夜晚。终于有一天，妻子发现他并不是因为加班才搞到那么晚。在妻子看来，他因为外遇而撒谎的可能性，显然要高于其他原因而撒谎的可能性，因此答案只有一个，那就是他出轨了。我们当然知道这个答案是错的，她错的不仅仅是答案。她的整个推理过程都是错的，她搞混了丈夫有外遇时行踪鬼祟的概率，以及她丈夫行踪鬼祟时是在搞外遇的概率。

这是个常见的错误。假设老板回复你最近一封电子邮件的时间比以往要长，那么很多人会觉得这是扫把星即将降临的预兆，因为如果你的幸运星不见了，老板就可能更晚回复你的邮件。但老板之所以邮件回复慢了，可能仅仅因为他最近更忙些，或者他母亲刚好生病了。因此，当他回复邮件比较慢时你要倒霉的可能性，与你快要倒霉时他回复邮件的速度变慢的可能性相比，前者要小得多。许多阴谋论都来自对这种逻辑关系的错误理解，也就是说，当一系列事件是某个大阴谋的产物时，这些事件发生的可能性，与当一系列事件已经发生而这些事件证明存在着一个大阴谋的可能性，两者被混为一谈了。

贝叶斯理论讨论的全部内容，就是当其他事件已经发生，或者在给定其他事件已经发生的前提下，某事件发生的可能性会因此受到怎样的影响。为了看看这个影响到底是什么样的，现在我们转到与第 3 章中的两个女儿问题相关的另一个问题上。假设一个远房亲戚有两个孩子。在两个女儿问题中，我们知道这两个孩子中至少有一个是女孩，而我们想知道到底有几个女孩，一个，还是两个？如果一家子有两个孩子，如果其中至少有一个是女孩，那么两个都是女孩的可能性有多大？第 3 章并没有用上面的措辞讨论这个问题，但「如果」两字，就将问题变成一个条件概率问题了。如果没有这个如果，两个孩子都是女孩的可能性是 1/4，对应 4 种可能的出生顺序为（男孩，男孩）、（男孩，女孩）、（女孩，男孩）和（女孩，女孩）。但知道至少有一个女孩这个额外信息时，两个都是女孩的可能性就变为 1/3，这是因为，如果至少一个孩子是女孩，那么两个孩子的性别就只有 3 种可能情况 ——（男孩，女孩）、（女孩，男孩）和（女孩，女孩），其中一种正好对应了两个孩子都是女孩的结果。这大概就是理解贝叶斯思想最简单的方法，跟以前一样，其实这也就是个记账的事情。首先，把样本空间 —— 也就是所有可能情况的清单 —— 写下来，如果这些情况的可能性不等，就将其各自的概率一同记下（在分析容易让人犯糊涂的概率问题时，这的确是个好办法）。接着，把被条件（在现在的问题中，就是「至少有一个女孩」这个条件）否定的那些可能性划掉，剩下的就是条件满足时的可能情况，以及它们的相对概率。

2『计算条件概率通俗方法，做一张任意卡片。（2021-02-20）』——已完成

这种方法看上去似乎理所当然。你可能会自信满满地认为，用不着亲爱的贝叶斯神父帮忙，自己也能想通这一点。说不定你现在正在考虑，等下次泡澡的时候，一定要把我的这本书扔到一边，另外再抓本其他的书来读。因此，在进一步讨论之前，我们来看看两个女儿问题的一个看上去稍微有点儿不同的变体，而这个问题的答案，大概会给你带来更多的震惊。

新问题如下：有一家人，家中有两个孩子。如果两个孩子中有一个是名叫佛罗里达的女孩，那么两个孩子都是女孩的概率有多大？是的，我说的是一个名叫佛罗里达的女孩。这个名字看起来好像是随便取的，但实际并非如此。虽然这是以古巴移民、橙子以及那些为享受棕榈树和玩宾戈游戏而卖掉大房子的北方老人而出名的一个州的名字，但它同时也是一个真实的人名。实际上，在 20 世纪前 30 年里，佛罗里达是 1000 个最常见的美国女性名字之一。我是深思熟虑之后才挑中这个名字的，因为这个题目的一部分是这样一个问题，如果佛罗里达这个名字有影响，那么会是什么影响呢？哎呀，我说得太多了！在继续之前，请大家思索一下：在这个「名叫佛罗里达的女孩」问题中，两个都是女孩的可能性，是否仍为 1/3（跟之前那个两个女儿问题的答案相同）？

我将很快证明，答案是否定的。有一个女孩名叫佛罗里达的这个事实，将我们要求的概率变成了 1/2：如果你想不通，也不必担心。不管是理解随机性问题，还是其他任何数学问题，关键并不在于能否只靠直觉马上得出答案，而在于是否掌握了求解的工具。

1『求解数学问题的关键在于掌握求解的工具而非只靠直觉获得答案，做一张金句卡片。（2021-02-20）』——已完成

那些对贝叶斯是否确实存在还抱有疑虑的人，至少在一件事情上是对的：贝叶斯从未发表过哪怕一篇论文。他的生平我们几乎一无所知，不过他进行研究的目的多半出于他自己的兴趣和快乐，他可能并不觉得有什么必要去和别人交流他的研究成果。从这方面以及很多其他方面来说，他和雅各布·伯努利正好是两种相反类型的人：伯努利反对神学研究，而贝叶斯信仰虔诚；伯努利追求名誉，而贝叶斯对此毫无兴趣；最后，伯努利定理考虑的是，假如你打算用一枚均匀的硬币进行多次投掷，那么可以有较大把握得到的正面朝上的次数是多少，而贝叶斯研究的却是伯努利最初的那个目标，即当你知道了正面朝上的次数时，你能在多大程度上相信硬币并不会特别偏爱其中的某一面。

1『上面的这个对比太妙了，把贝叶斯求解逆概率的本质解释的通俗易懂。做一张任意卡片。（2021-02-20）』——已完成

使贝叶斯留名至今的理论最早为世人所知，是在 1763 年 12 月 23 日。当时，另一位牧师兼数学家理查德·普赖斯在英国皇家学会（英国的国家科学院）宣读了一篇论文。贝叶斯的这篇论文名为《通往机遇学说的一个问题之解决的短文》，并于 1764 年发表在英国皇家学院的《哲学会刊》上。贝叶斯在遗嘱中将这篇论文连同 100 英镑一起留给了普赖斯。贝叶斯在遗嘱中用「我想应该是纽因顿格林的一名传教士」来称呼普赖斯，而在写完遗嘱的 4 个月后，贝叶斯就离开了人世。

尽管贝叶斯提到普赖斯时相当漫不经心，但后者并非一个躲在大家看不见的阴暗角落中的传教士。普赖斯是宗教自由的著名倡导者本杰明·富兰克林的朋友，他深受亚当·斯密信赖，并对《国富论》的草稿提出若干批评意见，此外他还是一位有名的数学家。他是公认的保险精算学的创建者。1765 年，一个名为公平社会的保险公司派了 3 个人向他求助，他也因此建立了这个学科领域。跟保险公司这次见面的 6 年后，普赖斯在《评继承支付》（Observations on Reversionary Payments）这本书中发表了他的研究成果。直到 19 世纪这本书都还是精算师们的《圣经》，不过由于一些糟糕的数据和估算方法，他好像低估了人们的预期寿命。这一低估使得人寿保险费用大为提高，而他那帮公平社会保险公司的伙伴也因此发了横财。与此相对，英国政府也是根据普赖斯的表格制定养老金支付标准的，而当这些领取养老金的人没有按预期退出历史舞台的时候，倒霉的政府因此大亏一笔。

我之前提到过，启发贝叶斯建立条件概率的，就是伯努利最开始感兴趣的那个问题：我们怎样才能根据观察推算隐含概率？如果一种药物在临床试验中只治愈了 60 名病人中的 45 名，那么根据这个数据，我们能知道多少关于这种药物在下一个病人身上有效的可能性信息？如果药物是对 100 万个病人中的 60 万人有效，那么药物的有效率落在 60% 附近的可能性显然很高。但对规模更小的试验来说，我们能从中得出什么结论呢？而且贝叶斯同时还考虑了另一个问题：如果在进行试验之前，我们有理由相信该药物的有效率只有 50%，那么在开展试验以评价有效率时，试验所得的新数据应占多大的权重？后面这种做法，正是我们多数生活经验的来源：先观察一个相对比较小的结果集，从中获得一些信息，然后对造成这些结果的内在机理进行判断。不过这一系列推理究竟应当如何进行呢？

2『贝叶斯推理，贝叶斯研究的问题，做一张主题卡片。（2021-02-20）』

贝叶斯通过一个类比考虑上述问题。假设我们现在有一张方桌和两个球。我们把第一个球滚到桌子上，而且我们滚动这个球的方式，是保证它可以等可能性停在桌上的任意一点。接下来，我们不看桌子和球，但是要确定这个球的水平位置。帮助我们完成这个任务的工具，就是第二个球。我们以同样的方式反复滚动第二个球，同时我们的搭档将记录第二个球是停在第一个球的左边还是右边。等试验结束后，搭档会将第二个球停在左右两边的次数告诉我们。第一个球模拟的就是我们要求的未知量，第二个球则是我们能够实际获得的数据。如果第二个球总是停在第一个球的右边，我们就可以很有把握地认为第一个球距桌子最左边很近；如果第二个球并非一贯落在右边，那么我们对于刚才这个结论的信心随之降低，而会去猜想第一个球实际停在了更靠右一些的位置。贝叶斯告诉我们的，就是如何根据第二个球的数据，确定第一个球停在水平轴上任意给定位置的准确概率，以及在给定更多新数据的情况下，如何修正初始的估计值。用贝叶斯的术语来说，初始估计被称为先验概率，而修正后的新猜测被称为后验概率。

贝叶斯设计这个游戏的原因，是生活中的许多决策过程都可以转化为相同的问题。在药物试验的例子中，第一个球的位置代表了药物的真实有效率，而第二个球提供的信息相当于在病人身上得到的试验数据。第一个球的位置还能代表一部影片的流行程度、产品质量、驾驶水平、勤奋程度、固执程度、天分高低、能力高低或任何能决定行为成败的因素。而第二个球所提供的东西，代表了我们观察或收集得到的数据。贝叶斯理论告诉我们怎样去估计未知的概率，以及如何根据新数据修正旧的结果。

如今，贝叶斯分析已被广泛应用于科学和工程的各个领域。例如在确定汽车的保费时，所用模型中就包含一个参数，它描述的是单位驾驶时间内，投保者遭遇 0 次、1 次或更多次交通事故的概率。我们在下面的讨论中设想一个简化的模型，其中每个人都将被归入两种类型之一：平均每年至少遭遇 1 次事故的高危司机，和平均每年遭遇不到 1 次事故的低危司机。如果你的驾驶记录告诉保险公司，在过去 20 年中你一次事故都没发生过，或是在过去 20 年中你发生了 37 次事故，那么保险公司可以很清楚地知道应该把你归为哪一类。但如果你是新司机，那么你应该算低危类型（遵守限速且志愿成为模范驾驶员的好孩子）还是高危类型（一边猛灌只剩一半的 2 美元一瓶的布恩农场苹果酒，一边在主干道飙车的坏孩子）？保险公司缺少你的个人驾驶数据，也就是说它对「第一个球的位置」完全一无所知。那么这时它可以按等概率把你归类，或者根据所有新司机的汇总数据，估计出你属于高危类型的初始可能性为比如 1/3。后面这种情况下，公司可以把你作为一个低危和高危的混血儿来建模，也就是 1/3 的高危加 2/3 的低危，然后根据 1/3 的高危保费加 2/3 的低危保费收钱。经过一年的观察后，相当于把贝叶斯那第二个球滚动一次后，公司将会使用新的数据重新评价给你建立的模型，调整之前所设的 1/3 和 2/3 的比例，重新计算出新的保费。如果这一年中你没有发生事故，那么低危的比例以及对应的低费用的比例会相应增加；如果你发生了两次事故，那么这些比例会相应降低。精确的调整幅度由贝叶斯定理给出。按同样的方法，保险公司今后就能定期调整评估值，以便反映你到底是不会发生事故的那类司机，还是连着两次事故都是在单行道上逆行，而且还是左手拿手机右手拿甜甜圈的家伙。保险公司之所以给「好司机」打折，就在于没有交通事故的事实，提高了司机属于低危类型的后验概率。

贝叶斯定理的许多细节显然都十分复杂。不过我在分析两个女儿问题时就说明了，解决问题的关键，在于用新信息精简样本空间以及相应地调整概率。在两个女儿问题中，初始样本空间为（男孩，男孩）、（男孩，女孩）、（女孩，男孩）和（女孩，女孩）；但如果我们得知至少有一个是女孩，样本空间就精简为（男孩，女孩）、（女孩，男孩）和（女孩，女孩），从而使两个都为女孩的可能性变为 1/3。让我们继续使用这个简单的策略，看看如果家里有一个名叫佛罗里达的女孩会发生什么。

在名叫佛罗里达的女孩问题中，新信息不仅与孩子的性别有关，还与女孩的名字有关。既然初始样本空间是一张列出所有可能情况的清单，那么现在它应该是一张包含了性别与姓名的清单。我们以女孩 F 来表示「名叫佛罗里达的女孩」，以女孩 NF 来表示「名字不是佛罗里达的女孩」。于是现在的样本空间就变成了：（男孩，男孩）、（男孩，女孩 F）、（男孩，女孩 NF）、（女孩 F，男孩）、（女孩 NF，男孩）、（女孩 NF，女孩 F）、（女孩 F，女孩 NF）、（女孩 NF，女孩 NF）和（女孩 F，女孩 F）。

接着精简样本空间。既然已知两个孩子之一是名为佛罗里达的女孩，样本空间便可以缩小为（男孩，女孩 F）、（女孩 F，男孩）、（女孩 NF，女孩 F）、（女孩 F，女孩 NF）和（女孩 F，女孩 F）。到了这一步，问题就与原先两个女儿问题有所不同了。由于一个女孩名叫或不叫佛罗里达的概率并不相等，因此，这个样本空间中的元素并非等概率事件。

在 1935 年，也就是美国社会安全署提供姓名统计数据的最后一年，大约每 3 万名女孩中，就有一个叫佛罗里达。这个名字现在已经慢慢消失了，所以为了叙述方便，我们假定现在这个概率是百万分之一。这也就意味着，如果我们知道某女孩的名字不是佛罗里达，那么并不稀奇；但如果我们知道某女孩的名字是佛罗里达，就相当于买彩票中了大奖。即使不考虑父母通常都不会给孩子起重名的事实，两个女孩都叫佛罗里达的可能性也微乎其微，因此我们完全可以忽略掉两个女孩都叫佛罗里达的可能性，现在样本空间中只剩下（男孩，女孩 F）、（女孩 F，男孩）、（女孩 NF，女孩 F）和（女孩 F，女孩 NF），而它们各自发生的概率十分接近。

既然 4 个元素中有一半（2 个）对应了这一家子有两个女儿的情况，因此问题的答案就不再像两个女儿问题那样是 1/3，而变成了 1/2。这个额外增加的有关女孩姓名的信息，让答案变得不同了。

1『算是看懂了，蒙洛迪诺的讲解过程太精彩了，这个例子。（2021-02-20）』

要是还有人想不通，那就用另一种方式来理解吧。设想 7500 万个家庭在一个异常巨大的房间里聚会，每个家庭都有两个孩子且至少有一个是女孩。正如两个女儿问题告诉我们的那样，房间里大概 2500 万个家庭两个孩子都是女孩，而其他 5000 万个家庭则是一男一女（其中又有 2500 万个家庭女孩是姐姐，而剩下的相同数量的家庭女孩是妹妹）。接下来我们开始精简：只留下那些有一个名叫佛罗里达的女儿的家庭。既然给女儿起名叫佛罗里达的概率是百万分之一，那么 5000 万个有一个女孩的家庭大概 50 个家庭留了下来；至于那 2500 万个有两个女孩的家庭，也有大约 50 个家庭会留下来，其中 25 个长女名叫佛罗里达，而另外 25 个则是次女。这就好比我们把女孩看成彩票，而名叫佛罗里达的女孩是中奖的那张。尽管有一个女孩的家庭比有两个女孩的家庭多了一倍，但这些两个女孩的家庭有两张彩票，因此在最终的中奖者中，一个女孩的家庭跟两个女孩的家庭，两者数量大致相等。

现在，我已经讲完了这个名叫佛罗里达的女孩的问题。我的描述可能有太多细节，这些细节有时甚至令人不快到让邻居把我列入派对黑名单的地步。不过我这么做可不是想让你们也获得同样的待遇，而是因为这个例子中的内在关系十分简单。相同的推理同样可以让许多实际场景变得清晰明了。下面，我们就来说几个这样的事情。

我与贝叶斯神父最值得铭记的相遇，是在 1989 年某星期五的下午。医生打了个电话给我，说我会有 99.9% 的可能性活不过 10 年。他还加了一句：「我真的十分抱歉。」就好像他对某些病人说的抱歉并不是真心诚意的。在回答了我问的几个有关病情发展的问题后，他挂断了电话，很可能是向别的病人送惊喜去了。我很难说出甚至回忆起我到底是怎样度过那个周末的，不过那个周末我肯定没有去迪士尼乐园。可为什么被下了这个死亡判决后，我今天还能好好儿地在这里写书来说这件事呢？

这个令人心惊肉跳的事情，起因于我和妻子申请办理人寿保险。这个申请需要进行血检。过了一两个星期，我们的申请被拒绝了。这个向来节俭的保险公司，这次竟然不惜血本地用两封内容几乎相同的信件，告诉了我们这个消息。给我妻子的信中，不过就是把我的那封信中「由于你的血检结果」而否决了保险申请的措辞，改为了「由于你丈夫的血检结果」。这唯一多出来的「丈夫」一词，显然是好心的保险公司愿意提供的关于我们投保被拒的唯一线索。我带着不祥的预感去看了医生，做了一次 HIV（人类免疫缺陷病毒）检查。检查结果是阳性。尽管开始时，我因为这五雷轰顶的消息都忘了问问这个结果是否真的可靠，但是根据后来的了解，我知道了医生是如何得出那个 0.1% 的健康概率的：在 1000 个没有艾滋病病毒的血液样本中，会有一个 HIV 阳性结果。这听起来好像没什么不同，但事实并非如此。医生将「如果我没有感染 HIV 而检查结果呈阳性」的概率和「如果我的检查结果呈阳性而我并没有感染 HIV」的概率搞混了。

为了理解医生所犯的错误，让我们来使用贝叶斯方法。首先定义样本空间。我们可以把所有曾接受过 HIV 检查的人都包括进来，但如果能有更多和我自身状况有关的附加信息，那么对我而言结果将会更准确一些。因此我们只考虑所有曾接受过 HIV 检查、不滥用静脉注射吸毒的异性恋美国白人男性（我们会看到，这个附加信息将给出多么不同的结果）。

现在我们已经知道哪些人应该被归入样本空间。接下来，我们将这些人分为几类。现在我们问题中的类型不再是男孩或女孩，而是检查呈阳性且确实为 HIV 感染者的人（真阳性）、检查呈阳性但没有感染 HIV 的人（假阳性）、检查呈阴性且没有感染 HIV 的人（真阴性）以及检查呈阴性但实际感染了 HIV 的人（假阴性）。

最后，我们来看一看每种类型的人数。考虑一个 1 万人的初始人群。根据美国疾病控制与预防中心的统计数据，我们可以估计在 1989 年，大约每 1 万名接受检查的不滥用毒品静脉注射的异性恋美国白人男性中，会有 1 名感染了 HIV。假设假阴性率非常接近 0，这就意味着，大约每 1 万人中有 1 人会因为真实感染而被检测出阳性。此外，由于假阳性率是医生所说的 1/1000，因此，大概另有 10 人虽然没有感染 HIV，但还是被查出呈阳性。而样本空间中剩下的那 9989 人，检查结果是阴性。

现在精简样本空间，使之仅包含那些检查结果为阳性的人，也就是 10 个假阳性和 1 个真阳性。换句话说，在 11 个被查出为阳性的人中，只有 1 个是真的 HIV 感染者。医生告诉我检查结果出错，就是我实际上没患病的可能性是 1/1000。不过他更准确的表达应该是：「别担心，你没有感染 HIV 的机会不小于 10/11。」对我来说，这个筛查显然被我血液中的某种标记物给欺骗了，要查的病毒其实并不存在。

了解假阳性率对于任何检查结果的评价都十分重要。举例来说，假设一个检查能查出 99% 的恶性肿瘤，这个诊断率听起来令人印象深刻，但我可以很容易就设计出一个能 100% 查出肿瘤的方法：我可以让所有被检者的结果都是阳性。我的方法和真正有用的方法之间的差别，在于我的检查方法假阳性率很高。但我的遭遇说明，只知道假阳性率还不足以确定检查的实用性，我们还需要比较假阳性率与疾病的真实流行情况。如果疾病十分罕见，那么就算假阳性率很低，阳性结果也不表示就一定患病了；但如果是常见疾病，阳性的检查结果就更有意义。如果我是同性恋又被查出阳性，那么这时疾病的流行度会如何影响阳性结果的诊断意义呢？假定在 1989 年的男同性恋中，进行 HIV 检查的人的感染率为 1% 左右。也就是在 1 万个检查结果中，真阳性的数量不是之前的 1 个，而是 100 个，此外还有 10 个假阳性。那这时，阳性结果的被检查者确实被感染的概率，就变为 10/11。这也就是为什么使用检查结果时，确定被检查者是否属于高危人群对于诊断结果十分有帮助。

贝叶斯理论告诉我们，B 发生时 A 也发生的概率，一般不同于 A 发生时 B 也发生的概率。医生们常犯的错误，就是因为没有清楚地认识到这一点。在德国和美国进行的几项研究中，研究者告诉参加实验的医生，乳腺 X 射线检查有 7% 的假阳性率，然后请这些医生估计一下，一名无症状的 40-50 岁且乳腺 X 射线检查结果为阳性的妇女，她真正患乳腺癌的可能性有多大。此外，他们还告诉这些医生实际的乳腺癌发病率约为 0.8%，而假阴性率约为 10%。把这些数据凑到一块，就能用贝叶斯方法得出，真正因患乳腺癌而得到的乳腺 X 射线检查呈阳性的比例，仅为 9% 左右。但在德国医生组中，有 1/3 的医生认为这个概率为 90%，所有受试者给出的估计值中值则是 70%。在美国医生组中，100 名医生中就有 95 名估计这个概率应该在 75% 左右。

在体育运动员的药检中也出现了类似问题。假阳性率这个实际上与问题没有多少直接关系的数据，又一次被拎出来。运动员违反禁令的真实情况被假阳性率扭曲了。例如世界级的田径运动员，1983 年的 1500 米和 3000 米世界冠军获得者史兰尼 1996 年在亚特兰大参加美国奥运会选拔赛，希望能够就此回到田径场上。不过药检结果显示她服用了睾酮类药物。在慎重讨论后，IAAF（国际田径联合会，2001 年起国际田联的官方名称）仍然确认史兰尼「违反了药物禁令」，并事实上终结了她的职业生涯。在史兰尼的这个案子里，有很多证据表明，她所接受的尿检的假阳性率高达 1%。这个数字让许多人对于史兰尼所受的处罚感到心安理得，因为她确实服用了禁药的可能性应该就是 99%。但我们已经看到，这个结论并不正确。假设有 1000 名运动员接受了检查，而他们服用禁药的真实比例是每 10 人中有 1 个。假设检查能以 50% 的概率发现确实服了禁药的运动员。那么，每 1000 名受检的运动员中，会有 100 名确实违规，而其中 50 名会被尿检查出。同时，剩下的那 900 名清白的运动员中，也有差不多 9 个人的结果呈阳性。因此，尿检阳性并不意味着史兰尼罪有应得的可能性是 99%，而是 50/59=84.7%。史兰尼确实违规的可能性，跟扔骰子没扔出 1 点的可能性差不多。而这个大小的可能性，显然给质疑这个判决的合理性留下了足够的空间。更重要的是，这个例子表明，如果药检规模很大（每年有 9 万名运动员接受尿检），那么之前那种推理过程会使许多无辜者蒙冤。

与上面那个错误恰好相反的，则是法律圈中被称为「检控者的谬误」的情况。之所以得此名，是因为检方常常用这种靠不住的论断，诱导陪审团仅凭单薄的证据就对犯罪嫌疑人定罪。我们来看看发生在英国的莎莉·克拉克案。克拉克的第一个孩子出生后 11 周死亡。当时得到的死因是 SIDS（婴儿猝死综合征），而这是尸检无法查出意外死亡的婴儿死因时做出的诊断。后来克拉克再次怀孕生子，而这次孩子出生才 8 周又不幸死亡，死因仍是 SIDS。第二个孩子死后，克拉克被警方逮捕，并被指控将两个孩子窒息致死。在法庭上，检方传唤了老资历的儿科医生罗伊·梅多爵士。爵士证明，SIDS 本身是很罕见的，因此两名婴儿都死于 SIDS 的可能性只有 1/7300 万。但除此之外，检方拿不出任何不利于被告的实质性证据。这个概率够不够用来定克拉克的罪呢？陪审团觉得够了。因此，1999 年 11 月，克拉克太太入狱服刑。

梅多爵士是这样来估计上面那个概率的。首先，他估计一名婴儿死于 SIDS 的机会是 1/8543。所以两个孩子都死于 SIDS 的概率，就是把上面这个数字跟自己再乘一次，即 1/7300 万。不过这个计算中隐含了一个假设，那就是两起死亡事件是相互独立的，或者即使哥哥或姐姐因 SIDS 而夭折，也没有任何环境或遗传因素会增加第二个孩子的死亡风险。但实际上，审判结束几周后出版的那一期《英国医学杂志》的编者按中，给出两名兄弟姐妹都死于 SIDS 概率的估计值为 1/275 万。当然，这个概率还是很小。

理解克拉克是蒙冤入狱的关键，在于搞清楚我们现在所面临的错误：我们真正要找的，并不是两个孩子都死于 SIDS 的概率，而是两个孩子的死因都是 SIDS 的概率。克拉克入狱两年后，英国皇家统计学会发布了一份新闻稿，从而加入这个话题的讨论。这份新闻稿指出，陪审团的决定是基于「一个严重的、被称为检控者的谬误的逻辑错误。陪审团应当衡量的，是对婴儿死因的两种相互对立的解释：SIDS 或谋杀。两起死亡由 SIDS 或谋杀造成的可能性都十分小，但在本案中，其中之一显然已经发生。在案子中真正重要的，是两种死因的相对大小…… 而不仅仅是（死于 SIDS 的情况）到底有多么不可能……」一名数学家后来估计了因为 SIDS 或谋杀而失去两个孩子的相对可能性。根据能够得到的统计数据，他得出的结论是两名婴儿死于 SIDS 的可能性 9 倍于谋杀。

克拉克家提起了上诉，并请这位数学家作为专家证人。上诉以败诉告终，但他们并没有放弃寻找孩子的死因。在这个过程中，他们发现了一个被隐藏的情况：检方的病理学家隐瞒了第二名婴儿在死前被病菌感染的事实，而这个感染有致死的可能。这个新发现让法官最终撤销了有罪判决。在坐了差不多三年半的牢房后，克拉克被释放。

著名律师、哈佛大学法学院教授艾伦·德肖维茨在辛普森谋杀前妻妮可·布朗·辛普森及其男友一案中，同样成功地运用了检控者的谬误来为辛普森辩护。辛普森这名前橄榄球明星的案子，是 1994 年到 1995 年媒体的一大热点。警方掌握的对辛普森不利的证据分量相当足：他们在其住所发现了一只染血的手套，而且与在谋杀现场发现的那只似乎正好是一对儿；在两只手套上、辛普森的白色福特 Bronco 中、卧室中的一双袜子上以及车道和房屋中，都发现了与妮可血型相符的血迹；而且在罪案现场提取到的血样 DNA，也与辛普森的 DNA 吻合。辩方除了以种族主义（辛普森是一名非洲裔）指责洛杉矶警察局，并质疑警方的可靠性和证据的权威性之外，大概能够帮上的忙也不多了。

检方决定在案子开审时，将焦点集中在辛普森对妮可的暴力倾向上。检察官将开庭后的头十天，花在了出示被告虐待妻子的证据上。检方称，哪怕只考虑这些证据，就足以怀疑被告谋杀了被害人。按他们的话来说：「扇耳光就是杀人的前奏。」辩方律师则利用检方的这一策略，指责检方缺少诚信。他们辩称，检方花了两周的时间，目的不过是试图误导陪审团。辛普森之前暴打妮可的这些证据，根本说明不了什么问题。下面就是德肖维茨的推理过程：在美国，每年有 400 万妇女遭到丈夫或男友的殴打，而在 1992 年，根据 FBI（美国联邦调查局）犯罪报告汇编，共有 1432 名，也就是 2500 名被殴打者中就有 1 名妇女确实被丈夫或男友杀害。因此辩方称，那些扇伴侣耳光或殴打伴侣的男人，其实并没有几个真正发展到谋杀的地步。这对不对呢？对。确信无疑？是。与本案有关？无关。与本案有关的数字，不是一个殴打妻子的男人会杀害她的概率（1/2500），而是一名遭殴打并被谋杀的妻子，凶手是她的施虐者的概率。根据 1993 年美国本土及海外的犯罪报告汇编，德肖维茨（或检方）应当提供的概率是下面这个：1993 年，所有被谋杀的曾遭受家庭暴力的美国妻子，差不多有 90% 是被施虐者杀害的。这个统计数字却没有出现在法庭上。

在最后的判决时刻，美国长途电话的通话量掉了一半，纽约股票交易所的交易量则下降了 40%。据估计，大概有 1 亿人打开电视或收音机来收听法庭的最终判决：无罪。德肖维茨大概对他有意误导陪审团的行为问心无愧，因为按他的话说：「我们在法庭宣誓所说的，仅陈述事实及事实之全部，这句话，只适用于证人。辩护律师、检察官和法官都不用进行这个宣誓…… 事实上，我们可以很公平地说，美国司法系统就是建立在不说出事实之全部的基础上的。」

条件概率的出现，是认识随机性方面的一场革命。不过贝叶斯本人却跟革命一点儿都扯不上关系。他的成果虽然于 1764 年发表在享有盛誉的《哲学汇刊》上，却在无人理睬中渐渐被淡忘。让科学家重新注意到贝叶斯的思想，并最终告诉人们怎样才能根据观察结果推算出隐藏的真实概率的重任，就落在了法国科学家与数学家拉普拉斯的肩上。

读者们大概还记得，在我们真的把硬币抛出去之前，我们可以根据伯努利的黄金定理估计出现某特定结果的可能性 —— 如果硬币没有被做手脚的话。你可能也还记得，这个定理并没有告诉我们，在具体完成了一系列抛掷后，我们实际得到的结果表明硬币没有被动手脚的可能性有多大。与此类似，如果我们知道一名 85 岁的老人能活到 90 岁的可能性为 50 比 50，那么黄金定理能告诉我们，1000 名 85 岁的老人中一半在接下来的 5 年中过世的概率有多大。但如果现在某群体中一半的人在 85 岁到 90 岁的年龄段去世，黄金定理就不能告诉我们，这个群体中单个个体的生存率为 50% 的可能性有多高。再举个例子。假设福特公司已经知道，它生产的每 100 辆汽车中就有 1 辆存在传动故障，那么黄金定理将告诉福特，每 1000 辆汽车中就会有 10 辆或更多辆存在传动问题。但如果福特在一个 1000 辆汽车的样本中，发现了 10 辆存在传动问题的汽车，黄金定理却不能说出这批汽车中存在传动问题的可能性为 1% 的可靠性有多高。在这些例子中，后面的那个概率常常更加有用：除了博弈游戏，我们一般都没有关于所需概率的理论知识，因而必须通过一系列观测进行估计。科学家的处境也一样，他们一般不是在已知某物理量的值之后，再来确定对该量进行测量时得到不同测量结果的可能性，而是在给定观测结果后，设法确定这个物理量的真实值。

我着重强调了这两类问题的区别，因为这一点非常重要。这个区别定义了概率和统计这两个学科之间最根本的不同：前者关心的是根据确定概率进行预测，而后者考虑的是根据观测数据计算那些概率。

2『概率和统计的根本区别。概率是根据确定概率进行预测，统计是根据观测数据计算那些概率。连接「概率」和「统计」的桥梁是正态分布，这个信息目前没弄明白。做一张主题卡片。（2021-02-20）』

拉普拉斯阐明的就是后一类问题。他并不知道贝叶斯理论的存在，因此为了解决后面这类问题，他只能亲自动手重建这个理论。他的理论框架中所考虑的问题如下：给定一系列观测值后，被观测量的真实值的最佳估计是多少？这个最佳估计落在真实值「附近」（不管我们对这个附近的定义如何苛刻）的机会有多大？

拉普拉斯的研究工作开始于 1774 年的一篇论文，但这项研究持续了 40 多年。尽管拉普拉斯才智超群，而且有时也相当慷慨，但他也时不时借用他人的成果，却没有对他人的成果表示任何的认可或致谢。拉普拉斯对于自吹自擂也是乐此不疲的。最重要的是，拉普拉斯还是根墙头草，他总是根据政治风向确定自己的政治立场。正是由于这种性格，他才得以不间断地钻研自己的研究课题，几乎没有被当时动荡的时局干扰。在法国大革命前，拉普拉斯获得了一个油水颇丰的皇家炮兵考官的职位。在这个职位上，他幸运地主持了一个名叫拿破仑·波拿巴的前途光明的 16 岁考生的考试。1789 年法国大革命开始后，他曾在短期内被怀疑是个反革命分子。但和很多人不同的是，他毫发无伤，全身而退。他公开表明了「对王权无法磨灭的痛恨」，并从共和国获得了新的荣誉。到 1804 年，当他的老熟人拿破仑自行加冕为帝时，他又立刻放弃了共和主义，并于 1806 年受封伯爵爵位。波旁王朝复辟后，拉普拉斯在他的著作《概率论的解析理论》1814 年版中对拿破仑大加抨击：「对于一个企图统治世界的帝国，精通概率计算的人都能知道它灭亡的概率是非常高的。」而更早一点儿的 1812 年版则被他献给了「伟大的拿破仑皇帝」。

拉普拉斯的政治灵活性对数学的发展而言是件幸事，因为他的研究最终带来了比贝叶斯的成果更为丰富和完整的理论。有了拉普拉斯打下的基础，我们将在下一章离开概率论的领域，进入统计学的地盘。将两者联系在一起的，就是所有数学和科学学科中最重要的曲线之一 —— 钟形曲线，它又被称为正态分布。这条曲线，以及随之而来的新的测量理论，构成了下一章的主题。