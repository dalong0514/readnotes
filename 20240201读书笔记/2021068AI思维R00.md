## 记忆时间

## 卡片

### 0101. 主题卡 —— AI 思维

信息摘自「2021068AI思维0000.md」：

我与丁磊博士在人工智能领域有颇多的交流，我们都认为人工智能不应该是浮于表面的概念。人工智能具有深刻的内涵，值得我们静下心来研究，也值得生活中的每个人去理解。人人都能学 AI，人人都能懂 AI，AI 也能为人人所用。丁磊博士在人工智能领域工作近 20 年，总结出了一套颇具特色的人工智能知识体系和思维方式 ——「AI 思维」。AI 思维是一种通过数据驱动决策的思维模式，包括数据、模型、算力和业务模式四要素。从数据出发，通过模型和算力形成决策，最终在业务中产生价值。因此，AI 思维的基础在于数据，核心在于模型，实现在于算力，应用在于业务模式。从这种意义上说，本书深入浅出，从「道」「法」「术」「器」「用」「势」几个方面循序渐进地向读者介绍了从数据中创造价值的「炼金术」。

2『 AI 思维是一种通过数据驱动决策的思维模式，包括数据、模型、算力和业务模式四要素。AI 思维，做一张主题卡片。（2021-02-20）』——已完成

毋庸置疑，人脑和人工智能在处理信息上存在相似之处，我们对事物的认识可以分为四个阶段：信息、经验、规律和思维。这是一个动态的过程，从单个信息的联系中形成经验，在经验中发现规律，再提炼升华出思维。思维阶段，也是方法论层次的总结，进一步指导实践，不断找出更多的规律和结论。人工智能的底层逻辑就是数学规律，万丈高楼平地起，从底层逻辑中衍生出人工智能的知识体系。人工智能落地意味着从数据中产生价值，在这个过程中人工智能既是方法和工具，也是思维逻辑，可以指导行业的应用和发展。

未来的时代一定是智能化的时代，人工智能作为各个行业的风口，也必然会成为未来社会的发展趋势。《AI 思维》总结了人工智能落地实践的全过程，并且具有优化各种业务的突出价值。而对于个人来说，AI 思维可以帮助我们更深入地理解我们所处的时代，把握时代的机遇和发展方向，最终帮助我们更好地生活和工作。这是人工智能的使命，也是我们理解人工智能的意义。

我们要改变原有的认知方式，如果单靠知识填充，难以达到质的改变，需要转换思维模式。我一直相信，万事万物皆有规律，只有快速把握规律，才能理性认识存在，提升思维能力，抓住时代脉搏。当然，数字世界也不例外，数据之中也有规律性。在利用人工智能（AI）发现和挖掘数据规律与价值的实践中，我认识到人工智能不仅是一种技术方法，其中蕴含了一种思维逻辑，也就是 AI 思维，这才是人工智能的真正精髓，它集中体现在对数据理解方面的优势，能够帮助我们突破认知局限，从而找到自身的真正优势，获得展现个体主动策略优势的收益。

2『上面的信息补充进主题卡片「AI 思维」里去。（2021-02-20）』——已完成

提到人工智能，大众的认知普遍是无人驾驶、视觉识别、语音识别或者是像 AlphaGo（阿尔法围棋）那样的机器人等，但其实这些只是人工智能的具体应用，只是人工智能的冰山一角，却在很多人心中成了人工智能的代名词，这说明目前对人工智能的认识还有局限性。运用于商业各个领域以及工业生产、日常生活中的人工智能是有共通之处的，可以从「器」的层面总结升华出「道」，即一套特有的思维模式 ——AI 思维。人工智能不仅仅是一种先进技术，其核心意义是一种分析数据的思维模式。深受我的合作导师、计算机视觉之父黄煦涛等几位学术大师的影响，我深信一切现象和对应的数据必有规律性，而 AI 思维就是发现和发掘这种规律性的强大工具。

2『这里的信息补充进主题卡片「AI 思维」里去。（2021-02-20）』——已完成

AI 思维，简单来说就是从大量数据中形成模型，进而对未知情况做出最佳预测的思维模式。这样的预测无论对个人、组织还是社会整体，都有积极的意义，能够避免经验主义带来的主观、片面的判断。AI 思维的基础在于数据，核心在于模型，实现在于算力，应用在于业务模式。AI 思维与大数据相伴相生，恰如炼油的过程，大数据是原油，AI 思维则是从原油中提炼产品产生价值的「炼金术」。

AI 思维也是对现有科学体系进行「数据驱动」升级的方法论。人工智能给社会带来的价值远不只哗众取宠的「黑科技」，也不只是给人们带来便捷或者帮助企业重塑商业模式，它最终能够关乎民生的方方面面。无论是在零售还是金融行业，抑或是在医疗和教育领域，通过 AI 思维你都能更快速、更直接、更准确地预测个体的行为或表现结果，从而既能满足行业发展本身的需求，又能在实践中创造出前所未有的价值，将先进的经验和知识惠及所有人。想象一下，通过人工智能，所有的病人可以获得全球最优秀医生的诊断和治疗，所有的孩子可以获得全球最先进的教育方法的培养，我们生活的世界将会变得怎么样？「千百支蜡烛可以被一支蜡烛点燃，而那支蜡烛的生命不会因此缩短。」在人工智能时代，每个人的数据都可以转化为知识，帮助别人并由此受益。

我阅读过很多面向大众的人工智能方面的书籍，其中讲述「器」和「用」的居多，很少涉及「道、法、术」层面。而且，「器」的介绍较容易变成「动物园」模式，仅仅介绍了人工智能算法，没有总结上升到理论和法则的高度，而「用」层面的案例也主要集中在智能机器人和无人驾驶汽车等吸引眼球的领域，缺乏必要的系统化行业落地框架和实践。这也难怪读者很容易将人工智能误认为是明天的科技，或将人工智能局限地认定在几个特定的领域。在这样的理解下，很难把握人工智能的思想精髓，人工智能对个人和社会的潜在影响也大打折扣。所以，本书试图打破这种局限，分为八章，精心设计「道、法、术、器、用、势」体系，旨在避免上述的问题，既包括 AI 思维的方法论，也包括 AI 思维在行业中的应用和发展，帮助读者从宏观到微观、从理论到实践，一步步、一层层地通过系统性框架，逐渐脱下人工智能神秘的外衣，帮助读者理解 AI 思维的实质以及对每个人的价值和意义。这是我创作本书的初心，但也深知长路漫漫，任重道远。

具体来说，本书第一章从「道」的层面阐述 AI 思维内在逻辑和价值，用 AI 思维来思考问题；第二章从「法」的层面介绍 AI 思维的底层逻辑，从规律的角度了解 AI 思维；第三章从「术」的层面讲解 AI 炼金术如何通过数据驱动决策，形成一套从数据到价值的完整方法论；第四章从「器」的层面引入人工智能落地所涉及的方法和模型，模型在 AI 思维中具有核心位置；第五、六、七章从「用」的层面分别介绍数字化赋能、人工智能平台化思维和人工智能实战案例；第八章从「势」的层面介绍人工智能落地过程中存在的挑战和相应的对策，期待人工智能未来的发展。

本书的章节分别从不同角度逐一阐述 AI 思维的价值和意义，大部分内容都以「数据 + 人工智能 + 场景 = 价值」作为核心逻辑，希望任何一个不想在新经济中落伍的人，在阅读本书之后，都能理解 AI 思维，并对工作和生活有所助益。

信息摘自「2021068AI思维0101.md」：

要从质的层面去做认知提升，不仅要提升认知能力，还应该转化思维模式。而我们要谈的 AI 思维，是一种时代前沿的思维模式，也许能够为你提供一种新的路径。AI 思维可以在一定程度上解决我们的认知局限性的问题，帮助我们进行认知升级。它不同于目前很多人对人工智能的认知，他们眼中的人工智能等同于机器人、无人驾驶、人脸识别或者语音识别等，但这只是人工智能的具体应用，只是人工智能的冰山一角。我们要阐述的是 AI 思维，可以说是人工智能的真正精髓，是人工智能冰山的内核，它能够帮助我们找到自身真正的优势，获得真正展现我们个体主动策略优势的超额收益，从而使我们的生活和事业蒸蒸日上。

2『上面的信息补充进主题卡片「AI 思维」里去。（2021-02-20）』——已完成

如前所述，过往的经验确实能帮助我们做决策，尤其当我们不得不基于模糊的信息进行判断时，经验能发挥巨大的作用。然而，在信息爆炸、算法决策高度发达的今天，光靠以往经验做判断、做决策的思维模式已经显现出弊端，掌握着大量数据和科学决策工具的人，早已成为你前面的领跑者。落后于时代的思维，带来的是慢于时代发展的速度，其产生的收益必定比他人低，而且会越来越低。

本质上，人工智能模拟的是人脑，但又不同于人脑。AI 思维是从数据产生模型，如果遇到新的输入，人工智能就能通过模型做出准确的预测。AI 思维与人脑思维的相似点在于，AI 思维也是通过对过往的分析习得规律，得出结论，但是 AI 思维分析过往数据的过程是不同的。

那么数据是什么？数据是人类经验的数字化形式。如图 1-2 所示，就像人从经验中获得规律一样，人工智能能够根据数据形成模型。一旦遇到新场景的输入，模型就能做出判断、产生预测。人工智能的这种思维能够充分利用数据，尽量减少主观臆断，以我们想达到的目标为中心，挖掘规律，形成模型，运用模型，产生预测。人工智能就好比一个可预知未来的水晶球，掌握了 AI 思维，你就可以做出科学意义上最佳的决策，产出前所未有的收益。

2『上面的信息补充进主题卡片「AI 思维」里去。（2021-02-20）』——已完成

就像过去的互联网思维一样，在互联网出现之前，一个人只能与周围的几十个人产生联系，而有了互联网之后，与世界各地任何人、无数人产生联系成为可能。而人工智能出现之前，人只能借助过往经验或者周遭环境等有限的信息做出判断；而借助人工智能，人们能够发现和挖掘无数的相关信息和数据来做预测和决策，而做出最优决策也是 AI 思维的一大特点。从广义上来看，人工智能具有感知、认知和决策的能力。决策就是通过上述模式而产生的，比如在股市中，人工智能可以根据历史数据生成模型，然后来指导股市决策。人工智能的感知和认知功能包括感知图像、理解语言、识别语义信息等，它的逻辑和股市决策是一样的，也是一种预测，只是预测的目标不一样。例如，人工智能在进行人脸识别时，也是根据许多人脸数据生成模型，然后遇到一个新的人脸数据，这个模型就能判断出它是否是特定的那个人脸。

在商业世界里有一个名词阿尔法（alpha）收益。经常买基金的朋友应该都知道，阿尔法收益是相对于贝塔（beta）收益而言的，贝塔收益是一种基准收益，而阿尔法收益是在贝塔收益期望之上的超额收益，是积极操作所带来的投资回报。就好比我们理财一样，央行的基准活期年利率是 0.35%，就是说我们有 1 万元放在银行存活期，一年可以赚到 35 元，而央行年利率提高 0.1%，我们就多赚 10 元钱，这个就类似于贝塔收益。但是我们用这 1 万元钱去买余额宝、理财通、股票，投资房产，可能收益翻倍，这个多出来的收益，就是我们积极操作所带来的阿尔法收益。1% 的阿尔法就意味着比市场带来的投资回报多了 1%。毋庸置疑，无论在哪个市场，你都希望能跑赢它，都希望能找到属于自己的正向阿尔法。AI 思维的作用就在于它能带着你的认知更上一层楼，赋予你跑赢大盘、产生高阿尔法的能力。

### 0102. 主题卡 —— AI 思维的要素

信息摘自「2021068AI思维0101.md」：

人工智能早在 1956 年美国的达特茅斯会议上就被提出，但直到 2016 年，才开始被大众熟知，近几年才开始被普遍运用在社会生活中的各行各业。这是为什么呢？原因在于，以前很多人工智能所必需的要素还没有发展起来。随着互联网的普及，人们对于人工智能的研究更加深入，这几年这些要素有了突飞猛进的发展。那么，AI 思维得以实现，需要依赖于哪些要素呢？

2『 AI 思维的要素，做一张主题卡片。（2021-02-20）』——已完成

第一个要素就是大数据。

我们处在一个数据井喷的年代，无论是企业业务环节产生的数据，还是个人移动设备里面的数据，信息量都非常大，并且这个数据量在近几年呈爆炸式增长。如图 1-3 所示，根据智研咨询发布的《2017-2023 年中国大数据应用行业市场全景调查及未来前景预测研究报告》，全球数据总量的年增长率将维持在 50% 左右；并预测，到 2020 年，全球的数据总量将达到 40ZB（1ZB = 1 万亿 GB）。我们想想 20 年以前，个人计算机里面的数据可能只有区区几十兆，而现在的数据都是以 TB 或者 PB 作为单位的数量级。我们知道 AI 思维建立在对数据学习的基础上，数据越多，人工智能学会的东西越多，人工智能做出的判断决策就越准确，越具有实用性。所以说，大数据的形成是 AI 思维的一个要素。

第二个要素是模型。

我们的大脑由许多神经网络连接而成，每天能帮助我们做各种各样的决策。早期的人工智能模型包括人工神经网络，它本质上是对大脑，也就是我们自有神经网络的模拟。这种模型在 20 世纪 80 年代就已经被发明出来了，它能够帮助我们从数据中提炼出知识。而今我们在人工神经网络的基础上有了更深的研究，产生了一系列的深度学习模型，其实可以把深度学习模型理解为传统的神经网络模型的加强版。一般的人工智能模型随着数据量的增加，预测效果会提升，但很快达到瓶颈。而深度学习的预测效果随着数据量的增加，会持续提升。

深度学习强大的学习能力决定了它能够更好地模拟人类大脑的运算机制，它最擅长的是理解和识别图像、视频、声音、文本这样的数据。通过对图像进行深度学习，它实现了人脸识别，比如支付宝刷脸支付；通过对声音的深度学习，实现了音频自动转换为文字，比如讯飞听见能够一键录音转文字；通过对文本的深度学习，人工智能已经能够独立创作，比如微软的人工智能机器人小冰出版了原创诗集《阳光失了玻璃窗》。

深度学习不但能为人工智能提供技术支撑，其发展也为人工智能在各个领域的应用提供了无限的可能。ImageNet 是计算机视觉领域很著名的一个图像识别竞赛，是该领域的「奥赛」。很多专家、学者都会参与，微软、谷歌、百度等科技公司也是该比赛中的佼佼者。在 ImageNet 竞赛中，随着深度学习的发展，图像识别能力有了很大的提升，从 2010 年到 2015 年这 5 年间，错误率从 30% 左右缩减到 5%。5% 的错误率已经基本上匹配了人对图像识别的错误率，这促进了人工智能在更为广阔的图像识别领域的应用。除了图像识别以外，语音识别的发展也依赖于深度学习。20 世纪 50 年代，第一个语音识别系统 Andry 只能够识别 10 个英文数字；而现在，深度学习助力语音识别，应用于市场上的语音识别系统对普通话的识别准确率高达 95%，百度、搜狗、讯飞的语音识别的错误率维持在 3%，比人类识别语音 5.7% 的错误率更低，这为人工智能在语音识别的各个领域展开布局提供了强有力的支持。所以说，深度学习的不断发展也促进了人工智能应用的不断普及。

第三个要素是算力。

AI 思维的实现需要很强的计算能力的支撑。我们想到计算能力，首先想到的可能是电脑、手机等智能设备，它们能提供一部分算力。对我们做人工智能来说，这样的算力是不够的。我们需要一个大规模的计算机集群，需要成百台上千台计算机连接在一起，进行大规模的运算。谷歌 X 实验室推出的谷歌大脑就是将 16 000 台计算机的处理器连接在一起，这样强大的算力使其具有强大的自主学习能力，成为全球最大的人工智能大脑之一。

除了计算机集群，算力还需要 GPU 的架构。GPU 全称是 Graphics Processing Unit，就是我们常说的图形处理器，是一种专门在电脑和移动设备上进行图像运算工作的微处理器。与之相对应的是 CPU，即中央处理器，其功能主要是解释计算机指令以及处理计算机软件中的数据。GPU 的架构有别于传统 CPU 的架构，能够很好地支持深度学习模型的运算。你可能对 GPU 这个名称很陌生，其实你可能早已接触过它。如果你是一名电子游戏爱好者，不管你玩王者荣耀还是和平精英，都需要 GPU 的支持来实现游戏中人物的移动及其他图像变换。GPU 现在已经发展到了第四代，它提供的强大算力能够支撑人工智能的开展以及落地。

强大算力的加持，使人工智能有了更为广阔的发展空间。例如，2019 年 8 月，人类在强大算力的支持下首次成功重建了果蝇大脑神经元的 3D 模型。果蝇一直以来都是生物学领域公认的研究动物，但为什么一直到 2019 年才建出第一个果蝇大脑神经元的 3D 模型呢？因为果蝇的大脑有 10 万多个神经元，要想建立一个完整的 3D 模型，需要强大的算力支持，而这个条件是先前并不具备的。2019 年，在谷歌、剑桥大学以及霍华德·修斯医学研究所的合作下，研究人员将果蝇的大脑切割成 7 042 个 40 纳米的超薄切片，并用透射电子显微镜生成切片的图像。这些图像像素高达 40 万亿以上，数量共计 2 100 万张。数千块谷歌开发的深度学习加速芯片 Cloud TPU（Tensor Processing Unit）为这些图片数据的处理提供了算力，最终才生成了人类历史上第一个果蝇大脑神经元的 3D 模型。

第四个要素是业务模式。

我们知道，人工智能要落地，必须在一个场景中去实践它。例如，在金融领域，传统上我们的银行机构只对征信良好的用户发放贷款，而征信记录不良的用户就得不到相应的贷款服务。单纯使用人力去判断一个用户的信用是件费时费力的事情，工作效率极其低下。但通过人工智能，我们能在很短的时间内对用户的信用状况进行分析和判断，决定是否向其提供贷款服务。这样不但减轻了银行工作人员的工作负担，还提高了工作效率。基于人工智能迅速准确且不知疲倦的特点，它还能为更多更大的用户人群提供贷款服务，扩大业务范围。基于这些人的大数据，通过人工智能模型和算力，还能对用户的信用状况进行分级，不但能够判断是否提供贷款，还能判断向这个用户提供多少金额最合适。人工智能为金融机构的工作提供了参考依据，这就是一种基于人工智能的业务模式。实际上，这样的商业模式，把传统的银行和金融机构的业务模式推广到了更大的用户群，帮助我们实现了普惠金融的理想。当然，除此之外，人工智能还能运用在更多的领域，还有更多的创新业务模式。正是因为有了这些创新业务模式，人工智能才能顺利地在各行各业落地，帮助企业产出价值。

如前所述，AI 思维的基础在于数据，而核心在于模型，实现在于算力，应用在于业务模式。只有大数据、模型、算力、业务模式这四个要素同时存在，并行发展，人工智能的价值才能得以体现，AI 思维才算完整。这是从具体要素角度对 AI 思维的阐述，下面我们从认识论的角度展开对 AI 思维价值的理解。

### 0103. 主题卡 —— AI 思维带来的三个价值

信息摘自「2021068AI思维0101.md」：

在当代，数据是一种重要资产。数据反映了事物的原理和规律，当你找到它的规律后，就可以去预测未来的事情。如果将数据比作原油，那么人工智能就是从原油中提炼各种高价值产品的加工厂，它的重要性可见一斑。从数据中发现知识、洞察和规律，这本身不是一个新的概念，几百年前就有过这样的实践 —— 譬如说，开普勒从几百页关于天体位置的数据中，提炼并总结出了天体运动的三定律，至今仍被使用。现在，在 AI 思维的帮助下，我们借助大规模计算的方法，从海量的数据中自动地学习知识和规律。那么，从实际应用的角度出发，作为一个数据驱动的决策框架，AI 思维都带来了哪些价值？

2『 AI 思维带来的三个价值，做一张主题卡片。（2021-02-20）』——已完成

首先，数据驱动的人工智能框架可以带来个性化的体验。人工智能可以根据用户的历史浏览记录、成交记录对用户的喜好建立模型，得出各商品或内容和用户喜好的相近程度，并把相近程度排行最高的商品或内容推荐给用户。例如，当我们进入一些购物网站，可能会发现许多这样个性化的体验，若你之前购买过衣服，它可能会给你推荐其他的搭配商品，若你之前购买过图书，它可能会给你推送同类型书单。数据驱动下的人工智能框架带来的个性化体验让网站不再千篇一律，网站给出的每一条推荐都是根据用户需求调整和优化后得出的，真正实现了千人千面的精准体验。对于用户来说，这样省去了他们检索的时间，还更加符合他们的需求，带来了更好的用户体验，对于网站来说，这样可以提高网站的浏览量、点击率，还能提高商品的销量。此外，人工智能带来的这种个性化体验也能为我们的生活提供更多的便利，带来更多的幸福感，例如现在的智能家居系统，可以提供自动控温等贴心服务，提升了家居的安全性、便利性、舒适性，并且环保节能，让你感觉到这就是最适合你的，为你量身定做的家。

其次，数据驱动的人工智能框架可以带来细粒度的行业策略。行业策略细粒度意味着企业的经营会更加精细化。例如，企业可以把一个产品的目标客户群简单地划分为一定年龄范围的男性或女性，但这样的客户群划分显然没有针对性。利用数据驱动的人工智能框架进行目标客户群划分，得到的结果更加详细，比如我们不仅可以考虑基于年龄、性别这样的因素，还可以交叉考虑包含更多维度，例如兴趣爱好、行为习惯等的目标客户群，从而得到细粒度的营销策略。以视频软件芒果 TV 为例，为了提高视频的点击率，芒果 TV 运用人工智能来判断向用户推送视频的类型和内容。比如，追求放松娱乐的白领一族会收到《快乐大本营》的相关推送，喜爱烧脑解密的年轻人群会看到《明星大侦探》的相关广告。而随着用户观看视频数量的上升，人工智能的推送方案也会更加个性化，细化到满足每一个用户的需求。与传统方式相比，人工智能提供的细粒度视频推送方案为芒果 TV 提高了 30% 的点击率，真正实现了精细化运营。

最后，数据驱动的人工智能框架可以带来知识和洞察。我们去学校或者从经验中可以学习到知识，而数据驱动的人工智能框架可以赋予我们持续高效地从数据中学习知识、挖掘洞察的能力。这些知识和洞察可能不是列在教科书上的条条框框，但却一定是从数据中实时地、最大体量同时也是最有效获取的，并能够运用于业务实践中。例如美国哈佛大学地球与行星科学系的布伦丹·米德（Brendan Meade）教授团队通过深度学习分析了来自世界各地的地震数据集，发现了余震发生的规律，在此基础上开发了一套能够预测余震的智能系统。这套系统为避免余震二次伤害，顺利进行灾后救援和恢复工作提供了很大的帮助。

AI 思维不是捷径，但它却可以帮你更加快速地抓住事情的本质，找出用户的需求，洞察世事的发展，进行准确的预测，产出更大的价值。这是科学探索的目标动力，也是人类实践的追求所在。

著名的科技思想家凯文·凯利（Kevin Kelly）说人工智能是认知化。如果说电力化带来了人工的动力，那么认知化带来了人工的智能。大量的实践表明，在感知方面，包括视觉、听觉、语言理解等，人工智能可以接近人脑。前文已经提到过，现在的图像识别错误率已经控制在 5%，基本和人脑识别错误率持平；在专业决策方面，在海量数据的支持下，人工智能甚至可以超越人脑。例如，在金融风控领域，通过人工智能输出模型的 KS 值（通常用来衡量风险识别有效性的一个指标），可以做到 40-50% 甚至更高，有效地控制住风险。基于人工智能的快速信贷审批，效果可以超越传统的人工方法。在传统出版业，一个编辑编辑一本书至少需要一个月的时间，但全球最大的中文期刊网龙源期刊开发了一个人工智能编辑平台「知识树」，它是一个能够根据定义内容自动编辑图书的智能系统，可以在一天之内完成一本图书的编辑工作，极大地提高了图书编辑工作的效率，缩短了图书出版的周期。

AI 思维是一种「数据驱动决策」的思维，它不怂恿你去追逐虚无缥缈的白日梦，而是教你学会用数据筹码四两拨千斤。不论你研究的是什么领域，从事的是什么职业，通过 AI 思维，你都能从数据中理出头绪，更加快速、直接、准确地预测出研究对象的行为或者结果。绳锯木断，水滴石穿，掌握了以小博大的 AI 思维，你不但是一个梦想家，也能成为一个真正创造价值的实干家。

### 0104. 主题卡 —— 模型的泛化能力

信息摘自「2021068AI思维0201.md」：

一个模型能带来多大的价值，取决于模型预测的准确率有多高。而模型预测的准确率又依赖于模型的泛化能力（generalization ability）。也就是说，在一定程度上，模型的泛化能力决定了一个模型最终能迸发出多大的能量。那么泛化能力到底是什么呢？

2『模型的泛化能力，做一张主题卡片。（2021-02-21）』——已完成

泛化能力是用来描述模型对新样本的预测能力的。我们在日常生活中也称之为举一反三或学以致用的能力。机器学习的目的是学到隐含在数据背后的规律，对具有同一规律、训练集以外的数据，模型也能给出合适的预测。这就是泛化能力的表现。

泛化能力体现了模型智能水平的高低，如果一个模型只在训练数据上能准确地分类，作用是很小的，因为这充其量是模型「记住」了各种输入和对应的类别，在新的场景中没有办法做出准确预测。

在进一步讲泛化之前，我想先讲一个故事。我有一对情侣朋友，女生是一个中国姑娘，叫郭霓禾，男生是英国人，叫安德费汀。郭霓禾是一个牙科医生，她诊病的程序十分烦琐，一个简单的牙疼，她会给病人量体温、测视力、检查血压，有时甚至还要检查心电图，除此之外，她还会询问病人一些无关的信息，比如身高、体重以及最近吃过什么。她饱读各种医学类书籍，还研究过各种偏方，最后再结合她的临床经验，总结出一些独特的治病规律。如果一个新的病人的所有指标符合她总结出来的规律，她才能判断这个人的患病情况，如果情况不符合，她就无法做出判断。比如有一次一个病人牙疼，经过检查和询问，她发现这个病人体温 37℃，视力 0.8，身高 1.7 米，体重 70 千克，是在吃了西红柿之后智齿开始发炎。于是她就总结出一个体温 37℃、视力 0.8、身高 1.7 米、体重 70 千克的人会在吃了西红柿之后引发智齿发炎的规律。刚刚好，安德费汀也符合这几个条件，有一次安德费汀智齿也发炎了，但因为安德费汀没有吃西红柿，郭霓禾认为他不符合自己总结出的规律，诊断安德费汀的牙疼不是因为智齿发炎引起的。而安德费汀是一个股票投资分析师，对于自己的经验和能力十分自信，他认为凭借自己的经验，只需要看一下股票的走势，就可以判断一只股票到底是应该买入还是卖出。他根本不考虑政策、大盘环境、主力资金进出等变化因素，每天只看一下电脑屏幕上股票的涨跌状况就做决定。这样的判断显然十分不科学，导致了他的大部分积蓄都被套牢在股市。

郭霓禾和安德费汀两个人都各有特点。郭霓禾对待事情很认真，看事情很全面，但是由于她顾及的事情太多太细，有时可能会过度重视一些无关紧要的特质，总结出一些没有作用的规律，比如那些奇怪的指标与智齿发炎其实并没有关系，只是那个病人刚好在智齿发炎前是那样的身体状态，刚好吃了西红柿，这样过度关注无关因素反而妨碍了病因的评估。安德费汀则正好相反，他看事情太片面，没有综合考虑影响股市涨跌的因素，导致他的判断和股市的实际情况产生了很大的偏差，成为被迫割肉那一批人。

故事讲完了，我想告诉你，郭霓禾和安德费汀其实都是我虚构的朋友，他们的名字其实就是过拟合（overfitting）与欠拟合（underfitting）的谐音。过拟合和欠拟合是两类统计学现象，有这两种现象的模型，不具备良好的泛化能力。

在统计模型中，由于模型太过复杂而拟合了训练样本中的噪声，以至于输出的结果与真实值相差很大，就像郭霓禾诊断病人一样，这就是过拟合。欠拟合则刚好相反，是由于模型过于简单，以至于得到的模型难以拟合训练数据，就像安德费汀没有考虑到影响股市的其他因素，而导致判断错误。

我们总是希望在机器学习训练时，机器学习模型能在新样本上有很好的表现。过拟合时，模型过于复杂，把训练样本学得过分好了，就很可能把一些训练样本自身的特性当成所有潜在样本的共性。这样一来，模型的泛化性能就下降了。欠拟合时，模型又过于简单，无法很好地学到训练样本的一般性质，所以不论在训练数据还是预测数据中，表现都很差。

过拟合就是过多学习了一些不必要的数据特征。比如你的模型需要区分男人和女人，模型学习了训练样本中所有男人和女人的特征。如果训练样本中的女人刚好都穿了红色的衣服，过拟合的模型就可能会把穿红色衣服作为区分男人和女人的一个特征。我们都知道，穿什么颜色的衣服并不能作为区分人的一个特征，这时模型学习的这个特征就属于过度学习。过度学习不仅毫无作用，甚至还会对模型的预测结果产生误导，比如出现了一个新的预测样本，是一个穿红色衣服的男人，模型很有可能会根据他穿了红色衣服这个特征就把他识别为女人。

欠拟合与过拟合正好相反，它对于训练样本的特征学习得不够充分，导致训练出来的模型不能很好地进行预测。而且，由于欠拟合的模型没能很好地捕捉到数据特征，它不但不能对新的样本数据进行预测，在训练集中的样本数据时表现也不是很好。比如你要参加一场考试，考试前做了许多模拟题，发现有一些知识点你还不明白，在模拟题中你有部分题目做不出来，这就是没有很好地掌握训练样本的规律。当你要对新样本进行预测时，也就是当你去参加这场考试时，考试结果也不会很好。不论是过拟合还是欠拟合，都会使模型不能很好地输出预测结果，所以，在机器学习中，这两种现象都是需要极力避免的。

图 2-2 形象地展示了拟合的几种情况。我们有一些数据样本，大致呈二次函数形式，可以看出，用二次函数来做拟合最合适的是图 2-2 中间的图像。但是如果我们不采用二次函数呢？比如，我们用线性的函数来拟合它，我们可以得到如图 2-2 中左图的直线，这显然没有很好地拟合训练样本数据，更不用说预测数据了。我们用高次函数来拟合，可能会得到如图 2-2 右图那样的曲线，显然，这并不是我们想要的模型，它把个别数据的偶然偏离也当成了共性，而过度拟合了进去。

1-3『过度拟合：把个别数据的偶然偏离当作共性。想到了「随机性」无处不在，那个数据里的随机性不是规律，应该剔除掉。（2021-02-21）』

图 2-2 函数拟合示意图

通常，解决欠拟合的方法包括：1）增加新特征，也可以考虑加入特征各种形式的组合，来增大模型可操作的空间；2）尝试非线性模型，比如非线性支持向量机（SVM）、决策树、深度神经网络（DNN）等模型。

解决过拟合的方法包括：1）交叉检验，即拿出大部分样本进行模型训练，留小部分样本用模型进行预测，并通过调节这小部分样本上的预测误差来得到较优的模型参数；2）特征选择，从已有特征中选择部分特征以减少模型所用特征数；3）正则化，即为原始模型引入额外信息来限制模型的复杂度；4）增加训练数据在一定程度上可以避免过拟合。

真正的泛化能力需要回避过拟合和欠拟合，一个好的模型必须真正把握数据的底层规律，既不比数据本身复杂，也不比数据本身简单。人工智能行业的趋势是要用越来越复杂的模型来尝试做出更好的泛化效果，这需要我们更加谨慎地看待：如果训练数据量不够多，或者并不支持复杂的模型假设，那么，很有可能我们只是在过拟合，而不是在产出优质可泛化的模型。什么样的模型既不过拟合，也不欠拟合，是运用 AI 思维时需要考虑的核心问题。

### 0105. 主题卡 —— 相关性大于因果性

信息摘自「2021068AI思维0201.md」：

在日常工作生活中，我们更需要关注相关性，而不是强求因果关系，也就是说，只需要知道「是什么」，而不总是需要知道「为什么」。这能使人跳过洼地，快速地获取结果。这种思维方式推翻了自古以来人们更加注重因果关系的惯例，使我们理解现实和做出决定的最基本方式受到挑战。但是不破不立，破而后立，相关性的思维方式也让一切事物变得看起来很简单。AI 思维从数据中训练出模型，但它从不思考为什么这样做，这让模型训练变得简单直接，体现出相关性思维的特点。

从传统的因果性思维转向相关性思维是 AI 思维最突出的一个特点，传统的因果性思维是说我们一定要找到一个原因，推出一个结果来。而基于 AI 思维的预测没有必要找到原因，不需要证明这个事件和那个事件之间有一个必然、先后关联发生的因果规律。在相关性思维中，如果出现了某些迹象，数据统计的高概率会显示出相应的结果。那么，当我们发现这些迹象时，需要做的就是根据这些迹象去预测结果，做出决策。这和以前的思维方式不一样，和传统科学的思维不一样。虽然同样基于数据，但是传统科学要求找到准确的因果关系。

但是，在这个纷乱复杂的社会关系里面，充满了差异性，不同的人在不同的时间节点可能会为了不同的原因去做一件同样的事情。比如，有的人觉得紫外线太强怕被晒黑，有的人觉得阳光刺眼，有的人觉得雨季要到了，这时他们都可能会买一把伞。不论中间的思考过程有多曲折，各自的理解如何大相径庭，他们最终都指向同一个结果。其实，我们在很多时候，最终为的也不过是这个结果罢了，所以在这期间耗费过多的精力去寻找里面的因果关系并非那么必要，毕竟在这个节奏如此快的社会，等你从头到尾都想得一清二楚的时候，这个事情可能早就不值得办了。

所以人工智能时代的思维更像「action!」（行动指令）、「reaction!」（立刻反应）这样一种直线思维。也就是说，你听到或者看到一个明显的指令或者迹象，你不需要去追究太多，只需要按惯例做出反应就可以。只要我发出这个口令，就一定能够得到一个既定的、预期内的回应，这就可以了。就像在运送快递时，如果有玻璃制品这样易碎的物品，快递盒子外面一般会有「易碎物品，小心轻放」的提示。看到这个提示，快递员不需要知道盒子里面是什么物品，也不需要知道它为什么易碎，他只需要在送快递过程中做到小心轻放，不让盒子中的物品破碎就可以了。

全世界的商界人士都在高呼人工智能时代来临的优势：早在很久以前，商家就明白了相关性销售的精髓。比如，商家很容易根据你买东西的数量知道你家有多少人吃饭，你是单身还是一大家子。将牛肉干等一些简便的下酒食品与各种酒品摆在一起，也能很大程度地提升销售业绩，因为很多时候这些关联是更契合人性的。比如，你只喝酒，难免肠胃寡淡，根据人体自然需求，会需要同时补充一些重口味的小吃。喝酒就是为了爽快，谁会为了几块钱的小吃而折损了喝酒的享受呢？抓住了这些关联也就抓住了人性，从而能实现高销售。数据透露出来的信息有时确实能起到出人意料的效果。比如，下雨或者高温暴晒的时候，往往订外卖的人数会激增，这时候在办公区附近的餐馆都会提前做好「备战模式」，例如提前预备好外卖餐盒、准备好外卖常点的菜品，这些老板不需要去考虑究竟是因为下雨、暴晒的时候大家觉得出门麻烦而选择订外卖，还是因为这种天气下大家心情不好而选择点外卖，他只需要根据天气变化采取相关行动就可以。

这些例子共同说明了一个道理：用相关性思维方式来思考问题、解决问题的做法值得关注。寻找原因在以前被视为理所当然，但是大数据推翻了这个论断。过去寻找原因的信念正在被更为实用的相关性所取代。随之而来产生了一个值得思考的问题：在探求因果关系转变为注重相关关系的过程中，我们怎样才能既不损坏奠定社会繁荣和人类进步的因果推理基石，又能真正推动社会的进步呢？需要强调的是，转向相关性，并不是要抛弃因果关系这块科学基石，而是通过相关性更加快速直接地解决问题。

在当今这个信息化的时代，只要能够得到充足的数据，加之用高效的 AI 思维寻找到相关性信息，就可以预测用户的行为，为企业做出准确决策提供支撑。比如，金融行业非常注重风险的把控，以往我们识别金融风险最常用的方式就是查看客户的过往征信记录，寻找各种渠道去打探对方的信誉。这个过程不但耗时、费力，还未必能够保证信息全面。

有了人工智能加持之后，金融机构就可以通过数据建立模型，识别出客户相关的异常行为以及异常关系，为金融决策提供广泛、确切的有效信息。在这个领域中，人工智能能够帮助解决金融信用体系中的关键问题。那么人工智能是如何在这个过程中发挥作用的呢？首先需要构建人工智能模型，然后通过模型实现特征分析，进而根据模型的输出判断异常。比如说现在我们要判断是否给某个客户贷款。为了解决这个问题，金融机构就要对该客户以往的行为进行分析。如果金融机构通过人工智能分析发现，这个客户曾经多次逾期还款，收入不稳定、工作情况变动大，那么这就意味着他不是一个很好的贷款对象，因为财务状况不稳定与出现财务问题之间有很大的相关性，放贷给他可能会影响到钱款的正常收回，导致出现损失。相反，如果客户过往的财务状况稳定，并且有着合理的发展规划，就说明他是一个值得信赖的客户。向这样的客户贷款，风险较低，相对安心。

尽管在过往，这些工作也能通过人工粗略地进行，但是由于细枝末节的信息不计其数，而人力始终是有限的，在这种情况下，人工的分析自然容易出现疏漏。此外，人工耗时长，对于金融这个看重时效性的行业来说，是一个重大的弱点。相比之下，人工智能通过自身的模型学习，能够在短时间内就发现隐患，使得应对决策能够正确有效地实施。所以，在商业社会里，「action!」「reaction!」的行为模式是更为合理，也是适用更广的。细究其中，你会发现，事实上所有事件的处理方式都在遵循相关性原则，无论你把事情考虑得多么周全，仍然可能出现问题；在应急的当下，你也一定是运用了相关性来处理绝大部分问题。而且根据人们使用的情况来说，在生活的方方面面，它都饶有成效。有时候，相关性可能就是人们所说的「下意识」，看到或者听到某些事物，条件反射地设想出下一秒产生的结果，下意识地为这个结果做出反应。

哲学上讲，联系是指一切事物、现象、过程及其内部诸要素之间的相互影响、相互作用和相互制约，也就是说，万物之间都是存在相关性的。也许你没有意识到相关性的存在，但就像你看到打雷就知道要下雨一样，人们无时无刻不在使用着相关性思维。相关性这种通过分析不同事件之间的联系，由起点直接到终点的思维方式，是 AI 思维能够快速准确地进行预测的内在逻辑。物有本末，事有始终，掌握了相关性，你就能事半功倍地得到想要的结果。

2『这一小节的信息感触很大，相关性大于因果性，做一张主题卡片。（2021-02-21）』——已完成

### 0106. 主题卡 —— 大规模商业应用 AI 的两大必要条件

信息摘自「2021068AI思维0701.md」：

在前面的章节，我们讲解了人工智能可以赋能很多行业和领域，但其实并不是所有领域都适合大范围使用人工智能。要满足大规模商业应用人工智能，应具备两个必要条件：第一，数据的数量和质量必须达到一定的要求，尤其是整个流程中数据的打通和定期的数据更新和反馈，这决定了人工智能发展的基础是否牢固。第二，所在领域是否对需要解决的问题有相对清晰的定义。如果领域本身没有明晰的问题定义，或者不能通过数字化的方法描述出来，则很难通过人工智能来解决这类问题。

2『大规模商业应用 AI 的两大必要条件。做一张主题卡片。（2021-02-21）』

从整体来看，金融行业经过多年的发展已经沉淀出大量金融数据，而且金融领域现在需要解决的问题也很明确，营销获客、风险控制和投资顾问等一系列清晰的问题早已浮出水面，由此可见金融行业已经比较接近人工智能大规模商用的两点要求。随着人工智能的发展和在金融领域的不断探索，人工智能现在已经能够赋能金融行业的不同的业务场景，例如智能营销、智能风控、智能投顾和智能投研等，下面会通过具体的案例来展示人工智能对金融业的赋能和提升。

### 0107. 主题卡 —— 机器学习 4 个典型问题

我们获取知识的途径有两种，一种是通过他人的传递，例如我们遇到不会的问题时去请教老师或同学；另一种是在没有接受指导的情况下自学获得的。类似地，机器学习也有两种：监督学习和无监督学习。

监督学习是从标记的数据来学习模型的任务，每个标记的数据都是由一个输入数据（也就是通常所说的 x ）和一个期望的输出数据（也就是通常所说的标记 y ）组成。无监督学习处理的则是没有标记的数据。监督学习适合有明确预测目标的应用场景，即 y 可以被明确地定义和量化。而无监督学习通常适用于无法预先知道输出值的场景，只能对现有输入向量进行观察分析，它可以从数据中发现具有相似输入向量的结构，这些结构统称为簇（cluster）。

机器学习问题根据输出的数据来分，也有两类。一类是离散输出，通常用来表示个体的类别，比如把人分为两类，男人和女人；把客户分两类，高价值客户、低价值客户。数学中的离散是和连续相对的，所以另一类就是连续输出。连续输出的数据是指那些在一定区间内可以任意取值的数据，其数值是连续不断的，相邻的两个数据之间可以做无限的分割。比如说两趟地铁之间的间隔是 10 分钟，一个乘客在地铁站等地铁的时间是一个随机变量，取值范围可以是从 0 到 10 这个区间内的任意实数。所以连续输出有很大的应用空间，比如要预测公司的收入、客户的价值、生产流程的能耗、生产系统输出的气体浓度等，这些都需要用连续数字来表示，就都需要连续的输出。

监督类型分为通过监督学习和无监督学习，是机器学习问题分类的一种依据；输出分为离散型和连续型，是机器学习问题分类的另一种依据。将以上四类排列组合，就形成了四种不同类型的机器学习问题，如表 4-1，分别是：

如果通过监督学习，得到离散输出，就是分类问题。

如果通过无监督学习，得到离散输出，就是聚类问题。

如果通过监督学习，得到连续输出，就是回归问题。

如果通过无监督学习，得到连续输出，就是降维问题。

1-2『丁磊从「有无监督」「输出为离散或连续」这两个维度将机器学习问题划分为 4 大类，这个角度之前从未看到过，有一种醍醐灌顶的感觉，而且两维度划分四个区域这种方法论在其他 N 多领域看到过，很经典很经典。机器学习 4 个典型问题，做一张主题卡片。（2021-02-27）』

表 4–1 机器学习问题的类型

| - | 监督学习 | 无监督学习 |
| --- | --- | --- |
| 离散输出 | 分类问题 | 聚类问题 |
| 连续输出 | 回归问题 | 降维问题 |

这四类问题是机器学习的基本问题，深入理解了这四类问题，我们就能对机器学习有一个完整的把握。无论在哪一类问题中，机器学习的目标都是根据新的输入，做出预测。理解清楚了这四类问题的框架，我们就能深入体会到人工智能解决实际问题的思路。下面我会深入分析两类问题 —— 聚类问题和分类问题，它们也是机器学习中最常使用的两类。

### 0108. 主题卡 —— 分类问题

信息摘自「2021068AI思维0401.md」：

最近邻分类、线性分类、K-近邻分类。

前面以图像为例说明了机器学习分类的过程，下面我们来了解一种基本的分类方法：最近邻分类。这种方法不需要训练环节，只需要针对输入数据的距离定义。

2『分类问题，做一张主题卡片。（2021-02-27）』——已完成

如图 4-4 所示，我们用方形和圆形分别表示两种不同的训练样本，一个新的预测样本会根据离两类训练样本距离最近的数据点，来确定自己的分类。也就是说，如果和预测样本最近的样本是方形样本，我们就把它分类为方形，相反，如果和预测样本最近的样本是圆形样本，我们就把它分类为圆形。

图 4-4 最近邻分类示意图

这个分类过程类似人的思考过程，好比我们对一个不熟悉的物品，一个没去过的地方，一个不认识的人，我们会下意识地把它跟我们接触过的物品、地方、人做对比，用一个我们熟悉的事物的类别作为对这个新事物类别的「预测」。人的思维如此，机器学习也应用了这个原理。

虽然最近邻分类比较简单，但是它在很多实际场景里的应用效果尚能差强人意。有的时候，你可能并不知道要用什么样的模型来分类数据，那我建议你试试最近邻分类，先看看它能产出什么效果。对最近邻分类有了一些了解后，下面我们来介绍更多的分类模型。

在机器学习领域，线性分类是一种经典的分类方法，它的目标是寻找一个线性函数，直观上也就是一条线，来分割两类数据，如图 4-5 所示，在这条线的一边是方块的一类，另一边是圆形的一类，而且这条线与两边的距离要适中。

图 4-5 线性分类示意图

当然，分割线未必只能在纸上，也就是在二维空间里画的线，它也可能是三维空间里的一个平面，又或者是高维空间里的超平面。这个线性函数可以在任意维度的空间里，它取决于机器学习任务中特征向量的维度。例如，我们有 2 000 张花花草草的照片，如图 4-6 所示，每张照片由这个高维空间中的一个点表示。如果要把这两千张照片按花和草来分类，那这个线性函数就是图 4-6 所示的超平面。（因为我们无法看到高维空间里的超平面，所以这里的超平面用平面来表示。）

图 4-6 高维空间线性分类示意图

我们实现线性分类的方法叫作最小二乘法，又称最小平方法。通过最小二乘法可以计算出进行分类的这个线性函数的参数，也就是说可以计算出一条分类的最佳分割线。原理上，这个划分两类的分割线，要能充分「拟合」两边的训练数据，不能相差太远。但既然是拟合，就难免会有误差，在数学上，最小二乘法就是通过最小化误差的平方和来寻找最佳拟合的线性函数的。不论你的特征向量维度是多少，最小二乘的方法论都是通用的。理解了线性分类，我们就能理解更多的机器学习模型。机器学习最终学习出的函数形式可能会很复杂，不一定是线性的，但原理上都是通过最小化一个目标值来算出最佳的分类函数。

在实际应用中，线性分类最重要的优势是它的结果易于解读。线性分类会针对每个特征变量，输出一个权重，这个权重决定了变量在分类中的重要性。权重的绝对值越大，变量越重要。如果权重是正数，就意味着变量和预测目标有一定的正相关性；如果权重是负数，就意味着变量和预测目标有一定的负相关性。

举一个简单的例子来说明一下权重。比如你今天到商场逛街，逛累了之后要决定午饭吃些什么。那你就需要收集商场里所有能吃饭的地方的信息 —— 当然可能不需要复杂到建立一个模型，但是肯定也会在大脑里经过思考。假如你十分喜欢吃辣的食物，可以接受面食，不喜欢吃甜食，那么在这次决策里，吃辣的食物以及吃面食这两种变量所对应的权重就都是正数，只不过吃辣的食物权重更高，而吃甜食的权重就是负数。最终你的选择是这些变量的加权线性组合决定的：权重是正数的变量，权重数值越大，相应方案被选择的可能性就越大；权重是负数的变量，权重的绝对值越大，相应方案被选择的可能性就越小。所以你最后很有可能选择比较辣的食物，比如说川菜。

在人工智能里，除了最近邻分类、线性分类外，还有很多种分类方法，比如下面要介绍的 K - 近邻分类。K - 近邻分类的一般原理是给定一个训练集，输入新的样本，在训练数据集中找与该向量最邻近的 K 个样本。这些样本多数属于哪个类别，就把该新样本分到这个类别中。最近邻分类可以看作 K＝1 的情况。

我们举个例子来更好地理解 K - 近邻分类。如图 4-7 所示，下面是我们收集的几部电影的数据：主要统计的是电影中的战斗镜头和拥抱镜头的数量，还有电影的类型（未知电影除外），比如电影 A 中有战斗镜头 4 个，拥抱镜头 109 个，电影 A 为爱情片。

图 4-7 电影镜头数据统计图

根据上述收集的电影数据，我们可以计算出已知电影和未知电影的距离，如图 4-8 所示。

图 4-8 电影距离数据统计图

按照距离的递增排序，可以找到 K 个距离最近的电影，假定 K=3，则三个最靠近的电影依次是：电影 B、电影 C 和电影 A。所以未知类型电影的类型应该和离它距离最近的电影是一样的，所以它应该是爱情片。

除了 K - 近邻外，还有逻辑回归、支持向量机、决策树、随机森林和深度学习等模型。这些模型各有各的特色，就像是十八般武艺，了解之后你也能在实践中使用它们，做到游刃有余。最后，让我们再回到机器学习问题的本源，我们需要建立模型做出准确的预测，不同结构的模型都是通过数据学习出来的。模型在实践中的预测效果以及对业务的提升，都需要相应数据的支撑。一旦模型学习好了，人工智能就会像人在经验中总结出规律一样，在面对新问题时，帮助我们做出正确决策。

这个世界对于我们来说充满了太多的未知，需要我们不断地去探索和发现。人工智能的出现让我们在面对新的事物、新的问题时不再不知所措。不论是针对有标记的事物还是未标记的事物，机器学习都可以有效地进行预测，最终形成决策并为我们提供参考，帮助我们有章可循地认识这个世界，改造这个世界。

### 0109. 主题卡 —— 工业数字化赋能的 5 个阶段

信息摘自「2021068AI思维0501.md」：

我们已经明确了工业数字化的总体目标：不但要将工业所处的物理世界数字化，而且还要将数字化反作用于物理世界，驱动和改变物理世界。如图 5-5 所示，工业数字化赋能的实现可以分为五个阶段：试点连接、全面连接、数据洞察、业务优化和链路集成。

2『工业数字化赋能的 5 个阶段，做一张主题卡片。（2021-02-28）』——已完成

图 5-5 工业数字化赋能阶段示意图

在试点连接阶段中，要完成试点工业设备连接、数据采集集成、设备故障收集和设备性能分析等，这是最简单的数据收集，可以在单点上完成。此后进入全面连接阶段，把所有生产设备、检测设备和客户反馈等相关数据通过 IoT 和其他手段收集到数据中台上，完成大规模数据的采集和全链路数据打通。

下一阶段就是在数据基础上，搭建初步的 CPS，形成完整架构，进行数据洞察分析。在这一阶段中，通过收集的全链路数据，建立人工智能模型，进行设备故障诊断、故障预测、可靠性分析、寿命预测和质量分析等。接下来继续完善 CPS，根据预测性结果，进行业务优化，对整个工业生产链路做出相应的资产性能优化、维护策略优化、备件库存优化和产品性能优化等。业务优化阶段完成后，进入链路集成阶段，实现上下游信息和流程的集成、资源的共享，完成从生产型企业向服务型企业的转型。这也是企业成为数字化领导者的实现路线。整个过程从分步连接数据，到数据洞察、迭代和扩展，再到链路集成和整合优化业务流程，最终形成业务模式的创新。

通过工业数字化赋能的路线图，我们可以更形象地理解智能生产制造的各个阶段 —— 从试点连接阶段，进阶到在 IoT 平台上连接更多设备和节点，对数据进行全面洞察，做出预测，从而优化业务目标，更好地提升产能、降低能耗、降低故障率等。工业生产的指标都可以通过数字化的方法进行优化，最终形成整个链路上的集成，向智能制造方向过渡和发展。

在工业数字化赋能的路线图中，要实现数字化赋能，最重要任务之一就是建立人工智能模型，也就是建立相关输入因素数据 x 及目标值 y 之间的相关函数关系。如图 5-6，模型的作用就是在获得相关输入因素数据（例如生产数据、能耗数据、质量数据和环境数据等）以及和生产目标相关的输出值后，对这些数据进行学习，进而通过人工智能产生因素数据和目标值对应关系的模型。在实际生产过程中，工厂将各生产过程中感知到的数据导入生成的模型，根据输出的结果完成决策和反馈，实现工艺参数推荐、过程优化和设备综合效率优化，最终实现预期的生产目标，如提升优良率、降低成本、提升效率或是节省能源等。

图 5-6 工业数字化赋能运作流程示意图

所以简单地说，工业数字化赋能的核心是提供全链路人工智能模型服务，通过分析工艺参数和关键指标之间的关系，进一步预测生产制造环节的关键指标，再根据预测结果完成相应的操控决策和反馈的闭环，最终为企业带来良品率提升、能耗降低和效益增加等效果。数字化赋能的过程完成之后，操作人员在生产制造中每一个环节需要关注的重点、操控的参数等，就都可以被科学地预测和制定。这样就可以做到生产制造环节的数字化赋能和优化。

以上的数字化赋能主要是针对生产制造而言的。虽然生产制造和零售是业务中两大不同的环节，但这一数字化赋能的方法论是通用的。也就是说，在数字化系统建立起来后，只要设定了业务目标，我们就能通过学习输入和输出之间的相关性进行预测性判断。至于如何操控系统参数，如何调整业务流程等，对于生产制造和零售环节的应用来说是异曲同工的。

### 0110. 主题卡 —— 机器学习平台

信息摘自「2021068AI思维0501.md」：

机器学习（包括深度学习）是人工智能发挥作用的核心，因此 AI 中台的核心就是机器学习平台，其中包括一套成熟的机器学习流程运作，涵盖从数据出发进行特征处理、样本调节、模型训练、模型参数调优、模型验证和提供预测服务的各个步骤。图 6-1 对机器学习平台做了梳理，机器学习平台的输入包括客户数据、行为数据、交易数据、机器数据、生产数据等，需要预测的目标也都会输入到平台上，经过以下各个流程的加工：

图 6-1 机器学习平台示意图

第一步，通过对原始数据的提取与融合，形成结构化的、后续步骤可以操作的数据。

第二步，通过数据特征向量化，将结构化的数据转换为特征向量。

第三步，对特征向量进行缩放和归一化处理，这些对特征数值的调节能够优化后续人工智能模型的效果。

第四步，通过特征选择和降维，降低特征向量的维度，形成建模样本。维度过高会对后续模型训练产生影响。

第五步，通过各种统计采样方法对建模样本进行样本调节，生成均衡样本。均衡的样本有利于产生优质的模型。

第六步，根据均衡样本进行模型选择和训练，产生初级模型。

第七步，利用网格搜索、随机搜索等方式对初级模型进行模型参数调优，形成优化模型。

第八步，将优化模型进行模型验证，合格后输出模型至模型仓库。

第九步，利用输出模型进行预测服务，给出预测分数。预测通常是以打分形式体现，无论多么复杂的人工智能应用，都是通过复杂的流程，最终输出对事件、流程或个体的打分。这个打分既可以是实时打分也可以是批量打分，既可以是在线的，也可以是离线的。获得预测分数后，根据分数产生针对实际业务的决策。

1-2『这里的机器学习平台启发很大，设计流数据一体化平台可以按照这个方向走。做一张任意卡片。（2021-02-28）』——已完成

在实践中，人们通过对中台上已经打通的大量生产制造和零售环节的数据进行复杂的处理，对大量的数据实现深入的人工智能分析，最终达到指导和优化决策的目的。无论是生产制造环节的预测还是零售环节的预测，通过上述平台都可以实现标准化的管理。有了这套体系后，开发新的人工智能应用的时候就不需要重新开发框架，而是利用这个平台在每一个环节上通过简单的配置和脚本进行定制。对于实际应用来说，如果让每一位开发人员修改平台本身，就会容易出错，所以，只有把整套平台尽可能地固化下来才是最优的，在统一的环境下用一套完备的平台治理人工智能模型，降低它本身带来风险的可能性，这样也有利于企业人工智能体系的迭代和发展。综上所述，在人工智能已经有一定应用空间以后，企业适合建立一个以机器学习平台为核心的 AI 中台，这样可以确保人工智能模型之后的延伸和发展具有可靠性和易管理性。

补充：

人工智能领域权威学者吴恩达在 2018 年工业互联网峰会上说过：「人工智能是新电能，一百年来，电能为很多企业带来了大量的改变，今天人工智能也会为这些企业带来一样的改变。」更有人说，是人工智能带来了第四次工业革命。「革命」就意味着颠覆，AI 中台就是人工智能颠覆时代的发电机。下面就让我们一起来了解，AI 中台是如何在历史的洪流中推动工业向前发展的。

在工业领域，生产制造是最重要的环节。生产制造的目标是提质、增效、降本和减存，这也是 AI 中台优化工业生产环节的目标。首先我们需要知道，AI 中台要发挥作用，通常需要先收集生产制造过程中各种各样的数据。企业的数据仓库里，存储了大量数据，包括原料、采购、生产、渠道和销售等各环节的数据，然后通过数据中台将数据打通。AI 中台要做的就是对这些打通的数据进行学习，生成定制化模型，对工艺、损耗和良品率等进行监控和诊断，得出生产制造环节相应的预测。最后，依据输出的决策进行反馈，在优化质量、降低成本、增加效能和减少库存等方面做出优化，实现生产制造的智能化转型。接下来，就让我们来详细了解 AI 中台在生产制造环节是如何具体应用的。

工业 AI 中台就是 AI 中台在生产制造环节的具体应用，其总体架构如图 6-3 所示，包括数据采集、数据筛选、信号过滤、特征提取、模型学习和结果反馈六大模块，具体流程包括以下步骤：

图 6-3 工业 AI 中台示意图

第一步，数据采集：通过数据采集控制器和数据采集传感器从机器设备上取得相应数据。

第二步，数据筛选：因为生产制造环节产生的数据非常多，所以需要对原始数据进行一定的筛选。

第三步，信号过滤：对数据进行信号过滤，一般包括数据清洗、信号同步和信号分割等操作。

第四步，特征提取：对过滤完毕的数据进行特征提取，例如对机器特征、原料特征以及时间和频率域特征等的提取。

第五步，模型学习：将提取的特征数据通过机器学习实现性能预测、能耗预测和故障预测等功能。

第六步，结果反馈：最终由模型输出的控制参数反馈到机器设备上，从而操控机器设备，实现智能优化。

2『这里的工业 AI 中台架构，补充进主题卡「机器学习平台」。（2021-02-28）』——已完成

这是生产制造环节中 AI 中台的典型架构。传统上，生产制造的参数仅凭操作工人的经验决定，有时甚至是工人一时兴起拍脑袋决定的，控制水平很大程度上取决于人的主观判断和操作水平，非常不稳定。有时候一不小心操作过头或者是疏忽大意了，都会影响最终的生产效果。而人工智能不仅可以解决这些问题，满足生产制造的需求，还能够降低成本，提升效益。在生产制造过程中，可以采集到大量数据，收集可观测的变量。能够观测的变量可能会达到成百上千个，通过感应和采集这些变量，在工业 AI 中台之上进行加工和分析。然后，要明确优化目标和优化手段，比如目标是提升生产效率，还是降低原料消耗，常用的优化手段是调节控制参数。可以说，工业 AI 中台在生产制造领域的核心应用之一就是调节控制参数，并且反馈到相应设备上，从而实现既定的优化目标。

例如，在生产过程中，产生的气体温度和浓度都会有一个理想范围，可以通过人工智能进行预测和优化控制。也就是说，人工智能模型可以根据每个时间点的状态，指导具体的控制决策。再例如，国家对工厂有环保和废气排放方面的限制要求，工厂利用石灰对废气进行脱硫，可以通过 AI 中台精准控制某一个时间点该放多少石灰原料，从而优化运营效率，降低原料消耗。

### 0201. 术语卡 —— 赫布型学习

信息摘自「2021068AI思维0101.md」：

赫布理论：人脑学习的机制。

1-3『看到赫布感觉好亲切，在「王立铭的生物科学五十讲」专栏里知道这位大牛了，从底层上解释了我们学习的原理（神经元的频繁联系）。（2021-02-20）』

AI 思维与人脑思维有些相似，为了让你更好地理解，首先，我们需要知道人脑的学习机制。在各类经验学习的过程中，无论是视觉、听觉，还是更复杂的决策，人脑都有着它独特的思维机制。

为了研究总结大脑的思维机制，加拿大生理心理学家唐纳德·赫布在 1949 年提出了赫布理论。赫布理论表明，人脑中有许多神经元，前一个神经元通过突触 —— 一个连接不同神经元的结构 —— 持续向后一个神经元产生刺激。在这样的情况下，两个神经元之间的传递效能增加，形成细胞回路；如果这种刺激持续重复，突触传递的效能不断增加，人脑就记住了这两个事物之间存在的联系。比方说，我们在上学的时候，打铃就代表要上课或者下课，也就是说当铃声响起时，一个神经元被激发，而同一时间出现的上课或下课的场景会激发附近的一个神经元，经过多次这样的刺激之后，它们之间的联系会被默认下来，这就是人脑的学习机制。这种学习模式又称作「赫布型学习」，人无时无刻不在接触新的事物，建立事物之间的联系和规律，人的大脑也是无时无刻不在进行着赫布型学习。

2『赫布型学习，做一张术语卡片。（2021-02-20）』——已完成

宏观上，人们从经验中受到刺激时，人脑就学习到了事物之间的相关性，从而总结出相关的规律。如图 1-1 所示，经验改变了人脑的回路，通过习得的规律，我们可以快速分类新的问题，从而形成判断乃至做出决策。所以，人类对新问题的判断，来自过往的经验。

### 0202. 术语卡 —— 模型的训练和预测

信息摘自「2021068AI思维0201.md」：

在人工智能领域，机器学习是产生模型的途径和方法论。和我们的学习一样，分类问题的机器学习框架也分为训练和预测这两个最基本的环节。

2『模型的训练和预测，做一张术语卡片。（2021-02-21）』——已完成

训练环节中需要给定一个训练集，通过训练集中的标记样本 `{{x1,y1}, ..., {xn,yn}}` 训练出一个预测函数 f，也就是我们的预测模型。标记样本是由第 1 个到第 N 个输入数据 x 以及与其相对应的输出数据 y 组成的。在预测环节中，我们要对在训练环节中形成的预测模型输入一个新样本 x，使用 f 输出预测值 y = f(x)。需要注意的是，在训练环节中，由于样本是给定的，所以样本的标记是已知的，但在预测环节中，使用的都是新数据，所以样本的标记是未知的。

任何分类模型都要经过这两个环节。在训练环节中，机器通过分析训练集学习模型，发现其中的规律，并以预测模型 f 的形式产出。在预测环节中，碰到新的样本，即使模型先前没有见过这个样本，仍然能够输出相应的分类。正如人的思维方法是从经验中学习规律，人工智能通过训练环节从数据中学习模型。训练环节使用了何种模型，以及模型训练的质量，决定了模型的有效性，其中最重要的指标是模型在新样本上的预测效果。

如果一个模型能够对新样本进行有效的预测，就可以在实际使用中产生效益。比如，一个模型成功地预测了某位用户购买某款商品的概率为 80%，那么商家可以积极地向该用户推送自家的该商品，用户经常接收到自己喜欢的商品的信息，下单的概率也会有所上升。成功地预测出用户是否会购买，帮助商家提高销量，这样的模型才是有实际意义的。

信息摘自「2021068AI思维02401.md」：

监督学习的模型不是想当然地形成的，它要经过严格的训练和预测环节，这两个环节也是监督学习最基本的环节。

2『监督式学习中，训练和预测，是两个核心环节。此处的信息补充进术语卡片「模型的训练和预测」。（2021-02-27）』

训练环节中：给定一个训练集，由标记样本构成 {(x1,y1), …, (xn,yn)}。所谓标记样本就是既有特征向量 x ，又有对应的标记 y 的一组数据。通过最小化训练集上的预测误差，估计一个预测函数 f，也就是我们的预测模型。需要特别注意的是，训练集都是由样本和对应的标记构成的。例如我手中有大象、猴子、长颈鹿等各种动物的图像，然后给这些图像打上相对应的名称标记（图像和名称标记一一对应），打过标记并且一一对应的图像称为训练集。

预测环节中：在新预测样本 x 上，使用 f 输出预测值 y = f(x)。就比如人工智能经过了刚才关于动物图像的训练，我们再把新的图像输入给它，此时人工智能就可以输出图像上的动物是什么了，这就是预测环节。

在训练阶段，样本的标记是已知的，但是在预测阶段，样本的标记是未知的。就像读书的时候，平时死记硬背的同学不一定考试考得好，考试考得好的同学，也未必在社会上发展出色。机器学习也是这个道理，在新的、未曾见到过的预测集上的预测效果，才是做好机器学习的关键。那么要做好机器学习，也就是训练出一个预测效果好的模型，需要多少数据样本呢？这个问题是无法一概而论的。如果你的数据样本大，行为或模式复杂，要预测的标记本身也会发生变化，那么这个模型需要的训练数据就多。通常，跟训练简单模型（好比后面我们要说的线性模型）比较，训练复杂模型需要的样本也会比较多。

需要注意的是，用来训练的样本一定要代表实际的业务场景，这样机器学习产生的模型才能在实际业务中产出良好的预测效果。如果在实际业务中遇到的预测样本和训练样本的特性相差甚远，那么模型是很难产出良好的预测效果的。比如你想开一家饭店，但却只在上海地区展开饮食喜好的调查，那么你大概会得出「消费者都比较喜欢吃清淡一点的食物」的结论。根据这个结论，你精心研发了一份清淡可口的食谱，但是这家饭店最终选址在川渝地区。可想而知，饭店开业后并不会有太好的生意，因为两地的人群样本对食物的喜好相差很大，上海样本上得出的结论很难在川渝样本上产生同样的效果。

通过前面的阐释，我们已经知道了分类的概念，下面再通过一个具体的图像分类的例子来更加深入地了解分类。如图 4-2 所示，训练阶段我们提供了一组有类别标记的图像，预测阶段，给定一个图像，我们的模型可以输出图像上的物体类别。

图 4-2 图像分类示意图

训练的时候，我们给了 6 类训练图像，分别是 3 种水果和 3 种动物。每张图像先经过特征化处理，产生图像特征。根据这些图像特征和标记，机器学习能够学习出一个模型。预测的时候，我们给定一张图，把它特征化后，模型就可以针对这个图像特征，输出一个类别预测。

之前提到过，机器学习中，数据以向量形式表示。对图像来说，有很多种向量表示的方法。我们挑选 3 种基本的向量表示方法展开讲解：原始像素值特征、直方图特征、GIST 特征。如图 4-3 所示，原始像素值特征，用的就是原图的彩色或者灰度像素值，把它们拉成一个向量作为图像的表示，这种简单的方法只能表示简单的图像。图像的像素值很容易受到环境中各种因素的干扰，用它们表示复杂图像的内容，可用性不强。直方图特征，是指加工原图像素值，用加工后的像素值分布，而不是原始值来表示图像。GIST 特征，用更复杂的方法来全面表示图像中的场景，能够更好地刻画图像的视觉特点，比如说是自然场景还是人工场景，场景是封闭的还是开阔的。

1『此时此刻看到直方图（不同亮度像素点的部分），直接想到了正态分布，是不是大部分比较常规的图片，其曝光图部分（直方图）基本是符合正态分布的，最和谐的。（2021-02-27）』

图 4-3 图像的特征向量表示方法

对于图像来说，设计的特征越精巧，在机器学习中，图像识别的效果就能够做得越好，但是人的肉眼却很难看明白这些复杂的特征。人工智能和人的思维方式不一样，对于人来说很直接的原始图像，计算机却很难处理；而构造精妙的图像特征向量，人则不一定能看明白。

### 0203. 术语卡 —— 偏差和方差

信息摘自「2021068AI思维0201.md」：

在机器学习中，机器从训练数据中学习到模型。任何有监督的机器学习的目标都是在给定训练数据的情况下，对输入变量和输出变量之间的映射关系（下文称为「真实函数」）进行最佳估算。既然是估算，肯定就会有误差。通常，机器学习的预测误差可分为三部分：偏差、方差以及不可减少的误差。其中，不可减少的误差是无论采用什么模型都不可能被减少的误差，因为这种误差是由未知变量引起的。比如一个预测用户是否会买车的模型能根据用户的收入、职业、年龄、家庭状况等一系列数据进行预测，但是这个预测不一定完全精准。因为一个用户是否会买车不只会受这些变量的影响，还会受生活方式等的影响，而像生活方式这样的变量通常是不可知的，因此这种误差是不可减少的，但是，偏差和方差是可以通过机器学习模型进行影响的。

2『偏差和方差，做一张术语卡片。（2021-02-21）』——已完成

偏差描述的是在使用不同的训练数据时，预测值的平均值与真实值之间的差距，即模型本身的精准度，反映的是模型本身的拟合能力。偏差的产生是因为为了使真实函数更容易学习，而对模型的假设做了简化。偏差高意味着模型是欠拟合的。

方差衡量的是在使用不同的训练数据时，真实函数的估算值所改变的量，也就是预测值的波动情况，它反映的是模型的稳定性。方差的产生是因为为了使模型的预测结果更加符合真实数据，而对模型提出了更加复杂的假设。方差高意味着模型是过拟合的。

下面我们用一个更直观的例子来说明一下偏差和方差。假如有一个视力不好的人想要学习射击，那么他不管练习多少次，也不能打中靶心。但是如果这个人的视力很好，对环境的敏感度很高，瞄准时还能考虑到风速、风向等环境因素，那么经过训练后，他就很容易打中靶心。如果我们此时给他换一个环境，而他不能迅速适应这个环境的话，他的射击也不会有之前那样高的命中率。

在这个例子中，靶心代表的是真实值，若这个人视力不好，他的拟合能力相对而言就不高，无论怎么练习都不能很好地命中靶心，也就是预测值和真实值之间存在差距，产生了偏差。假如这个人视力没有问题，而且他能够根据环境因素来改变射击的方式以此来提高命中靶心的概率，也就是为了使输出更好地符合真实值，而提出了更多的条件假设，但是他又没有完全掌握这种方式，环境一发生变化他的命中率就会下降，这就说明了提出的假设越多，稳定性就越低，就越容易产生方差。

在图 2-3 中，第一行的两个靶，射击的痕迹都十分靠近靶心，说明其拟合能力比较好，也就是偏差小；第一列的两个靶，射击的痕迹都十分集中，这说明其稳定性非常好，也就是方差小。

图 2-3 偏差与方差示意图

1-2『这图看起来好直观，一下子弄明白了偏差和方差的概念。作者丁磊的「功力」确实深，很庆幸在老俞的知识城邦里看到这本书的信息，错过这本书是个很大的损失。丁磊，做一张人名卡片。（2021-02-21）』——未完成

在数学领域有一个概念叫作「参数」。在研究问题时，我们经常会在模型中引入一些变量来描述数据的变化，这些变量就是参数。一般来说，在机器学习中，参数化的模型会有相对较高的偏差，这样它们学习起来很快，也更容易理解，但是高偏差就意味着它对模型做了很多的假设，在训练过程中，不是每个数据都可以完美拟合，因此，这个模型就不那么灵活。反之，如果这个模型对真实函数提出的假设很少，那么这个模型的偏差就很低，几乎能拟合每一个数据，但是这样的模型近乎一种对数据的记录，预测性能就不足了。低偏差机器学习模型的例子包括：决策树、K-最近邻和支持向量机。高偏差机器学习模型的例子包括：线性回归、线性判别分析和逻辑回归。

用机器学习模型是通过训练数据来对真实函数进行估算，模型或多或少都会产生一定的方差。理想情况是，训练数据集的改变对真实函数的估算结果不会产生很大影响，这意味着该模型能够很好地计算出输入和输出变量之间隐藏的底层映射。如果模型的方差过高，训练数据对其产生的具体影响明显，那么训练的细节就会较大地影响到描述映射函数的具体参数。如果模型的方差较低，训练数据对其产生的具体影响很小，那么训练的细节对描述映射函数的具体参数的影响也会很小。

任何有监督的机器学习模型的目标都是做到低偏差和低方差，也就是说该模型应达到很好的预测性能。但是在机器学习中，偏差和方差二者又不可兼得，偏差减少必将增加方差，方差减少必将增加偏差。造成这种现象的原因是，当我们想要尽量减少模型的偏差时，我们就会尽可能多地保证模型在训练样本上的准确度，但是这样学习出的模型就会过度拟合，反而降低了其预测能力，增加了模型的不确定性，也就是方差增加了；相反，我们在追求模型的低方差时，会增加许多对模型的假设和限制，虽然这提高了模型的稳定性，但是忽视了拟合程度，偏差也随之提高了。所以为了模型能够拥有更好的预测能力，我们需要权衡偏差和方差的关系。

2『这里的信息补充进术语卡片「偏差和方差」里。（2021-02-21）』——已完成

我们通过在具体情况下选择模型的复杂度来达到偏差和方差的权衡，寻找这个权衡的过程就叫作泛化误差的优化。研究发现，模型的泛化误差可以通过偏差的平方、方差以及不可减少的误差相加而得出：

$$模型的泛化误差 = 偏差^2 + 方差 + 不可减少的误差$$

模型的泛化误差还可以通过更加形象的方式来表示，如图 2-4 所示，随着模型复杂程度的上升，模型的偏差越小，方差越大，图 2-4 中最上方的那条线，表示的就是模型的泛化误差。我们要找的方差和偏差的最佳权衡点就是图中虚线所在之处，此时模型的复杂程度处于最佳状态，模型的泛化能力最好。

图 2-4 模型的泛化误差示意图

我们从图 2-4 中可以很容易地发现，偏差和方差之间是存在冲突的。虽然大多数情况下，我们不能计算实际的偏差和方差项，但是对偏差和方差的把握为模型预测性能的优化提供了思维框架。

### 0204. 术语卡 —— VC 维度

信息摘自「2021068AI思维0201.md」：

前面我们讲到，模型的偏差和方差与模型的复杂度是有关系的。模型的偏差会随着模型复杂度的上升而下降，而模型的方差会随着模型复杂度的上升而上升。那我们是怎么来定义和量化一个模型的复杂度的呢？为了定义和量化一个模型的复杂度，我们引入一个新的概念：VC 维度（Vapnik-Chervonenkis Dimension）。VC 维度是根据提出者统计学家弗拉基米尔·万普尼克（Vladimir Vapnik）和数学家亚历克塞·泽范兰杰斯（Alexey Chervonenkis）的名字来命名的。

2『VC 维度是描述一个模型复杂度的方法，做一张术语卡片。（2021-02-21）』——已完成

大自然的智慧是无穷的，它赋予我们聪慧的大脑，也在冥冥之中提示我们寻找规律，让我们首先从大自然的角度来理解 VC 维度。海豚经过训练可以打乒乓球、钻火圈，被称为世界上最聪明的动物，海豚大脑的重量占海豚体重的 1.7%。平时我们总会用「蠢萌」这个词来形容的狗，它的大脑重量仅占它体重的 0.8%。经过对多种动物大脑重量占它体重比例的研究以及这些动物日常表现的观察，科学家们提出，大脑重量占体重的比重越大的动物越聪明。人类大脑的重量占人体重的 2.1%，是地球上所有生物中占比最大的，这也充分证明了上述观点。大脑占的比重越大，说明脑细胞相对就越多，也就是大脑的复杂度越高。如果从 VC 维度的角度来看，大脑的 VC 维度越高，就越聪明。

接下来，让我们从理论的角度来了解一下 VC 维度。首先我们需要了解一下分类器。分类是 AI 思维考虑的重要问题：比如我们要将顾客分为高购买价值和低购买价值两类，以此来决定我们的精准营销方案。在人工智能中，这些数据的分类是通过分类器进行的，而分类器的复杂程度取决于它能够准确分类的数据的多少。假如现在要用分类器为一组数据点分类，那么这种分类器的 VC 维度的定义就是：对于每个可能的数据点的标记，单个分类器可最多分类的数据点个数。但是需要注意的是，这里有一个隐含条件，就是不要求对在同一直线上的点分类。比如：如图 2-5 中前三张图所示，在二维空间上，一个线性分类器的 VC 维度是 3，因为它可以对任意三个点进行准确分类，无论它们如何排列。但是如图 2-5 中第四张图所示，单个线性分类器无法对四个点进行准确分类，即使它们不共线。

图 2-5 二维空间线性分类器示意图

如果要判断分类器的 VC 维度就要看它能够对几个不共线的点进行分类。通过上述图片所示，我们可以直观地看出来，二维空间中单个线性分类器可以分类的最大数量是 3，所以这种线性分类器的 VC 维度是 3。而随着分类器能准确分类数据的增多，VC 维度也会相应地增加。因此，VC 维度是描述模型复杂程度的一种方法。

VC 维度是反映泛化误差与训练误差关系的重要指标，正如以下公式所示：

$$泛化误差 ≤ 训练误差 + \sqrt{\frac{8}{N}ln(\frac{4(2N)^d}{δ})}$$

其中 N 指的是训练样本数量，d 指的就是 VC 维度，δ 指的是一个概率相关的参数。虽然这个公式看似十分复杂，但是仅从数量关系的角度看，VC 维度与泛化误差和训练误差的差值呈现正相关，VC 维度越大，泛化误差和训练误差的差值就越大。而我们现在已经知道了 VC 维度代表的就是模型的复杂度，所以模型的复杂度与泛化误差和训练误差的差值也呈现这样一个正相关关系。那么，模型 VC 维度的法则在现实中有什么意义呢？

首先我们要知道，VC 维度并不是越大越好，但是根据上述公式可以发现，训练样本的数量位于分母位置，VC 维度位于分子位置，如果分子分母的数量同时扩大，也就是说训练样本数量和 VC 维度同时扩大，泛化误差和训练误差的差值可能并不会发生显著改变。换言之，如果在训练样本的数量越来越多的情况下，提升 VC 维度，也就是使用更加复杂的模型可能是一个更加合理的选择。所以，模型 VC 维度的大小是要根据训练数据的多少来进行选择的。只有选择了合适的 VC 维度模型，人工智能才能产出实际价值，为各行各业提供优质的服务。

1『获取到了一个关键信息：模型的复杂度要根据训练数据量的大小来选择，数据量大的时候模型复杂度选高点不会过度拟合，选择合适的模型复杂度特别重要。（2021-02-21）』

我们现在使用的人工智能都是经过了漫长的发展才达到现在可以普遍应用的水平，例如语音识别从 1952 年就已经出现了，但当时的语音识别建立在一个数据量很小的基础上，所以当时它只能识别出 10 个英文数字的发音，虽然这是语音识别的开端，具有划时代的意义，但它也确实不能进入应用阶段。随着语音识别马不停蹄地发展，训练语料库越来越大，相应地，语音识别模型的 VC 维度也在不断升高，随之而来的是语音识别的错误率也越来越低。目前，主流智能语音识别的准确率已经超过 97%，比通常人工转录的准确率还要高。

我们之前提到过的图像识别领域的「奥赛」ImageNet 比赛也反映出这样的趋势。从 2000 年开始，每年冠军参赛模型的 VC 维度都在不断上升，与之相对应的，冠军模型识别图片的错误率在不断下降，在这背后，冠军模型面对的其实是数据量越来越大的现状。不论是在语音识别、图像识别还是在其他人工智能应用上，都体现了这个规律：几十年前，数据量很小，人工智能技术刚刚起步，模型不需要很高的 VC 维度来处理数据，所以当时建立的一些模型都很简单。但随着时代的发展，数据量的增加，为更好地解决层出不穷且越来越复杂的问题，提供更优质的服务，近几年新建立的模型都呈现出 VC 维度越来越高、复杂程度越来越高的趋势。

与此同时，各种新兴行业也通过 VC 维度的提升有了新的发展。2019 年 8 月 2 日，腾讯人工智能实验室研发的人工智能系统叫作绝悟，它在王者荣耀世界冠军杯中战胜了职业选手，证明了现在的人工智能也可达到电竞职业玩家的水平。8 月 3 日，绝悟在中国国际数码互动娱乐展览会（ChinaJoy）上参与的 504 场 1 对 1 人机对战中，获胜率为 99.8%，输掉的那一场是输给了国内最顶尖的专业玩家。绝悟之所以能取得如此高的胜率，正是因为选择了具有合适 VC 维度的模型。

这些年，中国电竞在世界级比赛中也获得了不俗的成绩：2018 年雅加达亚运会电子竞技表演赛中斩获 2 金 1 银、「英雄联盟」S8 全球总决赛捧得冠军奖杯。这说明中国电竞业正在逐步崛起，电竞职业选手的能力也逐渐逼近世界水平。这时如果发明出电竞人工智能，也会希望它达到世界级水平。但是，电竞人工智能所要面临的问题是十分复杂的。以王者荣耀为例，它作为一个团队作战游戏，双方每方 5 位参与者要在英雄搭配、技能应用、路径调换及团队协作等方面面临大量、持续而且即时的选择，其操作可能性高达 $10^{20 000}$ 种。因此，绝悟在训练过程中选择的是 VC 维度极高的深度强化学习模型。在短短半个月的训练周期内，绝悟每天的训练强度相当于人类训练 440 年的量。与此同时，绝悟在训练中用了 384 块 GPU。在这样高等级算力的支持下，VC 维度高的模型的训练下，绝悟的电子竞技能力直线上升，达到了世界级电子竞技选手的水平。

「权衡」二字出自南朝刘勰的《文心雕龙》：「权衡损益，斟酌浓淡。」古人早已告诉我们，要懂得权衡才能找到处理事情的最佳方法。通过权衡偏差和方差平衡模型的复杂程度和稳定程度，找到最合适的模型；通过权衡各种条件，找到最合适的 VC 维度，这样打造出来的模型才是真正能解决问题的模型。弱水三千只取一瓢饮，虽然选择很多，我们只要最合适的那一个。这和 AI 思维是一脉相承的，通过权衡各种复杂条件做出最佳的决策，不但可以帮助我们解决各种复杂的商业问题，还能使我们在激烈的行业竞争中脱颖而出。

### 0205. 术语卡 —— 因果性

信息摘自「2021068AI思维0201.md」：

证明因果，首先要证明两个事件有关联。这种关联一般来说是一种常见的现象，比如一些老人喜欢说的「爱笑的人都很善良」，「满脸愁容、精神颓废的人都很苦命」，「筋络粗壮的都很奔波」，等等，是根据一种静止表象来推测动态发展倾向。虽然关联现象不一定意味着因果关系，但认识到或者察觉到它，却是一个很好的起点。如果某两个事件显示出一定的相关性，往往会引起研究者的注意，吸引他们去发掘其中可能存在的因果关系。

从日常生活到严谨的科学实验室，想要证明事件之间有无关联或密切程度的方法有很多。就像前面说的，从统计学的角度，能够通过数据分析看出两个事件之间是否存在正相关和负相关的关系，如果不存在关联就不存在因果，因为关联关系是因果关系的基础。当确定两个事件之间存在关联后，我们再进一步分析两个事件之间的细节规律，建立起一个假设，即它们之间发生的先后关系的推测。想要验证这个推测，首先可以预设是某一事件导致的另一事件，这个结论成立的两个条件是：第一，一个事件发生在另一个事件之前；第二，前一个事件的出现能预测另一个事件的出现。

1-2『这里的「因果性」是目前看到的，解释最清晰的，做一张术语卡片。（2021-02-21）』

因果关系的链条是单一的。上述条件只是证明了两者之间存在链条，我们还要进一步检验事件之间链条的单一性，也就是排除掉其他可能的混淆变量。所谓混淆变量，就是发生在前一事件以外的其他事件导致了后一个事件的发生，这就违反了因果关系链条的单一性，这个因果关系就不是那么明确地能够成立了，需要再往深一步去挖掘其真实的因果关系链条。比如，在众所周知的狐假虎威的故事当中，每一次狐狸出现，森林里的动物们都十分害怕，四散而逃，但是动物们逃走并不是因为狐狸，而是因为狐狸的身后跟着百兽之王老虎。在这个故事中，老虎就是那个混淆变量，狐狸出现与动物们逃跑之间并不存在链条的单一性，也就是因果关系并不成立。

去掉混淆变量的常见方法是设计实验组和对照组。实验组，就是在这一组样本中对某一因素做处理。对照组，就是不做任何处理，直接放置，然后观察两组现象的差别。要证明因果，就是需要实验组出现预设的现象，而对照组不出现预设现象。如果实验组因为做了某一因素的处理而出现预设现象，对照组未做任何处理而没有出现预设现象，就能证明某一因素的改变导致了预设现象的出现，而没有这一改变就不能导致相应现象出现。

例如，最近喝各种养生茶变得流行起来，有些人喜欢清淡的，有些人接受不了苦味，有些人却偏偏喜欢特别苦的。如果我们想要知道是哪一种原料导致了茶的苦味，就可以进行一次对照实验。例如，我们的推测是里面的苦菊导致了苦味，那么我们需要泡两杯茶，一杯花果茶的茶包原料不变，照常加水泡开；将另一杯花果茶的茶包原料里的苦菊挑拣出来，再加水泡开。如果品尝后发现前一杯茶带有苦味，而后一杯茶没有苦味，则验证了我们的推测是正确的，即苦菊是导致这杯茶带苦味的原因，苦菊与茶的苦味之间的因果性成立。当然，我们还可以做更多推测，比如考察是哪种材料导致了奇怪的味道，等等。

### 0206. 术语卡 —— 深度学习

信息摘自「2021068AI思维0301.md」：

深度学习的概念最初起源于人工神经网络（Artificial Neural Networks）。科学家发现人的大脑中含有大约 1 000 亿个神经元，大脑平时所进行的思考、记忆等工作，都是依靠神经元彼此之间的连接而形成的神经网络来进行的。人工神经网络是一种模仿人类神经网络来进行信息处理的模型，它具有自主学习和自适应的能力。

2『深度学习，做一张术语卡片。（2021-02-26）』

1943 年，数学家皮茨（Pitts）和麦卡洛克（McCulloch）建立了第一个神经网络模型 M-P 模型，能够进行逻辑运算，为神经网络的发展奠定了基础。生物神经元一共由四个部分组成：细胞体、树突、轴突和突触，M-P 模型其实是对生物神经元结构的一个模仿，如图 3-5 所示，左边是生物神经元的示意图，右边是 M-P 模型的示意图，为了建模更加方便简单，M-P 模型将神经元中的树突、细胞体等接收到的信号都看作输入值 x ，突触发出的信号视作输出值 y 。1958 年，计算机科学家罗森布拉特（Rosenblatt）发明了感知机，分为三个部分：输入层、输出层和隐含层。感知机能够进行一些简单的模式识别和联想记忆，是人工神经网络的一大突破，但这个感知机存在一个问题，就是它无法对复杂的函数进行预测。20 世纪 80 年代，人工智能科学家鲁姆尔哈特（Rumelhart）、威廉姆斯（Williams）、辛顿（Hinton）、莱库（LeCun）等人发明的多层感知机解决了这个问题，推动了人工神经网络的进一步发展。20 世纪 90 年代，诺贝尔奖获得者埃德尔曼（Edelman）提出 Darwinism 模型，并建立了一种神经网络系统理论，对 90 年代神经网络的发展具有重大意义。

从这之后，神经网络技术再也没有出现过突破性的发展。直到 2006 年，被称为人工智能教父的辛顿正式提出了深度学习的概念，认为通过无监督学习和有监督学习相结合的方式，可以对现有的模型进行优化。这一观点的提出在人工智能领域引起了很大反响，许多像斯坦福大学这样的著名高校的学者们纷纷开始研究深度学习。2006 年被称为「深度学习元年」，深度学习从这一年开始迎来了一个爆发式的发展。2009 年，深度学习应用于语音识别领域。2012 年，深度学习模型 AlexNet 在 ImageNet 图像识别大赛中拔得头筹，深度学习开始被视为神经网络的代名词。同样是在这一年，人工智能领域权威学者吴恩达教授开发的深度神经网络将图像识别的错误率从 26% 降低到了 15%，这是人工智能在图像识别领域的一大进步。2014 年，脸书开发的深度学习项目 DeepFace 在识别人脸方面的准确率达到了 97% 以上。2016 年，基于深度学习的 AlphaGo 在围棋比赛中战胜了韩国顶尖棋手李世石，在世界范围内引起轰动，这一事件不但使深度学习得到了认可，人工智能也因此被社会大众所熟知。2017 年，深度学习开始在各个领域展开应用，如医疗影像、金融风控、课堂教学等，在不知不觉中已经渗透到我们的生活中。

### 0207. 术语卡 —— 深度学习的两大经典模型

消化：卷积神经网络擅长识别独立的数据（图像），循环神经网络擅长识别连续数据（连续事件，有上下文关系的数据）。

信息摘自「2021068AI思维0301.md」：

那么深度学习到底是什么呢？深度学习是建立在计算机神经网络理论和机器学习理论上的科学，它使用建立在复杂的网络结构上的多处理层，结合非线性转换方法，对复杂数据模型进行抽象，能够很好地识别图像、声音和文本。深度学习有两种经典模型：CNN 和 RNN。

CNN 全称是 Convolutional Neural Network，也就是卷积神经网络。对于卷积神经网络的研究最早出现于 20 世纪 80 至 90 年代，到了 21 世纪，随着科学家们对深度学习的深入研究，卷积神经网络也得到了飞速的发展，该网络经常用于图像识别领域。如图 3-6 所示，卷积神经网络共分为以下几个层级部分，输入层（input layer）、卷积层（convolution layer）、池化层（pooling layer）、全连接层（fully connected layer）。

图 3-6 卷积神经网络工作过程示意图

当图像进入输入层，模型会对这个图像进行一些简单的预处理，比如降低图像维度，便于图像识别。卷积层里的神经元会对图像进行各个维度的特征提取。这一提取动作不是针对原图像进行的，而是仅对图像的局部进行特征提取，比如需要识别的是一张包含小狗的照片，但是神经元只负责处理这张照片中的一小部分，比如狗的耳朵、眼睛。卷积层对图像不同尺度进行特征提取，大大丰富了获取特征的维度，有助于提升最终识别的准确度。池化层对图像进行压缩降维，降低图像识别需要处理的数据量。全连接层需要做的就是将前面所提取出来的所有图像特征连接组合起来，如图 3-7 中，将提取到的小狗的头、身体、腿等局部特征组合起来，形成一个完整的包含小狗的特征向量，然后识别出类别，这就是卷积神经网络进行图像识别的全过程。

图 3-7 卷积神经网络图像识别过程示意图

通过对卷积神经网络工作过程的梳理，我们总结出卷积神经网络的三个特性：第一，图像识别不需要识别图像的全部，每个神经元只需要聚焦到图像的一小部分，识别的难度降低；第二，卷积层对应的神经元可以应用于不同的图像识别任务，比如图 3-7 中的神经元，经过训练，已经能够识别出小狗，那这些神经元也可以应用于识别其他任何图像中的相似物体；第三，虽然图像特征的维度降低了，但是由于保留了图像的主要特征，所以并不影响图像识别，反而降低了识别图像需要处理的数据量。这三个特性决定了卷积神经网络非常适合用于图像识别。例如由牛津大学开发的 VGG 模型就是基于卷积神经网络模型建立的，它在识别物体的候选框生成、图像的定位与检索等方面十分准确，这使得它在 2014 年 ImageNet 竞赛定位任务中获得了第一名。

1-2-3『图像识别算法既然这么成熟了，好好吃透其原理，那么完全可以应用于识别我们设计图纸中的各种图形，直觉上一定可以落体，找到不止一个的应用场景。留个心眼，待发掘。（2021-07-21）』—— 未完成

人工神经网络和卷积神经网络在深度学习领域都占有一席之地，但它们识别的都是独立的事件，比如卷积神经网络非常擅长识别独立的图像，如果让它识别 100 张照片，输出的结果互相不受任何影响，但是让它识别或者预测一句连续的话，比如一个寓言故事或者翻译一段英文，可能就没有这么好的效果了。可是在现实生活中，我们会遇到很多连续的事件，比如「小明每次去超市都会买很多苹果，因为他最喜欢吃（ ）」，联系上下文，我们可以很容易推测出括号里应该是「苹果」这个词，因为括号前的「吃」字是一个动词，动词后面经常跟着的是名词，而这个句子中的名词只有「苹果」最合适。为了能够识别这些连续性很强的事件，弥补人工神经网络和卷积神经网络的不足，RNN 模型诞生了。

RNN 全称是 Recurrent Neural Network，也就是循环神经网络。对于循环神经网络的研究最早出现于 20 世纪 80 年代，由约翰·霍普菲尔德（John Hopfi eld）、迈克尔·乔丹（Michael Jordan）以及杰弗里·埃尔曼（Jeffrey Elman）等人提出，该模型经常用于时序信号（如语音）的识别和理解。

循环就是重复的意思，循环神经网络模型在运行时会对同一个序列进行循环操作。序列是被排成一列的对象，序列中的元素相互依赖，排列顺序非常重要，比如时序数据、对话等，一旦顺序错乱，含义和作用都会发生巨大改变。循环神经网络解决了卷积神经网络不能很好地识别连续性事件的问题，在深度学习领域发挥着不可替代的作用。

循环神经网络之所以能对连续性事件进行识别，是因为它不仅将当前的输入数据作为网络输入，还将之前感知到的一并作为输入。根据记忆的长短，从第一层开始，将激活传递到下一层，以此类推，最后得到输出。图 3-8 就是一个循环神经网络的示意图，它由输入层、隐藏层和输出层三部分组成。循环就发生在隐藏层。隐藏层里一般会设置一个特定的预测函数，当我们向循环神经网络模型输入一个连续性事件后，在隐藏层的这个函数就会进行运算，这个运算结果又可以作为输入进入隐藏层再一次进行运算。如此这般，就形成了一个不断循环的预测，这个预测与新输入的数据有关，也取决于每一次循环的输入。

图 3-8 循环神经网络原理示意图

连续性数据在日常生活中出现的频率之高决定了循环神经网络有着广泛的应用空间。例如，我们可以依靠循环神经网络预测一句话中的下一个词语或一篇文章中下一句话是什么，以此来生成文本，现在很多写稿机器人就是基于循环神经网络来进行运作的。循环神经网络模型还可以将文本翻译成其他的语言，所以它也广泛用于机器翻译。循环神经网络另一个常见的应用是语音识别，我们现在使用的很多智能语音助手都应用了循环神经网络。

股票的价格波动也存在一定的规律，根据前一段时间的股票波动情况可以大致预测出之后股票的走势。因此，循环神经网络在股票预测方面有先天的优势。随着经济的发展，股票市场的规模不断扩大，大量股票历史数据的积累使得循环神经网络可以学习股票的走势规律。比如，当循环神经网络发现，某只股票价格不断下跌超过七天，之后就会缓慢上升，并且在很长一段时间内这只股票都呈现出这个规律时，如果这只股票价格再一次持续下跌，那么下跌的第七天就是股民买入的最好时机。实践证明，循环神经网络对股票的预测能够较好地拟合真实数据，具有很高的应用价值。

循环神经网络可以有效地进行文本识别，而在商业世界中，最重要的一种文本数据就是商品评论。随着生活节奏的加快、电子商务的兴起，人们越来越倾向于网络购物。网购时，用户没有见过真实的商品，只能通过商家的描述进行了解，而商家的描述又不能保证用户了解到的信息完全属实，此时，用户的商品评论就成为反映商品质量和商家信用的一个重要参考标准。但是，用户的评论也有很大的主观性，如何结合用户的主观评价正确评估商品质量及商家信用成为一个亟须解决的问题。在循环神经网络强大的文本识别功能的帮助下，我们可以很好地解决这个问题。循环神经网络在分析评论的过程中，最重要的一个步骤是对用户的主观评价进行处理，即通过循环神经网络分析用户的商品评论，再将其转化为对商家的等级评价。比如，循环神经网络识别出不同的商家同时在售卖同一种商品，但在商品质量方面，商家甲好评数远远高于商家乙，那么在这一方面，商家甲的等级评价就会高于商家乙的等级评价。影响商家等级评价的因素还有很多，比如服务态度、发货速度，以及商品与描述相符度等，将这些因素全部考虑在内，就会形成一个全面的商家等级评价。循环神经网络在商家评价方面的应用使用户不会被海量商品信息以及其他用户的主观评价所混淆，直接找到符合自身需求并且质量上乘的商品，提升了用户的网上购物体验。

2『深度学习的两大经典模型：卷积神经网络和循环神经网络，做一张术语卡片。（2021-02-26）』

1-2-3『目前认为循环神经网络可以实现自动编写安全专篇这种文档。待深挖。（2021-07-21）』

### 0208. 术语卡 —— 网络中的边介数

消化：

1、边介数的定义。边是网络中节点的连接，边介数是边的一个属性，指网络中所有最短路径中，通过该边的个数。直接看这个定义还是有点懵，但下文里小区间必经通道的边介数高的例子比较形象了。

2、划分出一个社区的一种方法：1）计算网络中所有边的边介数。2）删除边介数最高的那条边。3）重新计算剩余各边的边介数。重复上述步骤直到产生合适的社区结构。

信息摘自「2021068AI思维0401.md」：

那么，我们怎么去进行社区发现呢？有很多常用的社区发现模型，例如吉尔韦安（Girvan）、纽曼（Newman）等人在 2003 年提出的 GN 社区发现方法（以两位开创者的名字首字母命名），就是社区发现中的一个比较经典的模型。GN 社区发现方法提出了边介数的概念。那么，什么是边介数呢？由网络中社区的定义可知，所谓社区就是指其内部节点的连接稠密，而与其他社区内的节点连接稀疏。这就意味着社区与社区之间联系的通道比较少，一个社区到另一个社区至少要通过这些通道中的一条。如果能找到这些重要的通道，并将它们移除，那么网络就自然而然地分出了社区。在实践中，我们用边的边介数来作为这个分割的依据。

边的边介数定义为网络中所有最短路径中经过该边的数目。跟节点的中介中心性类似，它反映了相应的边在整个网络中的作用和影响力。联系定义可知，通过社区内部的边的最短路径的数目相对较少（边介数较少），而通过社区之间的边的最短路径的数目则相对较多（边介数较多）。因为社区之间的联系只能经由这几条路径发生，就像车流要从停车场开到外面一样，如果停车场只有一条通道，那么车流都得从这条通道走，这条通道的使用率就是 100%，非常高；如果这个停车场内部有 5 条通道，车流可以分散开来，可能每个通道的平均使用率只有 20%，远没有前者高。

2『网络中的边介数，做一张术语卡片。（2021-02-28）』——已完成

GN 社区发现方法是基于删除边的方法，其本质是基于聚类中的分裂思想，原理上使用了边介数作为相似度的度量方法。GN 社区发现通过移除网络中的边来将整个网络划分成为合适的社区结构，将原来的网络分割成为任意数目的社区。在 GN 社区发现方法中，每次都会选择边介数高的边删除。GN 社区发现方法的步骤如下：

第一步，计算每一条边的边介数。

第二步，删除边介数最大的边。

第三步，重新计算网络中剩下的边的边介数。

重复上述步骤，直到产生合适的社区结构。

通过上述步骤，GN 社区发现方法可以较好地发现网络中存在的社区结构。在网络理论中，复杂网络是由数量繁多的节点和节点之间错综复杂的关系构成的。GN 社区发现方法用边介数的概念来探测边的位置，从而在盘根错节的复杂网络中划分出社区。

人与人之间的互动使其相互间产生了或紧密、或松散的联系，也在不经意间建立起了一张张连通社会各个层面的网络：通信往来、商业交易和互联网社交等。社区发现模型可以用来找出网络中的社区聚类，让人们洞察这些网络中隐藏的形形色色的「社区」，也可用于评估一个网络结构中个体组合或分裂的程度，并从中获取很多新发现。

### 0209. 术语卡 —— 信息物理融合系统

信息摘自「2021068AI思维0501.md」：

18 世纪末，蒸汽机的出现使人们进入工业 1.0 时代；20 世纪初，电力的大规模应用使整个世界进入工业 2.0 时代；20 世纪 70 年代，电子技术、信息技术以及工业机器人的广泛应用推动世界进入工业 3.0 时代；现在，随着物联网、大数据和人工智能的融合应用，我们已经进入了工业 4.0 时代。在新一代技术革命浪潮中，数字化趋势已经势不可当。我们需要利用数字化技术促进产业变革，尤其是通过人工智能的应用创建具有适应性、高资源效率和更加人性化的新一代智能工厂。在这样的背景下，不仅需要将工业所处的物理世界数字化，数字化的目标还需要反作用于物理世界，驱动物理世界，改变物理世界。

1-3『突然想到瓦特的生命线：1736-1818，82 岁。（2021-02-28）』

数字化反作用于物理世界的第一步就是将物理世界抽象成标准化的数据集合，这是物理世界向数字世界转化的基础。这一步可以借助物联网（Internet of Things，简称 IoT）完成。物联网，顾名思义，就是「万物相连的互联网」，是将各种信息传感设备与互联网结合起来的网络，它可以在任何时间、任何地点将能够独立发挥作用的物体连接在一起，实现互联互通。所以物联网的核心和基础仍然是互联网，它只不过是在互联网基础上进行了延展，扩展到了任何物品与设备之间。物联网上涵盖了大量的数据，各设备相互连接并且不断地进行数据交换。将物联网上的数据经过数据采集、数据分析和数据处理后，我们再把这些数据存储在标准化数据集合里，物理世界的抽象过渡就基本完成了。

但仅仅完成数据的抽象是远远不够的，工业 4.0 时代要做到数字化驱动物理世界并改变物理世界。因此，这里我们要引入一个概念 —— CPS（Cyber-Physical Systems），即信息物理融合系统。这是一个综合计算、网络和物理环境的复杂系统，它将计算、通信与控制深深地嵌入物理过程，使之与物理过程密切互动，实现了计算进程和物理进程的统一，从而给物理系统添加了新的能力。信息物理融合系统包括了很多智能系统，通过建立物理世界数据的人工智能模型，在数据采集输入后，系统可以进行管理、操作和预测，从而把相应的决策和洞察再反馈到物理世界。

2-3『信息物理融合系统（CPS），在之前研读的有关「智慧工厂」多篇论文里看到。做一张术语卡片。（2021-02-28）』——已完成

所以，CPS 紧密连接了物理世界和数据计算，通过计算进程和物理进程相互影响的反馈循环，实现深度融合和实时交互来增加或扩展新的功能，达到实时监督或者控制物理世界的目的。也就是说，CPS 不但可以看作工业数据的集合地，而且同时将这些数据进行机器学习或深度学习，建立起物理世界的数据模型，并且基于这些数据模型产生智能预测和决策，从而最优化地驱动和改变物理世界。

总体来说，物理世界的数字化过程首先要有数据，然后通过 IoT 打通生产制造环节将数据整合在一起，再通过建立相应的人工智能模型，进一步理解整个生产制造过程，比如其中的某一个步骤需要怎么调控参数，怎么优化生产制造的目标，从而形成最优化的决策，实现效果的提升。其中，CPS 不仅可以实现针对物理世界的实时计算，还可以通过数字世界建立的模型将操控指令反馈到物理世界，驱动物理世界的调控和改变。

### 0301. 人名卡 —— 丁磊

本书作者。

美国俄亥俄州立大学人工智能专业博士，美国哥伦比亚大学博士后，持有斯坦福大学高级项目管理证书。

人工智能商业化落地先行者，曾为硅谷明星公司 PayPal 创立了人工智能平台并担任负责人，历任百度金融首席数据科学家、PayPal 全球消费者数据科学部创始负责人和腾讯腾云智库专家等高级职务，并曾在 IBM Watson 研究院和美国伊利诺伊大学贝克曼研究所从事研究工作。

2018 年被第一财经和阿里巴巴旗下的 DT 财经联合评选为中国「数据科学 50 人」成员。在人工智能和数据科学领域具有近 20 年从业经验，成功帮助过国内外包括世界 500 强在内的数十家企业运用人工智能提升效益，与中国农业银行、中国电信、万科集团、联合利华和亿客行等行业巨头达成过深度合作，推动人工智能战略的落地和升级。在 IEEE 会刊和多个学术会议等发表高质量论文 20 余篇，获得美国专利 4 项，担任 20 多个权威国际期刊和专业会议的特约审稿人或委员会成员。

3『

谷歌学术里搜索：Lei Ding + AI，找到一篇 Paper：[Artificial intelligence system of faster region-based convolutional neural network surpassing senior radiologists in evaluation of metastatic lymph nodes of rectal cancer](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6595714/)。应该就是作者了，已经存入 Zotero，待确认信息。（2021-02-21）

[https://ieeexplore.ieee.org/author/37267078500](https://ieeexplore.ieee.org/author/37267078500)

』

### 0401. 金句卡 ——

最后根据他写的非常震撼的话语——产生一张金句卡。

### 0501. 数据信息卡 —— 人工智能的分类

信息摘自「2021068AI思维0000.md」：

人工智能可以分为弱人工智能、强人工智能和超人工智能。目前人工智能处在弱人工智能阶段，这意味着人工智能的能力是针对特定领域的，它只在某些方面比人强。因此，人工智能作为一个赋能的体系帮助行业升级换代，一定要跟具体的应用领域深度融合在一起。人工智能的应用领域非常广泛，在零售、工业、金融、教育和医疗等行业中起着越来越重要的作用。人工智能的落地也迫使人类社会重新分工，促使这些传统行业迅速转型与升级。

2『人工智能的分类，做一张信息数据卡片。（2021-02-20）』

我们日常生活的方方面面都需要决策，不论是应用于哪种业务场景下的人工智能系统，想要发挥作用，都需要通过模型来解读数据并作用于业务，达到优化决策的效果。思维的高度决定了决策的质量，因此，如果说人工智能是未来社会发展趋势的话，那么我们有必要做一些相关知识的普及和思维的传播。人工智能技术不仅可以改变我们的生活方式，当它转化为一种思维时，更能真正地为我们的人生带来裨益。

### 0502. 数据信息卡 —— AI 在工业领域应用所遇到的难点

信息摘自「2021068AI思维0701.md」：

虽然人工智能现在已经能为工业领域乃至整个人类社会带来很大的裨益，但目前人工智能仍处于早期的发展阶段，在推动人工智能在工业领域落地的过程中仍然存在着诸多的问题。其中最主要的问题是工业业务理解中的巨大门槛和工业应用定制化程度高的问题。在一个细分问题对应一个模型的情况下，如果要在工业领域落地，那么涉及的细分问题成千上万，繁杂程度可见一斑。另外，还存在一系列问题，如技术门槛高，人工智能人才在短期内难以有效补充；行业缺乏统一的系统和标准，应用开发和实施成本高；所依赖的数据的完整性和质量有待提高；应用场景的碎片化、个性化、专业化制约着复制推广和用户接受程度等。由此可见，人工智能要还有很多难关需要攻克，但人工智能所蕴含的强大动力让我们有足够的信心相信在未来的发展过程中，它能够不断完善，解决这些问题，逐步实现在工业领域的落地。

1-2『这里讲到了 AI 在工业领域应用所遇到的难点，做一张信息数据卡片。（2021-02-21）』

虽然企业还是需要按部就班地进行生产制造，但人工智能已经开始为整个工业领域带来很大的颠覆，加速生产制造进入工业 4.0 时代的步伐。人工智能带来的是为整个工业的强大赋能，从生产优化到供应链管理，从降低成本到提升效益，从降低能耗到智能环保，从立足数据到驱动决策。这是人工智能赋予工业的强大动力，也是 AI 思维下工业转型的必由之路。

### 0601. 任意卡 —— AI、机器学习和深度学习的关系

我们知道，机器学习是人工智能的分支，它专门研究计算机如何模拟和实现人类的学习行为。在人工智能发展过程中，机器学习占据核心地位。通过各种模型，机器学习可以从海量的数据中学习出规律，从而对新的数据做出智能识别或者预测，并且为决策提供支持。深度学习是机器学习的一种。如图 3-4 所示，人工智能是一个范围很大的概念，其中包括了机器学习。机器学习是人工智能提升性能的重要途径，而深度学习又是机器学习的重要组成部分。深度学习解决了许多复杂的识别和预测难题，使机器学习向前迈进了一大步，推动了人工智能的蓬勃发展。那么深度学习又是如何发展起来的呢？

1-2『看到这里的信息才算明确了：AI、机器学习和深度学习的关系，做一张任意卡片。（2021-02-26）』

## 推荐序：「AI 思维」—— 人工智能的落地指南

肖京

近年来，AI 越来越成为万众瞩目的焦点。随着大数据、物联网和 5G（第 5 代移动通信技术）等技术的发展，「万物皆可 AI」不再仅仅是一个美好的愿景，人工智能早已进入我们的生活，并作为核心驱动力，对各行各业进行了深刻的塑造和改变，推动着国家战略、经济结构和商业模式的升级革新。纵观生活的方方面面，人工智能已经和我们的日常生活连接在了一起，并且与每个人都息息相关。智能革命是大势所趋。

人工智能可以分为弱人工智能、强人工智能和超人工智能。目前人工智能处在弱人工智能阶段，这意味着人工智能的能力是针对特定领域的，它只在某些方面比人强。因此，人工智能作为一个赋能的体系帮助行业升级换代，一定要跟具体的应用领域深度融合在一起。人工智能的应用领域非常广泛，在零售、工业、金融、教育和医疗等行业中起着越来越重要的作用。人工智能的落地也迫使人类社会重新分工，促使这些传统行业迅速转型与升级。

2『人工智能的分类，做一张信息数据卡片。（2021-02-20）』

我们日常生活的方方面面都需要决策，不论是应用于哪种业务场景下的人工智能系统，想要发挥作用，都需要通过模型来解读数据并作用于业务，达到优化决策的效果。思维的高度决定了决策的质量，因此，如果说人工智能是未来社会发展趋势的话，那么我们有必要做一些相关知识的普及和思维的传播。人工智能技术不仅可以改变我们的生活方式，当它转化为一种思维时，更能真正地为我们的人生带来裨益。

我与丁磊博士在人工智能领域有颇多的交流，我们都认为人工智能不应该是浮于表面的概念。人工智能具有深刻的内涵，值得我们静下心来研究，也值得生活中的每个人去理解。人人都能学 AI，人人都能懂 AI，AI 也能为人人所用。丁磊博士在人工智能领域工作近 20 年，总结出了一套颇具特色的人工智能知识体系和思维方式 ——「AI 思维」。AI 思维是一种通过数据驱动决策的思维模式，包括数据、模型、算力和业务模式四要素。从数据出发，通过模型和算力形成决策，最终在业务中产生价值。因此，AI 思维的基础在于数据，核心在于模型，实现在于算力，应用在于业务模式。从这种意义上说，本书深入浅出，从「道」「法」「术」「器」「用」「势」几个方面循序渐进地向读者介绍了从数据中创造价值的「炼金术」。

2『 AI 思维是一种通过数据驱动决策的思维模式，包括数据、模型、算力和业务模式四要素。AI 思维，做一张主题卡片。（2021-02-20）』——已完成

毋庸置疑，人脑和人工智能在处理信息上存在相似之处，我们对事物的认识可以分为四个阶段：信息、经验、规律和思维。这是一个动态的过程，从单个信息的联系中形成经验，在经验中发现规律，再提炼升华出思维。思维阶段，也是方法论层次的总结，进一步指导实践，不断找出更多的规律和结论。人工智能的底层逻辑就是数学规律，万丈高楼平地起，从底层逻辑中衍生出人工智能的知识体系。人工智能落地意味着从数据中产生价值，在这个过程中人工智能既是方法和工具，也是思维逻辑，可以指导行业的应用和发展。

未来的时代一定是智能化的时代，人工智能作为各个行业的风口，也必然会成为未来社会的发展趋势。《AI 思维》总结了人工智能落地实践的全过程，并且具有优化各种业务的突出价值。而对于个人来说，AI 思维可以帮助我们更深入地理解我们所处的时代，把握时代的机遇和发展方向，最终帮助我们更好地生活和工作。这是人工智能的使命，也是我们理解人工智能的意义。

此推荐序作者肖京博士，现任中国平安集团首席科学家、集团执委，曾获第九届吴文俊人工智能杰出贡献奖。

## 前言

数字时代，既是机遇，也是挑战。互联网、大数据、人工智能的发展使得生产、商业和生活的各个领域都发生了改变，新生信息层出不穷，知识总量爆炸式增长。面对这个日新月异的时代，我们 —— 渺小的个体，有限的精力，受限的知识面 —— 唯有不断更新自我，提升认知，才不至于被激烈而残酷的竞争所淘汰。

我们要改变原有的认知方式，如果单靠知识填充，难以达到质的改变，需要转换思维模式。我一直相信，万事万物皆有规律，只有快速把握规律，才能理性认识存在，提升思维能力，抓住时代脉搏。当然，数字世界也不例外，数据之中也有规律性。在利用人工智能（AI）发现和挖掘数据规律与价值的实践中，我认识到人工智能不仅是一种技术方法，其中蕴含了一种思维逻辑，也就是 AI 思维，这才是人工智能的真正精髓，它集中体现在对数据理解方面的优势，能够帮助我们突破认知局限，从而找到自身的真正优势，获得展现个体主动策略优势的收益。

2『上面的信息补充进主题卡片「AI 思维」里去。（2021-02-20）』——已完成

我与人工智能的故事早在 20 年前就开始了。世纪之交入学浙江大学，「形上谓道兮，形下谓器」的校歌时至今日仍不时回荡在我的耳边。我对人工智能的探索便开始于在浙江大学读书的阶段。大学四年，我从「器」的层面了解人工智能、机器学习、模糊数学以及神经网络等领域。当时，越来越多的富媒体数据出现在互联网上，我便猜测人工智能接下来的使命是让计算机自动理解这些数据，从而增进用户的效率和体验。读博士时，我毫不犹豫地将当时相对冷门的人工智能作为专业方向，因为我深信人工智能将成为信息技术的下一范式。

我对 AI 思维的认识和总结，是从实践中不断丰富而来的。在美国博士毕业后，我先后经历过高等研究院所、国际大型企业以及各个阶段的创业公司，服务过 IBM（国际商业机器公司）、亿客行（Expedia）、Orbitz（旅程网）和 PayPal（贝宝）等公司。在硅谷，我也成为将人工智能运用于深度商业运营的早期实践者和探路人之一。早在 2011 年，我领导建立的人工智能系统在全球最大的在线旅游平台亿客行上线，通过电商网站访客的行为信号，精准预测访客线上消费行为，并以此为基础投放恰当的广告。这是业内较早、规模较大的电商行为预测和智能营销平台，至今仍优化着全球数以亿计的用户体验。后来，作为 PayPal 全球消费者数据科学部的创立者和负责人，我在电商、支付和广告领域通过人工智能和深度学习技术，领导团队开发了基于大数据的消费者动机预测引擎、精准推荐引擎以及最佳行动引擎，大幅度提升了全球数百万商家的赢利性和数亿用户的购物体验，并因此受邀在哈佛大学、麻省理工学院等学校做专题演讲。

在美国工作期间，我同样关注国内人工智能的应用和发展，发现国内人工智能的研发与商业运用之间存在脱节的问题。而后我应邀回国工作，致力于发掘人工智能在行业中新的增长点。在百度金融任职首席数据科学家期间，我负责金融领域的数据挖掘和变现，通过大规模特征挖掘和深度学习技术，从海量的互联网数据中提取金融相关变量，提升金融产品的市场竞争力，运用人工智能帮助金融机构升级换代，促进普惠金融的健康发展。

从对人工智能模型的攻坚克难到运用人工智能帮助企业解决业务问题，在长期实践中，我逐渐体会到，人工智能作为一种技术，可以用于商业活动中，处理数据，提高效率，提升体验。但是，人工智能远不仅是一种技术。当下人人都在说人工智能，但往往都说不清。自从 1956 年达特茅斯会议「人工智能」的概念正式提出，人工智能既经历过至暗时刻，也经历过辉煌岁月。什么是人工智能？这是一个很多人在尝试回答，但是又感觉力不从心的问题。

提到人工智能，大众的认知普遍是无人驾驶、视觉识别、语音识别或者是像 AlphaGo（阿尔法围棋）那样的机器人等，但其实这些只是人工智能的具体应用，只是人工智能的冰山一角，却在很多人心中成了人工智能的代名词，这说明目前对人工智能的认识还有局限性。运用于商业各个领域以及工业生产、日常生活中的人工智能是有共通之处的，可以从「器」的层面总结升华出「道」，即一套特有的思维模式 ——AI 思维。人工智能不仅仅是一种先进技术，其核心意义是一种分析数据的思维模式。深受我的合作导师、计算机视觉之父黄煦涛等几位学术大师的影响，我深信一切现象和对应的数据必有规律性，而 AI 思维就是发现和发掘这种规律性的强大工具。

2『这里的信息补充进主题卡片「AI 思维」里去。（2021-02-20）』——已完成

AI 思维，简单来说就是从大量数据中形成模型，进而对未知情况做出最佳预测的思维模式。这样的预测无论对个人、组织还是社会整体，都有积极的意义，能够避免经验主义带来的主观、片面的判断。AI 思维的基础在于数据，核心在于模型，实现在于算力，应用在于业务模式。AI 思维与大数据相伴相生，恰如炼油的过程，大数据是原油，AI 思维则是从原油中提炼产品产生价值的「炼金术」。

AI 思维也是对现有科学体系进行「数据驱动」升级的方法论。人工智能给社会带来的价值远不只哗众取宠的「黑科技」，也不只是给人们带来便捷或者帮助企业重塑商业模式，它最终能够关乎民生的方方面面。无论是在零售还是金融行业，抑或是在医疗和教育领域，通过 AI 思维你都能更快速、更直接、更准确地预测个体的行为或表现结果，从而既能满足行业发展本身的需求，又能在实践中创造出前所未有的价值，将先进的经验和知识惠及所有人。想象一下，通过人工智能，所有的病人可以获得全球最优秀医生的诊断和治疗，所有的孩子可以获得全球最先进的教育方法的培养，我们生活的世界将会变得怎么样？「千百支蜡烛可以被一支蜡烛点燃，而那支蜡烛的生命不会因此缩短。」在人工智能时代，每个人的数据都可以转化为知识，帮助别人并由此受益。

我阅读过很多面向大众的人工智能方面的书籍，其中讲述「器」和「用」的居多，很少涉及「道、法、术」层面。而且，「器」的介绍较容易变成「动物园」模式，仅仅介绍了人工智能算法，没有总结上升到理论和法则的高度，而「用」层面的案例也主要集中在智能机器人和无人驾驶汽车等吸引眼球的领域，缺乏必要的系统化行业落地框架和实践。这也难怪读者很容易将人工智能误认为是明天的科技，或将人工智能局限地认定在几个特定的领域。在这样的理解下，很难把握人工智能的思想精髓，人工智能对个人和社会的潜在影响也大打折扣。所以，本书试图打破这种局限，分为八章，精心设计「道、法、术、器、用、势」体系，旨在避免上述的问题，既包括 AI 思维的方法论，也包括 AI 思维在行业中的应用和发展，帮助读者从宏观到微观、从理论到实践，一步步、一层层地通过系统性框架，逐渐脱下人工智能神秘的外衣，帮助读者理解 AI 思维的实质以及对每个人的价值和意义。这是我创作本书的初心，但也深知长路漫漫，任重道远。

具体来说，本书第一章从「道」的层面阐述 AI 思维内在逻辑和价值，用 AI 思维来思考问题；第二章从「法」的层面介绍 AI 思维的底层逻辑，从规律的角度了解 AI 思维；第三章从「术」的层面讲解 AI 炼金术如何通过数据驱动决策，形成一套从数据到价值的完整方法论；第四章从「器」的层面引入人工智能落地所涉及的方法和模型，模型在 AI 思维中具有核心位置；第五、六、七章从「用」的层面分别介绍数字化赋能、人工智能平台化思维和人工智能实战案例；第八章从「势」的层面介绍人工智能落地过程中存在的挑战和相应的对策，期待人工智能未来的发展。

本书的章节分别从不同角度逐一阐述 AI 思维的价值和意义，大部分内容都以「数据 + 人工智能 + 场景 = 价值」作为核心逻辑，希望任何一个不想在新经济中落伍的人，在阅读本书之后，都能理解 AI 思维，并对工作和生活有所助益。

## 后记

人们在各行各业的长期实践中积累了大量的知识。在这个过程中，数据经过处理成为信息，而信息提炼沉淀为知识。人们从各种渠道获得知识，文明由此而延续。然而面对浩海般的数据，传统的分析方法无论在效果还是效率上都显得力不从心。通过 AI 思维的支持，我们可以有效地拥抱海量的数据，驱动最佳的决策，从数据中挖掘持续的价值。得益于此，在人工智能时代，每个人的数据都可以转化为知识，使自己和他人受益。恰逢本书定稿之际，人工智能作为新型基础设施建设的方向之一，再次站上风口，这意味着人工智能有机会为未来社会的发展提供全方位的服务，真正能够为人人所用，使人人受益。

然而，人工智能的特点决定了这个领域的创新所带来的价值在时间上是有延迟的，不能够立竿见影，而且人工智能很难像华丽的交互界面那样为人所感知。如何在不确定的预测面前寻找确定性的业务结果，并带来可量化的价值，确实是困扰着机构和人工智能从业者的一大难题。所以，我希望本书能够为即将开展人工智能工作的人们提供一个相互理解与信任的平台，在这个平台中，他们能够了解人工智能的思维框架与运行逻辑，从而更有效地进行规划与交流。

最后，我想感谢在我从事人工智能工作以来，指导和帮助过我的师长、同事和合作伙伴，以及一同在这条路上探索的同人们。本书中许多观点的形成得益于和你们的讨论、交流以及思想碰撞。本书的部分内容源于我给中高层管理人员授课的材料，学员们的反馈坚定了我写作的信念。矫凤涛和刘书颉在本书写作过程中给予了大力协助，在此表示衷心的感谢。

「路漫漫其修远兮，吾将上下而求索。」虽然人工智能时代已经到来，但道路险阻，前途未知。幸运的是，同人们探索和深耕的决心，以及社会各方对人工智能的关注与支持，一直为我在这条路上的前行提供动力。我相信，人工智能的发展，未来可期。