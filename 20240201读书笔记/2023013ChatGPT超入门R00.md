参考：方军.(2023).2023013ChatGPT超入门.中信出版社 => xxxx

## 导读：向 AI 提问的 8 个原则性技巧

⽅军

2023 年 7 ⽉，第⼀版。代《ChatGPT for Dummies》译者序

ChatGPT 对你来说意味着什么？你该如何⾼效地利⽤它的超能⼒？

2022 年底，OpenAI 公司推出的 ChatGPT 聊天机器⼈开启了 ⼈⼯智能（AI） 的新时代，⾃此 AI 进⼊⼤众应⽤阶段。ChatGPT 只有⼀个简单的对话式界⾯，但通过这个界⾯，每个⼈都可以向它提问（如「这是什么意思？」），或向它提出要求（如「帮我撰写邮件初稿」、「帮我按说明编写程序」）。

很快，它背后的 AI 模型以应⽤助⼿的形式出现在各种软件⾥，⽐如 Notion 笔记软件、微软公司的办公软件以及各类企业营销软件。微软巧妙地将这类⼯具命名为「副驾驶」（Copilot），这个名字象征着，AI 助⼿坐在副驾驶位置上，为我们⼈类⽤户提供⽀持和引导。

AI 应⽤新阶段的两个关键词分别是⼤众应⽤与⽣成。让我们关注「⽣成」，这⼀ 波 AI 模型的特点正是它们能够⽣成新的内容。整个 2010 年代，占据主导的模型是判别式的，例如这些模型能指出「这张图⾥有⼀只猫」。现在，新模型能够⽣ 成新的⽂字、图像以及合成数据，⽐如它能根据你的指引写⼀个猫的故事，它能⽣成⼀张新的猫的图⽚，它能总结出之前未被明确表述的规律。

在 ChatGPT 以聊天机器⼈的形式引爆热潮之前，在 2022 年年中，由⽂字⽣成图 ⽚就已经开始突破，并在和视觉有关的产业中得到应⽤。但是，对话界⾯直接将 AI 模型的各种能⼒展现在⼈们⾯前：语⾔理解、⽣成⽂本、⼴博⼜有深度的知识、指令遵循能⼒、推理能⼒等。这让所有⼈都感到震撼。这种震撼感是必然的，因为我们⼀直认为语⾔和⼈的智慧直接关联。⼈⼯智能⼀直被⼀个问题牵引着，即「机器能思考吗？」这⼀次，我们向前迈进了⼀⼤步：如今，机器能够有效运⽤语⾔了，它似乎能思考了。当然，答案取决于你如何定义思考。

传媒和产业界通常⽤「⼤模型」来说新⼀波 AI 浪潮，以强调这⼀次有着⽂本与图像⽣成能⼒的 AI 模型，即深度学习⼈⼯神经⽹络模型的参数之⼤，但更精确的说法应该是「⽣成式 AI」（Generative AI），或综合⼆者称它们是「⽣成式 AI ⼤ 模型」。⽣成式 AI 模型⼜可进⼀步分成两类，主要处理⽂本的⼤语⾔模型与采 ⽤扩散算法的图像⽣成模型。但通常认为预训练语⾔模型是更基础的，以 OpenAI 为例，它的⼤语⾔模型 GPT ⽀撑着 ChatGPT 聊天机器⼈，同时它的图像⽣成模型 Dall-E ⼜是基于 GPT 和图像数据进⼀步训练⽽来的。

假设我们站到多年之后看，2023 年上半年也注定是 AI 发展历程中最为沸腾的六个⽉。在 OpenAI 的 GPT 模型探明了路径、ChatGPT 聊天机器⼈确认了⼤众需求之后，⼤语⾔模型在数量上和质量上都出现了⼤爆发，应⽤更是层出不穷。我们来看看这六个⽉中爆发式出现的⼤语⾔模型，其中有些是之前模型的新版本：OpenAI 的有⼒竞争者 Anthropic 推出 Cluade 模型及聊天机器⼈。Facebook ⺟公司 Meta 在 2 ⽉推出 LLaMA 开源模型，3 ⽉斯坦福⼤学团队基于它训练了微调版本 Alpaca，这⼀开源体系已发展成繁荣的⽣态。⾕歌公司推出 PaLM 模型，百度公司推出⽂⼼⼀⾔⼤语⾔模型，阿⾥推出通义千问模型，华为推出华为云盘古⼤模型，科⼤讯⻜推出讯⻜星⽕认知模型。清华⼤学团队与智谱公司推出 ChatGLM 模型，阿联酋科技创新研究所推出 Falcon–40B 模型，王⼩川创业团队推出百川模型。在模型开源平台 HuggingFace 上，⼏乎每天都有新的模型、新的微调版本出现。同时，⼤量和⼤语⾔模型相关的论⽂被发表，⼏乎每个相关的细分领域都被深⼊地研究。

简⾔之，ChatGPT 揭开了⼀场未来变⾰的开端：现在，⼈们已经找到⼀种⽅ 法，可以将⼏乎⼈类所有的书⾯化的知识与能⼒压缩进模型，然后我们⼜可以将这些知识与能⼒调取出去使⽤。过去⼏⼗年，互联⽹带来的变⾰是以搜索引擎为象征的「让信息触⼿可及」，现在，这个变⾰的实质是⼤语⾔模型和聊天机器⼈所代表的「让知识触⼿可及」。这给每个⼈带来的冲击是显⽽易⻅的：之前，我们个⼈依靠经漫⻓的求学和实践⽽来的知识与能⼒占据某些独特优势。现在，所有⼈都可以直接向模型调取这些知识与能⼒，这意味着，别⼈能轻松运⽤你⾃以为很独特的知识。如果你的知识和技能能被别⼈轻松超越，你怎么办？

并且，AI 甚⾄能够帮我们直接完成某些任务。在做有些⼯作与任务时，⼈可以被排除在外。例如，AI 助⼿完全可以直接提取数据、查阅资料、进⾏分析，⽣ 成带有数据分析和建议的报告给我们，中间⽆需我们的介⼊与参与。如果你的 ⼯作可以由机器直接完成，你怎么办？

因此，⾯对这样的巨变，我们应该严阵以待：不能以为它就是聊天机器⼈⽽ 已，也不能因为⼀时恐惧⽽拒绝⾯对。回顾每⼀个曾经对⼈的⼯作、⽣活产⽣ 巨⼤影响的技术浪潮，⽐如个⼈电脑、互联⽹、移动互联⽹，我们都会发现，有效的应对之道是，理解它的原理与影响，了解它带来的新能⼒，更为重要的是，尽早尝试使⽤它，尽快熟练运⽤它。

幸运的是，使⽤⽣成式 AI 有⼀条捷径，它有⼀个统⼀的运⽤⽅式。我们向模型给出所谓的提示语（prompt），也就是向它提出问题、给出任务。它会理解我们的意图，并⽤新⽣成的⽂字、图⽚、⾳视频等即时回应我们。这本书聚焦的是 ChatGPT 聊天机器⼈和它背后的⼤语⾔模型，因此接下来，我将尝试根据作者的讨论以及我们⾃⼰的研究和应⽤实践，从使⽤⼤语⾔模型的⻆度为你列出 8 个向 AI 提问的原则性技巧。

原则性技巧之⼀：理解「⽣成的本质」是模式预测

原则性技巧之⼆：警惕「幻觉」，始终做事实核查

原则性技巧之三：提问采⽤结构化提示语（ICDO）

原则性技巧之四：模型能从提示语中直接学习

原则性技巧之五：让模型进⾏「链式思考」，采⽤慢思考模式

原则性技巧之六：将复杂的任务分解成更简单的⼦任务

原则性技巧之七：⽤模型能够理解的格式输⼊信息

原则性技巧之⼋：坐稳主驾驶位，与机器共舞

研究者、开发者、使⽤者们已经收集整理了⼤量技巧，这⾥试图为你梳理列出那些基础元素（element），也就是原则性技巧。另外，在了解如下原则性技巧前，你还应该知道⼀个预备技巧：在学习和使⽤⽣成式 AI 的过程中你有任何疑问，你都可以直接向 AI 提问，它会给你即时的、针对性的回答。值得注意的是，这些原则不只是适⽤于 ChatGPT，它适⽤于所有的⼤语⾔模型。

### 原则性技巧之⼀：理解「⽣成的本质」是模式预测

通过聊天机器⼈与我们对答如流的 AI 模型真的会说话和写作吗？能够按我们的 ⽂字描述绘制出图⽚的 AI 模型，它是否真的拥有如同达芬奇绘制蒙娜丽莎的技艺？它⼜为何能「拍摄出」想象中的照⽚？只有理解⽣成的本质，我们才能⽤好这⼀新出现的新技术，同时也不致于误⽤、错⽤它。

本书作者在第⼀章即强调了⽣成式 AI 模型的本质是「模式预测」。他写道：

ChatGPT 不像⼈类那样思考。它基于其已学习到的模式进⾏预测，然后根据其所预测到的偏好和单词顺序，（组织成⼀句句话）进⾏回答。这就是为什么它⽣成的内容可能⾮常优秀，也可能是错得离谱的。当它的预测准确时，魔⼒就出现了。它的数字⽔晶球有时候是正确的，有时候可能是错的。

⽣成的本质是模式预测，这是为什么有⼈说，⼤语⾔模型是「下⼀个词预测器」。这也是为什么它看起来有语⾔表达能⼒、代码编写能⼒、掌握某些知识与信息、具有推理能⼒等。当它预测的词句形成连贯、有条理的意思时，我们认为它掌握了这些能⼒，但实际上，它仅仅在做预测。你可以这么看，我们在说话和交谈时，我在写这篇⽂章时，我们做的也是根据⾃⼰学到的模式进⾏「预测」⽽已。

了解到模型仅是在做预测，这会让我们减弱两种谬误：

第⼀是「轻信」。我们容易轻信⽂字通顺、格式正确的话，就像更容易相信穿着考究的骗⼦。形式是形式，内容是内容。知道模型仅是在做预测时，就可以⼤ 幅减少轻信。

第⼆是「轻视」。⽣成式 AI 模型⽣成的内容中很容易有错漏。⽤图像来说可能更为形象，⼀年前，AI 画的图⽚像拙劣的画笔乱涂乱抹，⼀年后，它能够模仿艺术家的绘画和摄影师的照⽚。但是，虽然进步很快，错漏和不合理仍是难免，我们看到过很多 AI ⽣成的漂亮但错误的画⾯。当⼤语⾔模型完全出错时，它会胡说⼋道，也就是它出现「幻觉」（hallucination）。这些错漏会让我们轻视 AI 模型。

了解到它仅是在预测，同时预测能⼒在快速进化，会让我们摆脱轻视的⼼态，去按它当前的能⼒⽔平去尝试着利⽤它。

了解⽣成的本质是学习模式并做出预测，还可以让我们避免将「⽣成式 AI」与「搜索引擎」混淆与误⽤。简单地说，搜索引擎根据你的关键词检索出互联⽹上已经存在的链接和⽂本，⽽⽣成式 AI 则是通过模式预测，根据你的提示语⽣成出新的内容。它们不是替代关系，⽽是互补关系。

### 原则性技巧之⼆：警惕「幻觉」，始终做事实核查

在本书中，作者这样定义⽣成式 AI 模型的幻觉：「（它）会⾃认为给你了⼀个正确答案，对此⾮常有信⼼，但实际上，它给出的是⼀个明显的错误答案，即产 ⽣了幻觉。」这是为什么⼈们说它们会胡说⼋道。那么，⼤模型的研究者、开发者们能否彻底消除幻觉呢？作者给出了精彩的解答：

（它）能够⽣成回答的能⼒，也正是导致其不可靠的原因。为了让⼈类或机器想象出不存在的事物，如⼩说或电影中的虚构世界，必须先解放它们，即让它们摆脱现实规则的限制。

简⾔之，我们如果要让它具备⽣成能⼒，就必须容忍它可能产⽣幻觉。我们只能尽量压制它的幻觉，但⽆法彻底消除。

从技术⻆度看，⼤语⾔模型在做下⼀个词预测时，会根据所谓温度参数的不同来选词。温度低时，从较相关词中选择，温度⾼时，则扩展到更多可能的词。ChatGPT 聊天机器⼈选⽤了⼀个相对较⾼的温度（据猜测可能是 0.7），这让它的回答不会显得过于呆板。但当我们希望回答更贴近原始材料时，我们会选择把温度降到接近于 0。

幻觉问题让作者在这本书中反复强调，必须对 AI 的回答进⾏严格的事实核查。实际上，我们应该把这句警告贴在每⼀台使⽤ ChatGPT 或者其他⽣成式 AI 的电脑与⼿机旁边：

始终对它⽣成的内容进⾏事实核查。

我经常演示⼀个例⼦，来试探⽣成式 AI 模型的能⼒，我会提问说：请解释杜甫的「窗前明⽉光」。能⼒较弱的模型会被误导⽽出现幻觉，它会跟着说，这是杜甫的诗，⽽不会⼀眼看出作者是李⽩，同时也看不出诗句应为「床前明⽉光」。这个例⼦也直观地展示了⽣成式 AI 与搜索是不同的。这也是为什么我们同时需要两者：⽣成式 AI ⽤于解释，搜索引擎可协助事实核查。

除了事实核查之外，我们还认为，现在我们更加需要批判性思维，更加需要它建议的质询。批判性思维经典著作《如何提问》建议我们问如下问题：论题和结论是什么？理由是什么？哪些词语意思不明确？假设是什么？论证有没有谬误？证据是否有效？有没有其他可能性？

### 原则性技巧之三：提问采⽤结构化提示语（ICDO）

刚开始使⽤ ChatGPT 等聊天机器⼈时，我们经常进⾏朴素的提问：「什么是相对论？」「给我解释下深度学习。」但我们很快会意识到，我们在向⼀台庞⼤的机器提问，那么，⼀⽅⾯，我们应该遵循基本的提问技巧，另⼀⽅⾯，我们的提问应该符合这台机器的格式。

当我们向⼈请教问题时，我们需要选择向正确的⼈提问，要提供必要的背景信息，要明确提出具体的问题，并尽量说明期待的回答⽅式。向机器提问时，这四个基础技巧也同样适⽤。但机器与⼈⼜不同：机器有很多知识与信息，但它不知道此时的背景是什么；机器也不会向我们询问更多的信息（如「你说的这个什么意思」）；机器更不会重述问题以便更好地回答（如「你的问题是不是……」）。我还可以列出很多区别。

实际上，数年前在 ChatGPT 的模型的早前版本出现时，应⽤开发⼯程师就开始总结如何向 AI 提问的结构化框架。其中，由埃尔维斯·萨拉维亚（Elvis Saravia）等⼈总结的框架被⼴泛接纳，它指出，提示语应按顺序包括四个部分：指令 (Instruction)、上下⽂ (Context)、输⼊数据 (Input Data)、输出要求 (Output Indicator)。我们总是记不住这个框架的顺序，因此，我们为这个框架创建了⼀个巧妙的⾸字⺟缩写 ICDO，当你向 AI 给出提示语后，它回应说：「I See, Do!」（我明⽩了，做吧！）

我们对每个部分做了进⼀步的细化：指令部分应包括⻆⾊、任务、规则；上下 ⽂部分包括技能、步骤、样例；输⼊数据部分不做进⼀步拆分；输出要求部分包括输出规则、输出样例、输出指示符。

在使⽤结构化提示语前，我们的⼀个请求帮忙翻译的提问可能是：「请帮我翻译：（待翻译的英⽂）。」之后，我们的翻译提问就变为：「你是⼀个⼈⼯智能专业⼈⼠，你的任务是将英⽂翻译为中⽂。翻译时请参考如下词汇表：（词汇表略）。要翻译的段落是：（略）。翻译是：」

在这个提示语中，通过界定⻆⾊，我们能够更好地调动 AI 的相应知识与能⼒。很容易直观地理解这种做法：模型是⽤⼤量的质量有⾼有低的资料训练⽽来的，我们赋予它⼀个领域专业⼈⼠的⻆⾊，会触发了算法去调⽤较⾼质量的部分。

在开头明确任务，在最后重复任务，让模型能更好地遵循我们的指令。2023 年 6 ⽉，斯坦福⼤学研究者的⼀篇论⽂《迷失在中间：语⾔模型如何使⽤⻓上下 ⽂》⽤严谨的实验证明了这⼀点：它擅⻓利⽤开头和结尾的信息，⽽对处于中间部分的信息处理得较差。

总体⽽⾔，我们在向 AI 提问时，应该假设它对任务⼀⽆所知，尽量逻辑清晰、 全⾯地阐明我们的要求。结构化提示语 ICDO 的⽬的就是让我们能够做到这⼀ 点。接下来的原则性技巧（4、5、6、7）将进⼀步解释这个框架。

### 原则性技巧之四：模型能从提示语中直接学习

AI 模型掌握了很多知识，但也有很多知识它未掌握。⽐如，截⾄ 2023 年 7 ⽉，OpenAI 的模型的信息是 2021 年 9 ⽉之前的，其他模型也各有⾃⼰的截⽌时间，它们不掌握最新的知识。它也可能不掌握我们所要求的特定的知识，⽐如你的公司独特的⽂档格式要求。它也可能掌握⼀个知识的多种形式，但不能确定你希望采⽤哪⼀种。

这时，我们可以⽤原则性技巧之四来向 AI 提问：模型能够从提示语中直接学习，我们可以在提示语中给它新知识。这个技巧通常也叫「少样本提示」，它是 ⼤语⾔模型发展过程中的⼀个重要⾥程碑。2020 年 5 ⽉，GPT–3 模型发布时，它对应的论⽂题⽬是《语⾔模型是少样本学习器》，这意味着模型能通过我们在提示语中给的数个样本来学习新知识。当然，除了样本之外，我们还可以在上下⽂中提供知识，让模型学习、然后⽴即运⽤。

提供上下⽂知识和样例，以及期望的输出格式样例，我们能让⽣成式 AI 更精准地回答问题。你会发现它很聪明，⼀教就会。⽐如，我们请它帮忙拟回复邮件，给它三个邮件样例，它就能很好地模仿你的表达⻛格。

⼜⽐如，我们想让 AI ⽤⼀个特定的知识框架分析问题，我们可以在上下⽂部分描述这个⽅法论。假设我们分析企业时⽤的是⼀个改造版的波特五⼒竞争⼒分析框架，以适应数字经济时代的产业特征，你会发现，当你把你的⽅法论在提示语中告诉模型后，它可以学会并使⽤这个⽅法论。通常，即便模型掌握某些知识，提问时重述⼀遍⽅法论仍可以让回答更符合我们的需求。

当然，所谓的上下学习（In-Context Learning, ICL）并不像这⾥说的这么简单。举⼀个⼩例⼦，⽐如说，我们希望⽣成式 AI 能够根据我们给的例⼦，快速地学习电商平台上⽤户评论是正⾯还是负⾯。但如果我们给了三个例⼦，分别是正⾯、正⾯、负⾯，这会带来很差的学习结果，模型会倾向于将 2/3 的评论认为是正⾯的，1/3 是负⾯的。但是，这是它从你给的例⼦中学到的。因此，如何提供示例是需要技巧的。如何有效地提供示例，才能正确地引导模型进⾏回答？这是研究者们在重点研究的⽅向之⼀

同时，并不是给的例⼦越详尽越好。2023 年 6 ⽉，⾕歌等机构的研究⼈员在⼀ 篇论⽂的题⽬中直接说明了他们的研究结果 ——《⼤语⾔模型会很容易被不相⼲ 的上下⽂误导》。如果你的例⼦过⻓、相关性⼩，均可能会误导 AI 模型，导致它⽆法有效地回答问题。

### 原则性技巧之五：让模型进⾏「链式思考」，采⽤慢思考模式

⾯对⼀道需要相对复杂推理的题⽬，我们⼈类可以凭直觉直接回答，也可以慢下来⼀步⼀步思考。在《思考，快与慢》中，认知学家尼尔·卡尼曼这样说明： 系统 1 的运⾏是⽆意识且快速，系统 2 将注意⼒转移到需要费脑⼒的⼤脑活动上来，例如复杂的运算。

⽣成式 AI 模型的数学推理能⼒⼀直是它的短板，⽐如甚⾄简单的⼩学⽣数学题它可能做错，带点脑筋急转弯的更会让它迷惑给出错误答案。可能的原因是，它在⽤省计算资源的「系统 1」回答。⼈们很快找到了提⾼它的能⼒的技巧，也就是让它的思考从所谓」系统 1」调整到」系统 2」。

2022 年 1 ⽉，⾕歌研究⼈员在论⽂中证明，「链式思考提示语能让⼤语⾔模型开始推理」。链式思考（Chain of Thought, CoT）的思路是，指导模型⼀步⼀步解决问题。让我们以⾕歌论⽂中的⼀个例⼦来为你解释。在给了⼀个示例之后，我们要求模型解答数学题。注意其中的关键点是，我们在例⼦中直接给出了答案，因此模型也会直接给答案。Q: 罗杰有 5 个⽹球。他⼜买了 2 罐⽹球，每罐有 3 个⽹球。现在他有多少个⽹ 球？

A: 答案是 11 个。

Q: ⻝堂有 23 个苹果。如果他们⽤ 20 个来做午餐，然后⼜买了 6 个，那么他们现在有多少个苹果？

我们把这个问题直接给数种 AI 模型，得到的回答都是「答案是 27」，但这是错的。

只需略微调整示例，在示例中向 AI 展示应该⼀步⼀步做，⽐如像这样：「罗杰开始时有 5 个⽹球。2 罐⽹球⼀共是 6 个⽹球（每罐 3 个）。5 + 6 = 11。所以答案是 11 个。」AI 的回答则会相应地变为：「⻝堂原来有 23 个苹果。他们⽤ 20 个来做午餐，所以他们剩下的是 23 - 20 = 3 个。他们⼜买了 6 个苹果，所以他们现在有 3 + 6 = 9 个。答案是 9 个。」当 AI 放慢思考速度之后，答案就对了。

实际上，对于简单的问题，我们都不需要向 AI 这样展示应该⼀步⼀步做，你只要说⼀个神奇的提示词，它就会进⼊「链式思考」的慢思考状态：

「让我们⼀步⼀步想。」

OpenAI 的「提问最佳实践」⽂档重点讨论了这⼀技巧，这是⼀个给应⽤开发者的指南。它直接告诉我们说，你要给模型时间去思考。它还给出⼀些具体的建议。⽐如（我们的任务是判断⼀个学⽣的解题是否正确），在让模型匆忙得出结论之前，指示模型先⾃⼰找到题⽬的解答，然后再判断学⽣的解题是否正确。

⼜⽐如，让模型做内⼼独⽩（Inner monologue），即把它的分析和推理过程写下来，但作为应⽤开发者我们会把独⽩隐藏起来，只把答案给最终⽤户。这就像是教师要求学⽣做题时必须写草稿，但只需要提交最终答案。值得注意的是，在具体使⽤现在的 AI 模型时，我们发现必须在提示语中告诉模型把「内⼼独 ⽩」回答显示出来才⾏，如果不显示，则链式思考模式⽆法启动。作为应⽤开发者，我们会在⽤户界⾯上隐藏这些「内⼼独⽩」，只展示结果。

总体⽽⾔，向 AI 提问时，要求它⼀步⼀步慢思考，让它把推理过程写下来，这能极⼤提升答案的正确性。

在本书中，作者从⼀个独特⻆度对链式思考进⾏了讨论，即「在对话中思考」：

在对话中产⽣的⼀系列消息可称为「消息串」（thread）。想要提⾼使⽤ ChatGPT 的成功率，你应编写提示语时应将它看成对话消息串的⼀部分。使⽤简单提示语，你得到的回答很可能过于常规或有些模糊。当你以消息串来考虑对话时，你不是仅仅编写⼀系列简单提示语。你做的是，将提问拆分到⼀系列的提示语中，引导 ChatGPT 的回复朝着你希望对话的⽅向前进。

### 原则性技巧之六：将复杂的任务分解成更简单的⼦任务

这个原则性技巧的题⽬我们直接借鉴了 OpenAI 的提问最佳实践中的说法，但这⾥我们来从普通使⽤者的⻆度为你解释。

完成⼤型任务的重要⽅式就是分⼯，总⼯程师对任务进⾏拆解、分⼯到组，各组负责⼈再对任务进⼀步拆解、分⼯到⼈。当我们要让 AI 帮忙完成⼀个任务时，除⾮是较为简单的任务，否则，你作为「总⼯程师」拆解任务，然后逐个让 AI 执⾏，你会得到好得多的结果。

在使⽤对话式的聊天机器⼈时，拆解任务和逐个提问是⾃然⽽然的做法，我们将任务拆解成⼀个问题列表，然后⼀次⼀个提问。要求 AI ⼀次完成复杂任务时，你也可以将拆解⽅法先告诉它。⽐如，它的任务是对客户问题进⾏回答，我们预先告知它，你要处理的客户问题的主要类别为账单、技术⽀持、账户管理、其他常规提问，⽽这些每个类别⼜细分为⼦类别。因此，在接收到客户问题时，它会先按要求进⾏任务分类，然后再尝试回答。

在使⽤⽣成式 AI 时，我典型的使⽤习惯正是这⾥的例⼦中体现的两点：

第⼀，我总是⾃⾏拆分任务到较为具体的点，然后向 AI 提问。问题越具体，答案越符合期待。同时，问题的规模越⼩，也越容易对答案进⾏事实核查。

第⼆，我总是尽量在提示语的上下⽂部分附上完成任务的步骤。让 AI 按照步骤做，得到的结果通常更好。这样做的好处是，我还可以持续迭代步骤，从⽽让之后每⼀次结果都能⽐上⼀次更好。

### 原则性技巧之七：⽤模型能够理解的格式输⼊信息

在⽤结构化提示语提问时，我们输⼊的信息开始变⻓，采⽤便于 AI 理解的格式变得很重要。⽐⽅说，ChatGPT 聊天机器⼈的确能够理解从⽂档中拷⻉出来的 ⽆格式表格⽂字，但若能输⼊ CSV 格式的数据或 Markdown 格式的表格，它能更好地理解表格数据。当然，你可以分步操作，先让它把⽆格式表格数据转化成带格式的，然后再⽤这些带格式数据进⾏提问或请它制作图示。

通常，我们可以参考以下做法，让 AI 更容易理解信息：

⻓段的⽂本⽤特殊的分隔符分开。⽐如，当我们要输⼊⼏段⽂章时，可以前后⽤三个英⽂引号（」」」）将段落包含起来，让模型能够知道这是输⼊的⻓ 段⽂本。⼜如，输⼊编程代码程序前后⽤三个英⽂反引号（```）包含起来。如果要强调句⼦中的某些信息，可以像写⽂章⼀样，⽤引号（「」）将关键词凸显出来，这会让模型注意到。我会采⽤更为直接粗暴的做法，我通常在需要强调的词或句⼦后直接⽤括号加上标注（这很重要！）。采⽤结构化的标识与格式。⽐如，你在提示语⾥直接标明表明序号如第⼀部分、第⼆部分、第三部分、第四部分。⽽每⼀个部分的⼦项⼜进⼀步编号，如 1.1，1.2，1.3 等等。⼜⽐如，如果你提供了多个样本，可以给这些样本加上编号。不要⽤句号来分隔，⽽是⽤分⾏来分隔不同的样本。

在⽣成式 AI 出现之后，有⼈欢呼说，我们跟计算机系统打交道不再需要编程语 ⾔了，可以⽤⾃然语⾔来编程了。但你很快会发现，如果你写的提示语像程序 ⼀样结构清晰、简洁，遵循编程的某些原则（⽐如 DRY「不要重复⾃⼰」），你将得到更好的回答。

另外，在这本书中，作者给了⼀个建议，很值得你参考：

不要只是满⾜于简单使⽤ ChatGPT，或像⼤多数⼈⼀样使⽤。要明⽩，你要 ⽐ AI、⽐其他使⽤ AI 的⼈更有优势，你需要有思考能⼒和创造能⼒。因此，开始寻找新⽅法，让你有优势地运⽤ ChatGPT。尤其重要的是，提⾼你的提问技巧，锤炼这⼀技能到你能够达到的最⾼⽔平，持续地拓展你的思维。

### 原则性技巧之⼋：坐稳主驾驶位，与机器共舞

⽣成式 AI 出现之后，特别是对于那些体会到模型的强⼤能⼒的⼈来说，⼈们的 ⼀个担忧是，我的⼯作会不会被机器所取代？

在本书中，作者借⽤《星际迷航》中博格星⼈的说法，「抵抗是徒劳的」。「AI 快速进步、被⼴泛应⽤，这是⽆法避免的事，你如何看并不重要，它们必将会继续存在下去。」同时，我与作者在⼀个问题上观点⾼度⼀致，即没有必要担⼼所谓统治⼈类的冷酷的「机器霸主」会出现。它们只存在于科幻⼩说之中，在可⻅ 的未来都不会发⽣。简⾔之，强⼤的 AI 不可避免，但我们没必要恐惧不存在的东⻄。

⾯对这样的剧变，我们应该如何做？对个体⽽⾔，答案很清晰。如果某些⼯作 AI 能够做得⽐我们更好、效率更⾼时，我们应做的是，通过向 AI 提问让它做，⽽不是继续⾃⼰做。⼀⽅⾯，我们要掌握⾼超的技巧，以发掘 AI 的最⼤潜⼒。另⼀⽅⾯，我们要选择去做更有创造性、更有挑战性、也更有成就的任务。

我们要深⼊思考这个原则性技巧 ——「坐稳主驾驶位，与机器共舞」。副驾驶越来越强⼤对我们是好事，同时，我们要认识留在我们肩上的四项重⼤责任：

1. 追问⽬的。当你提问或提出要求时，你要达成的⽬的是什么？我们现在可以借助 AI 追求更⾼的、更难、更创新的⽬标。

2. 学会提问。你需要掌握向 AI 提问的技巧，以得到优质的回答。你总是需要多问⼀下⾃⼰：如果改变下提问⽅法，我会不会得到更好的回答？

3. 判别与鉴赏。你要有判别⼒，能够判断答案是对、是错。你更要有鉴赏⼒，知道什么是杰出的答案、或有启发的答案。

4. 承担责任。当你将回答应⽤于现实世界时，获得收益或遭受损失的是你，⽽ ⾮ AI。

以上就是向 AI 提问的⼋个基本原则。在使⽤⽣成式 AI 时，你会发现这些原则是所有各种技巧的基础。但我们也可以说，技巧本身并不重要，真正重要的是你如何运⽤这些或其他技巧，获得⾃⼰想要的回答，实现⾃⼰的⽬标和愿景。

## 0301. 编写 ChatGPT 提示词

参考：方军.(2023).2023013ChatGPT超入门.中信出版社 => 0301. 编写 ChatGPT 提示词

的空间，你可以删除不需要存储的对话，也可以将数据复制或导出到其他地方存储。你还可以如图 3-6 那样，当一场对话结束时，请 ChatGPT 为你将对话编写为摘要。

图 3-6：ChatGPT 告诉你如何总结之前的对话，保留对话精髓但释放出对话历史存储空间。

图中信息：

提问：如何让你为我总结一次聊天？

回答：要让我为你总结一次聊天，你需要提供对话的关键要点或主要观点。你可以复制粘贴聊天文本，或者简单概述对话的内容。有了这些信息，我将为你提供一份简明扼要的聊天总结，并突出重要主题和结论。

ChatGPT 会记得你在同一场对话中先提出的问题，并基于这些信息继续与你对话。但是，这种记忆是有限的。具体来说，模型可以记住对话中最多约 3000 个单词或 4000 个标记符。它不能引用你们的其他对话，不管它们是发生在几周之前还是刚刚发生。

如前所述，ChatGPT 将你的提示语变成标记符。但是，标记符不一定由一整个单词组成，因为空格和其他信息也可以包含在标记符中。OpenAI 建议开发者将标记符视为「单词的片段」。

英语与许多语言相比较为简洁，因此用英语编写提示语所需的标记符较少。以下是一些英语对应的标记符计量示例：

1 个标记符相当于 4 个英文字符

100 个标记符约等于 75 个单词

两个句子约等于 30 个标记符

一个典型的段落约为 100 个标记符

一篇 1500 字的文章总共约 2048 个标记符

1 token equals about 4 characters.

100 tokens translates to about 75 words.

Two sentences equals about 30 tokens.

A typical paragraph is about 100 tokens.

A 1500-word article totals around 2048 tokens.

在计算调用 API 的成本时，采用的计量单位是标记符。在计算 ChatGPT 的输入和输出长度限制时，采用的也是标记符。目前，ChatGPT 包含输入和输出的总长度限制为 4096 个标记符。① 因此，如果你的提示语非常长，比如 4000 个标记符，你得到的回复将在第 97 个标记符处被截断，即使这是在句子的中间。

① GPT-4 的 API 提供一场对话上下文长达 3.2 万个标记符的版本，而 Anthropic 的 Claude 聊天机器人有一个版本，提供一场对话上下文长达 10 万个标记符。—— 译者注

如果你想知道你的提示语有多少个标记符，可使用 OpenAI 的分词工具 Tokenizer 测算，如图 3-7 所示，你可在如下网址找。

## 0701. 在教育中使用 ChatGPT

参考：方军.(2023).2023013ChatGPT超入门.中信出版社 => 0701. 在教育中使用 ChatGPT

### 7.1 将批判性思维转换为新学习模式

如前所述，有人担心，使用 AI 的学生会错失培养批判性思维能力的机会。我们可以通过转换教学模式规避这个问题。

通常情况下，教师会传授信息，然后对学生进行测试。而使用 ChatGPT 时，学生必须先提出正确的问题才能解锁信息，与传统基于批判性思维的教学和测试过程正好相反。

ChatGPT 的输出质量取决于人类输入的质量。学生只有仔细思考并批判性地设计他们的问题或命令，才能让 AI 提供他们所需要的答案。教会学生如何思考并提出问题，是有效培养学生批判性思维能力的方式。

请比较以下两个例子。

图 7-1 显示了一个简单的提示语和 ChatGPT 的回应。

图 7-2 则给出了一个更有策略性的经过思考的提示语，从而引出了一个更复杂也更有用的回答。

这个比较说明，为什么掌握批判性思维能让你在使用 ChatGPT 时更有优势。

提问：你是一个由 5 名教师组成的团队，所有人都在教美式英语的创意写作，但面对的是不同水平的学生。其中两名老师在大学教学：第一位教大一新生；第二位教博士研究生；第三位教四年级学生；第四位教八年级学生；第五位面向高中生教授高中阶段英语。请你的团队每个人都重写下面的段落，展示如何改进它：「猫和老鼠向一边跑去，而狗则叫并跳跃。孩子们欢快地跳舞，而成年人则大声要求他们立即停下。混乱对一些人来说很有趣，对其他人来说则是烦恼。」

You are a team of 5 educators all teaching creative writing in American English but at different grade levels. Two educators teach at college level, one teaches freshmen and the other at the doctorate level. The third educator teaches 4th grade students, the fourth educator on your team teaches 8th grade English and the remaining educator teaches AP English to high school students. The team must rewrite the following paragraph to show how it can be improved: "The cat and the mouse ran to the side while the dog barked and jumped. The kids danced with the glee and the adults yelled for them all to stop immediately. Chaos is fun to some and an annoyance to others."

回答：作为一个 AI 语言模型，我可以提供如何为不同年级水平重写段落的建议。但请注意，这些只是示例，有许多方法可以为不同的读者群体调整段落。以下是针对每个年级水平的重写建议。

大学水平（大一）：

「猫和老鼠迅速地奔向周边，而犬则热情地大声叫并跳跃。孩子们兴高采烈，无拘无束地欢舞，而成年人则形成鲜明的对比，大声要求他们立即停止这种混乱。看起来，混乱对一些人来说是快乐的来源，但对其他人来说却是困扰。」

大学水平（博士研究生）：

「家养的猫和小巧的鼠类动物忙乱地向侧面边界冲去，而犬类的对应动物则以喧嚣的吠声和有力的跳跃做出回应。聚集的年轻成员沉醉于这场混乱中，他们的动作以欢快的舞蹈为特点，而成熟的个体则发出强烈的反对声，要求他们立即停止这场混乱。人类对此的二分法观点因此得到了体现 —— 对一部分人来说，混乱是一种令人振奋的解放；而对另一部分人来说，它是一种烦人的干扰。」

四年级水平：

「猫和老鼠快速地跑向一侧。狗大声地叫，高高跳跃。孩子们跳舞，感到非常开心，但是大人们大喊着让所有人立即停下。有些人认为放肆和吵闹很有趣，但另一些人一点也不喜欢。」

170ChatGPT 超入门八年级水平：

「在狗大声叫和兴奋跳跃的时候，猫和老鼠则向安全的地方疾跑。孩子们在纯真的欢乐中跳舞，但是成年人并不开心，他们大喊着让所有人立即停止噪声并安静下来。有趣的是，有些人享受混乱的狂野，而另一些人觉得它真的很烦人。」

高中阶段英语：

「在狗出于本能的热情大叫和追逐的时候，猫和老鼠在一种狂热的逃亡中向场边疾跑。在这一场景的展开中，孩子们欢欣鼓舞地跳舞，他们的笑声回荡在空中。然而，成年人并不觉得这有趣。他们眉头紧锁，语气严厉，要求立即停止这场吵闹。在那一刻，人性的二元性被赤裸裸地展现出来 —— 混乱，对年轻的精神来说是一种喜悦，但对追求秩序的成熟来说是一种不受欢迎的干扰。」

请记住，以上只是示例，实际的重写可能会根据每位老师的具体教学风格和目标有所不同。（以上文本由 GPT-4 翻译。）

提示语对于运用 ChatGPT 和其他 AI 模型至关重要，因此，在 AI 领域中，提示工程是一项关键技能。教学生掌握批判性思维技能，将之用于编写提示语，这将确保他们拥有必备的工作技能和光明的就业前景。现在，公司愿意为高水平的提示工程师支付高薪，短期内应该都是这样的。当然，最终 AI 模型会逐渐发展到这样的程度：即使提示语的质量很差，它也会更好地猜测用户的意图。新兴的 AI 模型 AutoGPT 已经能够根据用户的简单建议制作自己的提示语。这种改进将能让更多人享受 AI 的优点，但是，这并不意味着不再需要创造性和批判性思维。在 AI 时代，能够娴熟运用这些工具的人将会取得成功。