## 记忆时间

## 目录

0701 Digging Deeper into Networks

0801 Perfect Storms in Networks

0901 All the world's a nets or not?

## 0701. Digging Deeper into Networks

深入挖掘网络

### 7.1 Who are your friends?

For every white American with a sexually transmitted disease, there are up to twenty African-Americans with the same condition in certain areas of the US, according to several studies carried out in the nineties. This figure is the outcome of persisting racial inequalities. However, the actual mechanisms of contagion that generate such a big difference are still partially obscure. In 1999, sociologists Edward O. Laumann and Yoosik Youm found an interesting piece of evidence: less sexually active African-Americans (those who had only one partner in the previous year) were five times more likely to have intercourse with more sexually active African-Americans (those who had four or more partners in the previous year) than whites in the same situation. In other words, in the sexual interaction network of the whites, the periphery of less active people was should not be underestimatede ok2 partially separated from the core of active individuals. On the contrary, these two groups were more connected in the African-American network. The reason for this difference is unclear, but its consequence is straightforward: in the first network, sexually transmitted diseases thrive mainly within the core, while in the African-American one, they also spill over to the periphery.

This is a case in which the degree of the nodes in the networks is not the most relevant quantity in understanding the situation. Individuals with exactly the same number of sexual connections have a different exposure to infection depending on whether they are African-Americans or whites. In situations like this, it is not enough to know how many 'friends' you have (your degree): it is necessary also to know how many friends your friends have. The degree distribution provides a great deal of information about the overall structure of a graph, for example whether it has hubs or not. However, it does not tell everything about that graph. For example, consider two networks with the same number of nodes and edges: the nodes may have exactly the same degrees, but the edges can be arranged in such a way that the outcomes are very different graphs. The degree is a local feature of a vertex. In order to capture the more subtle structure of networks, one has to dig deeper, and find measures that describe the surroundings of a node: its nearest neighbours, the neighbours of its neighbours, etc.

In the whites' sexual network, low-degree nodes tend to connect with low-degree nodes, and high-degree nodes with high-degree nodes. This phenomenon is called assortative mixing : it is a special form of homophily, in which nodes tend to connect with others that are similar to them in the number of connections. By contrast, in the African-Americans' sexual network, high- and low-degree nodes are more connected to each other. This is called disassortative mixing. Both cases display a form of correlation in the degrees of neighbouring nodes. When the degrees of neighbours are positively correlated, then the mixing is assortative; when negatively, it is disassortative.

Usually, the presence of these patterns of mixing is the outcome of some non-trivial mechanism acting in the network, possibly a form of self-organization. In random graphs, the neighbours of a given node are chosen completely at random: as a result, there is no clear correlation between the degrees of neighbouring nodes (although the finite size of a graph can disguise this to some extent). On the contrary, correlations are present in most real-world networks. Although there is no general rule, most natural and technological networks tend to be disassortative, while social networks tend to be assortative. For example, highly connected web pages, autonomous systems, species, or metabolites tend to be linked with less connected nodes of their networks. On the other hand, company directors, movie actors, and authors of scientific papers tend to link with those similar to them in connectivity: the higher the degree of an individual, the higher that of his or her neighbours in the network.

Degree assortativity and disassortativity are just an example of the broad range of possible correlations that bias how nodes tie to each other. For example, Laumann and Youm also showed that African-Americans, much more than other groups, tend to have partners from their own community. As a consequence, when an infection enters the community, it gets 'trapped' in it. This simple effect alone makes the likelihood of African-Americans having a sexually transmitted infection 1.3 times greater than the figures for white Americans. In this case, the correlation does not arise from the degree, but is a form of ">Maculinea arioneguhomophily with respect to an intrinsic character of each node, namely its ethnic identification. Another example is correlation with respect to body mass: it has been shown that people with similar body mass index tend to establish social bonds with each other more frequently than with other people. One must note that correlations do not always need to be positive, favouring homophily: for example, in foodwebs, edges connect plants to herbivores, and herbivores to carnivores, but very few connect herbivores with herbivores, or plants with plants.

谁是你的朋友？

根据上世纪 90 年代开展的一些研究，每有一个患有性传播疾病的美国白人，在美国某些地区就有多达 20 名同病相怜的非裔美国人。持续的种族不平等导致了这一结果。然而，产生如此巨大差异的真正传染机制在一定程度上仍晦暗不明。1999 年，社会学家爱德华·O.劳曼和尤思科尤姆发现了一个有趣的证据：性活跃程度较低的非裔美国人（过去年仅有 1 位性伴侣者）与性活跃程度更高的非裔美国人（过去一年中有 4 位或更多性伴侣的人）发生关系的可能性是相同情下白人的 5 倍。换句话说，在白人的性关系网络中，不那么活跃的外围群体某种程度上与活跃的核心群体彼此隔离。相反，这两个群本在非裔美国人中的关联则更多。这种差异的原因尚不清楚，但其结果却很明确：在第一个网络中，性传擂疾病主要在核心群体内部蔓延，而在非裔美国人中，这些疾病也溢出至外围人群。

在本例中，网络节点的度数对于理解这个现象并非最相关的变量。性伴侣数量相同的个体受感染的可能性也不尽相同，这取决于该个体是白人还是非裔美国人。在这样的情况下，仅仅知道你有多少「朋友」（即你所在节点的度数）还不够，还必须知道你的朋友有多少朋友。度数分布为图的大体结构提供了大量信息，比如它是否包含枢纽节点等。然而，度数分布并不能显示图的所有信息。比如，设想两个图具有相同数量的节点和边数：其中的节点可能有着完全相同的度数，但边的分布却可能导致这两幅图完全不同。度数乃顶点的局部特征。想要更加细致地认识网络结构，人们必须深入挖掘，并找到方法来描述节点的周边情况：距其最近的邻点，其邻点的邻点，等等。

在白人的性关系网络中，低度数节点往往与低度数节点相连，高度数节点则与高度数节点相连。这种现象又名「相称混合」：它是同质相吸的一种特殊形式，其中连接数类似的节点往往会互相连接。相反，在非裔美国人的性关系网络中，高度数节点和低度数节点则更容易彼此连接。这被称为「不相称混合」。这两种情况都显示了相邻节点在度数上的某种相关性。当相邻节点的度数呈正相关，则为相称混合；反之则为不相称混合。

通常，这些混合模式的存在是网络中某个重要机制作用的结果，这个重要机制可能就是自组织。在随机图中，给定节点的邻点完全是随机选择的：结果，相邻节点的度数之间并没有明确的相关性（尽管图的有限大小可在某种程度上掩饰这一点）。与此相反，大多数真实网络中都存在节点相关性。尽管不存在一般规则，但大多数自然和技术网络往往为不相称混合模式，而社交网络则为相称混合模式。例如，高度连接的网页、自主系統、物种或代谢物常常与其所在网络中连接较少的节点相互关联。另一方面，公司懂事长、电影演员和科学文献作者往往与那些连接性与自己类似的人相关联：个体的节点度数越高，其网络邻居的度数也越高。

度数的相称和不相称仅为让节点相互关联发生偏差的大量可能相关性中的一个例子。例如，劳曼和尤姆也证明了，相比于其他群体，有更多的非裔美国人倾向于从自己的社区选择伴侣。因此，当感染进入社区之后，它便被「困」在里面了。单单这种简单的效应便让非裔美国人感染性病的可能性高出美国白人 1.3 倍。在这种情况下，相关性并非源于节点度数，而是与每个节点内在特性相关的一种同质相吸，这个内在特性即种族身份。另一个例子是体重的相关性：研究发现，相对于与自己体重指数不同的人而言，体重指数相似的人倾向于更频繁地在彼此之间建立社交联系。要注意的是，相关性并不必然就是支持同质相吸的正面因素：比如，在食物网中，边将植物与食草动物、食草动物与食肉动物相连，但绝少将食草动物与食草动物或者将植物与植物相连。

### 7.2 Who are your friends' friends?

Cosimo de' Medici, the man who led his family to take over Florence in 15th century, was described as an 'indecipherable sphinx'. Although he rarely spoke publicly, and never committed openly to almost any form of action, he was able to build around him a strong party that made him the pater patriae (father of the nation) of the most important city of the Renaissance. In 1993, social scientists John F. Padgett and Christopher K. Ansell analysed the information about marriages, economic relations, and patronage links that connected the Medici to the other powerful families of the city. They found that Cosimo's family was at the centre of a network of ties with many of the leading lineages. More importantly, without the Medici connection, most of the time those families were weakly related, or even opposed to each other. Cosimo's reserved attitude helped him to establish relations of alliance and control with everyone.

The network with the Medici at the centre is an example of an ego network, a graph composed of a set of nodes with direct ties to a central one (the ego), as well as ties linking them to each other. Whenever one of the latter ties is missing (i.e. two neighbours of the ego are not neighbours to each other) the network has a structural hole. Cosimo's network was full of structural holes, and his family was able to use them to implement a divide et impera (divide and reign) strategy: the Medici were seen as a third party in many conflicts, and families had to ask their mediation in their relations with other families.

However, being surrounded by many structural holes is not always beneficial for an individual. Adolescent girls whose friends are not friends with each oth latter are twice as likely to commit suicide, according to a 2004 study. A possible explanation of this finding is the exposure to conflicting inputs from unrelated friends. Another example comes from workers' unions: when workers' networks lack structural holes (that is, egos are surrounded by nodes with abundant mutual ties), then a powerful, well coordinated, and communicative organization arises. In general, different patterns of structural holes point to different situations. For example, a scientist working in a specialized field is usually connected to other scientists in the field, which are likely connected to each other. On the other hand, a scientist working in a highly interdisciplinary field is probably connected to experts of various areas not necessarily in contact with each other.

In all these cases, it doesn't matter how many friends you have (your degree), or who they are (for example, whether their degree is similar to or different from yours). What really matters is who your friends' friends are; in particular whether or not your friends are also friends to each other. This concept is often referred to as transitivity, or clustering. Let us consider an individual with two friends: they form a connected triple. If the two friends are friends with each other, than in its random counterpart. Isccathen they also form a transitive triple, or triangle. The quantity of triangles in a network compared with the overall number of connected triples is the basic ingredient of the clustering coefficient of that network: this is a measure of the density of triangles in that graph, its overall transitivity. In random networks, the connections between the nearest neighbours of a node are as random as those between any two nodes. As a consequence, these graphs have just the quantity of triangles that emerge from a purely random disposal of edges. On the other hand, the clustering coefficient of almost all real-world networks is higher than their random counterparts. This suggests that some non-trivial process, possibly a form of self-organization, is at work in generating this extra transitivity.

The high clustering of many networks suggests the presence of groups where 'everybody is friends with everybody else'. At first sight, this picture seems to contradict the small-world property of networks: are networks 'open' worlds in which everybody is a few steps from everybody else, or are they the sum of tightly knit, segregated groups? In reality, there is no real contradiction between these two features: one can see this by having a closer look at the Watts–Strogatz model. The model starts by considering a circle of nodes, each of them connected with its first- and second-nearest neighbours, such as remote villages interchanging goods with their neighbours. This is a fully clustered structure, in which all the commercial partners of one village are commercial partners with each other. The model then allows for rewiring a few links to randomly chosen nodes: a few villages open paths to other faraway villages and bring goods there, declining to do business with one of their neighbours. A few paths are enough to reduce abruptly the distance between any two villages, but on the other hand we can think that the local tight commercial structure is disrupted, that is, its clustering goes down. However, Watts and Strogatz found that the decrease in the clustering is less pronounced than the decrease in the average distance. In practice, in order to make a noticeable drop in the transitivity, one has to rewire almost all the nodes. At this point, only random connections are present in the network. Since it is a random graph, we do not expect a large clustering. The take-home message is that networks (neither ordered lattices nor random graphs), can have both large clustering and small average distance at the same time.

Another interesting point about clustering is that in almost all networks, the clustering of a node depends on the degree of that node. Often, the larger the degree, the smaller the clustering coefficient. Small-degree nodes tend to belong to well-interconnected local communities. Similarly, hubs connect with many nodes that are not directly interconnected. In the Internet, for example, low-degree autonomous systems usually belong to highly clustered regional networks, interconnected by national backbones. A similar structure is likely to be present in many networks, where clustering decreases with increasing degree.

谁是你朋友的朋友？

科西莫·德·美第奇于 15 世纪带领家族接管佛罗伦萨，人们称他为「难以理解的斯芬克斯」。尽管他绝少公开发表言论，并且也从未公开采取任何形式的行动，但他依旧能够在自己周围建立起强大的党羽，并让自己成为文艺复兴时期最重要城市的国父（pater patriae）。1993 年，社会学家约翰·F.帕吉特和克里斯托弗·K.安赛尔分析了美第奇家族与佛罗伦萨其他权势家族之间的婚姻关系、经济联系和赞助往来。他们发现，科西莫的家族位于众多权贵家族关系网络的中心。更重要者，若无美第奇家族搭线，其他家族多数时候的联系并不多，甚至彼此抵牾。科西莫的克制态度帮助自己建立起了与各家族的联盟和共治关系。

以美第奇家族为中心的网络便是自我中心网络的一个实例，在这种网络中，一组节点与中心节点（自我节点）直接连接，这组节点彼此之间也相互连接。每当后一种连接丢失ー个（也就是自我节点的两个邻点彼此不再相邻），该网络就会出现结构洞。科西莫的网络布满了结构洞，其家族能够用它们实行分而治之（divide et impera）策略：美第奇家族被视为许多冲突的第三方，那些家族不得不要求美第奇家族调节他们彼此的关系。

1-2『这里的信息让自己对「结构洞」的认知加深了不少，结构洞做一张术语卡片。（2021-02-17）』——已完成

然而，对个人而言，周围布满许多结构洞并不总是件好事。根据 2004 年的一项研究，朋友之间不构成朋友关系的青春期女孩，其自杀概率为相反情况的两倍。这个发现的可能解释是，当事人会暴露在无关朋友的冲突之中。另外一个例子来自工会：若工人之间的联系网不存在结构洞（即自我节点被大量相互关联的节点包围时），则会形成一个强大、协调良好、交往密切的组织。一般而言，结构洞的不同模式表示不同的情况。例如，专业领域的科学家常常与该领域其他科学家相互联系，后者可能彼此也有联系。另一方面，高度跨学科领域的科学家则很可能与不同领域的科学家都有联系，后者并不必然彼此关联。

在所有这些情况下，你有多少朋友（即你的节点度数），或者他们是谁（比如他们的节点度数与你的相似还是不同）都不重要。重要之事在于，你朋友的朋友是谁：特别是，你的朋友彼此之间是否也是朋友关系。这个概念通常被称为传递性或集聚性。让我们考虑有着两位朋友的一个人：他们三人构成了连接三元组。如果此人的两位朋友彼此也是朋友，那么他们三人同样构成了可传递三元组，或者三角形。网络中的三角形数量与其中的连接三元组总数的比值便是该网络集聚系数的基本组成：这个系数衡量了该图中的三角形密度及其总体的传递性。而在随机网络中，某节点最近点之间的连接与任意其他两个节点间的连接具有同样的随机性。因此，这些图仅有纯粹随机连接的边所组成的三角形。另ー方面，几乎所有现实世界网络的集聚系数都高于其相应的随机网络。这意味着某种重要的过程 —— 可能是某种形式的自组织 —— 在产生这种额外的传递性过程中起到了作用。

许多网络的高度集聚性表明存在着其中「每人都是其他每个人的朋友」这样的群体。乍一看，这幅图景似乎与网络的小世界属性相矛盾：网络是否是个「开放」世界，其中每个人之间都仅隔几步之遥？或者说网络就是紧密编织的分离群体的总和？现实中，这两个特性之间并不存在真正的矛盾：通过仔细观察沃茨-斯托加茨模型就能看出这一点。这个模型以一圈节点为开端，每个节点都与其最近和次近的邻点相连，就像遥远的村庄与其邻村交换货物一样。这是个完全集聚的结构，其中，任一村庄的所有商业伙伴也互为商业伙伴。然后，该模型为随机选择的节点开放一些连接：少数村庄开放了前往其他遥远村庄的路径，并将货物带往该处，且拒绝与其邻居做生意。少量路径便足以陡然降低任意两个村庄之间的距离，但另一方面，我们可以认为当地紧密的商业结构已遭到破坏，也即，当地的集聚性下降了。然而，沃茨和斯托加茨发现，集聚性的降低并不像平均距离的减少那般明显。实际上，为了使传递性显著下降，人们必须重连几乎所有节点。此时，网络中仅剩随机连接了，而我们并不会期待随机图中存在高集聚性。此处的关键信息在于，网络（既不是有序网格，也非随机图）可以同时具备高集聚性和较短的平均节点距离这两个特征。

集聚性的另一个有趣之处在于，几乎所有网络中某节点的集聚性都取决于该节点的度数。通常，节点度数越大，集聚系数便越小。低度数节点往往属于彼此连接良好的局部网络。类似地，枢纽节点与众多节点连接，这些节点并不会直接地彼此连接。例如，互联网中低度数的自治网络常常属于高度集聚的区域网络，且经由全国主干网彼此连接。许多网络中都可能出现类似的结构，其中集聚性会随着节点度数的增加而呈下降趋势。

### 7.3 Who are your friends' friends' friends'…?

Money does bring some happiness, but being surrounded by happy people gives much more of it. Earning US$5,000 more per year increases the chance of being happy by just 2 per cent, according to a 1984 estimate, while having a happy friend increases it by 15 per cent, according to a 2008 study by sociologists Nicholas Christakis and James Fowler. The two scientists asked more than 12,000 people from Framingham, Massachusetts about their subjective feeling of happiness. Moreover, they mapped who was a friend, spouse or sibling of whom. By drawing th">Maculinea arioneguis network, the two found that connected people tend to have similar feelings: happy people tend to group together, as, on the other hand, unhappy people do. Christakis and Fowler found even more interesting evidence. The happiness of an individual is influenced by the happiness of people that are not their immediate neighbours. The 'happiness effect' two steps away (friends of friends) is about 10 per cent; three steps away (friends of friends of friends), it is about 6 per cent. The effect fades only at the fourth step. The two sociologists and other scientists found similar results for obesity, smoking habits, and word-of-mouth advice (such as finding a good piano teacher or finding a home for a pet): in all these cases, influence and information arrived to an individual from three degrees away. This three degrees rule, found in several social processes, is an example of hyperdiadic spread : that is, the diffusion of a phenomenon beyond dyadic relations, those that connect nearest neighbours. In this case, it is neither the degree of a node, nor the degree of its neighbours, nor the connections between its neighbours that matter. The influence goes beyond the immediate circle of each node. Actually in many phenomena, it goes even beyond the third degree. For example, a highly infectious disease can form longer chains of contagion; similarly, the spread of nutrients in a foodweb can span all the network.

In this kind of dynamics, a node can be more or less important depending on the number of chains passing through it. In order to capture this idea, sociologist Linton C. Freeman introduced the concept of betweenness centrality of a node. One takes all the pairs of nodes in a network and counts the shortest paths connecting them. The betweenness centrality of a node is basically the proportion of shortest paths that cross that node. The higher this proportion, the more central is the node. According to this measure, the Medici are the most central family in the network of lineages in 15th-century Florence. In this case, the betweenness centrality is a measure of the potential to slow down the flow or to distort what is passed along, in such a way as to serve the node's interests. Several studies show that the centrality of a firm in economic networks predicts well its ability to innovate (as measured by number of patents secured) as well as its financial performance. Interestingly, between 1980 and 2005, East Asian countries experienced huge increases in their centrality in the world trade web, while the centrality of most Latin American countries went down. However, the trade statistics of these two regions displayed similar patterns: the big difference in their development was not tracked well by macroeconomics statistics, while the network-based approach captured it. Moscow became in the Middle Ages the most central node of the river transportation network of central Russia, according to a 1965 study. Very probably this set the scene for the future importance of the city.

Central nodes usually act as bridges or bottlenecks: they are almost compulsory stops in the traffic on a network. For this reason, centrality is an estimate of the load handled by a node of a network, assuming that most of the traffic passes through the shortest paths (this is not always the case, but it is a good approximation). For the same reason, damaging central nodes (for example, extinguishing a central species or destroying a central router) can impair radically the flow of a network. Depending on the process one wants to study, other definitions of centrality can be introduced. For example, closeness centrality computes the distance of a node to all others, and reach centrality factors in the portion of all nodes that can be reached in one step, two steps, three steps, and so on. More:

The behaviour of centrality in many real-world networks is a further signature of their heterogeneity. In many real-world networks it exhibits the characteristic long tail of a heterogeneous distribution. The average centrality is not a valid estimate for the centrality of any node, because this magnitude varies a lot around the average: a few nodes are the main bottlenecks of almost all the shortest paths in the network, and a full hierarchy of less central nodes goes down from them. Given the importance of the more central nodes, it is natural to ask whether they are the same as the hubs of the networks. In many situations, this is in fact the case. For example, highly connected autonomous systems also act as bridges between regional networks; or polysemic words, with their many connections to other words, bring together separated areas of language. But this is not a general rule. A notable exception is the airport network: in this case, certain low-degree airports have exceptionally large betweenness. In 2000, the airport with highest centrality was Paris, a hub connected to more than 250 other cities. But the next highest was remote Anchorage, in Alaska, a medium-sized airport with just 40 connections. Other airports similar to it appear in the list of the most central ones. How is this anomaly explained? Alaska has many airports for internal flights, but Anchorage is its only bridge to the rest of the US, so many paths cross this airport. The anomaly is the result of the existence of regions with a high density of airports but few connections to the outside world.

谁是你朋友的朋友的朋友

金钱会在一定程度上来幸福，但周围快乐的人却能给人们带来更多的幸福。根据 1984 年的一项估计，每年多挣 5000 美元会增加 2% 的幸福感，而社会学家尼古拉斯·克里斯塔基斯和詹姆斯·福 2008 年的一项研究表明，拥有一个快乐的朋友则会提升人们 15% 的幸福感。两位社会学家调查了来自马诸塞州弗雷明汉的超过 12000 名居民的主观幸福感。不仅如此，他们还绘制了这些人之间的朋友、配偶或兄弟姐妹关系。通过绘制这个关系网，二人发现，联系紧密的人常常有着类似的感觉：幸福的人往往聚在一起，另一方面，不幸之人亦是如此。克里斯塔基斯和福甚至还发现了更多有趣的证据个人的幸福会受到其非直接相邻的人的幸福程度的影响。两步之外（朋友的朋友）的「幸福效应」约为 10%；三步之外（朋友的朋友的朋友）则为约 6%。这种效应仅在第四步就消失了。这两位社会学家和其他科学家也在肥胖、吸烟习惯以及口头建议（比如找一个好的钢琴教师或一个好的宠物之家）等方面发现了类似的结果：在所有这些情下，三度空间之外的影响或信息会对个人起作用。人们在不同社会过程中发现的这个三度空间规则是超二元扩散的一个例子，即超越连接最近邻居的二元关系的扩散现象。在这种情况下，每个节点的度数、其邻点的度数，还有邻点之间的连接都不再重要。影响超越了各节点最近的连接圈。实际上，在许多现象中，这种影响甚至超过了三度空间。例如，高度传染性疾病可形成更长的传染链；类似地，营养物则可扩散至整个食物网。

在这种动力机制中，节点的重要程度取决于通过它的链条数量。为了捕捉这个观点，社会学家林顿·C.弗里曼引入了节点的中介中心性这一概念。取某网络中的所有节点对，数一数关联它们的最短路径数。节点的中介中心性基本上就是穿过该节点之最短路径占所有路径数量的比例比例越高，相关节点的中心性就越高。按照这种量方式，美第奇家族便是 1586 世纪佛罗伦萨家族中最具中心性的一个。在这种情况下，中介中心性便可衡量减缓节点流或扭曲通过链条的可能性，它以这种方式服务于中心节点的利益。一些研究表明，企业在经济网络里的中心性很好地预示了它的创新能力（根据获得的专利数衡量）以及财务业绩。有趣的是，1980 年到 2005 年间，东亚国家在世界贸易网络里的中心性经历了大幅増长，而大多数拉美国家却呈下降趋势。然而，这两个地区的贸易统计显示出类似的模式：宏观经济统计并未很好地追踪二者发展的巨大差异，而基于网络的方法却捕捉到了这一点。根据 1965 年的一项研究，莫斯科在中世纪便成为俄罗斯中部河流运网络最具中心性的节点。很可能，这为其未来的重要性打下了基础。

中心节点通常充当桥梁或瓶颈：它们几乎是网络交通中的必经站点。因此之故，中心性乃是对网络节点的负荷的估计，前提是大多数节点之间的连接都经过最短路径（情况并非总是如此，但这是个很好的近似情况）。由于同样的原因，中心节点的损坏（例如，某个中心物种灭绝或某个中央路由器被破坏等）会从根本上影响相关网络的节点连接数。根据想要研究的过程，还可以引入中心性的其他定义。例如，接近中心性计算某节点到其他所有节点之间的距离，而抵达中心性则将网络内所有节点分解为经由一步、两步、三步等不同步数抵达的节点。此外中心性还有一些更为复杂的定义。

许多现实世界网络的中心性特征是它们异质性的深层标志。许多真突世界的网络会表现出异质分布特有的长尾。平均中心性并非对任一节点的有效估计，因为这一量值在平均范国内变化很大：少数节点便是网络中几乎所有最短路径的主要瓶颈，整个中心性较低的节点层级都要经由他们向下。考虑到中心性较高节点的重要性，我们很自然地会问它们是否与网络的枢纽节点相同。很多情况下，事实的确如此。例如，高度连接的自治系也可作为区域网络的桥梁；多义词因与许多其他语词连接，从而将语言中的不同领域联系在一起。但这并非普规律。机场便是一个显著的例外：其中，某些低度数机场具有特別大的中介性。2000 年，中心性最高的机场为巴黎机场，它是关联着 250 多座城市的枢纽节点。中心性次高的机场则为位于阿拉斯加州的偏远的安克雷奇，它是一个仅与 40 座城市连接的中等大小的机场。其他类似机场也出现在最具中心性的机场名单上。这种异常又该如何解释？阿拉斯加州有许多飞国内航线的机场，但安克雷奇是通往美国其他地方的唯一桥梁，因此，许多航线都穿过该机场。这种异常是局部地区机场密度高，却少有通往国外的航线的结果。

### 7.4 What group(s) do you belong to?

In 1972, two karate instructors in a university club in the US were so much in conflict that they decided to split their club into two different ones. This event, pretty unexciting for most of the world, was a goldmine in the eyes of social scientist Wayne W. Zachary. In 1977, he published a pioneering study in which he gave an unconventional view of this event.

In 1970, the karate instructor, Mr Hi, asked the president of the club, John A., to raise the prices of lessons in order to provide a better salary. All he received was a denial. As time passed, the entire club became divided over this issue, and after two years the supporters of Mr Hi formed a new organization under his leadership. During all that time, Zachary collected information about the karate lessons, the meetings, the parties, and the banquets of club members, and identified as good friends those that also met outside the club. At this point, he was able to draw a precise network of the friendships within the club: the resulting structure was clearly divided into two groups built around the two instructors, each of them composed of people who were friends with each other and with one of the instructors, with few connections with people in the other group ((( ))Figure 11). When the club split in two, the people divided almost exactly along the lines that separated the two groups.

Zachary's method was able to predict the club division almost perfectly, on the basis of the structure of the network alone. Since then, researchers have been striving to find a general method to identify communities or modules in networks. In Zachary's case, they could be seen just by examining the map, but other instances are much more complicated, and a general solution is still to be found. All real-world networks display some level of modularity. Alaska is obviously a specific module within the airport network structure, such as other regions well connected to the inside but not to the outside. Foodwebs are divided into compartments : groups of:

cliques: for example, studies with adolescents have showed that their behaviours are strongly influenced by the modules to which they belong. The neuronal network is divided into big areas, often corresponding to specific functions. The genetic regulatory network is divided into subnetworks, associated to specific functions or diseases. Degree, correlations, clustering, and centrality provide information on single nodes, their immediate surrounding, and their position with respect to the overall network, but they do not capture the discrete structures into which the overall graph is divided.

figure 11 The structure of friendships of a karate club studied by anthropologist Wayne Zachary allows us to predict the separation of the group into two communities

The simpler form of module is the motif, a pattern of connections within a few nodes repeated throughout the network. In foodwebs we frequently find a diamond-like structure: for example, a carnivore eats two different herbivores, and they both eat the same plant. Another common motif is a simple chain of three species: a big fish eats a small fish that eats an even smaller one. These patterns are not the result of pure chance: motifs appear with a much higher frequency in a real foodweb than in its random counterpart. In general, in large networks, one can isolate many subsets of nodes and edges that may be candidate motifs. However, a given subgraph is considered a relevant motif only if it occurs in a network with a higher probability than in its random counterpart. In the Web, a very common example is the bipartite clique : this is composed of two groups of websites, where all those in the first group have links to all those in the second. Often, this motif identifies a group of 'fans' with the same interests (say, blogs on rafting), pointing to their 'idols' (say, websites of rafting magazines). Networks that regulate genes are almost completely built out of motifs. When the bacterium E. coli is in a stressful condition, a specific genetic circuit senses the stress and coordinates the production of certain proteins. These proteins coalesce to build flagella, a kind of moving tail that allows the bacterium to swim away in search of better conditions. This same genetic circuit, the coherent feed-forward loop, is present in many other bacteria and several other organisms. Evolution seems to have selected specific motifs, because of their optimal properties, (e.g. because they use the smaller number of genes necessary to perform a certain function). Moreover, a clear advantage of modularity is that motifs can combine to give rise to new functions, and damage to one of them is not propagated to the others.

Motifs are a kind of small-scale, local, repeated modules. But when people think about communities, they usually aim at finding great partitions of a network, such as compartments of a foodweb, online communities, disciplinary areas, etc. These structures do not show a regular, repetitive pattern. The task of finding them is easier if we have some clue, for example if the members of the community are self-identified by some element. This might be a widget all the members of the community add to their blogs, a common way of dressing, etc. However, most of the time this information is neither available nor explicit, and we have to dig into the network structure to find the modules. The general objective of community identification is to find sets of nodes that are more highly interconnected:

topology of the network, is based on computing the edge betweenness. That is, finding the edges through which most of the shortest paths pass. The links with highest edge betweenness are akin to the weak links connecting otherwise separated groups in Granovetter's work. If one cuts a few edges with high betweenness, then the network splits into a certain number of isolated clusters: these are suitable candidate communities. One can continue cutting the higher-betweenness edges to find more detailed structures nested within the larger ones.

An interesting application of community finding is the analysis of the US political blogosphere. Physicist Lada Adamic found a clear separation between Democrats' and Republicans' blogs. The resulting structure showed two large groups with very few connections to each other. Moreover, the structure related to liberals' blogs was found to be less cohesive than the conservatives' one. For instance, in the part of this blogosphere dedicated to abortion, pro-life blogs show a denser interconnection than pro-choice blogs. As a result, an online campaign is likely to spread more easily in the first group than in the second. Another study analysed communities of students in US schools, to see whether ethnicity shaped social networks.

你属于什么群体？

1972 年，美国一所大学俱乐部的两名空手道教练发生了激烈的冲突，从而决定将他们的俱乐部一分为二。这件在世界上多数看来不值一提的小事却成了社会学家韦恩·W.扎卡里眼中的一座金矿。1977 年，他发布了一项关于此事的开创性研究，并在其中提出了一个新奇的观点。

1970 年，空手道教练希先生要求俱乐部主席约翰·A 提高课程价格，以提供更好的薪酬。而他所得到的只是拒绝。随着时间的推移，整个俱乐部都因此事而产生了分歧，两年后，希先生的支持者们在其领导之下组建了ー个新的空手道组织。在此期间，扎卡里搜集了空手道课程、会议、派对以及俱乐部成员的聚会等相关信息，并将那些在俱乐部之外还见面的人定义为好友。这时，他便能为该俱乐部绘制一幅精确的友谊网络图谱了：所得图形的结构明显围绕两位教练而分为两个群体，每个群体里的人都互为好友且与其中一位教练交好，而两个群体的成员之间却很少往来（图 11）。当俱乐部一分为二，人们几乎都沿区分两个群体的界线站队。

图 11 人类学家韦恩·W.扎卡里研究的空手道供乐部中的友谊结构能让我们预测到该群体会一分为二

仅仅基于网络结构本身，扎卡里的方法便能够几乎完美地预测俱乐部的分裂。从那时起，研究人员便一直致力于找出能够识别网络中的「社区」或「模块」的通用办法。在扎卡里的例子中，这些社区或模块仅通过查看图形便能看出，但在其他复杂得多 89 的情况中，人们尚未发现通用的解方案。所有真实界的网络都在一定程度上显示出模块化特征。很明显，阿拉斯加机场便是机场网络结构中一个特定的模块，其他内部连接良好却与外部没有连接的区域也是如此。食物网也分为若干不同的分部，即那些内部互动更加频繁而与其他物种联系较少的物种群体。社交网络也分为不同的团体：例如，针对青少年的研究表明，他们的行为强烈地受其所属群体的影响。神经网络常被划分为对应特定功能的大区块。基因调控网络则被分为不同的子网络，后者与特定的功能或疾病相关联。度数、相关性、集聚性以及中心性都提供了单个节点及其紧邻的周环境和节点在整个网络中的相对地位等信息，但它们并不体现整个图形所分解成的各别结构。

模块的更简单形式是模体，它是少数节点在整个网络中重复出现的连接模式。在食物网中，我们经常会发现某种菱形结构：例如，某种食肉动物捕食两种不同的食草动物，后两者食用同一种植物。另一种常见的模体是三个物种的简单链条：大鱼吃小鱼，小鱼吃虾米。这些模式并非纯粹概率的结果：模体在真实的食物网中出现的频率比在其随机对照网络中高出很多。通常，在大型网络中，人们可以区隔出许多可能为候选模体的由节点和边组成的子集。然而，只有当给定的子图出现在某网络中的频率高于其随机对照图时，该子图才能被认为是相关模体。在万维网中，一个十分常见的例子是「二分团」：它由两组网站组成，其中一组的所有网站与另一组所有网站之间相互连接。通常，这种模体能够确定一组有着相同兴趣的「粉丝」群体（比如有关漂流的博客），并指向他们的「偶像」（例如漂流杂志的网站等）。调控基因的网络则几乎完全由模体构建。当大肠杆菌处于应激状态时，特定的基因回路会感知到应激状态，并协调某些蛋白质的产生。这些蛋白质联合起来形成鞭毛，这种不断摆动的尾状物能让细菌游走以寻找更好的环境。相同的遗传回路，即协调前馈环还存在于许多其他细菌和一些其他微生物体内。演化似乎已经因为特定模体的最优特性而选择了它们（例如，因为它们能用更少量的所需基因来执行某项功能）。此外，模体机制的明显优点是模体可以组合产生新的功能，而其中某个模体受到破坏也不会影响到别的模体。

1-2『模体少数节点在整个网络中重复出现的连接模式，直觉上「模体」会在以后开发的「智慧工厂」模型里起到关键作用。做一张术语卡片先。（2021-02-17）』——已完成

模体乃某种小规模、局部的重复性模块。但当人们考虑社区时，他们通常意在发现网络中的大型分区，比如食物网的区划、在线社区、学科领域等等。这些结构并不表现出规律性的重复模式。如果我们掌握了某些线索，比如，假如社区的成员因某个因素而自发确定自己的身份，则相对容易找到它们。这个因素可能是社区内所有成员添加到他们博客上的小饰物、共同的着装方式等。然而，多数时候这种信息既非现成也不明确，我们必须深入挖掘网络结构以找到模块。社区识别的总体目标为发现那些内部连接比彼此之间连接更为紧密的节点集，就像空手道俱乐部网络中呈现的那样。口头表述是很容易的，但将此概念转换为数学表达却很难，以至于人们尚未发现确切的社群检测方法。一些方法可以聚合节点以满足最优性准则。其他方法则可将网络拆分为群组，然后再进一步将群组进行拆分，接着再进行拆分，进而创建一个嵌套社区的谱系树。还有一些方法在节点之间放置假想的弹簧，然后查看系统松弛之后所形成的节点群集。一般来说，还有很多其他方法上的选项。有一种有趣的技术聪明地利用了网络拓扑学，其基础在于计算边介数，也就是找出多数最短路径所通过的边。具有最高边介数的连接类似于在格兰诺维特的研究中连接原本相互分离之群体的弱连。如果去掉一些高介数的边，那么，网络就会分裂成一定数量的孤立节点群集：它们便是恰当的候选社区。我们还可以继续去掉网络中一些介数较高的边，以找出嵌套在更大结构中的更为精细的结构。

社区发现方法的一个有趣应用是对美国政治博客圈的分析。物理学家拉达·阿达米克在民主党人和共和党人的博客间发现了清晰的分隔。其得出的网络结构显示，这两大党的阵营绝少相互关联。此外，民主党的博客比共和党的博客更缺乏凝聚力。例如，在此博客圈的堕胎讨论专区中，反对堕胎的博客比支持堕胎的博客联系更为紧密。因此，在线造势运动更可能在前者的博客中得到传播。另一项研究分析了美国学校中的学生社区特征，借此了解种族是否会塑造社交网络。在种族非常多元和十分同质的学校中，这一因素似乎都是无关紧要的。相反，在种族多样性处于中间值时则能看出隔离特征。在代谢网络中，人们已经发现了与特定功能相对应的社区（碳水化合物代谢，核苷酸与核酸代谢，蛋白质、肽和氨基酸代谢，脂类代谢，芳香族化合物代谢，单碳化合物代谢和辅酶代谢等）。最后，公司股票则在价格相关性的基础上聚类，人们能从中发现与银行、矿业、分销、金融等各业务领域相对应的模块。

将社区定义为「内部联系比外部联系更为紧密」的子图非常普遍，但这种做法并未涵盖某些特定的模块。想想朋友间的电话通信链条，其中第一个呼叫第二个，第二个呼叫第三个，以此类推：根据上述定义，这种链条极有可能不会被归类为社区。另外一个例子则是同行业竟争者的网页：显然，他们并没有动力相互连接，尽管他们明显属于同一社区。此外，真实世界的社区比密集的节点群集复杂得多。多种划分可能同时出现；国籍、社会阶层、性别、工作、政治观念统统都可用来对同一群人进行分类。而且，社区之间可能互相重叠：ー个人可能同时从属于多个国籍或隶属关系。最后，嵌套社区也可能存在：例如，地域身份从属于国籍。

尽管过于简化，但图示法仍然能够捕捉到系统的诸多相关特征。若我们仔细查看图，便会发现大量相关信息，而运行的复杂测算越多，便会呈现越多细节。真实世界的网络几乎在任何时候都会偏离其随机对照网络，这意味着其中存在某种嵌入的秩序。同样，所有这些网络都未经过设计：偏离很可能产生于自组织过程。目前，在图的结构中寻找新的规律并揭示其潜在机制是网络科学仍然面临的一些挑战。

## 0801. Perfect Storms in Networks

网络中的完美风暴

### 8.1 Settings for Surprise

The island of Barro Colorado is a piece of rainforest in the middle of the waters of the Panama Canal. When a nearby river was dammed, just a few hilltops remained uncovered. The island has become an open-air experiment about what happens to a forest when it is fragmented into small pieces, as when highways, buildings, fields or mines substitute the original vegetation. A few years after the inundation around Barro Colorado, the population jaguars and pumas had shrunk dramatically. As a consequence, their prey thrived: now, in the island there is plenty of specimens of a large rodent, called agouti. These animals love the big seeds of acacias, so their boom is a big problem for acacias to successfully reproduce, as well as for microorganisms colonizing their seeds. As the acacia population shrinks, plants producing smaller seeds occupy their place, and animals eating them also increase in number. The original alteration of the ecosystem extends in all directions in the foodweb of the island.

Domino effects are not uncommon in foodwebs. Networks in general provide the backdrop for large-scale, sudden, and surprising dynamics. Pathogens spreading in transport networks, blackouts in power grids, large conflicts, or unexpected cooperative efforts in social systems: networks seem to be the ideal setting for ‘perfect storms’. Network nodes can represent individual entities (people, computers, species, genes…) exchanging material or information (information packets, energy, etc.), or they can represent locations (countries, airports…) exchanging individual entities (goods, travellers…). Within this very broad classification, the range of possible dynamics is enormous. Why are networks the natural playground for all these dynamics? How does the graph structure influence these processes? A general answer is impossible, but in many cases we can see that the heterogeneous, non-random organization of the underlying network makes a big difference to all the phenomena taking place on top of it.

意外之背景

巴罗科罗拉多岛是巴拿马运河中央的一块热带雨林。当其附近的一条河被筑坝拦截后，该岛便只剩下几处小山顶还显露在水面上。它现已成为ー个露天试验场，而试验内容是高速公路、建筑物、田地或矿井替代了原始植被，雨林被分割为若干小块之后的情形。洪水淹没巴罗科罗拉多岛周边数年之后，美洲虎和美洲豹的种群数量都迅速萎缩了。结果，它们的猎物种群数迅速攀升：现在，一种叫刺鼠的大型啮齿类动物已遍布该岛。这些啮齿动物爱好金合欢的硕大种子，所以，它们的繁盛对金合欢的成功繁殖以及依靠这些种子维生的微生物都构成了巨大难题。随着金合欢种群数量的减少，那些种子较小的植物便取而代之，而以后者为食的动物数量随之增加。生态系统的原初变化便向岛上食物网的各个方向延伸开去。

食物网中的多米诺效应并不罕见。通常，网络一般会为大规模的突发及意外动态提供背景支撑。运输系统中的病原体、电网中的断电、社会系统中的大型突或意想不到的合作努力等都证明了：网络似乎是「完美风暴」的理想背景。网络节点代 94 表交换物质或信息（信息包、能量等）的单独实体（人、计算机、物种、基因），或者它们也可以表示交换单独实体（货物、旅行者）的场所（国家、机场）。在这个非常宽泛的分类中，潜在动态的范围十分广大。为何网络会成为这些动态的天然发生场所？图的结构又会如何影响这些过程？对于这些问题不可能有总体答案，但在许多情况下我们能看到，底层网络的异质结构、非随机组织等特征会对表层发生的所有现象造成重要影响。

### 8.2 Failures and Attacks

On 18 July 2001, a train derailed in an underground tunnel in Baltimore (US), and began a fire. Soon after, the Internet was slowed down in several states along the US east coast. The fire had burnt optic cables passing through the tunnel, that belonged to several of the most important Internet Service Providers of the country. As a consequence, the accident created a domino effect that spanned a large part of the US. The Internet is constantly exposed to similar accidents. A percentage of routers are always out of operation at any time, for a broad range of reasons. Potentially, each one of these accidents may be as serious as Batimore’s derailment. Still, such macroscopic damages are rare. The network seems to tolerate a certain amount of chron">rich-get-richer mechanismm organismsic dysfunction without too many problems. It relies somehow on alternative paths, allowing traffic to get around failures. Still, like most networks, the Internet does not have many redundant links, and is not highly dense either. With these features in mind, it would be natural to expect it to break down easily.

While the Internet seems to be relatively resistant to errors and accidents, a carefully designed attack can wreak terrible damage. On 7 February 2000, an enormous number of users logged on to the Yahoo! website. There were so many that the company servers were not able to answer these requests and the web page went down. In the days that followed, a set of other web pages, ranging from eBay to CNN, went down for the same reason. After two months, the police discovered that the logons were artificial and came from a 15-year-old Canadian hacker, whose nickname was Mafia Boy. He did not need to burn any cable to block the Internet: what he did was enough to bring down the websites that attracted most of the traffic on the WWW.

As with the Internet and the WWW, most of the real-world networks show a double-edged kind of robustness. They are able to function normally even when a large fraction of the network is damaged, but suddenly certain small failures, or targeted attacks, bring them down completely. For example, genetic mutations arise naturally throughout life (and some of them can even delete certain proteins from the cell) or are produced artificially (as in the case of a genetic technique called gene knockout , that turns off the function of a whole gene in lab rats). Still, organisms display a great tolerance to many mutations, and to an unexpectedly large number of knockouts. Most of the time they continue to work normally, in overall terms. On the other hand, certain specific mutations are capable of completely disrupting the workings of a cell. The brain loses neurons all the time: a stressful experience for any given organ, such as getting drunk occasionally, can kill a considerable number of cells. But after the hangover everything works fine again, usually. In Parkinson’s disease, a large portion of the neurons can disappear without the patient even noticing. But when this portion exceeds a certain threshold, then the disruptive condition starts to become manifest.

In this respect, networks are very different from engineered systems. In an airplane, damaging one element is enough to stop the whole machine. In order to make it more resilient, we have to use strategies such as duplicating certain pieces of the plane: this makes it almost 100 per cent safe. In contrast, networks, which are mostly not blueprinted, display a natural resilience to a broad range of errors, but when certain elements fail, they collapse. How many errors can a network tolerate without even noticing the problem? And what are the elements that cause the collapse? With the objective of answering these questions, scientists have simulated failures by removing nodes from network maps and observing what happens. After the removal of a fraction of nodes, they check whether the surviving nodes are still connected (that is, whether a giant connected component is still present in the network) and close (that is, whether the average distance is still small). In order to simulate errors, the nodes are removed at random. When this is done to a random network, after a few removals the distance increases quickly and the graph breaks down in many disconnected components. A random graph of the size of most real-world networks is destroyed after the removal of half of the nodes. On the other hand, when the same procedure is performed on a heterogeneous network (either a map of a real network or a scale-free model of a similar size), the giant connected component resists even after removing more than 80 per cent of the nodes, and the distance wimad cow syndromeeguthin it is practically the same as at the beginning. The scene is different when researchers simulate a targeted attack, as in the strategy of Mafia Boy. They started by removing first the most ‘important’ nodes (hubs) of the network. In this situation the collapse happens much faster in both networks. However, now the most vulnerable is the second: while in the homogeneous network it is necessary to remove about one-fifth of its more connected nodes to destroy it, in the heterogeneous one this happens after removing the first few hubs.

Highly connected nodes seem to play a crucial role, in both errors and attacks. They are the ‘Achilles heel’ of most heterogeneous networks exposed to targeted attacks. In these networks, hubs are mainly responsible for the overall cohesion of the graph, and removing a few of them is enough to destroy it. On the other hand, hubs are also the ‘ace in the hole’ of these networks, when they are exposed to errors and failures: when nodes are removed at random, most of the time the selected nodes come out from the large population with low degree, so as long as hubs are kept untouched, the network stays together. This behaviour becomes clearer considering that the degree is usually correlated with the betweenness. High-degree nodes are most of the time bridges through which many paths of the network pass. When random damage is applied to a network, it will rarely affect one of the few hubs. While hubs are unaffected, they provide the necessary connectivity: there is no need for many redundant connections; paths crossing hubs keep the working areas of the damaged network connected. In those few networks in which some low-degree nodes have high betweenness and act like bridges (as certain airports do), attacking hubs still causes serious damage, but the most lethal strategy is attacking the most central nodes.

故障和攻击

2001 年 7 月 18 日，一列火车在美国巴尔的摩的地下隧道中脱轨并起火。稍后，美国东海岸几个州的网速就变慢了。大火烧毁了途经隧道的光缆，这些光缆分属于美国最重要的几个互联网服务供应商。结果，这一事故引发了横扫美国大部分地区的多米诺效应。互联网常常面临类似的事故。任何时候总会有一定比例的路由器由于各种原因而一直处于死机状态，而每次类似事故都可能会与巴尔的摩脱轨事故一样严重。然而，这种大范围的破坏还是很少见的。网络似乎会容忍一定数量的长期功能障碍而不会出太多问题。这在一定程度上依赖于替代路径，后者允许网络内部流量绕过故障区域。然而，互联网与多数网络一样并没有太多冗余连接，其密度也并不是很高。考虑到这些特征，我们很自然就能预料到它比较容易发生故障。

尽管互联网似乎相对能够承受一些错误和意外，但精心设计的一次攻击仍能造成严重破坏。2000 年 2 月 7 日，大量用户登录了雅虎网站，其规模之大令该公司的服务器无法响应这些请，网页于是随之崩溃。在随后的几天里，一系列其他网页（从趣到美国有线电视新闻网络等）也因为同样的原因而崩。两个月后，警察发现此类登录乃一名 15 岁的加拿大黑客所为，其昵称为「黑手党男孩」。他并不需要烧任何电缆便能阻塞互联网：其所做之事足以让这些吸引万维网上多数流量的网站崩溃。

互联网和万维网的情況一样，大多数真实世界的网络都显示出一种双刃的鲁棒性（robustness）。即便大部分网络到破坏，它们仍然能够正常运转，但某些突然的小故障或者有针对性的攻击则可能让它们彻底崩溃。例如，基因突变在整个生命过程中都会自然发生（其中有些甚至能删除细胞中的某些蛋白质），或者也能人为地产生（一项名为基因除的基因技术就是如此，它能关闭实验室老鼠一个完整基因的功能）。但是，生物体仍能表现出对诸多突变以及大量基因剔除的极强忍耐力。多数时候，生物体还是会在整体上继续正常工作。另一方面，某些特定的突变却能完全破坏细胞的工作。大脑一直在丢失神经元：一次给任一器官带来压力的经历，比如偶尔的酗酒，就会杀死大量细胞。但宿醉过后，一切又都恢复如初。以帕金森症为例，相当比例的神经元甚至会在病人毫无察觉的情况下消失。但当这一比例超过某一阈值，受损情况便开始变得明显。

在这方面，网络与设计而成的系统十分不同。以飞机为例，一个元件的损坏便足以让整个机器停止运转。为了让它更具复原力，我们必须采取策略，比如复制飞机的某些部件：这能让它几乎 100% 安全。相比之下，多数并非设计的网络则对广泛的错误表现出自然的复原力，但当特定元素失效，它们便会崩。网络能容纳多少错误而不出问题？而导致其崩溃的因素又是什么？为了回答这些问题，科学家通过移除网络节点以观察会发生什么情况的方式来模拟故障。删除一部分节点之后，他们会检查剩余的节点是否仍旧相互关联（即某种巨型连通分量是否仍存在于网络之中）且连接紧密（即节点之间的平均距离是否依旧很小）。为了模拟误差，节点是随机移除的。当在随机图中如此操作时，几次移除就会导致节点间距离迅速增加，图也瓦解为许多不相连部分。在半数节点移除之后，与大多数真实世界网络大小ー样的随机图便遺到破坏。另一方面，异质网络（不管是真实网络图还是大小类似的无标度模型图）中经历相同的过程时，其中的巨型连接通量在 80% 的节点都移除之后仍然存在，而其内部的距离则实际上与最初无异。而当研究者模拟像「黑手党男孩」使用的那样一项针对性攻击时，情况则有所不同。他们一开始移除了网络中最「重要」的节点（枢纽节点）。在这种情况下，两种网络的崩溃速度都比之前快很多。然而，后者更为脆弱：在同质网络中，需要移除大约 1/5 的枢纽节点オ能将其推毁，而异质网络刚被移除少数枢纽节点，就会发生坍塌。

1『同质比异质的冗余度大。（2021-02-17）』

高度连接的节点似在错误和攻击中都发挥着至关重要的作用。它们是暴露在针对性攻击之下的多数异质网络的致命弱点。在这些网络中，枢纽节点主要负责图的整体聚合，移除其中少数枢纽节点便足以将其推毁。另一方面，枢纽节点也是这些网络在暴露于错误和故障中时的「王牌」：当随机移除节点时，多数时候被选出的节点均为低度数节点，因此，只要枢纽节点保持不变，网络便不会坍塌。考虑到节点度数常常与中介性相关，这种情就会煎加清晰。高度数节点多数时候都是许多网络路径经过的桥梁。当网络遭到随机破坏，为数不多的枢纽节点很少会受到影响。既然枢纽节点不受影响，它们便提供了必要的连接：许多冗余连接则显得多余；经过枢节点的路径会让受损网络的工作区域保持连接状态。在某些低度数节点具备高中介性且扮演桥梁角色（就像某些机场一样）的少数网络中，枢纽节点遭到攻击仍然会导致严重的破坏，但最致命的策略还是攻击最具中心性的节点。

### 8.3 Domino Effects

The possibility of a sudden transition from a resilient behaviour to a global collapse should ring some alarm bells. In ecosystems, a certain rate of extinction is inevitable: one in each million of species becomes extinct every year, according to some estimates. Usually, foodwebs rearrange after these events, and most of the species do not suffer major damage from these natural extinctions. But large-scale collapses are possible too: about 250 million years ago, more than 90 per cent of the species disappeared in a relatively short period, the famous Permian extinction. Five massive extinctions of this kind have been registered in the last 500 million years. Researchers have argued that external factors may be the cause, such as the much-debated meteorite that may have made dinosaurs extinct. However, a network explanation is also possible. Cases of extinctions in chain, or co-extinctions , are not unknown to ecologists. For example, the introduction of the virus of myxomatosis to control the population of rabbits in England in the mid-20th century ended up making the big blue butterfly ( Maculinea arion ) extinct in 1979. The virus decimated rabbits, and as a consequence the tall grass they ate spread in the fields. This destroyed the habitat of ants, that used to make nests in low grass, where the sun could reach. Ants had a mutualistic relation with blue butterflies’ larvae: they took care of the larvae, which responded by providing liquid food to the ants. The disruption of their habitat gradually impaired the reproduction of the butterflies, bringing them to extinction. This is not a coextinction in the literal sense, since rabbits did not disappear due to mixomatosis and blue butterflies have been partially reintroduced. However, it gives an idea of how far damage to foodwebs can go. A large-scale version of this story, with a chain of extinctions that depletes almost a full ecosystem of species, is a possiblemad cow syndromeegu alternative explanation to the great extinctions of the past. This should also be taken into account when massive attacks on ecosystems are voluntarily carried out by humans, as in the case of too much fishing currently depleting marine ecosystems at an unprecedented scale.

Several other dynamic processes on networks could give rise to similar cascading failures , or breakdown avalanches . A typical example is a large-scale blackout: the failure of a power station overloads another one, which fails in its turn, propagating the overload throughout a large part of the network. In this phenomenon, the failure of a node results not only in loss of interconnection or reduction of the average distance but also in a domino effect. The systemic failure of economic networks experienced during financial crises is another instance of this phenomenon. The same can happen in congestion phenomena , such as cars collapsing certain points of the street network, people collapsing a subway station during a special event, or online traffic collapsing certain Internet services. In all these cases, studies have shown that hubs are crucial, both because they reduce transit times and because they are first in becoming saturated.

多米诺效应

系统可能会从能够容错的弹性状态突然转向全局性崩溃，这应该引起人们的警醒。根据估计，一定速度的物种灭绝在生态系统中是不可避免的：每年，每一百万个物种中就会有一个灭绝。通常，食物网会在灭绝事件发生之后重组，绝大多数物种并不会受到此类自然灭绝事件的重大影响。但大规模的食物网崩溃也是可能的：大约 2.5 亿年前，超过 90% 的物种在相对较短的时期里纷纷灭绝，这便是著名的二叠纪大灭绝事件。过去 5 亿年里，地球上总共发生过 5 次类似的大灭绝事件。研究人员认为地外因素可能是罪魁祸首，比如充满争议的可能导致恐龙灭绝的陨石坠落事件。

然而，也可以用网络来解释这些事件。物种的连环灭绝或共同灭绝事件对于生态学家而言并不陌生。例如，英国曾于 20 世纪中期引入黏液瘤病毒以控制兔子的种群数量，这最终导致大蓝蝶于 1979 年灭绝。这种病毒消灭了兔子，但兔子食用的高茎草却因此得以蔓延。后者又破坏了蚂蚁的栖息地，它们习惯在有阳光的低茎草中筑巢。蚂蚁与大蓝蝶的幼虫之间有着共生关系：它们会照看幼虫，而幼虫则报之以流食。因此，蚂蚁栖息地的破坏逐渐损害了大蓝蝶的繁衍，进而导致其灭绝。这并非真正意义上的共同灭绝，因为兔子并没有因为黏液瘤病毒而灭绝，而部分大蓝蝶也被重新引进。然而，这一事件却让我们对食物网可能受损的程度有所了解。将此事件的规模扩大，其中的连环灭绝几乎耗尽整个生态系统的物种，这便可能成为以往大灭绝事件的另一个解释。当人类主动对生态系統进行大规模破坏时也应考虑这种情况，例如，目前过多的捕捞正以前所未有的规模消粍着海洋生态系统。

网络上少数其他动态过程也可能引发类似的连锁故障或雪崩式崩溃。大规模停电便是一个典型例证：某个发电站的故障导致另一个发电站过载，这又导致后者出现故障，继而在网络中大范围传播电力过载故障。在此现象中，某一节点的故障不仅会导致节点互联的损失或降低节点之间的平均距离且还会引发多米诺效应。金融危机中出现的经济网络的系故障则是这种现象的又一例证。拥堵现象中也会发生同样的情况，比如车流致使街道网络某些地点的交通发生瘫痪，人流因特殊事件而在地铁站中形成阻塞，又或者网络流量导致某些互联网服务器崩溃，等等。研究表明，枢纽节点在所有这些情况中都至关重要，不仅因为它们能减少运输时间，还因为它们会率先饱和。

### 8.4 Epidemics

In 1347, one of the most devastating plagues in human history appeared in Constantinople. During the following three years, the Black Death moved to Europe, leaving a large fraction of its population dead. The disease covered Europe like a wave, at a velocity of 200–400 miles per year ( Figure 12 left). This picture is much different from that of modern pandemics. The 1918 influenza that is estimated to have killed 3 per cent of the world population took just one year to spread, reaching even isolated Pacific islands in that time. The 1957 flu virus, also called ‘Asian flu’, swept the globe in about six months. More recent outbreaks, such as 2009’s swine flu, leapt from one side of the planet to the other in a few weeks ( Figure 12 right). While the Black Death travelled with pilgrims, merchants, and sailors, lurking in ships and carriages, at a few miles per day, modern diseases can rely on much more efficient means of transportation, such as highways, trains, and aeroplanes. In the 14th century, physical distance was a leading factor in the spread of an epidemic. In the modern networked world, an infection can jump on a plane and reach the opposite side of the planet in a few hours.

Epidemics spread in networks both at the global level (for example, through the airport network) and at the local level: infectious diseases that jump from person to person depend on individuals’ social networks. For example, flu spreads partially through face-to-face contact between individuals, while HIV spreads in the network of unprotected sexual contacts. In 2001, the Cabilan physicists Romualdo Pastor Satorras and his Italian colleague Alessandro Vespignani decided to study the problem by modelling and simulating the spread of a disease in a social network. They introduced just the minimal ingredients of an infectious process: at the beginning, a few individuals of a social network get infected; if a healthy individual is in contact with one of them through a link, he or she has a certain probability of being infected; on the other hand, infected individuals have a certain probability of recovering. This model of infection is called SIS , because each individual passes through the cycle susceptible–infected–susceptible (a healthy individual is ‘susceptible’ to being infected). The process represents infections such as the than in its random counterpart. I0H5A common cold, from which people usually recover. It can be further complicated to represent other diseases, for example by introducing the possibility that people die or are immunized. However, the general direction of the results are not changed by these modifications.

Pastor Satorras and Vespignani found that, after an initial phase of expansion, the virus can either be eradicated — it shrinks and finally disappears from the population — or become endemic — it sustains itself and infects a certain fraction of the population indefinitely. The disease is said to be below the epidemic threshold when, for every infected individual, fewer than one person gets infected: in this case, it becomes extinct. The disease is above the epidemic threshold if every infected individual passes the disease to more than one individual: in this case, it thrives. If vaccines are available, the disease can be pushed below the threshold by means of campaigns that immunize a sufficient portion of the population. Very contagious diseases are usually the hardest cases, because they have a low epidemic threshold and so they become endemic very easily. If eradication is too hard, pushing the disease closer to the threshold still has a positive effect: that is, reducing the proportion of people indefinitely affected by the endemic disease.

In their study, Pastor Satorras and Vespignani found that the epidemic threshold depends crucially on the features of the underlying network. When the SIS dynamics are performed on a random network, a clear threshold is found that allows us to estimate how many individuals have to be immunized to extinguish the disease. But when the dynamics are performed on a heterogeneous network, then the threshold almost disappears: it is much lower than in the random graph; moreover, the larger the size of the system, the lower the threshold. In a large enough network, the threshold is so low that it is almost unavoidable to have a proportion of infected individuals. The disease cannot be pushed below such a low threshold without immunizing almost all the population. In epidemics, as in many other dynamics, heterogeneity makes a difference. Studies of errors and attacks have shown that hubs keep different parts of a network connected. This implies that they also act as bridges for spreading diseases. Their numerous ties put them in contact with both infected and healthy individuals: so hubs become easily infected, and they infect other nodes easily. The super-spreaders identified by epidemiologists are likely the hubs of social networks.

The vulnerability of heterogeneous networks to epidemics is bad news, but understanding it can provide good ideas for containing diseases. Ideally, almost all the population should be immunized to block the infection completely. However, if we can immunize just a fraction, it is not a good idea to choose people at random. Most of the times, choosing at random implies selecting individuals with a relatively low number of connections. Even if they block the disease from spreading in their surroundings, hubs will always be there to put it back into circulation. A much better strategy would be to target hubs. Inmunizing hubs is like deleting them from the network, and the studies on targeted attacks show that eliminating a small fraction of hubs fragments themad cow syndromeegu network: thus, the disease will be confined to a few isolated components. This strategy faces a practical problem: nobody really knows the full map of social connections of a human group, so it is hard to identify its hubs. However, a clever tactic to find them was suggested in 2003 by physicists Reuven Cohen, Shlomo Havlin, and Daniel ben-Avraham: they suggested selecting people at random and asking them the name of somebody they are connected with. The most repeated names in this list are most likely the hubs of the social network: in fact, for its many connections, a hub will be tied to many people, so it will probably be mentioned by many of those interviewed. It should be noted that immunizing hubs works perfectly in theory, but many real-world details could impair it, such as whether the network disposes of specially redundant paths that go around hubs, or whether the network of contacts is fixed in time or evolving: for example, if Alice has HIV, and has unprotected sex with Bob, and Bob has unprotected sex with Carol, it makes a big difference to Carol whether Bob has sex with her before or after having sex with Alice.

The picture of the spread of an epidemic in a social network can be partially generalized to the case in which nodes do not represent people but locations (say, airports), and what spreads on the network are people (say, infected or healthy travellers). In this case, one can define a global invasion threshold , above which the disease becomes a pandemic, and below which it remains contained at local level. Closing airports is rarely a good idea: we would need to shut down 90 per cent of airports to block certain epidemics effectively, which would have too high a social and economic cost. Cleverer strategies, such as sharing antivirals with developing countries (which are often the source of new pandemics), are much more effective.

12 The 14th-century bubonic plague swept Europe like a wave (left), while 2009 swine flu was more similar to a fire throwing sparks from one side of the planet to another (right): the difference is due to the dramatic change in human transportation networks

流行病

1347 年，一场人类史上最具破坏性的瘟疫在君士坦丁堡暴发。之后的三年里，黑死病蔓延至欧洲，导致该地区大部分人口死亡。这种疾病像波浪一样以每年 200-400 英里的速度在欧洲蔓延开去（图 12 左）。这种传染图景与现代流行病大异其趣。据估计导致世界 3% 人口死亡的 1918 年大流感仅用了一年时间传播，它甚至延到了与世隔绝的太平洋岛屿上。1957 年的「亚洲流感」病毒仅用了半年时间便席卷全球。而更近的 2009 年的猪流感则在几星期之内便从地球一侧蔓延到了另一侧（图 12 右）。黑死病潜伏在船只和车厢中经由朝圣者、商人和水手等媒介传插的速度每天不过数英里，而现代疾病则依赖更高效的交通方式传播，比如高速公路、火车和飞机等。14 世纪时，物理距离是流行病传播的主导因素。而在现代的网络世界中，传染病能跳上飞机，数小时之内便可到达地球的另一端。

14 世的瘟像波浪一样在欧洲蔓延（左），而 2009 年的猪流感则更像火团从地球的一端至另一端溅下火花（右）其中的差异在于人类交通网络的巨大变化

流行病经由全球网络（比如机场网络）和地方网络传播：人际传染病则依靠个人社交网络传播。例如，流感在一定程度上通过个人之间的面对面接触传播，艾滋病病毒则经由无保护性接触网络传播。2001 年，卡比兰公司的物理学家罗慕阿尔多·帕斯托尔·萨托拉斯及其意大利同事亚历山德罗·韦斯皮尼亚尼決定通过建模和模拟疾病在社交网络中的传播来研究这个问题。他们只引入了疾病传染过程的最简机制：一开始，社交网络中的少数个体感染了疾病；如果某健康个体通过某种关联与这些人中之一有过接触，则他或她有一定的概率会被感染；另一方面，被感染个体也有一定的概率会康复。这种感染模型被称为「SIS」，因为每个人都会经历「易感」，感染-易感（susceptible-infected-susceptible）这个周期（健康个体对疾病「易感」）。这个过程表现了类似普通感冒的传染病，感染人群往往会在这个过程中恢复。还可以将这个过程复杂化以表现其他传染病，例如引入致死或免疫等可能性。然而这些修改无法改变最终结果的大致走向。

萨托拉斯和韦斯皮尼亚尼发现，病毒在最初的扩张之后要么被根除 一一 迅速减少并最终从人群中消失 一一 要么成为地方病停留在某地并反复感染该地区的部分人群。若每个被感染个体所感染的人数少于一人，则该种疾病低于传播阈值：在这种情况下，该疾病会逐消失。若每个被感染个体所传染的人数超过一人，则该疾病便已超过传插阈值：在这种情况下，该疾病会逐渐传播开去。若疫苗可用，人们便可通过使足够比例的人口免疫而将相关疾病控制在传阈值之下。高传染性疾病常常最为棘手，因为它们的传值很低，进而十分容易传染开去。如果人们难以根除某种疾病，则将其传染性降至传播阈值附近仍有积极效果：这会降低受地方性疾病反复感染的人口比例。

在萨托拉斯和韦斯皮尼亚尼的研究中，他们发现传播阈值主要取決于底层网络的特征。当 SIS 机制作用于随机网络时，出现了一种能够使我们估测根除相关疾病所需免疫人数的明确阈值。但当这种机制作用于异质网络时，免疫阈值则几乎消失：它远低于随机图的阈值；此外，系统规模越大，免疫阈值越低。若网络足够大，免疫阈值会低至几乎无法避免部分人群被感染的程度。不将几乎全部人群进行免疫是无法将疾病控制在如此之低的阈值下的。流行病与其他许多动力机制一样，都会受网络异质性的影响。人们对故障和攻击的研究已经表明，枢节点会将网络的不同部分连接。这意味着它们也扮演着传疾病之桥梁的角色。枢纽节点的众多联系将它们与被感个体和健康个体相互联系：因此，枢纽节点很容易被感染，它们也容易感染其他节点。流行病学家确认的超级传播者很可能就是社交网络的枢纽节点。

异质网络在流行病面前十分脆弱不是个好消息，但加深对它的理解却会为疾病控制提供好的思路。理想情況下，几乎所有群体都应被免疫以完全阻断传染。然而，如果我们只能免疫一小部分人群，随机选择免疫人群便不是个好主意。多数时候，随机选择意味着会选出那些与他人联系相对较少的个体。即便这样能让他们阻断疾病在其周围的传播，但枢纽人物还是会让疾病重新传播开去。瞄准枢纽人物是更好的策略。对枢纽人物进行免疫就像将其从网络中删除，而对针对性攻击的研究表明，删除小部分枢纽节点会打碎网络：因此，疾病将被限于网络中少数孤立区域。这个策略面临着一个实际问题；无人真正知晓某个人群的完整社交联络图，所以很难确定枢纽人物。

然而，物理学家鲁文·科恩、什洛莫·哈夫林以及丹尼尔·本一亚伯拉军在 2003 年提出了一个精巧的策略以找到枢纽人物：他们建议对人群随机抽样，并询问与这些被选取人相互联系的人的名字。这个名单中重复最多的名字最可能是社交网络的枢纽：事实上，枢纽人物因自身的众多连接而与很多人相关联，所以许多受访者都会提到他们。我们应当注意，免疫枢人物在理论上十分奏效，但真实世界的诸多细节会降低其有效性，比如，网络是否会处理枢纽节点周围的特殊冗余路径，或者联系网是稳定不变还是在不断演化等：例如若爱丽丝携带艾滋病病毒且与鲍勃有过无保护性行为，而鲍勃又与卡罗尔有过无保护性行为，这两次性行为发生的先后顺序对卡罗尔而言则意义重大。

流行病在社交网络中的传播图景可部分推广至其中节点不表示人群而代表地点（比如机场）的网络中，并且在这个网络上传播的是人群（比如被感染或健康的旅行者）。在这种情況下，我们可以定义一个全球入侵阈值，高于此阈值的疾病成为流行病，反之则为局部层面的疾病。关闭机场往往并非上策：我们需要关 90% 的机场能有效阻止某些流行病的传播，这将带来巨大的社会和经济损失。与发展中国家（这些国家通常是新型流行病的源头）共享抗病毒药物这种更聪明的策略则有效得多。

### 8.5 Viruses, Ads, and Fads

A couple of obscure Pakistani programmers, a university professor, a group of high school students…these were the authors of the first computer viruses. During the eighties, these parasite programs started to jump from one computer to another, basically hiding in the floppy disks interchanged by users. The first viruses were academic experiments on self-replicating software, but soon they escaped from the lab. In 1986, the Brain virus appeared from Pakistan. In the same year, a German laboratory lost control of Virdem . One year later, a group of students put Vienna in circulation. In the nineties, computer viruses were already a global problem, but this was nothing compared to what was in store.

The advent of the Internet brought a new generation of viruses that were capable of sending themselves to other computers through the Net. In 1999, Melissa spread through the Internet: people started to receive email messages with subjects such as ‘Important message for you’ or ‘Here is the document you asked for…don’t show anyone else;-)’. The mail contained a file called list.doc. If the receiver opened it, it launched a program that sent the same message to the first fifty email addresses held in the computer. Iloveyou, Slammer, Sobig, Blaster , and many others exploded across the Net, using similar mechanisms and with disastrous effects: some of them destroyed companies’ computer systems, universities’ databases, and even affected Internet traffic.

Some features of a computer virus infection are strikingly similar to real-world epidemics. A computer becomes infected through its connections (for example, the social contacts of its owner as sampled by his or her email network) and infects others similarly. Some of the conclusions reach destinational of theed for diseases explain the puzzling behaviour of computer viruses. Even if antivirus programs are quickly updated, some viruses still circulate years after their first strike. This is no surprise if one considers the features of an epidemic spreading in scale-free networks: even if a large proportion of computers are immunized through antivirus programs, this is not enough to eradicate the infection: there is always some high-degree node here or there that puts it back in circulation.

This characteristic of endurance, which is a real problem with computer viruses, can be turned into a resource if one wants to disseminate information in a heterogeneous network. This is the principle behind viral marketing . Thanks to virtual social networks, today the WWW is full of videos, games, and applications that have ‘gone viral’: they are being forwarded by hundreds of thousands of people to all their contacts every day. One of the first examples of this idea was the spread of the Hotmail email service. In 1996, the company inserted into emails an automatic footer saying ‘Get your free web-based email at Hotmail’, containing a link to a form for setting up a new email address in a few seconds (see page 50). Similar strategies were implemented by the email services of Yahoo! and Google, and by many social networks that are launched on the basis of providing access by invitation only.

Viral marketing takes advantage of an underlying psychological phenomenon called social spreading . This is the general tendency of people to mimic their contacts’ behaviours, and to spread gossip, fads, rumours and ideas. This mechanism also acts in innovation adoption, group problem solving, and collective decision making. Sociologists and psychologists have found many examples of the striking tendency of humans to ‘copy’ each other. In 1962, a group of girls at a mission school in Tanzania experienced an unusual tendency to uncontrollable laughter. After a few months, tens of pupils of the school showed the same symptoms, and other people in the villages where some of the pupils were sent to rest showed the same disquieting giggling. After much investigation, doctors A. M. Rankin and P. J. Philip, who studied the case, came to the conclusion that it was an instance of ‘mass hysteria’. A similar case was reported in 1998 in a high school in Tennessee, when the experience of a teacher who had the feeling of smelling gasoline spread to hundreds of students. All environmental factors were excluded, and scientists came to the conclusion that a kind of ‘emotional contagion’ was at work.

Many similar cases of social spreading have been documented, but in recent years scientists have found that the same mechanism may play a role in less exceptional settings: for example, obesity and smoking seem to spread on social networks. Three reasons are behind the fact that people connected share certain features or behaviours. First, there are external factors, such as belonging to the same social class: for example, people belonging to lower social classes have an increased risk of smoking and becoming obese; at the same time they are more likely to establish ties with each other than with people of a higher social class. Second, there is homophily: people that smoke or have similar body mass tend to make friends with those with similar habits. Third, there is social spreading: if you are a friend of somebody who smokes or is overweight, you are more likely to consider taking up smoking or increasing your daily food intake. Probably all three mechanisms are at work, but social spreading is likely to be the least trivial of them and should not be underestimated. Sociologists argue that it’s not a specific condition that spreads; rather, it’s the sharing of norms about what">divide et impera sH5A is appropriate that is disseminated. This perspective could be used in public health, to foster safer habits by targeting hubs in social networks.

Naturally, the contagion of behaviours, as well as rumours and ideas, is different in many respects from that of diseases. Unlike contagion, the act of spreading information is necessarily intentional. On the other hand, acquiring information is usually advantageous, so it is a more active process than getting infected. Learning or being convinced may need a longer exposure than getting a disease. Moreover, many other competing mechanisms are present. If social spreading was the leading factor, uniformity would be the rule, but in fact mechanisms against simple assimilation generate diversity, minorities, and polarization. In any case, in certain settings social contagion may indeed be the most relevant mechanism. In the forties, Richard Feynman invented Feynmann’s diagrams as tools for modern high-energy physics. Some physicists accepted them with enthusiasm and others with scepticism, but they finally triumphed. A study of their diffusion in the communities of physicists of the US, Japan and USSR revealed that the observed trends could be quite accurately fitted with models used for epidemics, provided that the parameters were tuned to very different values.

病毒、广告与时尚

两个无名的巴基斯坦程序员，一位大学教授，一群高中生。这些人便是计算机病毒的始作俑者。上世纪 80 年代，这些寄生病毒程序开始在计算机之间传播，它们基本上藏身于用户互换的软盘上。第一批病毒是自我复制软件的学术实验品，但它们很快从实验室中逃逸。1986 年，「大脑」病毒出现在巴基斯坦。同年，一家德国实验室失去了对「波光」病毒的控制。一年后，一群学生传播了「维也纳」病毒。90 年代，计算机病毒已成为全球性问题，但这与即将发生的事情相比则微不足道。

互联网的出现也来了新一代病毒，它们能通过网络将自己拷贝发送至其他计算机。1999 年，「梅丽莎」病毒在互联网蔓延：人们开始收到主题为「有你的重要消息」或「这是你请求的文件。请勿转给他人。」的邮件信息。这些邮件中包含一个名为「ist. Doc」的文件。如果接收者将其打开，它就会启动一个程序，进而将相同的信息发送至计算机中保存的前 50 位联系人。「爱虫」「蓝宝石」「巨无霸」「冲击波」以及其他许多计算机病毒纷纷在网络上爆发，它们有着类似的机制并都造成了灾难性后果：其中些破坏了公司的计算机系统、大学的数据库，甚至影响了互联网流量。

计算机病毒传播中的一些特征与真实世界的流行病惊人地相似。计算机经由自己的连接（例如，作为计算机主人社交联系人样本的电邮网络）而受到感染，同时也以类似的方式感染其他计算机。一些关于疾病的结论解释了计算机病毒令人困惑的行为。即便杀毒程序会及时更新，一些病毒仍会在其首次攻击后的数年里继续传播。若考虑到流行病在无标度网络中的流行特征，这便不足为奇了：即使大部分计算机因杀毒程序而免疫，也不足以根除病毒感染：总会在这里或那里存在一些高度数节点让病毒重新流行。

若想在异质网络中传播信息，对计算机病毒构成严重问题的异质网络容错特性则可转变为某种资源。这便是病毒式营销背后的原理。多亏了虚拟社交网络，万维网如今充满了「像病毒般扩散」的视频、游戏和应用程序：每天都会有成千上万人将这些内容转发给自己的所有联系人。体现这个想法的首个例子是微软电邮服务的传播。1996 年，微软公司在邮件中插入写有「来微软电邮获取你的免费网页邮箱」的自动页脚，其中包含的链接能让人在很短的时间里设置一个新邮件地址（见本书第 50 页）。类似的策略也体现在雅虎、谷歌的邮箱服务以及许多基于邀请才能使用的社交网络服务中。

病毒式营销利用了一种被称为社交传播的潜在心理现象。这是人们模仿其联系人传播闲话、时尚、谣言和观念的大体趋势。这种心理机制也会在创新、团队解決问题和集体決策中起作用。社会学家和心理学家们发现了人类带有明显彼此「模仿」倾向的很多例子。—— 1962 年，坦桑尼亚所教会学校中的一群女孩就经历了一场无法控制笑声的非正常倾向。数月之后，同一所学校里的几十名学生也都表现出相同的症状，而这些学生中的一部分被送往一些村庄安置后，村中其他人也表现出同样令人不安的略略笑的症状。经过大量调查，研究该病例的医生 A.M.兰金和 P.J.菲利普得出结论：这是「集体歇斯底里」的一个病例。1998 年田纳西州的一所高中发现了一个类似案例，当时，感觉闻到汽油的老师将这种感受传递给了数百名学生。排除所有外部环境因素后，科学家们得出结论说，某种「情绪传染」机制在其中起了作用。

人们已记录了许多类似的社交传播案例，但近年来科学家们发现，同样的机制还可能在不那么特殊的环境中起作用：例如，肥胖和吸烟似乎也会在社交网络中传播。相互关联的人群共有某种特征或行为主要基于三个原因。首先在于他们属于同一社会阶层这种外部因素：例如，同属较低社会阶层的人吸烟和肥胖的风险较高同时，与社会阶层较高的人相比，他们更有可能与彼此建立联系。其次，人以群分：吸烟者或那些有着相似体重的人们往往会与有着类似癖好的人成为朋友。第三，社交传播的作用：如果你是吸烟者或超重者的朋友，那你更有可能开始吸烟或増加自己的日常食物摄入量。

这三种因素可能同时起作用，但社交传播可能最为重要，不应被低估。社会学家认为，传播的并非某种特定的情况；相反，是人们对何谓恰当的共识得到了传播。这种视角可应用于公共卫生领域，通过采取针对社交网络枢纽节点的措施来培养人们更加健康的习惯。

自然，行为、谣言及观念的传染在许多方面都与疾病传播有所不同。与传染病不同，散布信息必然是有意为之。另一方面，获取信息往往对人有利，因此它更多地是一种主动而非被动感染的过程。学习或被说服所需的接触时间可能比患上疾病要长。此外，许多其他竞争因素也会起作用。如果社交传播是主导因素，均一性将是其内在规则，但事实上，反对简单同化的因素会产生多样性、少数群体和两极分化。无论如何，社交传播在一定背景下或许的确是最为相关的因素。理查德·费曼于 1940 年代发明了费曼图这种现代高能物理学工具。一些物理学家满心热诚地接受了这种工具，另一些人则对其抱有疑虑，但这些图最终成功了。针对费曼图在美国、日本、苏联物理学家团体中扩散的研究表明，其扩散趋势可与流行病模型十分准确地吻合，前提是将模型中的参数调为十分不同的值。

### 8.6 Which Came First, Networks or Dynamics?

One of the keys to the success of ancient Rome was its strategic position close to the River Tiber, which at the time was first and foremost a communication and commercial route. When the city became more powerful, it started building the first branches of its formidable road network. In their turn, the roads were a crucial tool for maintaining and further expanding Rome’s power, since they provided a quick way to move goods and legions. More roads meant more power, and more power made it necessary to create even more roads: the result was that ‘All roads lead to Rome,’ according to an Italian saying. Similar patterns of development can be observed in almost every important city. A growing city attracts traffic and requires more connections (roads, railways, airlines…), which in their turn increase traffic and growth, which imply even more connections, etc. The communication network influences the dynamics of traffic, but this in turn reshapes the network, in a feedback loop.

Asking how network topology affects dynamics implies an assumption: that the network is an immutable structure, on top of which processes take place. In reality, all networks change during the dynamics.

网络及动力机制孰先孰后？

古罗马成功的关键因素之一是其紧邻台伯河的战略地位，该河当时乃首屈一指的通信和商业路线。城邦变得更加强大之后，人们便开始营建其强大的道路网络分支。反过来，道路网又成为维持并进一步扩张罗马强权的关键工具，因为路网使得运输货物和军团更加快捷。更多的道路意味着更多的权力，而更多的权力又必然会打造更多道路：结果便如意大利谚语所言，「条条大路通罗马」。我们几乎能在每个重要城市的历史上发现类似的发展模式。扩张中的城市吸引了更多的交通，也需要更多的连接方式（道路、铁路、航线），这些因素反过来又会增加交通流量和扩大城市规模，而这又意味着更多的连接。通信网络会影响交通的动力，后者反过来又会在反馈回路中重新塑造网络。

网络拓扑如何影响了动力机制这一题暗含了某种假设：网络乃不可变的结构，过程在它上面发生。现实中，所有网络都会在动力作用的过程中发生改变。因此，仅当动力机制的发生时间比拓扑早很多时，这一假设有意义。在某些过程中这是合理的：例如，人们每天或每周相互交换的信息会在固定的社交网络中传播，因为通常友谊与亲属关系的更替是按年进行的；或者，城市的车辆交通不论在哪一天都会在固定街道上进行：通常街道连接不会每天都改变。

然而，在其他情况下，这种假设是有缺陷的。例如，在性传疾病的传播过程中，与他人发生关系的时间顺序尤为重要。与某人建立无保护性关系发生在与受感染的他人建立无保护性关系之前还是之后很不ー样。如果我们想研究一个城市十年的发展，那么有必要考虑交通和正在改变的连接之间的相互作用。在类似对等文件共享系统等一些技术网络中，网络结构和信息动力机制在相同的时间段内变化且强烈地相互交织。而食物网中的种群动态能够引起网络的重组。当过度捕捞将某物种数量降至一定水平之下时，食物网会重新排列捕食次序，并让新物种代替旧物种。网络结构和动力机制的耦合在虚拟社交网络发展的特定时刻尤其重要。这些工具提供了个人网络结构和内容的恒定信息流。因此，研究者认为，这种增强的意识可能改变人们创作、维护和影响其社交网络的方式。

一些方法可用于处理网络结构和动力机制耦合这个问题。例如，我们可以通过最优化构建网络模型，其中需要优化的量与网络流量或搜索这样的动力机制相关。更加完善的方法在于修改适应性模型，使得适应性的值取決于ー些动态参数。当动力机制继续作用时，适应性也会相应地发生改变；这便可以重组网络。其他策略也是可行的，所有这些都现固了一个基本观点：多数情况下，当某个动力机制在网络结构中发生或与它耦合时，多数时候我们必须将基本图纳入考虑以充分理解正在发生的情形。

## 0901. All the world's a nets or not?

One of the fathers of quantum mechanics, Paul Dirac, was reported to say about the revolutionary discoveries of physicists at the beginning of the 20th century: 'the rest is chemistry’. He meant that all science could be derived from the first principles of physics. Unfortunately, no more than a few cases, essentially the atoms of hydrogen and helium, can be solved precisely with quantum mechanical equations. More complex objects, like molecules, must be approached through approximations or computer simulations. Apart from a few macroscopic quantum effects, at the moment fundamental physics is relatively useless in understanding biology, the mind, or society. Similar mistakes occur in genetics, when DNA is incorrectly framed as something that can explain all the features, diseases, and behaviours of humans. In general, the results of basic science should not be taken beyond their real range of effectiveness, and it should be acknowledged that more specialized disciplines can give much deeper insights beyond that range. Network science should avoid the trap of overhyping. Its holistic vision, the revelation of unexpected similarities between widely different systems, and the current cultural fascination with the concept of network bring with them the temptation to think of network science as a 'theory of everything’. Sociologists, engineers, biologists, and philosophers have warned about the bald generalizations drawn from network theory. Most of this criticism is reasonable, but the results of network science should not be underestimated, nor its potential for future discoveries impaired.

The first major limitation of network science is the hunger for large-scale data. Methods used in social science, such as questionnaires and interviews, are costly, time consuming, and sometimes prone to subjective biases. Data drawn from information technologies (phone calls, email, social networks, geo-localization, RFID chips, health data, credit cards, etc.) provide unprecedented access to people’s social relations, but they po">congestion phenomenam organismsse some problems too. A person delivering pizzas receives many phone calls, but most of them are from clients, not from friends: the pizza delivery guy problem shows that sorting out relevant information from large amounts of IT data (the list of phone calls, in this example) is not easy. Moreover, it should be mentioned that data mining with networks also creates ethical problems related to privacy and to their use by the military.

In many situations, only partial data are available. In order to draw aquatic foodwebs, ecologists capture fish and examine their digestive tracts: with this method, even the most brilliant scientist can miss some of the links. Genetic methods to deduce physical interactions between proteins can produce both false positives and false negatives. Maps of the Internet and the WWW are obtained by sending a 'probe’ from a node to explore the surrounding edges: a sufficient number of paths can give a fairly good representation of the network, but some edges may never be discovered by the probes.

Once the data are available, representing them in a graph is inevitably a reductionist act. The focus on topology is one of the strengths of the network approach, but it forgets many of the specific features of the elements. If we are interested in those features, the graph approximation can be inadequate. Sometimes, but not always, network models can be modified to include these features.

The graph representation can fall short when geography (that is, the physical location of nodes) is more important than topology. For example, the position of electrical substations, airports, or train stations is obviously relevant to the arrangement of their connections. Furthermore, in social networks and foodwebs, closeness can determine the actual possibility of establishing a relation. Another element that may escape graph representations is time. For example, in sexually transmitted diseases, establishing a link with a person after he or she is infected by another person is obviously very different from doing so before the infection: the timing of links is crucial for the spread of the disease. Timing is important in a large range of networks: for example, scientific publications are arrayed in time, and they can only cite papers that came out in the past.

Sometimes, identifying nodes and edges is not trivial. It is easy to distinguish between an eagle and a hawk, but one could easily lose count of the number of bacteria in an ecosystem. To avoid underestimating the number of 'small’ species, ecologists customarily aggregate organisms in trophic species, sets of organisms that share the same predators and the same preys. Similarly, social scientists aggregate individuals that are structurally equivalent : people that have the same number and kind of ties, for example within a family group. Similar procedures are applied to the Internet at the autonomous system level, the network of brain areas, etc. These procedures have to be performed in a coherent way to obtain a network that makes sense. Defining edges can be even more complicated. A company can hold a small fraction of the capital of another one, or up to 100 per cent of it. Two airports can be connected by one flight per day or by one per hour. In all these cases, a threshold must be established, below which a relation is considered too weak to be recorded. Weighting or putting a threshold on links strongly influences the shape of the resulting network, and must be done with very good reasons.

Once data have been arranged as a graph, a careful interpretation of the results is essential. An entire branch of network science is devoted to visualization, that is, producing algorithms to came to the conclusionttgu arrange nodes and links sensibly on paper or computer screen. However, most of the conclusions cannot be drawn by visual inspection, and mathematical analysis is needed. Criticisms have been made on the basis that not all complex networks have a heterogeneous degree distribution (and in any case this is never a mathematically exact power law). It is true that networks can be interesting also if they are not heterogeneous, but it is fair to say that often interesting networks are indeed heterogeneous. Perfect power laws are not vital: what matters is the presence of fat tails, revealing the existence of hubs. Interpreting heterogeneity as a signal of self-organization has been criticized, pointing out that a certain level of planning is present in many networks, as in the case of the precise design of local networks by administrators in the Internet. However, there is no doubt that the Internet, like many other networks, has not been designed at the large-scale level. So it is reasonable to argue that their deviationections do no

整个世界是否就是一张网？

据报道，量子力学的创始人之一保罗·狄拉克在谈及物理学家们在 20 世纪初的革命性发现时说：「其余都是化学过程。」他的意思是，所有科学都能从物理学的基本原理中推导出来。很不幸，仅有少数几种情況可以由量子力学方程精确求解，它们还基本都是氢氦原子。像分子那样更为复杂的东西则必须以近似法或计算机模拟的方式处理。目前，除了少数宏观量子效应，基础物理学当前对我们理解生物、心理或社会而言相对无用。类似的错误还发生在遗传学中，人们错误地将 DNA 界定为能够解释人类所有特征、疾病和行为的决定因素。

一般而言，基础科学成果的应用不应超出其真实的有效范围，人们应当认识到更专业的学科能够提供超出这一范围的更深刻洞见。网络科学也应避免落入被夸大的圈套。其整体性的视野，对差异明显的系统出人意料的相似性的揭示，还有当前对网络概念的文化上的迷恋，所有这一切使得我们很容易将网络科学视为「万用理论」。社会学家、工程师、生物学家和哲学家都曾警告世人注意从网络理论中提取的空洞概括。这类批评多数是合理的，但网络科学的成果不应被低估，其对未来各种发现的潜力也不应受到贬低。

网络科学的第一个主要限制是其缺乏大规模数据。社会科学中使用的调查问卷和访谈等方法十分昂贵且耗时，有时候还容易带有主观偏见。从信息技术（通话记录、电子邮箱、社交网络、地理定位、无线射频识别芯片、健康数据、信用卡等等）处获取的数据为我们了解人们的社交关系提供了空前的便利，但这也带来一些问题。披萨送货员会接到许多电话，但多数来自客户而非其朋友：「披萨送货员问题」表明，人们从信息技术数据（比如本例中的通话记录）中整理出相关信息并不容易。此外，还应提及的是，网络数据挖掘也制造了一些涉及隐私以及军事用途的伦理问题。

很多情况下，人们仅能获取部分信息。为了画出水生生物的食物网，生态学家会捕捉鱼类并检查其消化道：即便最杰出的科学家用这种方法也会错过一些物种联系。推导出蛋白质之间物质相互作用的基因方法既能产生假阳性也能产生假阴性结果。互联网和万维网图可以通过从某节点释放「探测器」以探索其周围各边的方式获取：足够数量的路径能很好地呈现网络，但某些边可能从不会被探测器发现。

一旦数据可用，将其呈现在图中则不可避免会将其简化。网络方法的优势之一是其对拓扑的关注，但它忽略了元素的诸多具体特征。如果我们对这些特征感兴趣，图形近似法便显得不够用了。网络模型有时候被修改后可以包含这些特征，但并不总是如此。

当地理（即节点的物理位置）的重要性高过拓扑时，图示法也会不够用。例如，变电站、机场或火车站的位置明显与其连接的安排有关。此外，社交网络和食物网中的节点接近性则能决定建立某种关系的实际可能性。图示法可能遗漏的另一个元素是时间。例如，在性传播疾病中，在某人被他人感染之后与其建立关系明显不同于在这之前与其建立关系：关系建立的时机对疾病的传播至关重要。时机在大量网络中都很重要：例如，科学出版物按时间排序，科学家们只能引用那些之前发表的文献。

有时，识别节点和边绝非小事。我们很容易区分鹰和隼，却很难数得清生态系統中的细菌数量。为了避免低估「微小」物种的数量，生态学家通常会将营养物种里的生物聚集，这些生物共享同样的天敌以及相同的猎物。类似地，社会科学家则会聚集结构上等同的个人：具有相同联结数量和种类的人，比如家庭成员。类似的方法还被用于自主系统层面的互联网以及大脑区域网络等。这些过程必须以连贯的方式进行以获得一个合理的网络。边的定义更为复杂。某公司可能持有另一个公司的小部分或全部资本。两座机场可通过每天一次航班或每小时一次航班相互连接。在所有这些情況中都必须建立阈值，低于该阈值则被视为弱关系而不被记录。为连接加权或设置值会强烈影响所得网络的形状，因此必须建立在充足的理由上。

一旦将数据组织为图，就必须仔细解读其结果。网络科学有一整个学科分支都在专门研究可视化，即制造算法以便在纸张或计算机屏幕上合理安排节点和连接。然而，多数结论无法经由目测得出，而要对其进行数学分析。一些批评指出，并非所有复杂网络都具备异质度数分布（在任何情况下，这都绝非数学上的精确幂律）。的确，若网络并非异质，它们也会有趣，但公平地说，有趣的网络往往是异质的。完美的幂律并不重要：重要的是肥尾的出现，它掲示了枢纽节点的存在。将异质性解读为自组织的标记这一点已受到批评，人们指出许多网络中都存在着一定程度的规划，正如管理员对局域网的具体设计一样。但无疑地，互联网与其他许多网络一样并未经过大规模设计。因此，人们有理由认为，这些网络对随机性的偏离可被归因于自组织过程。此外，度数异质性仅是网络复杂性的其中一个标记。异质性还出现在许多其他特征中，比如中介性、集聚性和权重等，复杂性同样也会出现在其他特征中，这一点与异质性不同：例如，模块和社区结构常常偏离随机性，并对网络顶层的动力机制产生强烈影响。

另外一个批评则指出，网络科学发现的只是不同系统和动力机制之间的模糊相似性，而非真实的普适类。后者是对应于相同基本数学定律（在特定细节被忽略的情况下）的不同现象群。当然，生物网络的具体特征与技术网络的具体特征完全不同，计算机蠕虫病毒的扩散与疾病的传染遵循着不同的规律。然而，网络理论为这些如此不同的结构和过程提供了一个共同的趋势和预测的框架。通常，如果系统足够大且相关现象的观察时间足够长，它们便会展现出十分相似的趋势。

网络科学已经在一些领域显示出了它的预测能力。它目前被应用于咨询行业，以帮助组织更好地开发各成员不同的技能；在公共卫生领域，它能预和防止传染病的蔓延；在警察和军事系統中，它被用于追踪恐怖分子、罪犯以及反叛团伙；此外网络科学在其他一些领域也有应用。还有许多问题亟待解决，其中包括制作更精细的模型以适配特定的网络和动力机制；寻找新的相关网络数据深入挖掘拓扑以发现未被注意到的规律，并充分解释现有规律；描绘小型网络的特征并学习如何处理众网之网；将生物网络与演化范式更有效地连接；发现新的应用（比如在药物设计中）；以及有可能的话找到普适类。

伽利略·加利莱伊有一句名言如此说道：「哲学写在宇宙这本大书之中......书写语言为数学，字母则为三角形、圆形以及其他几何图形......」我们相信，尤其在如今这个复杂的当代世界里，我们需要网络这种「字母」。

2『上面的名言写一张金句卡片。』——已完成