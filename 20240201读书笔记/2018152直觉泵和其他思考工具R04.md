## 记忆时间

2021-09-29

## 目录

2801 红发人那事儿 —— 大脑中的认知机制

2901 彷徨的双币机、孪生地球以及巨型机器人 —— 原初意向性和派生意向性存在明显的边界吗

3001 彻底翻译与蒯因式填字游戏 —— 不存在绝对正确的翻译

3101 语义引擎和句法引擎 —— 大脑只是通过句法引擎模仿语义引擎

3201 沼泽人遇上母牛鲨 —— 哲学家最喜爱的直觉泵

3301 两个黑盒子 —— 究竟是什么让红灯闪烁

## 第四部分更多关于意义的思考工具 —— 小结

为了处理意义的基础概念，21 种思考工具，包括十几个直觉泵和一些有用的概念悉数登场并投入使用。在它们的帮助下，我们做出了什么呢？它们是否全部奏效了？注意，证明一个直觉泵是否有价值有两种方法：首先，如果制作精良，它泵出的直觉就是可靠的、有说服力的，能够有力地遏制一些使人浮想联翩的错误路径；其次，泵出的直觉依旧可疑，但直觉泵可以帮助我们把注意力集中在它的前提上，看看出了什么问题。

2『检验直觉泵是否有价值的方法，做一张任意卡片。（2021-09-25）』—— 已完成

在这两种情况下，直觉泵都是一种杠杆，就像跷跷板，一边升，另一边就必须降，且唯有当它不会弯折或从中间断裂时方能奏效。直觉泵比跷跷板更复杂，因此，正如我在两个黑盒子的例子中所说的那样，我们需要拧一拧上面的旋钮，但毫无疑问，在接受它的结论前，我们还须检查其他旋钮。

对于意义，这一部分给出了什么样的结论呢？喜忧参半。意义不会是某种易于映射到大脑中的简单性质，我们也不会在任何地方找到可以解答某个句子、某个思想或某个信念的真正意义的「深层」事实。我们所能做的不过是，找到并锚定全部物理立场和设计立场以及现有资料的最佳解释。

如果我们能找到解决蒯因式意义困境的一个方法，那么，几乎可以肯定，我们就已经发现了唯一的解决之道，这是说，我们可以确信，不存在某个尚未发现的更好的解决办法了。正如前往巴拿马的双币机表明的那样，意义总是相对于某个功能背景，它并不需要什么原初意向性，除了我们「近似」自私的基因的意向性。自私的基因从经自然选择而进化的功能背景中获得其近似意向性，而不是从一个智能设计者那里获得这种东西，就像那个订购巨型机器人的有钱客户一样。两个黑盒子的直觉泵表明，要理解并解释世界上的因果规律，意向立场，连同它接纳的所有近似信念之类的东西，并不是可选项。

在 21 世纪，我们对这些问题的研究大大增强了，第一次可以严格地、积极地对那些有着数以万亿计的活动部件的机制进行思考，它们的运作方式并不神秘。多亏了图灵，起码我们现在可以隐约看到一条路径，让我们从无理解能力的物质「物理立场」开始，经由一系列重新安排「设计立场，以及近似意义」达到这样一种自我理解：我们是信者、知者、理解者的典范，经由意向立场简化为意向系统。

这些命题中的每一个都存有争议，或曾经存有争议，而且现在仍有许多专家不同意所有的这些命题。也许，将这些命题有序地组织起来会增强其说服力，同时我们会发现一个「临界质量」现象：它会吸引那些还不曾看到诸多部件是如何巧妙地啮合的人。

另一方面，把这些命题像这样组织起来能让批评者更容易地找出一条贯穿其中的错误主线。不论怎样，我们都能由此获得进步。或许我们会发现其中的花招，它们遮蔽了真理，而不是照亮了真理。要找到其中的破绽，我们得回过头去转动更多的旋钮，看看会发生什么。最起码，发现这些破绽是一种辛酸的进步：它暴露出那些诱人的错误思想，而且几千年以来一直有哲学家身陷其中。

我并不是说该部分给出了一种意义理论。它给我们的只是一个相当宽敞的逻辑空间，如果我是对的话，一个恰当的有关意义的科学理论必须能容纳于其中。[61] 既然我们对心灵的内容方面已经有了一个大致确定的了解，我们可否转向意识这一谜中之谜呢？还不行。我们需要建立更多的基础。理解意识的过程中浮现出很多问题，正如我们在这一部分已经看到的，这些问题都有着与进化相关的预设或影响。许多我们还在探索的主题已经涉及了进化，所以，在继续探索之前，让我们揭示这些主题，并对其加以澄清。这可是一个无限迷人的话题。

达尔文认为万物经自然选择而进化，在我看来，这是人类有史以来最为杰出的想法，因为它大胆地尝试将物质与意义联结在一起，而现实的这两个方面似乎有着天壤之别：一方面，我们拥有心灵世界以及它们的意义，我们有目标、希望、渴求，以及最为尊贵同时也是最为平常的哲学话题 —— 生命的意义。另一方面，我们头顶的银河不知疲倦地旋转，行星漫无目的地沿着轨道上升下落，无生命的化学机制按照物理规律运行，这一切毫无目的、毫无理由。

然而，达尔文出现了，他告诉我们前者如何从后者中孕育而生，创造了意义，这是一种关于诞生的重要性的冒泡式（bubble-up）图景，它颠覆了传统的涓滴式（trickle-down）图景。自然选择的想法并不十分复杂，但非常强大，以至于让有些人无法直视，他们拼命转移注意力，仿佛它是一剂让人厌烦、难以下咽的苦药。这里有一些思考工具，它们有助于我们看到这个想法是如何照亮存在中阴暗的角落，如何将奥秘转变为我们可以解决的问题，并揭示出前所未有的自然荣光的。

[61] 我有预感，一个恰当的有关意义的科学理论将呼之欲出，它会取代有效的老式人工智能的布尔式刚性逻辑结构，代之以一个更灵活的、基于模式搜索算法的贝叶斯统计或概率网络，但是要实现这些想法尚需时日。

1-3『写书籍《为什么》的大牛研究的应该就是这个领域的。（2021-09-25）』

## 2801. 红发人那事儿 —— 大脑中的认知机制

有个还算诱人的想法：大脑携带的全部信息，包括信念、看法、记忆、策略等，被分解成了类似语句的片段，而这些片段则被分类存档以待再次唤起。我们已经发现，这个想法存在着一些问题。脑写入（brain-writing）不能简单地置入一个虚假信念，而人们可以共享某个信念，例如发生在伦敦的那起谋杀，犯不着共享用脑语写成的公式。但是，大脑里还有什么可以储存信息呢？我们人类可以「零打碎敲地」进行学习，所以肯定有一些让孤立事实逐个地、粗略地加起来的方法。

经济学家和其他一些人常喜欢说，你不可能仅仅做一件事情。做「一件事」通常有诸多后果。同样，说你只能学习一件事物也不一定对。但大体上说这还是可能的。在先前的章节中，你了解到有一种叫作普度鹿的哺乳动物。除非你合上书去查资料，否则，除了它们会照料幼崽、长有脊椎并且相对稀少等事实，你不大能确认任何有关普度鹿的东西，因为如果它们不是那么稀有，你之前就该听说过这种动物了。你是如何学到这些并不神秘：你只是读到一句话并相信了这句话。但是，动物或尚未学会说话的小孩能否从一些有趣的零星经验中获知某个单一事实呢，比如简单句所表达的事实？知识、信念或学习过程一定得分解为句子般大小的碎片这一想法大概只是拟人论的幻象。人们在一天当中会碰上许许多多的陈述句，有些是口语的，有些是书面语的，据此得以获悉形形色色的事实，同样也会误信一些谎言。其中一些我们放在图书馆或者档案馆储存，而另一些我们只存放在大脑里。我们很少逐字逐词地记住一个实实在在的句子，但当我们记下眼前的一个句子的要点时，它一定是在大脑中被存储成了某种类似句子的东西，例如，一段用脑语写成的公式。真的是这样吗？如果不是这样，还能怎样？

设想帕特说「迈克对红头发的人有点看法」。帕特大概是想说，迈克对红发人有一种刻板印象，这当然意味着迈克对红发人有些不敬，也影响了他对红发人的期望和同他们之间的交往。迈克并不只是对红发人抱有成见，他对红发人还有相当独特的看法。帕特可能是正确的，比他自以为的更正确！我们可能发现迈克确实持有某种东西，它不是想法或见解，不是信念或想象，也不是其他任何我们常说的能提供意识体验的东西，而是大脑中的某种「次人」的认知机制，该机制总归涉及红发人。也就是说，只要话题是关于红发人的，该机制就会系统地发挥作用，调整迈克认知机制中的各种参数，使他不大能接受或承认对红发人优点的各种恭维，在面对红发人时也更易产生相对激进的行为，等等。这个涉及红发人的运作可能十分复杂，也可能相当简单。

「迈克对红发人有看法」绝对为我们提供了一些东西，它的意义无法否认，然而，其意义无法以一个让人信以为真的语句的形式表述出来，这种表述顶多只是一个助记标签。所以，这种东西不能称为信念，无论是明确还是含混的，例如：所有红发人都是 F 开头的单词（「F」可以替换为任何一种对迈克的态度的表达，只要它足够公允）。毫无疑问，迈克对红发人抱有某种态度，但那不是一种特定的命题态度。用哲学术语来说，无论我们如何千方百计地在上述表达式中塞入不可兼条款、限定词、概率算符或是对其内容做显式调节，它都无法被处理为以下形式：

迈克相信：对于所有 x，如果 x 是红发人，那么……

哲学家以及其他理论家往往想将所有认知状态「还原」为可以由上述公式表达的信息负载状态（information-bearing states），并把它们称为信念或者欲望。虽然这种手段是提供心理草图的好办法，也就是意向立场，但是想把它们高度精确地表达出来的希望依然渺茫。若是乐意，我们可以说，各种各样的信念在系统中是隐式的。这意味着系统当前的运行「基于这一假设」，即世界上的红发人有着一些如此这般的特征。电脑程序员有时会在源代码中加入一段注释，注明这个系统基于一套确定的假设，他们知道自己不必为精确表达耗费心力，因为这些注释不过是为观察者设置的助记标签，并不是由电脑近似读取或理解的东西，即便对于我们这些观察者来说，注释也不是有关内容的「详细说明」，与化学家在描述分子结构时用到的化学式也不尽相同。

为某种次人的大脑结构给出一种意向立场的解释，类似于为几段代码加上注释；注释得当，它就为我们提供了一个启发性的标签，但这并不等于把某个在信息处理过程中用脑语表达的公式译成了英语或其他什么自然语言。有些哲学家没能看透这一点，他们生造出一些内在语句操控机制（internal sentence-manipulating machinery）的奇妙世界，在这些奇妙的世界里，用选言式谓词（我看见一个男孩或女孩）或者没有逻辑结构的谓词（我看见一个孩子）来表达一个特定的大脑事件的内容，是截然不同的。

这个直觉泵的目的是什么呢？它只是一次尝试，试图表明：对于力挺思想语言的那番熟悉的反诘「还能是什么呢」，或许会有一个令人满意的答案，到时候就能让那些认为思想语言显然成立的人无话可说。我真希望自己能给出一套宏大的计算架构，大获全胜地展示出一个可行的替代方案，可惜我不行。至今还无人能行，甚至几乎无人尝试，因为很多人依然坚信，思想语言就像某人很多年前说过的那样，是「最后的救命稻草」。但是切记，在认知科学领域，至今还没有人发展出一套可行的思想语言模式，甚至也不曾为此努力过。这是一个异常困难的问题。[45] 但愿某个开放的心灵能受到这个直觉泵的启发，解决这个问题。

[45] 说点有关专家系统的题外话：CYC 项目（Lenat and Guha, 1990）无疑是最令人印象深刻的人工智能系统，它是思想语言这类想法的执行系统，一部百科全书（enCYClopedic），它拥有人工编制的海量数据库，并配有专属推理引擎负责管理该数据库。目前，CYC 项目的发展已经超过四分之一个世纪，参与人数众多，但就其设计而言，它力所能及的范围依然是冷冰冰的非生物、非心理的领域。参见 Wikipedia 上关于 CYC 的精彩介绍。几乎可以肯定，迈克有关红发人的看法不是一个用脑语表达的公理化的红发人微型理论，也未配备类似于 CYC 的那种大型数据库。我们尚不了解通过这类东西能做些什么。原因是，除了一些非常简易的模型，例如著名机器人制造专家罗德尼·布鲁克斯（Rodney Brooks）及其同事的类昆虫式包容架构（Brooks, 1987），我们目前仍未对此有过直接研究。布鲁克斯的 Cog 项目研制了一种类人机器人，这个项目的一个主要理论贡献在于：将这些高度非命题式的内容结构模型套用在人类心理上（Dennett, 1994b）。

## 2901. 彷徨的双币机、孪生地球以及巨型机器人 —— 原初意向性和派生意向性存在明显的边界吗

我把「迈克对红发人的看法」以及源代码写在了同一段落，这似乎在鼓励读者无视基础问题中的裂隙，更确切地说，是我关于意向性讨论中的鸿沟：原初意向性（original intentionality）问题，这个术语是塞尔在 1980 年发明的。表面上看，他在原初意向性和派生意向性（derived intentionality）之间做出的明确区分总体上令人满意，甚至引人注目。原初意向性学说主张一些人造物，例如书籍、电影、电脑以及指示牌，可能从我们身上获得某种意向性，而我们所具有的原初（或内在）意向性则完全不是派生出来的。比如印在本页的文字关乎哲学，恰恰因为作者和读者拥有关于哲学的思想和信念，我们设法通过这些文字传达有关哲学的思想和信念，若没有我们这些文字使用者，它们根本什么都不是。

相比之下，思想和信念的意义独立于任何隐秘的使用者；它们展露了原初意向性，它们是人造物的所有派生意向性的终极源头。这些人造物不仅包括词句、书籍，同样也包括地图、电影、印刷品、符号、标志、图表以及其他技术表征，最重要的还有电脑。你写在小纸片上或记在手机上的购物清单为什么能帮你买东西呢？仅仅是因为你了解这些符号结构的使用，你赋予它们意义，你有购物的欲望并且确信超市就是该去的地方。与购物单相比，这些东西更为直接，也更加根本。亚里士多德说上帝是不动的原动者（unmoved mover），套用这一说法，我们便是无意的赋义者（unmeant meaner）。

我们完全同意塞尔的话，任何东西都不能单凭其物理形状或其他类似的属性获得内在意向性。请看下图的字母形状：

F R E E B E E R

假设，由于某种机缘巧合，这些形状出现在火星的岩壁上，无论地球人多想把它读作「免费啤酒」，它（本来）也不会是这个意思。这个图案不会是对任何东西的表示，不管它乍看起来像什么。如果这世界上有某些事件和物件是关于其他东西的，它必定会从它所处的表征和解释的意向系统中获得意义，该系统的状态，如信念、欲望、大脑状态等总得是已经具有意向性的才行。

接下来的问题是，是否存在具有原初意向性的东西呢？乍一看很明显，必须存在某些具有原初意向性的东西，因为派生意向性必须得从某种东西中派生而来。具有原初意向性的候选者显然就是人类心灵了。尽管一些有名的哲学家在许多方面都极不赞同塞尔，如杰里·福多尔和索尔·克里普克（Saul Kripke），但是，在原初意向性问题上他们倒是意见一致。他们和许多志同道合的人认为，人类心灵或心灵状态具有原初意向性，就此而论，人类心灵完全不同于机器人控制系统。

坦率地说，他们全都错了。是的，我不是在开玩笑。由于原初意向性和派生意向性之分有着无可争辩的魅力，任何敢于冒犯它的尝试恐怕都会被「好心人」误解：「他不会当真说我们错了，他一定是在借此表达一些深奥的哲学观点，只不过他愚蠢而荒谬地给它们披上了挑衅的外衣罢了！」也许，我只有提供一个生动、清晰的有关派生意向性的事例，才能让人们相信我是认真的。下面我会证明，通过一番更为仔细的考察，人们所钟爱的这组对照，即派生意向性与作为原初意向性的人类心灵，将被消解掉。这是一项艰巨的任务，但我还是要尽力而为。我需要三个彼此联系的直觉泵来完成这一壮举。

### 29.1 彷徨的双币机

设想一种制式软饮料自动贩卖机，它在美国设计组装，并配有传感装置，可以接受 25 美分的硬币。我们可以把它叫作双币机（two-bitser）。[46] 通常，当我们往双币机中投入一枚 25 美分的硬币时，它便会进入 Q 状态，「意为」（注意双引号，此处只是近似意为）：「现在，我感到或收到了一枚货真价实的 25 美分硬币。」这种双币机设计得相当精巧，但并非绝对安全，它们确实会「出错」。当投入金属片或外国硬币时，它们有时也会进入 Q 状态，而有时它们也会拒绝合法硬币，未能进入本该进入的 Q 状态。

毫无疑问，我们可以检测造成机器「错觉」背后的模式。同样，具有足够的相关物理学以及传感机制设计参数知识的人至少可以断定某些「误认」的情况。那么就可以直接从物理规律推理出：不仅合法的 25 美分硬币能触发 Q 状态，其他某种 K 型物件也能触发 Q 状态，但是过重的 J 型物件或者磁性的 L 型物件不能触发 Q 状态。如此说来，K 型物件将是合适的金属片，它会可靠地「骗过」传感器。看看我在这段中多么不厌其烦地使用了「近似算子」，这样一来，在我给你们双币机的规格时就可以使用意向立场了。当你试着重写本段而不使用意向立场时，你会惊叹它多么有效，近似算子可谓不可或缺。

假使 K 型物件在双币机的正常使用环境中变得愈加普遍，我们就会期望双币机的拥有者和设计者研究出更高级、更敏感的传感器，以便可靠地区分真正的 25 美分硬币和 K 型金属片。当然，到时候狡猾的造假者可能会改变 K 型金属片的外观，因此，需要探测传感器的进一步升级，但技术上的升级可能带来收益递减，因为天底下本来就没有什么不会出错的机制。与此同时，工程师和使用者都清楚，这种基础版的制式双币机也能将就对付，为防范那些微不足道的造假者而做出技术上的升级太不划算。

唯有该装置的设计者、制造者、拥有者以及使用者之间的共同意向才能使之成为一部硬币探测器，而不是什么金属片探测器或者硬币 / 金属片二选一探测器。只有在这些使用者及其意向的环境或背景之中，我们才能挑出 Q 状态的某些情形，将其视为「切实」，从而把另外一些情形视为「出错」。也只有在意向的背景之下，我们才会一开始就将这种装置称为双币机。

我想，到目前为止，我已让塞尔、福多尔、克里普克等人点头称是了：意向正是如此这般地同人造物关联；这是一个关于派生意向性教科书般的案例，其间种种让人一览无遗。因此，没人怀疑，某种双币机直接从美国的工厂下线，贴上「A 型双币机」的标签，就可以安装在巴拿马的软饮料贩卖机上，并开始工作，接受或拒收巴拿马的法定货币巴波亚 25 分硬币。通过设计和加铸币印可以很容易地区分巴波亚硬币和美元硬币，但它们之间不能通过重量、厚度、直径或材质加以区分。

我可不是信口雌黄。我从稀有钱币飞鹰专柜的权威人士艾伯特·埃勒尔（Albert Erler）处获知，标准的自动贩卖机无法区分 25 美分硬币和铸造于 1966-1984 年间的巴波亚 25 分硬币。这没什么奇怪的，因为后者就是在美国铸币厂用美元硬币的储备造出来的。虽然与这个例子不甚相关，但我想补充一点，只当满足大家的好奇心：2011 年，巴波亚币兑美元的汇率是 0.98，所以今天的一枚巴波亚 25 分硬币的价值略小于一枚 25 美分硬币。

这样一个被带至巴拿马的双币机也会正常地进入确定的物理状态，无论将一枚 25 美分硬币、某个 K 型物件还是一枚巴波亚硬币投入该机器，我们都会以其物理特征来确认 Q 状态，但现在，被视为出错的情形不同了。在新的环境中，25 美分硬币就像 K 型物件一样，被视为引起机器出错、产生「错觉」和误认的金属片。反过来，在美国，巴波亚硬币就是一种金属片而已。

当双币机安装在巴拿马时，我们能不能说所谓的 Q 状态依旧发生了呢？该装置「接受」硬币时的物理状态依然发生了，但现在是不是应该说，我们将那种物理状态确认为「识别出」一种新状态 QB 呢？没错，我们该怎样说有相当大的自由，毕竟双币机只是人工制品，对其感知和误认、切实或非切实状态，也就是对其意向性的讨论，简言之，「只是隐喻」。双币机的内在状态，或随你怎么称呼，既不真正（原初地）意味着「现在收到一枚 25 美分硬币」，也不意味着「现在收到一枚巴波亚 25 分硬币」。塞尔、福多尔和克里普克等人会坚称，它没有真正意味着任何东西。它的内在状态仅仅近似于意味着某种东西，但是，对于我们这些原初意向性理论的欣赏者来说，这足以引发一些问题。让我们仔细地看一看。

双币机最初设计为一种用来检测 25 美分硬币的机器。这是它的「应有功能」（Millikan, 1984），毫不夸张地说，亦是其存在的理由。如果没有这种功能，没人会花时间把它造出来。鉴于此，一般说来，我们可以将这样一部装置主要地或恰当地刻画为双币机，它的功能是检测硬币，因此，相对于这一功能，我们不仅能确认它的切实状态，即正确地检测出硬币，也能确认它的错误状态。

但这不能阻止我们为一个新的用途而临时征用双币机。但只要是物理定律，任何新用途都可以被允许，例如，用作 K 型物件检测器、巴波亚硬币检测机、门挡，甚至一件致命的武器。对于它的新角色，也许会有短暂的混乱期或不确定性。当积累了多长的记录之后，某物就不再是双币机，而是变成了巴波亚硬币检测机（q 巴波机）、门挡或致命武器呢？[47] 一台双币机，经过 10 年的忠诚服役，刚刚变成了一部 q 巴波机，对于这部 q 巴波机的首次亮相，它的 Q 状态是否是对巴波亚硬币的正确检测呢？会不会有某种习惯性的怀旧错误导致它将一枚巴波亚硬币误认作一枚 25 美分硬币？

就像上面描述的，双币机与我们人类截然不同，它没有任何可成为过往经验的记忆，哪怕是其过往「近似」经验的「近似」记忆。但是，如果你认为这有影响，我们也很容易为它提供这种记忆。开门见山地说，假设原初意义上的双币机装有一个计数器，服役十年后它的记录为 1 435 792。设想，它运往巴拿马时计数器并未清零，所以它在巴拿马首次工作时计数器会跳到 1 435 793。这个数字意味着它还没能转接到正确地确认巴波亚硬币的任务吗？别忘了，它近似错误地将该事件当成了 Q 事件 —— 检测 25 美分硬币；它的用途就是检测 25 美分硬币。这一主题的变种以及并发问题会沿不同的方向驱动你的直觉泵吗？拧开直觉泵上的所有旋钮，看看你的直觉到底发生了什么。

可以肯定的是，若严格地就双币机自身来考虑，不考量它先前的历史，双币机并没有什么内在的东西，使其区别于真正的 q 巴波机，也就是巴拿马政府委托订制的机器。然而，鉴于它的前世今生，它首次进入我们所谓的 Q 状态时，它的功能、用途和意义就没有任何问题吗？这是一个进入 Q 状态（意为「接收美分硬币」）还是 QB 状态（意为「接收巴波亚硬币」）的问题吗？

我和有些人（Millikan, 1984）都认为，它在巴拿马的首秀被视为进入 Q 状态还是 QB 状态，完全取决于在其新的工作岗位上，我们是否选它来检测巴波亚硬币。例如，它被巴拿马百事可乐特许经营人选中。如果它被选中，那么，即便新的运营者忘了重置计数器，它的首次「感知」行为也会被当作一次作为 q 巴波机的正确辨认行为，因为这是它现在的用途。它的功能就是检测巴波亚硬币。另一方面，如果一台双币机被阴差阳错发往巴拿马，它的首次亮相将毫无意义，尽管用不了多长时间，那些为了新目的而征用它的相关部门就能意识到并认可它的作用，随后，它接下来的状态也就被视为 QB。在它用于检测巴波亚硬币之前，无论它检测巴波亚硬币的能力多么出色，它的接收状态也不会意味着（以其人造的、派生的近似意味方式）「现在接收巴拿马的巴波亚硬币」。

想必塞尔和他的同事对我这么说也会心满意足，双币机毕竟只是一个人工制品。它不具有原初意向性，因此也没有我们要试图揭示的什么「深度」事实。当隐喻式或者拟人化地谈论一部装置的状态时，他们会说，这不过是一个怎么说恰当的实际问题。

现在，我们已经牢牢地抓住了派生意向性，让我们看看非派生的原初意向性，即我们的意向性，有什么不同。在这一点上，塞尔、福多尔、克里普克等人不仅不同意我，也不同意哲学家露丝·米利肯（Ruth Millikan）、保罗·丘奇兰德（Paul Churchland）和帕特里夏·丘奇兰德（Prtricia Churchland）夫妇、认知科学家侯世达、马文·明斯基（Marvin Minsky），以及工作在人工智能领域的每一个人。历经 30 多年的聚讼，大家的情绪依旧高亢。我们在争什么呢？

[46] 在一开始创造这个直觉泵时，我或许不该使用这种过时的俚语。但我是不得已而为之，因为这种东西曾是一种流通量颇大的货币，所以让我继续用它吧。用「two bits」表示 25 美分有着模糊不清的起源，这让我们回想起旧时的西班牙银币八里亚尔、达布隆或其他海盗时代的遗物。

[47] 像你祖母常常用来熨衣服的那种尖头熨斗，就可以是一个相当不错的门挡。如果你想在旧货店或者「收藏品」网站淘一个的话，一定要确保它不是赝品。市场上有些不过是铁制的门挡，只是铸成了旧式尖头熨斗的样子。未来一百年也许就有人会造出稀奇古怪的门挡，看上去就像双币机，在硬币还能当钱用的年代，你的祖父还常常用它。你懂的。

### 29.2 孪生地球

设想有个人，就叫琼斯吧，他望向窗外，以为自己看到了一匹马。窗外可能有也可能没有马。但塞尔及其同事会说，「他处在自以为看到一匹马的心理状态」这一事实，根本就无关于解释。这是一个粗糙的事实，也是一个原初意向性的范例。接下来，我们来构造一个与双币机高度相似的思想实验，看看会发生什么。这是一个归谬法的实例。设想有一个和地球几乎一模一样的孪生地球，除了那里生活着犸，我们这里生活着马。[48] 犸看上去像马，除非让训练有素的生物学家用 DNA 测试，否则，可以说，它们几乎在任何方面都与马别无二致。但是，犸并不是马，就像海豚并不是鱼。孪生地球人可以管犸叫「马」「horse」或者其他什么名字，我们仅需记住：孪生地球与地球极其相似，除了那里生活着犸。

设想我们将琼斯送到孪生地球 —— 犸的家园，对此他毫不知情。我们可以给他下药，安排他在孪生地球的床榻上醒来。当我们把他带至一匹犸前，他会很自然地说或者想：「看哪！一匹马。」当他这么做时，要么他确实被激发，进入了「相信自己看到了一匹马」的状态，有了一种错误的、非切实的信念；要么他被那匹犸激发，生平第一次切实地进入了「相信自己看到了一匹犸」的状态。我们如何分辨他进入了哪一个状态呢？由犸唤起的信念是真还是假？如果一开始他错误地认为「我看到了一匹马」是错误的，那么当他生活在这些犸中，并与孪生地球人谈论犸时，他需要多长的时间才会调整「马」这个音在其语言中的意义呢（期间他并没有意识到这一点）？如果他在孪生地球上还生养了几个孩子，那么他们从老爸那里学来的词「马」是指马，还是指犸呢？他们从未看到过马，记住，那里只有犸。

这显然是一个诡谲、极端的例子，但它确实带来一个好问题：是什么决定了我们词语的意义？怎么决定的？历史是否总是对所有东西都具有重要意义？当前对词语的使用能否克服或推翻历史？在本例中，琼斯并未向我们提供独一无二的洞察；他甚至不知道自己已不再生活在地球上，因此，他大概会坚称「马」意指马。他的词语，即从他嘴里说出的词，其意义来自他的感知信念，他知道他所相信的：他在看一匹马。这就是他为什么说「看哪！一匹马」的原因。他可能还会加上一句「这不是显而易见的吗」。假设让我们告诉他这次旅行，并告知马与犸之间微小但重要的差别，接下来他会说什么呢？或者说他应该说什么呢？更重要的是，是否有个好理由支持他，无论他说什么都是确切无疑的？难道他不正是做了我们每个人都会做的吗？无论是他还是我们都不具有理论化地阐释这一处境的专享信息。假设他说他的词「马」现在意指犸，而且当他看到一匹犸并称之为马的时候，他并没有犯任何错。入乡随俗嘛。

他能否只是靠着声明其言其意就把问题解决了？如果随后他忘记他所做过的声明，又该如何？有时我们也会这样做：「从今往后，我就用（渣渣）来指盐啦！麻烦把渣渣递给我！」在科学理论化阐释的背景中，这种规定性定义是一种重要且已得到确认的做法，但它依赖于一个交往双方的合作共同体。如果琼斯具有原初意向性，想必在任何环境中，都应有一个关乎其词语意义的事实。但是，琼斯本人似乎无法参考他自己的原初意向性，他并不能比我们这些观察者做得更好。举例说来，设想我们骗琼斯说，他被我们送到了孪生地球；他相信了（在哲学家的直觉泵中，人就能这么轻信！），随后，如果他告诉我们，他的词「马」现在意指犸，这时他是对的吗？也许他应当说他不知道「马」现在意指什么。那么，由于我们知道自己也可能被送到了孪生地球，我们是不是也得承认，我们不知道「马」意指什么呢？

我们这些对原初意向性这一想法将信将疑的人已经有了关于这些问题的答案，但还需要第三个直觉泵使之更为清晰，以便同传统直觉来次难得的对战。所以，请读者们擦亮眼睛！我要设法诱使你们放弃你们珍视的直觉啦。

[48] 哲学家希拉里·帕特南（Hilary Putnam, 1975）多年前发明了孪生地球这一思想实验，我的直觉泵细致地模仿了相关细节。我的双币机的故事只是煞费苦心地重新设置了帕特南直觉泵上的旋钮。在过去 35 年间，哲学家们讨论过几十种甚至可能是上百种各式各样的变体。在最初的叙述中，帕特南选取了地球上的水和孪生地球上的水（其组成为 XYZ，而非 H2O）作为例子，但这会引入一些与我们的直觉泵不相关的复杂情形，所以，在这段叙述中，我们选用了犸 —— 就好比双币机中的巴波亚硬币。

### 29.3 巨型机器人

假设你想过 25 世纪的生活。已知的唯一办法是将你的身体保存在某种冷冻装置中，你会静静地、缓慢地进入沉睡，愿意待多久就待多久。你会在冷冻舱进入睡眠，直到 2401 年被自动唤醒。

设计冷冻舱并不是你面临的唯一工程难题，你还必须保护冷冻舱并提供必要的能量用来制冷或满足其他所需，使其可以运行 400 年。你不能指望你的儿孙负责日常管理，因为他们很可能活不到 2401 年，同样你也不大可能指望未来的后裔对你的生活计划感兴趣，你甚至可能根本没有后裔。因此，你必须设计出一个超级系统来保护你的冷冻舱并给它供应运行 400 年所需的能量。

有两种基本策略可供参考。第一种，你应该找一个你所能想到的最佳场所，在那里固定装置会很好地提供水、阳光和任何冷冻舱以及该超级系统本身所需之物。这样一套装置，或「设备」的一个主要缺点是，当有危害来临时它不能移动。比如，有人碰巧想在此处修一条高速公路。第二种策略更加复杂，但它回避了这一缺陷：为你的冷冻舱设计一个可移动的装置，配有所需的传感器和预警装置，使它可以避开可能的危害并寻找所需的能量。简言之，就是造一个巨型机器人并将冷冻舱安置其中。

显然，这两种基本策略均来自大自然，它们的区别大致相应于植物和动物的分野。第三种策略同样来自大自然：孢子或种子能够待在它坚硬的护甲里几乎无限期地存活下去，但这并不适合你，因为你的生命支持系统需要高能量，而孢子处在尽可能低能耗的惰性状态。由于动物的策略与我们的目的颇为相合，我们假定你决意造一个机器人安置你的冷冻舱。你应该试着将它设计为可以「自主决定」有助于实现你的最佳利益的行动。笨拙的行动或错误的转弯会使它不适合保护你到 2401 年，而这是它存在的唯一理由。毫无疑问，这是一个工程方面的老大难问题：这需要通过顶级的专门技术设计出一个「视觉」系统和其他一些「知觉」系统来保障运动。还有，在整个冷冻期间，你处于沉睡状态，因此你不能提供指导，并为它的策略做计划，所以你只能将其设计为可以自发制订计划以应对环境的变化。它必须「知道」如何「找到」并「识别出」可用的能量源、如何移动到更安全的区域，以及如何「预见」并「避开」危险。既然有这么多工作要做，而且还要做得快，那你最好想方设法精打细算：切勿赋予你的机器人超凡的识别能力，它只要能识别在这个世界上需要识别的东西就够了。

再次注意，我将所有意向词或「心智」词，例如「知觉」「找到」以及「预见」，都加上了双引号，用来表示这是一种特定的近似意向性：派生意向性。这种意向性完全取决于人类的目的。这是你制作的东西，无论它具有什么样的意向性，它都属于你 —— 它的制作者。若去掉了双引号，我就会被指责为在鬼鬼祟祟地搞某种意识形态，因为工程师等人往往因循守旧，会不加双引号地使用这类言语谈论某个信息处理装置的规格，例如升降电梯控制器。我有意没有这么做。为论证方便起见，我承认，使用意向语言对人造物功能进行的任何描述或规定都是隐喻。同样需要注意的是，像双币机一样，机器人的机制服从经济上的考虑：它需要「检测」或「识别」许多东西，但它的「识别器」并非完美无瑕。它可以出错，但什么算作错误归根到底取决于制作者的需要和欲求。假使制作者想造一个在「认不清」东西的世界里四处瞎撞的、滑稽的机器小丑，那么，这些「错误」中就会有一些是弄对了的，是小丑控制器的巨大胜利。

现在让我们回到直觉泵。由于你不能指望你的机器人是唯一执行该任务的机器人，你的任务将变得愈发困难。如果你的奇想流行开来：你的机器人很可能发现自己在与其他机器人，以及你的人类子孙争夺有限的能源供应、新鲜的水、润滑油等（见 67 章关于其他行动者的重要性的简短讨论）。那么，毫无疑问，你必须将机器人的控制系统设计得足够精密，允许它能计算与其他机器人合作或者结成互惠互利联盟的利益及风险。但是，再提醒一下，这种计算一定是「马马虎虎」的近似，是迫于时间压力的任意简化。

这一设计方案的结果将是一个能够表现出某种自我控制能力的机器人，因为你本人一旦进入睡眠状态，就不得不放弃对机器人的精细控制和实时操纵。因此，它能够评估当前状态与始终保护你的终极目标，并从中得到它自己的附加目标。这些次级目标可能要上百年的时间才能实现，尽管你在设计阶段尽了最大的努力，但其中一些目标可能仍不明智。也许，在被其他机器人「说服」去保护他人之后，你的机器人一行动就与你的目的背道而驰，甚至是自杀式的。

注意，在这个时候，即便机器人所有的意识状态和行为都源自你的目的，它们也会开始变得有点脱离你的目标了。因为你设计的机器人在某种程度上是「自主思考」的，它的「思考」可能超出你的预期。

考虑现实世界中一个非虚构的例子，比如一台国际象棋计算机，它可以击败它的创造者。我们说计算机正在「琢磨」车的行动，「决定」不去王车易位，这么说的唯一理由是因为人类设计者设计它做那种事。但是，由于设计者的目标是造出一台优秀的国际象棋计算机，所以，对于计算机的状态（派生性地）应当关于什么的许多决策，其实是在倒逼自己：既然国际象棋程序需要游戏规则和游戏状态的准确信息，就一定存在着诸多涉及每个象、每个兵的状态，还有在电脑的「后」吃掉了对手的「马」时对整个棋局进行评估的状态，等等。如果计算机的状态没有恰当地关联到棋盘上每一个兵的位置，无论设计者怎么做，这个状态都不会（派生性地）关涉存活在棋盘上的兵的数量。一旦确定了设计者的最大目标，比如制作国际象棋程序、巨型机器人或飓风模拟器，暴虐的大自然就会接管过来，并决定什么可行，什么不可行，哪个系统中的哪些状态是错误的或不准确的。

诗人可以通过一首看上去关于马但其实是关于教授的诗来表达自己的观点，比如威廉·布莱克（William Blake）告诉我们「愤怒的老虎比听从教导的马更有智慧」，然而计算机工程师却不能将自己的意图强加给他们的造物。

接下来让我们稍加盘点。巨型机器人精神状态的模造（simulacrum）只是这样：它并非在真的做决策、看、思考、规划，它不过是好像在做决策、思考和规划罢了。我们应该停下来想想这种说法包含了什么。我们设想的机器人肯定比不起眼的双币机复杂得多；我们赋予它「规划」新的行动方案、「从过去的错误中学习」、「养成忠诚」以及与其竞争对手「沟通」等能力。此外，为了能让它「规划」「学习」和「沟通」，我们不得不为它提供复杂的控制结构，赋予它自我反思或自我监控的能力。换句话说，它像人一样，可以通达自己的内部状态，当它「决定」不「想」向我们「撒谎」时，能够「报告」「坦承」以及「评论」其内部状态「需要」输入什么。它对这些状态的含义有「意见」，无疑，我们应该严肃地将那些「意见」视为充足的证据（这大概是我们能轻松拿到的最好证据），来证明这些状态在隐喻的意义上「意味着」什么。

切记，它不过是件人工制品，没有原初意向性；我们正在考察的是其派生意向性，对于观察者而言，其派生意向性与我们这些「真正」的行动者的意向性同样不明显。双币机没有能力动摇我们的解释性判断，因为它无法提供确定无疑的「声明」，表明它不知道自己现在身处巴拿马，或者看到巴波亚硬币让它感到意外。

对于这一直觉泵，可以有若干回应，我们将对它们略加检视。不过，我首先想引出我们在做出初始假设时所持立场的最显著含义：不管多少神奇的人工智能妙法植入其中，人工制品都不会有什么派生意向性。若坚持这一观点，我们就不得不接受，我们自己的意向性和机器人的意向性完全一样，因为我讲的科幻故事并不新鲜，它是理查德·道金斯（Dawkins, 1976）看法的另一种形式：我们和其他所有生物都是「生存机器」，其目的是延续我们自私的基因。我们是被造物，是历经亿万年设计而成的用来保障基因的生存机器，因为基因无法出于其利益迅速地、知情地行动。我们设想的自身利益和基因的「利益」很可能相悖，即便我们存在的目的就为了基因的「利益」。基因的保存是我们的原初存在理由，虽然我们学会了无视这个目标，并仰赖基因业已安放在我们身上的智力、学习能力，设计出自己的至善（summum bonum）。因此，我们的意向性源自「自私」基因的意向性。它们是无意的赋义者，而非我们！

当然，在任何意义上，我们基因的意向性都不是内在的；基因的「意义」首先取决于蛋白质的合成、发育，也就是说，取决于进化而来的、由 ACGT 密码子构成的「字母表」系统。原初只是说它是许许多多进化而来的表征系统（representational system）中的第一个。后来的所有系统都有行动者，即意向系统，行动者的表征从其推进的目标中获得意向性，就像巨型机器人的意向性那样。[49]

虽然这一图景为我们自身的意向性从何而来提供了一个满意的答案，但它似乎让人有点尴尬：我们自身的意向性派生自基因实体，而基因的意向性仅仅是类意向性。字面上的东西如何依赖于隐喻层面的东西？此外，在我的科幻小说和道金斯的故事之间显然有许多不同：在我的故事里，我假定，制造巨型机器人所涉及的工程是一个有意识的、慎思的、有远见的过程。即使如道金斯所言，我们是设计过程的结果，在此过程中，我们的基因是主要的受益者，那也是一个完全不存在有意识、慎思、有远见的工程师的设计过程。不过，我们马上就会看到，这不是一个好的反对意见。

自然选择理论的美妙之处在于，它告诉我们如何在关于种种起源的解释中将智能造物主排除出去。自然选择过程理应对这种非凡的、机巧的设计负责。基因不是设计者，它们本身再愚蠢不过了，它们不能推理、表达或理解任何东西。基因不能设计自己，它们仅仅是设计过程中的受益者，你可能会说，它们只是客户。在我们的故事里，基因可比作非常愚蠢、非常有钱的客户，他们雇佣最优秀的工程师为其建造生存机器。若不是他们，工程师就无钱可用，而且他们的存活正是其造物的代价。是谁或什么东西做的设计？当然是大自然母亲，或更直白地说，是自然选择压力下漫长而缓慢的进化过程。

在我看来，进化过程最令人着迷之处在于，它以其不可思议的能力映射出人类心灵（智能设计者）的某些性质。第五部分我们将更多地讨论如何思考进化，眼下，我想澄清一下可接受的意义理论和进化论之间强有力的联系。自然选择既无前瞻性，亦无目的性，虽然这怎么强调都不为过，但我们也不应无视这一事实：在对许多微妙关系做出无数有识别力的「选择」「辨别」和「鉴赏」之际，自然选择过程已然表明它对基本原理有着近乎完美的敏感。更挑衅地说，当自然做出选择时，它可以出于特定的理由来「挑选」特定的设计，却从不曾有意或无意地「表现出」选择或理由。自然「选择」心脏作为血液循环泵是出于其优越之处，并非出于它们跳动时迷人的节奏，尽管后者也可能是自然「挑选」其他东西时的理由之一。

巴拿马百事可乐的特许经营人可以因识别巴波亚硬币的功能选择双币机，把它用作一部巴波亚硬币检测器，同样的道理，进化也可以因为血液供氧的能力选择某个器官，将其作为肺。只有相对于这类设计「选择」或进化「认可」的目的，我们才能确认行为、动作、感知、信念或常识心理的其他范畴。[50]

我们是自然选择设计出的造物，这一想法既熟悉又引人入胜；但有些人可能会说，这种想法超出了严肃论争的范围。[51] 然而，为什么不仅是创造论者、「智能设计」理论家，就连塞尔、福多尔及其拥护者也有点儿下意识地抵制它呢？

我觉得，这一想法有两个相当不明显的含义让一些人难以接受。首先，如果我们「仅仅」是造物，那么，我们这些拥有思想的思考者就没有任何特别的权威来确认我们内心深处的思想意味着什么，甚至不能确认它们是否在根本上无所意味。用不着改变任何内在性质，双币机就可以变成 q 巴波机；过去常常用来指一种物事的状态现在意味着另一物事。所以，原则上，如果仅仅是造物，如果我们自己的意向性因此是派生的而不是原初的，同样的事就会发生在我们身上。例如，琼斯没有权威可以来认定他是在考虑马还是犸。其次，如果我们是这样的造物，我们非但不能保证有权通达深层事实来确定我们思想的意义，而且根本就不存在所谓的深层事实。功能解释有时是显而易见的，比如，心脏显然是一台泵，眼睛显然是用来看东西的。但是，当它并非显而易见时，比如当我们试图理解大自然母亲的心智时，那里并不存在任何可供解释的文本。当有关功能的「真相」（the fact of the matter）有争议时，也就是说，当多个解释都讲得通时，那里就不存在任何真相。

[49] 特库姆塞·菲奇（Tecumseh Fitch）在其重磅论文《纳米意向性：为内在意向性一辩》（Nano-Intentionality: A Defense of Intrinsic Intentionality, 2008）中提出，最早进化出「内在」意向性的实体是真核细胞，而非其祖先原核细胞。按他的说法，这是因为它们自我保全的天赋远较其祖先高超。他对单个细胞的自治性（能动性）的重视强烈影响了对我的小人儿式机械主义的各种修正（见第 20 章）。不过，对于他止步真核细胞的打算，我不表苟同。原核细胞与真核细胞一样，不能「被机器替代」；能动性可以一路下落直至蛋白质，最后就是自私的基因。

[50] 对本段坚持不懈而又激情四溢的反对来自福多尔和皮亚泰利-帕尔马里尼（Piatelli-Palmarini）的《达尔文弄错了什么》（What Darwin Got Wrong, 2010）。本书和那本书之中，肯定有一本是在大放厥词。至于为本书观点所做的详细辩护，见本书第五部分及拙作《理性的进化》（Evolution of Reasons）。

[51] 自 1984 年以来，露丝·米利肯发表了一系列才华横溢的著作，她较我更为细致地发展了这一主张。欲了解最新动态请参阅《米利肯和她的批评者》（Millikan and Her Critics, Ryder et al., 2013）。

## 3001. 彻底翻译与蒯因式填字游戏 —— 不存在绝对正确的翻译

当两个同样优秀的功能解释冲突时，有主张认为，根本不存在深层事实可以解决这一冲突，哲学家蒯因（Quine, 1960）以其彻底翻译的不确定性原理巧妙地捍卫了这一主张，他得益于一个著名的直觉泵。设想，在太平洋中心发现一座孤岛，岛民使用一种岛上特有的语言。由于没有双语翻译的帮助，人类学家或语言学家不得不通过观察、与岛民进行互动式试错来理解这种语言，这一任务被蒯因称为「彻底翻译」。蒯因认为，原则上，如果有两位调查员担负起为这种异域语言制作翻译手册的任务，他们大致可以做出相当不同但却同样优秀的翻译手册，并会为岛民的话语赋予不同的含义，因此不存在事实上正确的翻译。对许多哲学家而言，这种想法似乎过于极端，不值得认真对待，所以，他们对此只是不屑一顾，并继续固执己见。下面介绍的这种思考工具可以让上述想法看起来合情合理，甚至显而易见。有两件事需要解释：1）蒯因的说法如何在「原则上」可能为真；2）就算该说法原则上成立，我们为什么几乎无法给出一个实例。

我常用下边这道英语填字谜题考我的学生。片刻之后，他们中的大多数人都宣布做了出来。你可以在阅读下文前试试。

你做出来了吗？如果做出来了，你得到的是哪个答案？这道题有两组很棒的答案，它们藏在本书的第 76 章，在答案揭晓前给你一个机会做出这两组答案。这道题尽管小巧，但我花费了好几个小时才把它设计出来，因为横排和竖列之间的相互影响必须满足多重约束条件，它强烈地限制了设计的可能性。如果你有所怀疑，可以试着构造一个更大、更好的填字谜题！（如果你做到了，烦请发给我一份。我在其他地方会用得着的。）

有人会问，「第一竖列的单词应该是什么？」这代表了某种不合时宜的实在论。这道题根本就不存在唯一的答案。我是有意这样设置的。比如说，我并没有先定下一组答案（历史上第一个或原初的答案，「因此」是真正的答案），凑成这道填字谜题，然后再找出另一组答案。相反，我平时就收集了一些意思相近的四字母单词，从中我取出几对一并制定了这两组答案。

因为定义的规范允许有一些弹性，所以我们能构造出这样的一道谜题。这两组答案中都包含勉强满足定义的单词，但是，哲学家称之为整体论的那种严丝合缝的周边条件，却把这些单词放入了两个完全稳定的结构。你觉得有多大概率存在着与这两组答案平等竞争的第三组答案呢？通常，密码学家会抱持这样的信念：你若找到谜题的一个解决方案，你就已经发现了这道谜题的唯一解决方案。只有在特殊情况下才可能存在两个解决方案，但类似这道填字谜题这样的情况表明，存在一个唯一的解决方案并不是形而上的必然，而仅仅是在强大的约束条件下极其可能的一种结果。

人远比填字游戏或计算机复杂。人类复杂的大脑里充满了神经调质，大脑又连在身体上，而身体与整个世界深深地交织在一起，其进化史以及个人历史内嵌于世界，相互贯通，远超一个内嵌于语言共同体的字谜游戏。所以，米利肯等人是对的：鉴于设计约束的本质，在极端情况下不可能存在相异的解决之道，给出两个完全不同、有着全局不确定性且不分轩轾的解释。彻底翻译的不确定性在实践中当然可以忽略不计。不过，该原则依然有效。我们没有彻底翻译的不确定性，不是因为脑袋里存有「真正的意义」（蒯因称之为意义的「博物馆神话」，这是他的主要攻击对象）这个形而上的事实。

现实世界中我们没有不确定性，是因为有很多个独立的约束条件需要满足。密码学家的座右铭向我们保证了，这只是一个微不足道的烦恼。当现实世界遭受不确定性的威胁时，解决问题、确定解读的始终是更具「行为性」或「倾向性」的事实，而非某种神秘的「因果力量」或「内在语义性质」。意向解释几乎总是竭力达到某个单一的解释，但是，可以想象，在极端情况下双重解释通过了所有测试，于是就不存在任何深层事实可以确定哪个解释「正确」。事实确实能够确定解释，但始终是「浅层」事实在发挥作用。

## 3101. 语义引擎和句法引擎 —— 大脑只是通过句法引擎模仿语义引擎

意义如何能产生影响？它似乎并没有某种物理性质可以引发什么，如温度、质量或化学成分。大脑从激荡于感觉器官的能量流中提取意义，改善身体的发展前景，而身体则用以安置大脑并为之提供能量。大脑产生对世界上各种重要东西的预期，用这种形式「制造未来」，从而恰当地引导身体。大脑是一个非常耗能的器官，若不能完成这份重要的工作，它们就活不下去了。换句话说，大脑应该是语义引擎。大脑由大量的分子片段构成，这些片段的相互作用服从严格的化学定律、物理定律，对分子形状和分子力做出响应，换句话说，大脑事实上只是句法引擎。

设想你跑去找工程师，要他们为你打造一部验钞机或者其他类似的赝品检测器，要求它能将所有的真钞叠成一沓，而把所有假币堆成另一沓。工程师说，这不可能。我们造出来的东西只能响应「句法」性质，也就是各种物理细节：厚度、形状、纸张的化学成分、油墨的颜色模式以及其他难以伪造的物理性质。他们只能基于这类「句法」性质造出一部运作良好但并非万无一失的验钞机。做成你要求的那样太过浪费，间接、有瑕疵的检测就足够了。

大脑任何一部分的结构都受到同样的限制。无论大脑做什么，无论其输入意味着什么，或仅仅是近似意味着什么，都是由物理化学力引起的。虽然大脑有生命力，由蛋白质而不是硅和金属构成，但是，不要臆想大脑能凭借它内部的神奇组织直接地检测到意义。物理学永远胜过意义。直接响应意义的语义引擎像永动机一样，在物理上是不可能的。那么，大脑如何完成指定给它的任务呢？—— 作为句法引擎，它具有可以跟踪或模仿语义引擎的能力。[52] 但这可能吗？一些哲学家辩称，假使大脑运作的微观因果解释是完整的，没有任何未解的空白，那么，根本就没有意义发挥影响的余地。在第 33 章，我们会遇到一个直觉泵，通过展示语义性质，例如真理、意义以及指称在一些简单的因果过程中发挥着不容抹杀的作用，来证明上述看法是错误的。但在转向那个略显复杂的直觉泵之前，我打算检视一个更为简单的模型，它有助于驱散对哲学家的直觉泵的怀疑，若一切顺利，还可以消除一些可能会干扰理解的疑虑。

[52] 哲学家约翰·豪格兰德（John Haugeland, 1981）说，人工智能的第一原则是，「你若搞定句法，语义将自己搞定自己」。人们对这一口号有着不同的理解。最初的版本抱着过高的希望，鼓励人们去检索大数据库：这种数据库是一个世界知识的公理化形式体系，可以由某个纯粹句法的推理引擎维持并加以利用，CYC 就是最好的例子。这在大多数专家眼中已被视为是不可行的，但我们不妨将该口号看作是对以下想法的优秀表述：大脑是一种计算机器，并因此是一部句法引擎，得益于其设计，它大致在做语义引擎的工作。

## 3201. 沼泽人遇上母牛鲨 —— 哲学家最喜爱的直觉泵

直觉泵理应有效利落地工作，抽取待寻找的直觉，继而返回待命状态。但直觉泵往往会引发激烈的辩驳、反辩驳，对思想有所调整、有所扩展。20 世纪美国优秀的哲学家唐纳德·戴维森（Donald Davidson）曾对我说，他后悔发明了这个直觉泵，因为它怂恿了一种毫无节制且不具持久启发性的争吵。下面所述的是沼泽人直觉泵，也是哲学家最为钟意的直觉泵之一，尽管它不算是戴维森的得意之作：

设想一道闪电击中了沼泽里的一棵枯树，而我此时正好站在边上。我的身体被分解为各种元素，与此同时，完全出于巧合的是，那棵树中完全不同的分子变成了我的物理复制品。我的复制品，即沼泽人，和我的行动一模一样；出于天性，它离开了沼泽，碰上了我的朋友，它似乎认出了他们，说着英语同他们寒暄问候。它回到了我的家，似乎开始撰写有关彻底翻译的文章。没人能看出不同。

但有一处不同：我的复制品并没有认出我的朋友。它不能辨识任何东西，因为它本来就不能对任何东西有所认知。它无法知道我朋友的名字，尽管它看起来知道，也无法记得我的家在哪儿。它根本无法领会我所说的「家」的意义，例如，它发出的「家」这个声音并不是在某个背景中习得的，而只有这样一个背景才能在根本上给出「家」正确的意义，或无论任何意义。实际上，我不知道我的复制品怎么能通过发出各种声音来意指任何东西，或拥有任何思想。（Davidson, 1987, pp. 443-444）

当诸如孪生地球、沼泽人这种话题成为正儿八经的思考时，其他领域的学界中人，特别是科学领域的专家们，常常就哲学家这种不可思议的娱乐发难，对此，哲学家并非没有注意到。是科学家没文化、精妙莫测的哲学探索于其不过是对牛弹琴，还是哲学家错失了对实在的把握？我还是不要说了吧。

这些古怪的例子有意保留了某现象未被重视的一个特征，将其他所有特征的影响降至最低，并由此来证明概念上的要点，使真正重要的东西凸显出来。孪生地球一例设置了最大程度的内在相似性，即你被发送至孪生地球，却没注意到这次大转移，以便你的直觉能将外部环境的影响可靠地显示出来。而沼泽人直觉泵在让未来倾向和内在状态保持不变的同时，将「历史」的影响降到了最低。因此，此类思想实验在设计上模仿了科学实验，通过让其他变量保持不变，试图将变量间重要的交互作用隔离出来。这类实验的一个困难是，由于它们是直觉泵，因变量就是直觉，所以在产生直觉的过程中，想象力的贡献比哲学家认识到的更难控制。我们将拆除一些吊杆托架，它们实际上妨碍了读者的想象力，扭曲了他们的直觉，并因此使思想实验的「结果」变得毫无效力。

此外，这类实验还存在深层次的困难。凭空想出个例子就来「证明」深层的概念要点不过是小儿把戏。假设一头母牛诞下了某种生物，它同鲨鱼分毫不差。你若去问生物学家，它是鲨鱼吗？善意的反应可能是，你在费力不讨喜地搞笑。或者，设想在室温下，一个恶魔微微一笑就能将水变成冰。恶魔之水是冰吗？这种傻乎乎的假想根本不值得得到回应。一些哲学家认为，微笑的恶魔、母牛鲨 [53]、僵尸以及沼泽人在逻辑上都是可能的，尽管它们在自然法则上（因果上）不可能。他们认为这一点很重要，但我不这样看。大概，广泛撒下反事实性网的动机是，我们获得的答案会告诉我们论题的本质。但是，这世道谁会相信真正的本质呢？反正我不会。

下面，考虑一个会问及磁性物质的类似问题，我们注意到，对于磁性物质，有两个相互竞争的候选「真理制造者」，即典型性质或本质：（a）所有磁性物质都能吸引铁屑；（b）所有磁性物质都有某种内在结构，且称之为 M 阵列。老式的行为准则（a）会不会最终被新的内在结构准则（b）所取代呢？或者，后者不过是在还原意义上对前者做了解释？为了一探究竟，我们必须想着为科学家提出以下这些沼泽人式的问题。设想你发现了某种物质，它能够吸引铁屑但却不像标准磁性物质那样拥有 M 阵列。你会把它叫磁性物质吗？或者，设想你发现某种物质具有 M 阵列却不能吸引铁屑。你会将其称为磁性物质吗？物理学家可能会回应道，若真见到了这些假想的物质，他们会留意那些更为重要的事情，而不是思考管它们叫什么。他们整个的科学图景有赖于磁畴中原子偶极子的排列与铁吸引力之间的深层规律，打破这一规律在逻辑上是有可能的，但他们对这种「事实」毫无兴趣。「结构」因素和「行为」因素之间真正的协变关系才是值得关注的。如果发现规律不适用了，物理学家就会相应地调整他们的科学理论，重新安置这些术语。

沼泽人是否有思想？是否说英语？母牛鲨是不是鲨鱼？它像鲨鱼一样游动，还能同其他鲨鱼成功交配。天哪，我没告诉你们吗？除了在它的所有细胞里都是牛的 DNA 之外，它同鲨鱼毫无二致。不可能吗？哲学家会说这在逻辑上也不是不可能。正是如此明显的不可能造成了后续没营养的讨论。正如戴维森的记忆「痕迹」出现在沼泽人的大脑结构中在物理上不可能一样，一条鲨鱼由包含牛的 DNA 的细胞构成同样在物理上不可能。沼泽人也许在逻辑上可能，如果仅仅因为想象某种宇宙巧合就能产生沼泽人这种东西，那么，根据定义，它们在逻辑上是可能的，但这种事从未发生过，谁会在乎如果它们发生了，我们该怎么说呢？

「我在乎啊，」注重反问的哲学家会说，「我认为，以最大的严密性定义你的用词以及所有逻辑可能的事项向来非常重要。这才是追寻真理之道。」是这样吗？在真实世界中，进化、发展以及学习的多重扭结将过去的历史和未来的作用束缚在一起。正是因为戴维森的身体有其特定的发展轨迹，假以时日，它就能形成戴维森所有的记忆、信念以及期望，这些自然累积的过程不会有一个真正的替代品。虚构的情形违背了这些限定条件，它所能达成的结论，就我所见，没有任何用处。事实上，这种费尽心力搞出来的例子给我的印象是，为某种假想的两分创造条件，好让你有恃无恐。「不，不，」哲学家说，「它不是虚假两分！为论证起见，我们悬置了物理定律。伽利略在其思想实验中忽略了摩擦力，他不也做了同样的事吗？」确实如此，不过两相对照，我们可以看到一个一般性的经验法则：思想实验的效用与其脱离现实的程度成反比。

孪生地球在物理上不可能，但其不可能并非沼泽人的不可能！千万别想用量子力学的多重宇宙解释，它虽表明孪生地球归根到底在物理上是可能的，但该理论只有在某些领域得到青睐；即便真的有无限多的宇宙，它们中又有无限多的星球与地球几乎一模一样，我们也不能发送地球人到这些星球访问。相比之下，双币机到巴拿马一游是可能的，有关它的种种事情也都会发生。不必悬置任何自然定律，我们就能设想我们希望设想的有关双币机的一切细节。

[53] cow shark 是六鳃灰鲨（Hexanchidae）的俗称，作者的例子可能源于此。—— 译者注

## 3301. 两个黑盒子 —— 究竟是什么让红灯闪烁

有两个大型黑盒子 A 和 B，它们之间由一条绝缘的铜电缆相连。A 盒子上有两个按钮，标着 α 和 β；B 盒子上有三个灯泡，颜色为红（R）、绿（G）、黄（Y）。研究黑盒子行为的科学家观察到：按下 A 盒子上的 α 按钮，B 盒子上的红灯会短暂闪烁；按下 β 按钮，绿灯会短暂闪烁。黄灯似乎从不闪烁。他们在各式各样的条件下进行了几十亿次的实验，并没有发现例外。于是，他们得出结论，认为其间存在着某种因果规律，并简单地概括如下：

α 按钮导致红灯亮

β 按钮导致绿灯亮

他们确信，这种因果规律以某种方式通过这条铜电缆传导，一旦切断电缆，B 盒子就不会有任何反应；把两个盒子各自屏蔽起来，保持电缆连接，却不会破坏这种规律。他们当然很好奇，这种因果规律是如何通过电缆传导的呢？他们认为，也许按下 α 按钮会导致一个低压脉冲传至电缆，同时触发红灯亮；而按下 β 按钮将产生一个高压脉冲，它将触发绿灯亮。或者，按下 α 按钮引发单脉冲，触发红灯亮；按下 β 按钮则引发双脉冲，触发绿灯亮。显然，当科学家按下 α 按钮时，电缆中总是发生了什么事，而当他们按下 β 按钮，总是发生了一件与之不同的事情。揭示出这两个事情是什么，就能解释他们所发现的这种因果规律。

很快，对电缆进行的信号检测表明情况要复杂得多。无论何时按下 A 盒子上的按钮，一串脉冲流 —— 开或关，或比特串，确切地说，10 000 比特就会快速地沿电缆发往 B 盒子。但是，比特串的模式每次都不一样！

在比特串触发红灯或绿灯的情形中，一定有某种特征或性质。它会是什么呢？科学家们决定打开 B 盒子看看，当比特串送达其中时发生了什么。科学家在 B 盒子的内部发现一个普普通通的串行计算机，配有一个大型存储器，内含一个庞大的程序和数据库，当然也是由很多比特串写成。当他们跟踪比特串到达该程序时，并未发现什么奇怪的事情：输入串总是会以正常的方式进入中央处理器，在那里它会在极短的时间内引发几十亿次操作，并以 1 或 0 这两个输出信号中的一个结束，而输出 1 会打开红灯，输出 0 会打开绿灯。他们发现每一次都能在微观层面上解释这种因果规律的每一个步骤，没有任何困难或矛盾之处。他们并不认为运行过程有任何神秘原因，例如，当他们反复输入同一个序列的比特串，B 盒子中的程序总是产生同样的输出：红灯亮或绿灯亮。

但这还是有点儿让人困惑，因为，尽管 B 盒子始终给出同样的输出，但其中间步骤并不相同。事实上，在产生同样的输出前，它几乎总是经历不同的物理状态。于其自身而言，这并不神秘，因为该程序存有每个输入信号的副本。因此，当同一输入信号一而再再而三地送达时，计算机存储器的状态在每一次会稍有不同。但是，输出总是相同的：如果某个特定比特串的首次输入使红灯变亮，那么从此以后，同样的比特串总是会使红灯变亮，同样的规律对绿串（科学家开始这样称呼这些比特串）也适用。科学家很容易就假定，所有比特串要么是引起红灯闪烁的红串，要么是引起绿灯闪烁的绿串。当然，他们并没有测试所有可能的比特串，而是仅仅测试了由 A 盒子发出的比特串。

科学家们决定验证他们的假设，他们临时断开 A 与 B 之间的联系，并略微修改了由 A 发出的输出信号。令他们感到迷惑和沮丧的是，一旦他们修改了来自 A 的比特串，黄灯就会闪烁！仿佛 B 盒子侦测到了他们所做的改变。但是，毫无疑问，B 盒子能够接收人造的红串或绿串。只有当红串或绿串中一个或不止一个比特发生改变时，黄灯才会变亮，几乎总是如此。在看到一个「修改后的」红串变成了黄串，有人脱口喊道：「你们杀了它！」这还引发了一番猜测：红串和绿串在某种意义上是活的，也许分别代表了雌性和雄性，而黄串是死的。这个猜想很有吸引力，但它得不到什么结果，尽管科学家对数十亿有着随机差异的 10 000 位比特串进行了实验，这些实验强烈地提示科学家，实际有三种比特串：红串、绿串和黄串，而且黄串的数量比红串和绿串的数量多了很多个数量级（更多内容见第 35 章）。几乎所有的比特串都是黄串。这让他们发现的红 / 绿规律更令人兴奋，也更让人费解。

是什么东西让红串打开了红灯，绿串打开了绿灯？毫无疑问，对于每个特定的情况来说，根本没有神秘性可言。科学家可以通过 B 中的超级计算机来跟踪每个特定比特串的因果效力，从而带着令人满意的决定论看到它在不同情况下点亮红灯、绿灯或黄灯。然而，单是检查一个新比特串，在没有「人工模拟」它对 B 盒子的影响的情况下，科学家无法预测它会产生这三种效果中的哪一个。他们从经验数据中得知，除非一个新比特串是由 A 盒子发出的已知比特串，否则一个新比特串成为黄串的概率非常高，几乎可以认为，任何新比特串都将是黄串，在这种情况下，一个新比特串只有十亿分之一的概率是红串或绿串，但是，不用 B 盒子里的程序来运行该比特串，就没人知道它究竟会是哪种。

也许，秘密在于 A 盒子。于是，科学家打开它，发现了另一台超级计算机，它有着不同的款式和型号，运行着不同的巨型程序，尽管如此，它也只是一台普普通通的数字计算机。科学家很快查明，这台计算机内部有一个「时钟」，滴答滴答地走着，每秒百万次，无论他们按下哪个按钮，计算机做的第一件事就是从时钟处获取「时间」，比如，101101010101010111，并将其分解成串，从而确定调用哪个队列里的哪些子程序，以及在其准备将比特串送至电缆期间首先访问哪一部分内存。

科学家弄清楚了，实际上，正是这个保持着良好随机性的时钟查询机制保证了同一个比特串从来不会被重复发送。尽管依赖于这种随机性或伪随机性，但它还是能够保证，每当科学家按下 α 按钮，计算机产生出红串；按下 β 按钮，送出的比特串最终是绿串。事实上，科学家们发现了几个异常情况：在大约十亿分之一的实验中，按下 α 按钮会发出一个绿串，或按下 β 按钮产生一个红串。这个小小的瑕疵吊足了科学家的胃口，他们想去解释这一现象。

后来有一天，两个负责制作这些盒子的人工智能黑客出现了，他们解释了这一切。（如果你想自己弄明白就不必往下看了。）制作 A 盒子的黑客 Al，已经为某个「专家系统」工作了多年，该专家系统包含一个天底下所有「真命题」的数据库以及一部推理引擎，推理引擎可以从组成该数据库的公理中推断出进一步的结果。数据库中包含有美国职业棒球大联盟的统计数据、气象记录、生物分类学、世界各国的历史，以及大量的琐碎数据。与此同时，制作 B 盒子的瑞典黑客 Bo，为了打造自己的专家系统，一直在研发能与对手抗衡的「世界知识」数据库。在时间所能允许的条件下，他们都在往各自的数据库中塞入尽可能多的「真理」。[54]

但随着时间的推移，他们都觉得专家系统无聊乏味，该技术承诺的实际功能被大大高估了。事实上，该系统并没有很好地解决有意思的问题，也没能「思考」或「发现创造性的解决方案」。借着推理引擎，它们都善于以其各自的语言生产非常非常多的真语句，善于检测输入语句相对于它们的近似知识为真还是为假。因此，Al 和 Bo 想看看他俩费尽心力搞出来的东西如何能够派上用场。于是，他们决定做一个哲学玩具。他们选择了一种通用语来翻译他们的系统，实际上，两个系统发送的都是以标准 ASCII 码写成的英语 [55]，他们还把两部机器用电缆连起来。每当你按下 α 按钮，就会指示 A 随机或伪随机地择取它的某个「信念」，即某个存储在数据库中的公理或由公理集产生的推论，并将其翻译成英语（计算机中的英文字符已经是 ASCII 码的形式了），然后在末尾加入足够多的随机位使总位数达到 10 000 位，最后将该比特串发送至 B，而 B 将输入的比特串翻译成自己的语言即瑞典版 Lisp 语言，并与自己的「信念」（它的数据库）做比对。由于两个数据库均由真理组成，而这些真理大致相同，依赖于它们的推理引擎，每当 A 发送一个它所「相信」的东西，B 也同样「相信」，并以红灯闪烁来示意。而一旦 A 发给 B 一个它认为是虚假的东西，B 会通过闪烁绿灯表示确实如此。

一旦有人篡改了传输过程，几乎总是会产生一个不合语法规则的英语语句的比特串，除非所有的修改只发生在末尾无意义的随机位。由于 B 对格式错误零容忍，所以它闪烁黄灯做出回应。假使有人随机选择了某个比特串，这个比特串就极有可能不是合乎语法的真理或谬误，所以黄灯总是占优。

所以，Al 和 Bo 说，神秘的因果性质「红」实际上是英语真语句的性质，而「绿」是英语假语句的性质。突然间，让科学家多年来百思不得其解的探索成了小孩子的过家家。任何人都可以反反复复构造出红串。他只要写下「房子比花生大」「鲸不会飞」或「三乘四比二乘七少二」等语句的 ASCII 码就可以了。如果你想得到绿串，试试「九小于八」或「纽约是西班牙的首都」。哲学家很快就发现了一些小把戏：有些比特串在开始的头一百次是红串，尔后却变成了绿串。例如，ASCII 码编制的这句话：「这句话送往你那里做评估的次数少于一百零一次。」

但是，一些哲学家说，比特串的性质是红或绿并不真就是英语语句的真或假。毕竟，有些通过 ASCII 码表达英语真语句需要数以百万计的比特位，此外，即便尽了最大的努力，Al 和 Bo 在他们的程序中加入的也并非全是事实。例如，一些事以当时的常识看来为真，但在它们被收入数据库后，这些知识已被证明为假。为什么比特串的因果性质「红」并不等同于英语语句的真理性呢？理由很多。因此，也许这样定义「红」会更好：一段相对较短的表达式，用英语 ASCII 码写成，是近似信念几乎全为真的 B 盒子近似信以为真的东西。这个定义能让一些人满意，但出于种种原因，也有人吹毛求疵：它不够精确，或存在一些我们不能以任何非特例的形式排除的反例，等等。

但是，正如 Al 和 Bo 指出的，对于有待发现的性质，并不存在更好的描述，而且科学家念念不忘的不正是这种解释吗？难道红串和绿串的神秘性没有被完全消解掉？此外，既然神秘性被消解掉了，难道没有人发现，如果不使用某些语义学或心智学的术语，我们根本就看不到有任何解释我们故事开头讲的「α 按钮导致红灯亮，β 按钮导致绿灯亮」这种因果规律的希望？

一些哲学家辩称，虽然对电缆活动规律的新描述可以用来预测 B 盒子的行为，但说到底它不是因果规律。真理与谬误，以及刚刚考虑过的任何经过调整的替代者都是语义性质，其本身完全是抽象的，因此，它们不可能导致任何事情发生。其他人则反驳道，这是胡说八道，按下 α 按钮打开红灯正像是拧动点火钥匙发动汽车。如果发送到电缆上的东西无非是高电压、低电压，或单脉冲、双脉冲，人人都会同意这是一个典型的因果系统。该系统原本就是一部戈德堡式的机械 [56]，但这并不意味着 α 和红灯闪烁之间联系的可靠性没有因果关系。事实上，科学家每一次都能描绘出确切的微观因果路径，并用来解释实验结果。[57]

其他一些哲学家被这番推理说服，他们开始论证道，这表明红、绿、黄这些性质根本就不是真正的语义性质或心智性质，它们模仿语义性质，仅仅是「好像」语义性质。真正说起来，红和绿是非常非常复杂的句法性质。但是，这些哲学家拒绝进一步说明它们是什么样的句法性质，也拒绝解释为何连小孩子都能快速可靠地举出关于它们的例子，或是识别出它们。尽管如此，这些哲学家坚信，必须对该规律做出纯粹句法层面的描述。毕竟，成问题的因果系统「只是」计算机，而计算机「只是」部句法引擎，不可能有任何真正的「语义性」。

「让我们设想，」Al 和 Bo 反驳道，「如果你们在黑盒子里发现了我们，做着同样的事情，那时你们的态度就会缓和，同意运作中的因果规律就是实情或信以为实情。你们能提出做出这种区分的充足理由吗？」该反驳迫使一些人表态：既然 Al 和 Bo 创建了各自的数据库，并将其作为自己信念的模型，那么，在一个重要的意义上，Al 和 Bo 就已经在盒子里了。同样，这也使其他一些人否认说：这世界上不存在任何语义性质或心智性质。他们说，内容已经被消解掉了。尽管多年来一直众说纷纭，但我们一开始说的那种神秘性消失了。

### 33.1 堵住出口

黑盒子的故事到此为止。不过，经验告诉我们，天底下还没有哪个思想实验能清晰到让哲学家不误解它，因此，为了防止引发某些最具诱惑力的误解，我会不甚优雅地指出一些关键细节，并解释它们在这一直觉泵中的作用。

1、A、B 盒子中的装置不过是自动化的百科全书设备，它们甚至都不是「活的百科全书」，仅仅是「真理盒」。我们并没有在故事里预设或暗示这些设备是有意识、能思考的东西，或是行动者，除了在一个同样最低限度的意义上，我们可能会说温控器是行动者。它们是无聊透顶的意向系统，被严格地约束在一个单一的、简单的目标上。（当然，IBM 的沃森同样如此。）它们包含大量的真命题以及某种推理机制，该机制可以产生出更多的真理，并能通过与数据库中已有内容对比来检测某个候选命题是不是「真理」。

2、这两套系统是独立研制出来的，因此，很难认为它们恰恰包含着相同的真理，但出于戏剧效果以及我对它们在故事中所起作用的要求，必须假定它们之间有着非常大的重叠，这样一来，B 就极有可能识别出由 A 产生的真理。我认为，以下两方面考虑可以让这一点变得合情合理：（i）Al 和 Bo 可能生活在不同的国度，操不同的语言，但他们生活在同一个世界。（ii）尽管关于那个世界，即我们的世界的真命题的数量非常巨大，但 Al 和 Bo 都想打造出有用的数据库，这一事实将保证两套被独立研发出的系统高度重叠。虽然 Al 可能知道，在他 20 岁生日那天，他的左脚的位置更靠近北极点而不是南极点；而 Bo 也并没有忘记他的第一个法语老师叫杜邦，不过这些都不是他们会放入各自数据库的真理。单单因为他们都热衷于打造各国可用的百科全书系统，就能保证他们各自的数据库有密切的对应关系吗？如果你对此有怀疑，那就添上一个不痛不痒的事实：在多年奋斗期间，两人就要讨论的主题交换了意见。

3、为什么不是 Al 和另一个美国人 Bob 呢？或者，单就此事而言，为什么不干脆在 B 盒子里拷贝一个 Al 的系统呢？因为我不能让这种规律仅仅是显而易见的句法匹配，这一点对我的故事至关重要。在 A 进行语句生成任务、B 进行语句翻译及真理检测任务期间，我们要避免被窥探到潜伏于数据查询结构之间的底层语义共性。这就是 Bo 的系统为什么采用瑞典版 Lisp 语言的原因。电子计算机作为一个物理系统，充其量也不过是一部句法引擎，它直接回应物理上可转换的差异，而不是意义。但是，A 和 B 都被设计为一个尽可能接近我们想象中的无所不知的系统，一部语义引擎，其中装满了可被充分理解的真理。所以，当 A 和 B 这两种不同的句法系统被设计为如实反映同一个语义引擎的时候，为了解释它们所揭示出的那种引人瞩目的规律，唯一的方法便是上升到语义引擎的层面，在那里，真理得到认可，断言得到证实。我们的想法是创造出两个系统，它们的外部行为表现出令人着迷的规律，但内部则尽可能地不同，因此，只有当它们各自的内部结构同为一个共同世界的系统性表征时，才能解释那种规律。回想一下，这正是我在第 13 章想要的阐释的主题。

我们可能会停下来问，这样的系统是否真能如此不可思议，让逆向工程也对它无可奈何？或者换句话说，科学家们是不是真的困惑良久？鉴于密码学已经成为一个高度专门化、相当晦涩难懂的领域，一个人在回答上述问题前应当三思。我不知道是否有人能提供一个彻底有效的论证，来证明存在或不存在某种牢不可破的加密方案。但撇开加密术不提，黑客们都知道，当一段源代码程序编译完成时，所有源代码中的注释以及其他标注必须删除，只留下一段几乎无法破译的由机器指令组成的代码。「反编译」，也就是对目标代码进行逆向工程以及恢复源代码，有时在实践中是可能的（也许在原则上始终是可能的？），虽然它无法恢复注释内容，只是在高级语言中重新译出显著的结构。我认为科学家对程序进行反编译、解密数据库的努力会终成泡影。如果有必要的话，我们可以通过设想一种加密方案来强化我的观点。

在上述故事中，我们必须承认有件事非常奇怪：科学家们从来没有想过检查电缆中的比特流是不是经 ASCII 码翻译的。他们怎么能这么傻呢？有道理啊。你可以把整个装置，A、B 盒子以及连接线，发送到「火星」来解决这个思想实验中的缺陷，让火星科学家试着找出其中的规律。他们同样也会看到 α 按钮导致红灯亮，β 按钮导致绿灯亮，而随机比特串导致黄灯亮，就像我们看到的一样。但他们对 ASCII 码一无所知。除非火星科学家无意之中猜到每个盒子都包含着对某个世界的描述，而且它们描述的是同一个世界。否则，对他们来说，这份来自外太空的礼物将呈现出一种完全神秘的规律性，完全超出了所有的分析调查 [58]。针对同样的东西，两个盒子担负着五花八门的语义关系，通过不同的「术语学」和公理化系统表达。这一事实才是这种规律性的基石。

丹尼·希利斯（Danny Hillis）是连接机的发明者，连接机是 20 世纪 80 年代初他的公司「思考机器」（Thinking Machine）率先建成的大规模并行计算机。当我在他那里试用这个思想实验时，他立即为这一难题想到了一个密码学的「解答」，然后还理所当然地认为，我的解答正好可以看作是他的解答的一个特例：「Al 和 Bo 把世界当作‘一次性密码本'了啊！」这个词算是对标准加密技术的恰当说明吧。你可以通过想象另一种情形了解到这一点。比如，你和最要好的朋友即将被敌人（就算是太空海盗吧）抓住，他们懂英语，但对你们的世界知之甚少。而你们两人都懂摩尔斯电码，所以你们突发灵感想出了下边的加密方案：划表示讲真话，点表示讲假话。绑架者可以听到你们在说话。你说：「鸟会下蛋，青蛙会飞；芝加哥是一个城市，我的脚不是锡做的，美国职业棒球联赛 8 月开赛。」这样，无论你的朋友刚才问的是什么，你都在回答「No」（-∙，---）。[59] 而当下一回你需要说「No」时，你得用一些不同的句子。所以，即便抓住你们的人也知道摩尔斯电码，除非他们也能确定这些句子的真假，否则他们无法察觉是什么性质代表着点和划。

这种情形也可以作为噱头添加到我们的故事里，比如：我们不是把盒子里的计算机系统运到火星，而是把 Al 和 Bo 塞进盒子并将他们运送到火星。如果 Al 和 Bo 重施摩尔斯电码的恶作剧，那么，火星人也会对他们的行为感到困惑不解，就像他们对计算机的行为感到困惑不解一样，除非火星人得出结论：盒子里的这些东西需要语义解释。这对我们而言显而易见，但我们不是火星人。

这则故事的要点再简单不过了。没有什么东西可以代替意向立场，你要么采用意向立场的方式，找出语义层面的事实来解释这一模式，要么永远被这种显而易见的因果规律所困扰。[60]

在这个节骨眼上，你可能像许多哲学家一样，又一次被这样的主张所迷惑：该直觉泵之所以产生这样的效果，仅仅是因为 A 和 B 两个盒子是人工制品，它们所具有的意向性纯粹是派生性的、人造的。它们内存中的数据结构获得的这些参照项（如果它们可以得到任何参照的话），间接依赖于感觉器官、生活史以及它们的创造者 Al 和 Bo 的目的。人工制品中的意义、真理或语义性的真正根源在于这些东西的设计者。Al 和 Bo 具有原初意向性，而 A 和 B 都只有派生意向性。（当然，这就是为什么说在某种意义上 Al 和 Bo 都在各自的盒子里。）我其实可以把这个故事讲成另一个版本：盒子里面是两个机器人 Al 和 Bo，在把它们塞进各自的盒子里前，它们「终其一生」在世界各地游荡以搜集事实。我选择了一个更简单的版本，是为了避免有人问及 A 盒子或 B 盒子是不是在「真正地思考」，但如果你想重新考虑这个思想实验以及与此相关的复杂情形，那么你要注意，巨型机器人的直觉泵已经对「真正的意向性不可能出现在任何人工制品上」这一想法提出了质疑。

[54] IBM 超级电脑沃森的及时出现几乎将我的科幻故事变成了科学事实。如果乐意，你可以想象把沃森放入 A 盒子，而 B 盒子包含一个瑞典版的沃森，由 Bo 独立开发。当我首次发表该思想实验时（Dennett, 1995a），我所能说的不过是：「想知道真实世界中的一个例子，看看道格拉斯·莱纳特（Douglas Lenat）在微电子与计算机技术公司（MCC）的巨型 CYC 项目（Lenat & Guha, 1990）。」参见第 28 章关于 CYC 的脚注。沃森所采用的人工智能方案早在 1995 年还是难以想象的一件事，但它现已取得了巨大的进步。不同于 CYC 主要由手工编码，沃森可以在无人值守的情况下从互联网上获取事实信息，并能使互联网上那些可用数据的统计特性发挥强大作用。沃森和 CYC 均能以各自不同的方式近似理解它们数据库中的数据，它们对数据的理解远比其他拥有大型数据库的计算机强得多。

[55] 在我一开始写这个直觉泵的时候，ASCII 码（美国信息交换标准码）几乎是所有文字处理、电子邮件以及互联网语言的标准格式。现在，它已经被一种扩展了的逆向兼容格式 UTF-8 所替代，UTF-8 意为 8 位的通用字符集转换格式。也就是说，ASCII 码是 UTF-8 编码格式的一部分。

[56] 鲁布·戈德堡机械（Rube Goldberg machine）是一种设计得过度复杂的机械组合，以迂回曲折的方法去完成一些其实非常简单的工作，例如倒一杯茶或打一只蛋等。—— 译者注

[57] 本注只写给哲学家：已有人论证，我关于「实模式」（Real Pattern, 1911b）的解释是内容的副现象论（epiphenomenalism）。这就是我的回复。

[58] 一旦他们猜到了这种假设，火星人就能参与到蒯因的彻底翻译任务中，但是他们的任务将变得愈发困难，因为他们不能对「信息来源」，也就是 A 盒子或 B 盒子发问，比如拿起一个物体问，这是「球」？「铅笔」？诸如此类。

[59] 英文字母 N 和 O 对应的摩尔斯码分别是 -∙，---。—— 译者注

[60] 在解释进化史的历史事实时，我们可以得到同样的教训：即便你能细致入微地描述每只长颈鹿生活过程中的每一个因果事实，也永远无法解释那些显而易见的规律，比如，长颈鹿为什么长着长长的脖子，除非你上升一到两个层面追寻大自然母亲的理由，追问「为什么」。（更多讨论见本书第五部分。）