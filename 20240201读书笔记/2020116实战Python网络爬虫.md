## 记忆时间

## 卡片

## 13. 数据清洗

### 13.1 字符串操作

从网页上采集数据后，数据大多数是杂乱无章的，这时需要对采集的数据加工清洗，去掉数据中的一些垃圾数据才能得到我们所需的数据。清洗数据有三种常用的方法：字符串操作、正则表达式和第三方模块库。三种方法在不同场景下有不同优势，取长补短，应根据实际情况选择合理的清洗方法，三种方法同时出现在一个项目也是常见的事情。

### 13.2 正则表达式

扩展表示符里：

(?=...)，顺序肯定环视，表示所在位置右侧能够匹配括号内正则。在字符串 'pythonretest' 中，(?=test) 会匹配 'pythonre'。

(?!...)，顺序否定环视，表示所在位置右侧不能匹配括号内正则。如果 'pythonre' 右侧不是字符串 'test'，也就是说字符串为 testpythonre，那么 (?!test) 会匹配 'pythonre'。

(?<=...)，逆序肯定环视，表示所在位置左侧能够匹配括号内正则，与 (?=...) 实例一致。

(?<!...)，逆序否定环视，表示所在位置左侧不能匹配括号内正则，与 (?!...) 实例一致。

正则表达式特殊序列：

\A 只在字符串开头进行匹配，跟 ^ 功能一样。

\b 匹配位于开头或者结尾的空字符串。

\B 匹配不位于开头或者结尾的空字符串。

\d 匹配任意十进制数，相当于 [0-9]。

\D 匹配任意非数字字符，相当于 [^0-9]。

\s 匹配任意空白字符，相当于 [\t\n\r\f\v]。

\S 匹配任意非空白字符，相当于 [^\t\n\r\f\v]。

\w 匹配任意数字和字母，相当于 [a-zA-Z0-9]。

\W 匹配任意非数字和字母的字符，相当于 [^a-zA-Z0-9]。

\Z 只在字符串结尾进行匹配，跟 \$ 功能一样。

python 里的正则函数，参数 flags 标志位，用于控制正则表达式的匹配方式，如是否区分大小写、是否多行匹配等。参数 flags 的可选值如下。

re.I (re.IGNORECASE）：忽略大小写。

re.M (MULTILINE）：多行模式，改变 ^ 和 \$ 的行为。

re.S (DOTALL）：此模式下，'.' 的匹配不受限制，可匹配任何字符，包括换行符。

re.L (LOCALE）：字符集本地化，为了支持多语言版本的字符集使用环境，比如转义符 \w。

re.U (UNICODE）：使预定字符类 \w\W\b\B\s\S\d\D 取決于 unicode 定义的字符属性。

re.X (VERBOSE）：详细模式。在这个模式下，正则表达式可以是多行的，忽略空白字符，并可以加入注释。

前面介绍的是正则处理函数的常用函数，除此之外，正则处理函数还有：1）re.split(pattern, string [, maxsplit)：用匹配 pattern 的子串来分割字符串。2）re.subn (pattern, repl, string [, count])：与 sub() 函数一样，只是返回结果是一个元组。3）re.escape (string）：把字符串里除了字母和数字以外的字符都加上反斜杄。4）re.finditer(pattern, string [, fags])：搜索字符串，按顺序返回每一个匹配结果的迭代器。

### 13.3 Beautifulsoup 数据清洗

Beautifulsoup 位于一些流行的 Python 解析器中，比如 xml 和 html5lb 的的上层，这允许使用不同的解析策略或者牺牲速度来换取灵活性。Beautiful Soup 支持 Python 标准库中的 HTML 解析器，还支持一些第三方的解析器，常用的解析器有 lxml 和 html5lib。lxml 安装：

    pip install lxml

lxml 是一个用来处理 XML 的第三方 Python 库，它的底层封装了由 C 语言编写的 libxml2 和 libxslt，并以简单、强大的 python APl 兼容并加强了著名的 ElementTree API。另一个可供选择的解析器是纯 Python 实现的 html5lib，这是一个 Ruby 和 Python 用来解析 HTML 文档的类库，支持 HTML5 以及最大程度兼容桌面浏览器。使用 plip 安装 html5lib：

    pip install html5lib
    
标准库解析器的使用方法：BeautifulSoup(re.content, 'html.parser')

lxml HTML 解析器的使用方法：BeautifulSoup(re.content, 'lxml')

lxml XML 解析器的使用方法：BeautifulSoup(re.content, 'xml')

html5lib 解析器的使用方法：BeautifulSoup(re.content, 'html5lib')