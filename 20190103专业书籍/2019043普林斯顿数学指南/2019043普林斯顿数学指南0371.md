# 0371. 概率分布

Probability Distributions

James Norris

## 1.1 离散分布

当投掷一枚硬币时，我们对于它将会哪一面向上毫无所知。但是在一个不同的意义下，硬币的行为又是高度可预测的：如果投掷多次，则正面向上的次数之比，会很接近 1/2。

为了从数学上来研究这种现象，需要先建立模型，它是这样做的：首先是定义样本空间，就是可能的结果的集合，再在这个空间上定义概率分布，说明这些可能结果的概率。在投掷硬币的例子里，自然的样本空间就是集合 {H, T}，而一个明显的概率分布，是对样本空间的这两个元素各赋以概率。换一个写法，因为我们感兴趣的是正面出现的次数，所以就把投掷的结果用 {0, 1} 来表示：每一次投掷以后，正面出现的次数为 0 的概率是 1/2，出现次数为 1 的概率也是 1/2。更一般的情况是，一个（离散的）样本空间就是一个集合 Ω，其上的概率分布就是对的每一个元素赋给一个非负实数的方法，使得这些实数之和为 1。赋给一个元素的实数就解释为相应结果出现的概率，而总概率为 1。

如果 Ω 的大小为 n，Ω 上的均匀分布就是对 Ω 的每一个元素都指定概率 1/n 的概率分布。然而，对于 Ω 的不同的元素赋予不同的概率可能更适当。例如，给定个 0 和 1 之间的实数 p：`0≤p≤1`，对集合 {0, 1} 中的 1 赋予概率 p，而对 0 赋予概率 1-p，这个概率分布称为参数为 p 的伯努利分布 [1]，它可以用来作为投掷偏心硬币的模型。

现在设投掷一个不偏心的硬币次。如果我们关心的是每一次投掷的结果，这个结果可以写成长度为 n 的由 0 和 1 组成的序列。这种序列的集合就是我们需要的样本空间。举例来说，如果 n=5，那么 `01101` 就是这个样本空间的典型元素（它表示投掷的结果依次是反、正、正、反、正）。因为这样的序列共有 2^n 个，而且看来每一种结果的出现都是机会均等的，那么，对每一个序列就应该赋予概率 1/2。

如果我们关心的不是特定的正面、反面序列，而是在 n 次投掷中正面出现的总次数，那么又该怎么办呢？这时，样本空间就是集合 {1, 2, …, n}。正面出现的总次数为 k 的概率就应该是 2^{-n} 乘上在序列中出现 k 个 1 的这一类序列的总数。这个数就是：

$$\frac{n!}{k!(n-k)!} = \binom{n}{k}$$

所以对于样本空间中的元素 k 所予的概率是：

$$pk = \binom{n}{k}2^{-n}$$

3『

[5 分钟彻底了解排列组合 - 知乎](https://zhuanlan.zhihu.com/p/41855459)

这里「在所有序列中正面出现 k 次的序列有多少个」是一个典型的排列组合问题。等价于：1）给 n 个人颁发 k 个奖杯，有多少种？2）在 n 个物品中，选择 k 个物品出来，选择的顺序无所谓，那么选择的方式总共有这么多种？

如果考虑顺序：1）有 n 个运动员，要按顺序地颁发 k 个奖牌，有多少不同的颁奖方式呢？2）想在 n 个物品中，按顺序的选择 k 个物品，那么选择的方式总共有这么多种？此时：

$$\frac{n!}{(n-k)!} = \binom{n}{k}$$

』

一般的情况是：如果做 n 次独立的试验，而每一次成功的概率都同为 p，失败的概率则为 1-p，那么在这 n 次试验中有指定的 k 次成功，而其余 n-k 次失败，出现「这种成功和失败的特定序列」的概率就是 `p^k(1-p)^{n-k}`；而 n 次试验中恰好有 k 次成功（不论是哪 k 次）的概率则是：

$$pk = \binom{n}{k}p^k(1-p)^{n-k}$$
 
现在，样本空间仍然是集合 {1, 2, …, n}，而上面给出的概率分布称为参数为 p 与 k 的二项分布，它就是投掷偏心的硬币 n 次的模型。

假设无限地进行上面的试验，直到出现第一次成功为止。如果是在第 k 次成功，而前 k-1 次失败，这种情况出现的概率是 `pk = (1-p)^{k-1}p`。所以，当 k 变动时它给出了首次成功是第 k 次的概率。这也是一个概率分布，称为参数为 p 的几何分布。特别是投掷公平的硬币，在某一次首次出现正面的概率分布就是参数为 1/2 的几何分布。现在的样本空间则是 {1, 2, …, n}，是一个无限集合，而这时概率之和为 1 的条件应该写成：

$$\sum_{k=1}^{\infty}pk = \sum_{k=i}^{\infty}{(1-p)}^{k-1}p = 1$$

它实际上是成立的，因为：

$$\sum_{k=i}^{\infty}{(1-p)}^{k-1}p = p\sum_{l=0}^{\infty}{(1-p)}^l = p·\frac{1}{1-(1-p)} = 1$$

现在考虑一个比较复杂的试验，设有一个放射源，随时会因衰变而发射出一个 α 粒子。假设这些衰变是独立事件，则下面的假设是合理的，即在任何时刻衰变的机会都是均等的。如果每分钟平均的衰变次数例如是 λ，那么在给定的任意一分钟内，因衰变而发射出 k 个粒子的概率是多少？

考虑这个问题的方法之一是把一分钟分成大小相同的 n 个区段，这里 n 是个很大的数，那么在一个区段里发射了两个粒子的概率是如此的小，而可以忽略，所以既然每一分钟衰变的次数平均是 λ，则在任何一个区段里发生衰变，因而发射一个粒子的概率是 λ/n，记次数为 p。因为衰变是互相独立的，所以可以把衰变次数看成 n 次试验中成功的次数，而每一次成功的概率都是 p。这样就会得到一个参数为 n 和 p 而 p= λ/n 的二项分布。

注意，当 n 变大时，P 就会变小，而上面做到近似也就更好。因此自然会令 n→∞，而来研究所得的「极限分布」可以证明，当 n→∞ 时，二项分布的概率的极限是：

$$pk = \frac{λ^k}{k!}e^{-λ}$$

这些数在非负整数（就是 k）的集合上定义了一个概率分布，称为参数为 λ 的泊松分布。

1『看到这里才发现推导出了泊松分布，妙哉！这一节的信息值得反复研读。（2021-02-15）』

[1] 这里是指雅各布伯努利，见伯努利家族。—— 中译本注

## 1.2 概率空间

假设向靶子投掷一支镖。因为投手不甚长于此道，所以对于镖会射中靶上的何处，不能说得很清楚，但是至少可以用概率方法做一个模型。很明显，样本空间就是个圆盘，盘中的点就是镖射中之处。然而，现在有了一个问题，如果瞄准靶上的一个特定的点，则镖恰好射中此点的概率为 0。那么，该怎样定义概率分布？

回答这个问题的线索在于这样一件事，下面的问题完全容易说明其意思：「射中牛眼（bullseye）的概率是多少？」要想射中牛眼，镖就必须命中靶的一定区域，而发生这种事的概率当然不必是 0。例如，它可能是牛眼的面积除以靶的总面积。

我们所看到的事就是，哪怕不能对样本空间的个别的点指定其概率，我们仍然希望对其子集合给出其概率。这样，若样本空间是 Ω，而 A 是 Ω 的子集合，则可以试着对 A 指定 0 与 1 之间的一个数 P(A)，`0≤P(A)≤1`，P(A) 就表示随机的结果属于子集合 A 的概率，可以把这个概率看作是一个类似于 A 的「质量」的概念。

为了使这样做能解决问题，需要令 P(Ω) = 1（就是说，在样本空间总会发生什么事情，所以发生各种情况的总的概率为 1）。还有，如果 A 和 B 是 Ω 的两个分离的子集合，则 `P(AUB) = P(A)+P(B)`。由此得到，如果子集合 A1, …, An 都是互相分离的，则有下式成立：`P(A1…UAn) = P(A1)+…+P(An)`。事实证明了重要的是，要求此式不仅对于有限并成立，而且对可数个 [III.11] 子集合的并也成立（与此相关的一个事实是，我们并不打算对 Ω 的一切子集合 A 都来定义 P(A)，而只需要对它的一切可测子集合 [III.55] A 来定义 P(A)，而在我们的情况下，只要能对实际上能够定义的 A 来定义 P(A) 也就够了）

一个概率空间就是一个样本空间以及定义在所有「合乎情理的」子集合上的满足前两段中提出的条件的函数 P。P 本身称为一个概率测度或概率分布，而当具体地确定 P 时，概率分布这个词用得较多。

『这里的 [III.11] 指代本书的「0311可数与不可数集合」。[III.55] 指代本书的「0311可数与不可数集合」。』

[1] 靶的中心部分，其半径规定约为 13mm。—— 中译本注

## 1.3 连续的概率分布

有三个特别重要的定义在 R 上的概率分布，本节中只讨论其中两个。第一个是定义在区间 [0, 1] 上的均匀分布，我们很愿意精确地刻画：「在 [0, 1] 中的所有点都同等可能」这个思想，但是由于上面已经提出的一个点的概率可能为 0 的问题，这件事怎样去做呢？

一个好办法是认真地看待「质量」这个比喻。虽然我们不能通过计算一个物体的无穷小的点的质量并把它们相加来求这个物体的质量，但可以对这些点指定密度，然后对密度进行积分，在这里就是要这样做。在均匀分布的情况下，对 [0, 1] 中的每一个点都指定一个概率密度，然后定义一个子区间，例如 [1/3, 1/2] 的概率为一个积分：

$$P([1/3,1/2]) = \int_{1/3}^{1/2}{ldx} = 1/6$$

一般说来，子区间 $[a,b] \subset[0,1]$ 的概率就是其长度 b-a。这样规定了概率以后，「可数多个互相分离的子区间的并」的概率当然就等于各个小区间的概率之和，而整个样本空间 [0,1] 的总概率自然为 1。这样，对于概率分布的要求都得到了满足。

这个「连续的」均匀分布，也和它的离散的均匀分布一样，有时可以从对称性的要求自然地出现，它也可以作为一个极限分布而出现。假设有一位隐士，身居洞穴之内而不见天日，也没有钟表，他的「一天」的长度，可以随机地在 23 个小时到 25 个小时之间。一开始，他还可能有一点时间的概念，他可以说这样的话：「我才吃了午饭，外边大概天亮了吧」，但是，时间流逝，过了几个星期，他已经完全没有了这样的时间概念，对于他，说外界的时间是几点钟，都是一样的：是早晨、黄昏，概率完全一样。

现在来考虑一个有趣得多的密度函数，它依赖于一个正常数的选择，这就是定义在所有非负实数集合上的密度函数 $f(x)=λe^{-λx}$，现在，样本空间是 [0, ∞)。为了作出 [0, ∞) 的子区间 [a,b] 的概率，我们用下面的积分算出：

$$\int_{a}^{b}{f(x)dx} = \int_{a}^{b}{λe^{-λx}dx} = e^{-λa} - e^{-λb}$$

当然，关于概率所应该满足的条件如可数可加性和 `P(Ω)=P([0, ∞))=1` 都得到满足。

所得的概率分布称为参数为 λ 的指数分布。如果要为自发发生的事件的发生时间 T，如放射性核的衰变的发生时间，构造一个数学模型，还有下一封垃圾电子信件到达时间的数学模型，指数分布就是适用的，其所以如此的理由在于无记忆性。

例如，设已经知道一个放射性核在时刻 s 之前没有动静，那么，它在以后的时刻 s+t 发生衰变的概率和它从初始时刻一直到时刻 t オ衰变的概率是一样的。令 G(t) 表示在时刻 t 才初次衰变的概率，于是，它的衰变发生在时刻 s 和时刻 s+t 之间的概率应该是 `G(s+t)/G(s)`，而这又应该等于 G(t)。与此等价，有 `G(s+t)=G(s)·G(t)`。唯一具有这个性质的下降函数是指数函数 [III.25]。也就是形如 $G(t)=e^{-λx}$ 的函数，这里 λ 是一个正数。因为 1-G(t) 表示衰变发生在区间 [0,t] 中的概率，如果发生这一事件的概率密度是 f(t)，则由概率密度的定义，可以得出：

$$1-G(t) = \int_{0}^{t}{f(x)dx}$$

所以 $f(t)=e^{-λt}$。

1『意外收获，「唯一具有这个性质的下降函数是指数函数，也就是形如 $G(t)=e^{-λx}$ 的函数」，这个信息解释泊松分布函数里指数部分的来源。（2021-02-15）』

下一节要开始讲第三个也是最重要的一个概率分布。

## 1.4 随机变量，平均值和方差

给定一个概率空间，定义事件就是这个空间的一个「充分好」的子集合。例如，设概率空间为区间 [0,1] 以及其上的均匀分布，则区间 [1/2,1] 就是这样一个事件：它代表随机取出的一个数至少是 1/2，不仅要思考一个随机事件，而且思考与一个概率空间相关联的随机的数，这时常是很有用的。

例如，再次看一下投掷一个偏心的硬币的试验序列，而设投掷这个硬币时正面向上的概率为 p。与这个试验相关的自然的样本空间是所有的由 0 和 1 组成的序列的集合 Ω。在前面说明了在 n 次试验中得到 k 次正面的概率是：

$$pk = \binom{n}{k}p^k(1-p)^{n-k}$$

那时，我们是取 {0, 1, 2, …, n} 为样本空间，而取 pk 为概率分布的。然而，在许多方面都更加自然而且远为更加有用的是取这里的 Ω 为样本空间，而来定义其上的一个函数 X：Ω → R，表示正面向上的次数，就是说，X(ω) 表示序列中有多少个 1。这时，就可以写出：

$$p(X=k) = pk = \binom{n}{k}p^k(1-p)^{n-k}$$

一个像这样的函数就称为一个随机变量。如果 X 是一个在集合 Y 中取值的随机变量，则 X 的分布就是按下式定义在 Y 的子集合 A 上的函数 P:

P (A) =P (XA) =P ({∈2: X () ∈A})

不难看到，函数 P 就是 Y 上的一个概率分布

在许多时候，只需要知道一个随机变量的分布。但是，对于在一个样本空间上的随机变量的概念，包含了我们关于一个随机量的直觉，而且使我们能问许多进一步的问题。例如我们想要在下面的条件下求在 n 次投掷中出现 k 个正面的概率，条件是第一次和最后一次投掷的结果是相同的，这时，只是 X 的分布是不够的，但是更丰富的视 X 为定义在所有序列的集合即样本空间上的函数，这个模型就行此外，这个更丰富的模型】还使得我们可以讨论所谓独立的随机变量 X1,, Xm 其意义就是要求 Ω 的适合以下的条件的元素：对于所有的均有 X () ∈A，对于所有的乘积 A1×…An，这种所成的子集合 {: X (u) ∈A, =1,2, …, n} 的概率都等于乘积 P (X1∈A1) ×…×P (Xn∈An)

有两个重要的数可以从一开始起就用来刻画一个随机变量 X，就是它的平均值或称期望值（X）和方差 var (X），二者都可以用 X 的分布来定义。如果 X 只取整数值，而且其分布是 P (X=k) =Pk，则定义

E (X) = 四，ar (X) = ー) 2m ル = E (X)

平均值告诉我们平均有多大方差或者更好是它的平方根，即所谓标准差（stan dard deviation) =vvar (X），则告诉我们偏离其平均值典型地有多远，不难导出方差的另ー个有用的公式

为了更好地理解方差的意义，看下面的情况：设有 100 位考生参加一场考试满分是 100, 而他们的平均分是 75. 这个数据给了一些信息，但远非分数分布的完全的情况。例如，可能共有四个考题，其中三个非常容易，而另一个难得几乎谁也做

不出来，所以绝大部分的考分都聚集在 75 分左右；但也可能是 50 个学生得了满分，而另外 50 个只得了 50 分。为了做出考试结果的模型，设样本空间就是这 100 位考生。给定了一个随机的考生，记其得分是 X (），则在概率分布是均匀分布的

第一个情况下，方差会很小，因为每一个人的得分都很接近于 75 分的平均分。而在第二个情况下，方差很接近 252=625, 因为每个人的分数都离 75 分的平均值达到 25 分之多。方差就能帮助我们了解这两种情况的差别

正如本文开始时提到的，我们的经验是，投掷一个公正的硬币 n 次，我们所能「期望」得到的正面向上的次数是 n/2, 就是说，出现正面的比通常近于 1/2. 不难 算出，若用 X 来模拟 n 次投掷中出现正面的次数，而 X 服从参数为 n 和 1/2 的

二项分布，则 E (X) =m，而方差 vwar (X) =m, 所以自然地量度分布的分散程度

的是标准差 σ=。稍作计算就知道，对于很大的 m,X/m 以接近 1 的概率接近

于。这些计算与我们的经验都是相符的

般地说，设 X1, X2, …, Xn 是独立的随机变量，则它们的和的方差等于各个随机变量的方差的和：ar (X1+……+Xn) =var (X1) +…+var (Xn). 由此可知，如果所有的 X 都有相同的概率分布、相同的平均值、相同的方差 2, 则样本平 均值 X=n-1 (X1+…+Xn）的方差是 n2 (n2)=2/n，所以当 m 时，趋于 0. 这一点观察可以用于证明，当 n→时，X - 大于 e (e>0) 的概率趋于 0, 这里是任意正数。所以，样本平均值「依概率收敛」于平均值

这个结果称为弱大数定律。上面概述的论证中隐含地假设了这些随机变量具有有限的方差，而后来证明，这个假设实际上是不必要的。还有一个强大数定律，它指出，当 n→0 时，前 n 个随机变量的样本平均值以概率 1 收敛于。顾名思义，强大数定律比弱大数定律更强，意思是从强大数定律可以导出弱大数定律。注意，这些定律使得我们可以对那些用概率理论作模型的实际事件作出一种统计性质的长期预报。此外，这些预报是可以用实测来验证的，而试验数据确实证实了它们，这就给我们的模型以能够服人科学依据

## 1.5 正态分布与中心极限定理

我们已经看到，参数为 n 和的二项分布的概率是由公式 = ()

p）给出的如果 n 很大，把点（k, pk）描成一个图，就会得到一个钟形的曲线，它在平均值 np 处有一个很尖的峰值。这个曲线高耸部分的宽度的数量级有如标准差 vp (1）。为简单计，设是一个整数，并且定义一个新的概率分布 =+ 于是，新的曲线峰值移到了 k=0 处，如果再把这个图形的比例改变，水平方向按因子 vp (1 - の压缩，而垂直方向则按因子 np (1 拉伸，这样，原来的点都位于函数

①原书分母误为 2n，这里改成 n 中译本注

的图像附近。这是一个著名的分布，即 R 上的标准正态分布的分布函数。它也称为高斯分布

换一个不同的说法，如果投掷一个偏心的硬币很多次，然后从正面出现的次数

减去其平均值，再除以标准差，就会接于一个标准正态分布

函数 e-/2/2 出现在许多数学分支里，从概率论到里叶分析.27、到量子力学里面都可以找到它。为什么会这样？和许多这一类问题相同，答案是这个函数具有一些其他函数所没有的性质

这类性质之一是它的旋转不变性。假设再一次瞄着靶子上的牛眼掷出一支镖可以把两个在互相垂直方向上独立的正态分布加起来作为其模型：一个正态分布是 x 方向的模型，另一个是 y 方向的，而且设二者都有平均值 0 和方差 1. 如果这样做，那么 2 维的密度函数将是 (1/2) e-/2e-2, 它可以方便地写成 (1/2m) e-/2,r 表示由原点到（x, y）的距离换句话说，密度函数只依赖于到原点的距离（这就是为什么称它为「旋转不变的」）. 这个非常吸引人的性质在高维情况下也成立。可以 证明，(1/2m) er/2 是唯一具有这个性质的函数，就是说，它是唯一的旋转不变而且其坐标和 y 是独立的方差为 1 的随机变量的密度函数。这样，正态分布具有非常特别的对称性质

像这样的性质，使得我们在解释正态分布在数学中无处不在方面走了一大步然而正态分布还有一个甚至更加值得注意的性质，使得当用数学建立现实世界的无序性的模型时，正态分布总会出现。中心极限定理指出，对于任意独立的而且具有相同分布的随机变量的序列：X1, X2（它们的平均值都是有限的ル，方差也是相同的 2），则对任意实数总有

X1+……+Xn 的期望值是 m4, 标准差是√o，所以思考这个问题又可以换一个角 度：令 Yn=(X1+…+Xn ー n)/Vo, 这样把随机变量 X 重新尺度化为 Yn，则 Yn 的平均值成为 0, 而方差成为 1, 而上面的概率就变成了 Yn≤x 的概率。这样，不论从什么样的分布开始，在适当地重新尺度化以后，许多同样的随机变量之和的极限分布总是正态分布许多自然过程都可以很合乎实际地以大量微小的独立随机效应的聚集为其数学模型。这就是为什么我们所观察到的许多分布，如某个城市里成人身高的分布等等，都是我们熟悉的钟形曲线

中心极限定理有一个很有用的应用，就是它可以用于简化一些几乎无法处理的复杂计算。例如，二项分布概率的计算，当参数 n 很大时，复杂得几乎令人束手无 策但是，如果 X 是一个二项随机变量，设其参数例如为 n 和 1/2, 则可以把 X 写

为一个和 Y1+…+Yn, 而 Y1,,Y 是独立的参数为 1/2 的伯努利随机变量。于是，由中心极限定理有：

