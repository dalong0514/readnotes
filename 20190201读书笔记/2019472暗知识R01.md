## 记忆时间

## 目录

0101横空出世 —— 暗知识的发现

0201榨取数据 —— 机器能学会的知识

0301神经网络 —— 萃取隐蔽相关性

## 0101. 横空出世 —— 暗知识的发现

### 00. 导读

正当人类自以为掌握了关于这个世界的海量知识时，一种能够自我学习的机器给了我们当头一棒：机器发现了一类人类既无法感受，也不能理解的知识。这类知识的发现，逼迫我们重新审视过去所有关于知识的观念。我们回顾了 2500 年来在这个问题上的争论：知识是通过经验得到的还是通过推理得到的？直到大约 70 年前人们才注意到那些「只可意会，不可言传」的默知识的重要性。但这些争论在最新的脑科学研究结果面前都显得肤浅和苍白。

最近几十年的科学研究确认了认知的基础是大脑神经元之间的连接。有了这个基础，我们就很容易理解为什么有些知识无法表达，也才能明白为什么人类无法理解机器刚刚发现的这些暗知识。在此基础上，我们终于可以清晰地区分这样三类知识：人类能掌握的明知识和默知识以及只有机器才能掌握的暗知识。

### 1.1 骄傲的人类

也许是由于几十万年前人类远古祖先某个基因的突变，人们开始可以把一些有固定意思的发音片段组装成一个能表达更复杂意思的发音序列。这些发音片段今天我们叫作「单词」，这个表达特定内容的发音序列今天我们叫作「句子」。这种「组装」能力使人类用有限的单词可以表达几乎无穷多种意思，语言诞生了。

有了语言的复杂表达能力，人类的协作能力开始迅速提高，可以几十人一起围猎大型动物，很快人类就上升到地球生物链的顶端。作为记录语言的符号 —— 文字的发明可以让人类更方便地传播、记录和积累经验。任何一个地方的人类偶然发现的关于生存的知识都会慢慢传播开来。

一万年前，农业起源于今天的埃及、叙利亚和伊拉克的肥沃新月带，这些种植经验在几千年中传遍全世界，随之而来的是人类迅速在地球所有适宜农耕的角落定居繁衍。

2『农业起源的时间，做一张信息数据卡片。（2021-07-27）』—— 已完成

随着定居的人类数量的增加，人类的组织开始变得更大更复杂，从亲缘家族到部落，到城邦，再到国家。大规模的复杂组织可以开展大规模的复杂工程，如建设城市、庙宇和大规模灌溉系统。这些大规模工程需要更多的天文和数学知识。世界上几乎所有的古老文明都积累了许多天文知识，但只在希腊半岛诞生了现代科学的奠基石 —— 数学。欧几里得（Euclid，公元前 330-275）在公元前 300 年总结了他前面 100 年中希腊先哲的数学成果，写出了人类历史上最伟大的书之一《几何原本》（Elements）。这本书在中世纪由波斯裔的伊斯兰学者翻译成阿拉伯文，又从阿拉伯传回文艺复兴前的欧洲，直接影响了从哥白尼（Nicolaus Copernicus，1473-1543）到牛顿（Issac Newton，1643-1727）的科学革命。

发轫于 16 世纪的科学革命的本质是什么？是发现更多的知识吗？是创造出更多的工具吗？都不是。科学革命的本质是找到了一个可靠的验证知识的方法。

2『科学革命的本质是找到了一个可靠的验证知识的方法，做一张主题卡片。（2021-07-28）』—— 已完成

最能体现科学革命本质的就是天文学家开普勒（Johannes Kepler，1571-1630）发现三定律的过程。最初，在作为主流的托勒密（Ptolemy，90-168）地心说越来越无法解释天体观测数据时，哥白尼提出了日心说，用新的模型解释了大部分过去无法解释的数据。与伽利略（Galileo Galilei，1564-1642）同时代的天文学家第谷·布拉赫（Tycho Brahe，1546-1601）没有接受哥白尼的日心说，他提出了「月亮和行星绕着太阳转，太阳带着它们绕地球转」的「日心—地不动」说。遗憾的是，他倾尽毕生心血观察了 20 年的天文数据，直到去世都始终无法让观测到的数据与自己的模型相吻合。

在第谷去世后，第谷的助手开普勒拿到了他的全部数据，开普勒完全接受了哥白尼的日心说。他为了让数据与日心说完全吻合，把哥白尼的地球公转的圆形轨道修正为椭圆轨道，太阳在椭圆的一个焦点上。这就是开普勒第一定律。他用相同的方法发现了其他两个定律。开普勒三定律不仅完满解释了第谷的所有观测数据，并且能够解释任何新观测到的数据。

这个发现过程有三个步骤：第一，积累足够的观测数据（第谷 20 年的观测数据）；第二，提出一个先验的世界模型（哥白尼的「日心说」）；第三，调整模型的参数直至能够完美拟合已有的数据及新增数据（把圆周轨道调整为椭圆轨道，再调整椭圆轴距以拟合数据）。验证了这个模型有什么用？最大的用处就是可以解释新的数据或做出预测。在这里开普勒三定律就是新发现的知识。发现知识的可靠方法就是不断修改模型使模型与观测数据完全吻合。

上面这三个步骤奠定了现代科学的基本原则，正式吹响了科学革命的号角，直接导致了后来的牛顿万有引力的发现，一直影响到今天。

过去 500 年中人类对世界的认识突飞猛进，今天大到宇宙，小到夸克都似乎尽在人类的掌握之中。人类可以上天、入地、下海，似乎无所不能。人类有了「千里眼」「顺风耳」，甚至开始像「上帝」一样设计新的物种，并企图改变人类进化的进程。人类有理由相信没有什么知识是不能理解的，也没有什么知识是不能被发现的……直到 2016 年 3 月 15 日。

### 1.2 天才的哽咽

2016 年 3 月 15 日，美国谷歌公司的围棋对弈程序 AlphaGo 以五局四胜的成绩战胜世界围棋冠军韩国选手李世石。一时间这个消息轰动世界，全世界有 28 亿人在关注这场比赛，在中国更是引起极大的轰动。人们感觉 AlphaGo 就像从石头缝里蹦出来的孙悟空一样，完全无法理解一台机器如何能够打败世界围棋冠军。围棋历来被认为是人类最复杂的游戏之一。围棋每一步的可能的走法大约有 250 种，下完一盘棋平均要走 150 步，这样可能的走法有 250^150=10^360 种，而宇宙从诞生到现在才 10^17 秒，即使是现在世界上最快的超级计算机，要想把所有走法走一遍，计算时间也要比宇宙年龄都长。即使排除了大部分不可能的走法也是大到无法计算。机器是怎样学会这么复杂的棋艺的？

这场比赛后，世界排名第一的棋手柯洁在网上说：「AlphaGo 胜得了李世石，胜不了我。」而 2017 年 5 月 28 日，棋手柯洁以 0：3 完败AlphaGo，彻底击碎了人类在这种复杂游戏中的尊严。赛后，这位天才少年一度哽咽，在接受采访时柯洁感叹，AlphaGo 太完美，看不到任何胜利的希望。他流着眼泪说：「我们人类下了 2000 年围棋，连门都没入。」中国棋圣聂卫平更是把 AlphaGo 尊称为「阿老师」，他说：「AlphaGo 的着数让我看得如醉如痴，围棋是何等的深奥和神秘。AlphaGo 走的顺序、时机掌握得非常好。它这个水平完全超越了人类，跟它挑战下棋，只能是找死。我们应该让阿老师来教我们下棋。」他还说：「阿老师至少是 20 段，简直是围棋上帝。」

当人们以为这是对弈类程序的高峰时，AlphaGo 的研发团队 DeepMind（谷歌收购的人工智能企业，位于伦敦）团队再度碾轧了人类的认知。2017 年 12 月，DeepMind 团队发布了 AlphaGo Zero（阿尔法围棋零）。AlphaGo Zero 使用了一种叫作「强化学习」的机器学习技术，它只使用了围棋的基本规则，没有使用人类的任何棋谱经验，从零开始通过自我对弈，不断地迭代升级，仅仅自我对弈 3 天后，AlphaGo Zero 就以 100：0 完胜了此前击败世界冠军李世石的 AlphaGo Lee 版本。自我对弈 40 天后，AlphaGo Zero 变得更为强大，超过了此前击败当今围棋第一人柯洁的 AlphaGo Master（大师版），这台机器和训练程序可以横扫其他棋类。经过 4 个小时的训练，打败了最强国际象棋 AIStockfish，2 个小时打败了最强将棋（又称为日本象棋）AIElmo。

AlphaGo Zero 证明了即使在最具有挑战性的某些领域，没有人类以往的经验或指导，不提供基本规则以外的任何领域的知识，仅使用强化学习，仅花费很少的训练时间机器就能够远远超越人类的水平。

### 1.3 机器发现了人类无法理解的知识

AlphaGo Zero 给我们的震撼在于人类 2000 多年来一代代人积累的一项技艺在机器眼里瞬间变得一文不值！为什么会这样？围棋中的可能走法比宇宙中的原子数都多，而人类 2000 多年中高水平对弈非常有限，留下记录的只有几万盘。这个数字和所有可能走法比，就像太平洋里的一个水分子。而 AlphaGo Zero 以强大的计算能力，在很短的时间里探索了大量的人类未曾探索过的走法。人类下棋的路径依赖性很强，人生有限，想成为高手最稳妥的办法是研究前人的残局，而不是自己瞎摸索。但 AlphaGoZero 在下棋时，不仅一开始的决策是随机的，即使到了大师级后，也故意随机挑选一些决策，跳出当前思路去探索更好的走法，新发现的许多制胜走法都是人类从未探索过的，这就是很多走法让聂卫平大呼「看不懂」的原因。

AlphaGo Zero 给我们的震撼在于三个方面：

首先，人类能发现的知识和机器能发现的知识相比，就像几个小脚老太太走过的山路和几百万辆越野车开过的山路。越野车的速度就是计算机和 AI 芯片处理速度，目前继续以指数速度在提高。

其次，和机器可能发现的知识相比，人类知识太简单、太幼稚，机器谈笑风生，比人不知道高到哪里去了。

最后，机器发现的知识不仅完全超出了人类的经验，也超出了人类的理性，成为人类完全无法理解的知识。

2500 年前最有智慧的希腊哲人苏格拉底（Socrates，公元前 469-399）终其一生得出一个结论：「我唯一知道的是我什么都不知道。」他的学生柏拉图（Plato，公元前 427-347）认为我们感官观察到的世界只是真正世界的影子而已。18 世纪伟大的哲学家康德也仰望星空，发出了「我们到底能知道什么」的千古之问。但古代哲人只能模糊地感觉到人类认识的局限。今天，AlphaGo Zero 不仅清晰、具体地把他们的疑虑变成了铁的事实，而且先哲怎么也想不到人类的认识能力是如此有限！

你会质疑说：这不算什么震撼吧，人类早就知道我们已知的很少，未知的很多。但这个下围棋的例子告诉你：已知的是几万盘残局，未知的是 10^360 种可能走法，两者相差几百个数量级！（不是几百倍，是几百个数量级，一个数量级是 10 倍。）

你学过概率和统计，继续不服：我们早就知道组合爆炸。没错，但我们知道未知的组合爆炸里有比人类已经获得的知识高深得多的知识吗？AlphaGo Zero 是第一次活生生地证明了这点。听说过火山爆发和在现场看到的感觉能一样吗？

当然最震撼的就是第三个方面。我们也许知道我们不知道很多，甚至能用逻辑推断出未知知识里有比已知知识更高深的知识，但我们怎么也想不到这些知识是人类根本无法理解的。这是人类历史上第一次遇到这样的问题，我们给自己造了个「上帝」！这件事对哲学和认识论的冲击空前，人类突然不知所措，影响还在发酵，后果不可估量。

「理解」的意思是要么能用感觉把握事物间的关系，要么能用概念把经验表达出来，或者用逻辑把事物间的关系表达出来。无法理解就等于既无法感受又无法表达。

也就是说，机器发现了人类既无法感受也无法表达的知识。用更通俗的话说就是，机器发现了那些既无法「意会」又无法「言传」的知识。

一个无法理解的知识的表现形式是什么样的？如果无法理解又怎么判断它就是知识？当我们想回答上面的问题时，我们发现必须重新审视什么是「知识」。人类过去几千年是怎样获得知识的，获得了什么样的知识？就像每次科学上的重大发现都要迫使我们重新审视过去习以为常的观念一样，今天机器的震撼让我们必须重新审视过去所有关于「知识」的基本理念。

人类获得知识的行为就是认知。过去我们对世界的认识局限主要来自观察能力。在望远镜发现之前，第谷根本无法观测行星运动，当然更谈不上记录数据，也不会有后来的开普勒定律和牛顿万有引力定律。在显微镜发明之前，我们不可能发现微生物，一切关于细胞和基因的发现都无从谈起。今天谁能花 1000 万美元买一台冷冻电镜，谁就可以看到别人看不到的分子晶体结构，就可以经常在《自然》（Nature）杂志上发表文章。随着新的观察仪器的出现和已有观察仪器的改进，我们对世界的认识还会不断深入。

我们对世界认识的第二个局限来自解释能力。所谓解释能力就是发现事物间的因果关系或者相关性并能够表达出来。即使我们能观察到许多现象，如果我们无法解释这些现象则还是无法从这些观察中获得知识。例如第谷虽然有大量观测数据，但终其一生没有找到一个能解释数据的正确模型。又如我们观察到人有语言能力而黑猩猩没有，但不知道为什么，仅仅是知道这个现象而已。

人类几千年来关于知识的争论正是围绕着「观察」还是「解释」展开的。

1-2『上面这一节的信息感触很大，要反复研读。补充进主题卡片「知识」里。（2021-07-28）』—— 已完成

### 1.4 理性主义和经验主义之争

自从 5000 年前两河流域的苏美尔人发明了人类最早的文字 —— 楔形文字以来，人类一直在记录和积累知识。但直到 2500 年前希腊人才开始系统地研究关于知识的学问。在这个问题上，一直有两大流派：理性主义和经验主义。

第一个开启了理性主义的人是苏格拉底。人类此前的大部分「知识」要么从宗教教义中来，要么从传统习俗中来。人们从生下来就不加怀疑地接受了这些东西。而苏格拉底则要一一审视这些东西。苏格拉底说我们都希望有一个「好」的人生，但到底什么是「好」什么是「坏」呢？不去质疑，不去深究你怎么知道呢？所以深究和道德是不可分割的，不去深究我们身边的世界不仅是无知而且是不道德的，所以他的结论是：一个未经深究的人生根本就不值得过。

他平时没事就跑到大街上拉住人诘问：「什么是正义？」「什么是善？」「什么是美？」每当人们给他个定义时，他都能举出一个反例。他这种深究思辨影响了无数代人。后来当他的学生柏拉图把「人」定义为「没有毛的双足动物」时，当时的另一位哲学家提奥奇尼斯马上拿来一只拔光了毛的鸡说：「大家请看柏拉图的`人`！」经过一生的深究，苏格拉底得出结论「我唯一知道的是我什么也不知道」。

苏格拉底式思辨震撼了当时的社会，传统势力认为这样会搞乱人心，当政者用「腐蚀青年思想罪」判处他死刑，他最终饮毒酒身亡。他一生全部用来和人辩论，没有留下任何著作。幸亏他的学生柏拉图把老师的辩论编辑成了传世之作《对话录》。正是苏格拉底开启了通过逻辑思辨来验证知识的希腊传统。

如果说是苏格拉底开了理性主义的先河，他的弟子柏拉图就是理性主义集大成的鼻祖。苏格拉底的思辨主要集中在道德哲学领域，探究什么是「公平」和「善」。而柏拉图则对他的先辈毕达哥拉斯（Pythagoras，约公元前 570-495）开创的数学传统深为折服。柏拉图的学说深受数学严格推理的影响。他甚至在他创办的学宫门口挂了个牌子：「不懂几何者不得入内。」

柏拉图学说的核心是「理想原型」。他说，世界上每一条狗都不一样，我们为什么认为它们都是狗？人类心中一定早有一个关于狗的理想原型。我们知道三角形的内角之和等于 180 度，但我们从未见过一个完美的三角形。他认为人类的感官无法触及这些理想原型，我们能感受到的只是这些理想原型的失真拷贝。真实世界就像洞穴外的一匹马，人类就像一群背对着洞口的洞穴人，只能看到这匹马在洞穴壁上的投影。柏拉图奠定了理性主义的两大基础 —— 知识（理想原型）是天生的；感官是不可靠的，并由此推出理性主义的结论：推理而不是观察，才是获取知识的正确方法。

亚里士多德（Aristotle，公元前 384-322）17 岁进入柏拉图的学宫当学生，当时柏拉图已经 60 岁了。亚里士多德在学宫里待了 20 年，直到他的老师柏拉图去世。亚里士多德对老师非常尊敬，但他完全不同意老师的「理想原型」是先天的。他认为每一条狗都带有狗的属性，观察了许多狗之后就会归纳出狗的所有属性。这个「理想原型」完全可以通过后天观察获得，而不需要什么先天的假设。柏拉图酷爱数学，而亚里士多德喜欢到自然中去观察植物和动物。两人的喜好和经历是他们产生分歧的重要原因之一。亚里士多德认为：知识是后天获得的，只有通过感官才能获得知识。正是亚里士多德开了经验主义的先河。

经验主义这一派后世的著名代表人物有英国的洛克（John Locke，1632-1704），贝克莱（George Berkeley，1685-1753）和休谟（David Hume，1711-1776），贝克莱认为人生下来是一张白纸，所有的知识都是通过感官从经验中学来的。但理性主义则认为，经验根本不可靠。英国哲学家罗素（Bertrand Russell，1872-1970）有个著名的「火鸡经验论」。火鸡从生下来每天都看到主人哼着小曲来喂食，于是就根据经验归纳出一个结论：以后每天主人都会这样。这个结论每天都被验证，火鸡对自己的归纳总结越来越自信，直到感恩节的前一天晚上被主人宰杀。理性主义者还问：眼见为实吗？你看看图 1.1 中的横线是水平的还是倾斜的？

图 1.1 视错觉图（图中所有横线都是水平的）

理性主义的后世代表人物则有法国的笛卡儿（Rene Descartes，1596-1650）和德国的莱布尼茨（Gottfried Leibniz，1646-1716）。笛卡儿有句名言「我思，故我在」，我的存在这件事不需要经验，不需要别人教我，我天生知道。莱布尼茨是和牛顿一样的天才，他和牛顿同时发明了微积分，也是二进制的发明人，还发明了世界上第一台手摇计算器。他认为世界上每个事物都包含了定义这个事物的所有特性，其中也包含了和其他事物的关系。从理论上我们可以用推理的方法预测全宇宙任何一点，过去和未来任何时间的状态。

理性主义认为，感官根本不靠谱，最可靠的是理性，基于公理严格推导出来的几何定理永远都不会错。理性主义找出更多的例子来说明人类的最基本的概念是天生的。

例如自然数，我们怎么学会「1」这个概念的？拿了一个苹果告诉你「这是一个苹果」；又给你拿了个橘子告诉你「这是一个橘子」。但苹果是苹果，橘子是橘子，两者没关系，你怎么就能抽象出「1」这个概念来呢？又比如我们可以根据直角三角形的特点推导出勾股定理，又进一步发现世界上居然有无法用分数表达的无理数。这种革命性的发现完全不依赖感觉和经验。小孩一出生就知道这个球不是那个球，这条狗不是那条狗，这个「同一性」是理解世界最基本的概念，没人教他。

我们注意到理性主义有一个隐含的假设，就是因果关系。在莱布尼茨的世界里，一件事会导致另外一件事，所以才有可能推导。经验主义当然不服，休谟就问，一件事发生在另外一件事之后，两者未必有因果关系。譬如我把两个闹钟一个设在 6:00，一个设在 6:01，能说后面的铃声响了是前一个造成的吗？理性主义不仅认为事物间有因果关系，而且认为通过逻辑推理可以得到很多知识。譬如归纳推理：太阳每天早上都会升起。但休谟就质问：你能像证明数学定理一样证明太阳明天会升起吗？不能吧。那能观察吗？明天还没到来显然不能观察，那你凭什么说明天太阳一定升起，我要说明天不一定升起错在哪里了？我们看到休谟挑战的是归纳背后的假设：事物运动规律不变，在这里就是说地球和太阳系的运动不会改变。休谟最后说，物理世界没什么因果，没什么必然，你最多能根据以往的经验告诉我：明天早上太阳还可能升起。

这两派从 17 世纪吵到 18 世纪，这时候在德国偏僻的海德堡出现了一个小个子乡村秀才。他说，你们双方似乎都有道理，我来整合一下看看。他就是哲学史上最有影响力的康德（Immanuel Kant，1724-1804）。康德说，没错，我们当然要通过感官去理解世界。但我们对事物的理解包括这个事物的具体形态和它的抽象概念。譬如眼前这本书，一本书的具体形态千变万化，但「书」这个概念就是指很多页有字的纸装订在一起的一个东西。我们说「面前有这本书」的意思到底是什么？那至少要说现在几月几日几点几分，在某市某区某小区几号楼几号房间的哪个桌子上有这本书，也就是理解一个具体的东西离不开时间和空间的概念。但谁教给你时间和空间了？你妈从小教过你吗？你教过你孩子吗？好像都没有，我们好像天生就懂。所以康德说，你看，必须有这些先天就有的概念你才能理解世界。我们好像天然知道「书」是个「东西」，「东西」是一种不依赖我们的独立存在。谁教给我们「东西」这个概念的？没人，好像又是天生就懂吗？康德整合了经验主义和理性主义，他的一句名言是「没有内容的思维是空洞的，没有概念的感知是盲目的。只有把两者结合我们才能认识世界」。

在 2500 年的辩论中，经验主义当然不会否认数学中通过严格推理得出来的结论的可靠性，理性主义也不得不承认认知物理世界离不开感官。那么这场打了 2500 年的嘴仗到底在争什么呢？问题出在理性主义者企图把数学世界里证明定理这样的绝对可靠性推广到物理世界，也即他们企图找到一个检验知识的普遍的标准，能够适用于所有领域。

数学（例如几何学）是建构在公理之上的一个自洽而完备的系统（至少对自然数和几何是如此）。所谓自洽就是说，在这个系统里只要从公理出发就不会推导出互相矛盾的结论；所谓完备就是说，在这个系统里任何一个命题都是可以证实或证伪的。而亚里士多德时代的自然科学的可靠性判断标准是「观察与模型符合」，即观察到的自然现象和事先假设的模型的预测结果相符合。这种物理真实性的判断标准和数学中的判断标准完全不同。所以经验主义觉得硬要把数学中的可靠性标准搬到自然科学中来不适用，或者说经验主义认为在自然科学领域只能依赖感官。因此这场争论是不对称的：理性主义要从数学攻入自然科学，而经验主义死守自然科学的阵地。两方掰扯不清的另一个原因是谁都不知道感官和认知的本质是什么，或者说知识的本质是什么。双方根据自己的猜测和假设激烈辩论，一直到 20 世纪 50 年代人们对大脑的研究才取得突破。

1-2『这一节的理性主义和经验主义，是我个人目前看到的阐述这两个概念最清晰、最通俗易懂的。做一张主题卡片。（2021-07-28）』—— 已完成

### 1.5 知识的生物学基础 —— 神经元连接

你会发现，所有认知的基础都是记忆，如果没有记忆的能力，观察、理解、推理、想象等其他所有认知行为都不会存在，甚至不会有情绪。一个患阿尔茨海默病的人，面部甚至逐渐失去表情。人类胎儿在 30 周后就开始了最初的记忆，婴儿从刚生下就能分辨出母亲的声音了。

如果认知的基础是记忆，那么记忆的基础又是什么呢？你仔细想想，记忆其实就是一种关联。你在学「o」这个字母时，是把一个圆圈的图像和一个「欧」的发音关联起来。那这种关联在大脑中是如何形成的呢？

这种关联是通过我们大脑中神经元之间的连接形成的。大脑有大约 1000 亿个神经元，一个神经元可以从许多其他神经元接收电脉冲信号，同时也向其他神经元输出电信号。

如图 1.2 所示，每个神经元都能输出和接收信号。负责输出的一端叫「轴突」，负责接收的一端叫「树突」。每个神经元都有几千个树突，负责从不同的神经元接收信号。同样，每个神经元的输出信号可以传给和它相连的几千个神经元。那么这个最初的信号是从哪里来的呢？通常都来自感觉细胞，如视觉细胞、听觉细胞等。

图 1.2 大脑神经元和突触的结构

那神经元之间是怎么连接的呢？一个神经元的轴突和另外一个神经元的树突之间有 20 纳米（一根头发丝的 1/2000）的小缝隙，这个缝隙叫「突触」。图 1.2 的右半部分就是放大了的突触。它保证了两个神经元各自独立，不会粘在一起。记忆的主要奥秘就藏在这里。在这个连接的地方前一个神经元的电信号会转化成化学物质传递到下个神经元，下个神经元接收到化学物质后又会再转成电信号。不同的突触面积大小不同，化学物质的传递速度和量不同，因而造成有些突触是「貌合神离」，相互之间并没有电信号通过；有些则是「常来常往」，经常有信号通过。

2『神经元件突触间隙的尺寸数据，做一张信息数据卡片。（2021-07-28）』—— 已完成

你一定听说过俄国生理学家巴甫洛夫（Ivan Pavlov，1849-1936）的条件反射实验。受到条件反射的启发，加拿大心理学家赫布（Donald Hebb，1904-1985）在 1949 年提出了一个大胆的猜想。他认为当大脑中两个神经元同时受到刺激时，它们之间就会建立起连接，以后其中一个神经元被激发时会通过连接让另一个神经元也被激发。

譬如在巴甫洛夫对狗的实验中，送食物的时候同时摇铃，摇铃刺激了听觉神经元，食物味道刺激了嗅觉神经元并且导致分泌唾液，听觉和视觉神经元同时受到刺激，它们之间就建立了连接，一个神经元的激发会导致另一个神经元的激发。经过多次反复，它们的连接会越来越稳定。以后即使没有送食物，狗只要听到摇铃就像闻到食物一样会分泌唾液。人也是一样，比如说一个小孩被火烫过一次就能把「火」和「疼」联系起来。当小孩看见火时，他大脑中负责接收视觉信号的神经元被激发了，与此同时他的手感觉到烫，于是他大脑中负责接收皮肤感觉细胞的神经元也被激发了。如果看到火和感觉到疼这两件事同时发生，那么这两个神经元细胞就连通了，也就是有信号通过了。下次这个孩子见到火，马上会想到疼，因为当负责看到火的神经元被激发后，马上会把信号传给负责「疼」这种感觉的神经元，就能让小孩想到疼。刺激越强，神经元的连接就越稳固。孩子被火烫过一次手就永远记住了，再也不会去摸火；有些刺激很弱，连接就不稳固，长时间不重复就会断开。例如背英文单词，重复的刺激越多，信号的传递速度就越快。比如一个篮球运动员对飞过来的篮球的反应比普通人快很多，一个空军飞行员对飞机姿势和敌人导弹的反应都比普通人快，这些都是反复训练出来的。所谓赫布猜想，本质上是通过建立神经元之间的连接从而建立起不同事物之间的联系。后来这个猜想被科学家反复证实，就成了现在我们常说的赫布学习定律。

赫布定律揭示了记忆或者说关联的微观机制，启发了好几代计算机科学家，他们开始用电子线路模仿神经元，然后用许多电子神经元搭建越来越大的神经元网络，今天这些神经网络的记忆和关联能力已经远远超过了人类，许多机器的「神迹」大都源于这种超强的记忆和关联能力。在第三章，我们会介绍为什么神经网络的超强记忆和关联能力会转化为不可思议的「超人」能力。

这些在大脑中由神经元的连接形成的关联记忆又可以分为两类：可表达的和不可表达的。

### 1.6 可表达的「明知识」

目前，脑神经科学的最新研究发现，可表达的记忆并不是对应着一组固定神经元的连接，而是大致地对应于散布在大脑皮层各处的一些连接。原因是用来表达的语言和文字只能是体验的概括和近似。这类可以用语言表达或数学公式描述的知识就是人类积累的大量「正式知识」，也可以称为「明知识」。它们记载在书籍、杂志、文章、音频等各种媒体上。

要想把某种关联表达出来，人类唯一的方法是通过语言和符号。

语言和符号表达的第一个前提是要有概念。所谓概念就是某个特定的发音或符号稳定地对应于一个事物或行为。大部分的名词和动词都是这样的概念。

第二个前提是每个概念都不同于其他概念，猫就是猫，狗就是狗，不能把猫叫成狗，或者把狗叫成猫，两者要能区分开。这叫「同一律」。

第三个前提是猫不能同时也不是猫，黑不能同时也是白。这叫「不矛盾律」。

2『语言和符号表达所需要的 3 个前提，做一张任意卡片。（2021-07-28）』—— 已完成

有了这些基本前提，根据已知的事物间的关系我们就可以推导出新的知识或者论证一个决定的合理性。推理、假设、联想，这些本质上都是建立在语言之上的思维活动，没有语言就完全无法思维。所有的正常思维都要借助概念，要遵循「同一律」和「不矛盾律」。

语言是人类和所有动物的最大区别。黑猩猩可以学会很多概念，譬如「我」「吃」和「香蕉」等，但无论实验人员如何训练黑猩猩，它们都无法组合出「我要吃香蕉」这样的句子。人的语言能力的本质是什么？它的生物学基础是什么？语言和自我意识是什么关系？目前这些都还不清楚。但我们知道，人类语言是不精确的，越基本的概念越不容易定义清楚，像「公平」「理性」等。人类语言中有大量含混和歧义的表述，像「今天骑车子差点滑倒，幸亏我一把把把把住了」。

英国哲学家罗素企图把语言建立在精确的逻辑基础之上，他用了几百页纸的篇幅来证明 1+1=2。德国哲学家维特根斯坦（Ludwig Wittgenstein，1889-1951）认为人类有史以来几乎所有的哲学辩论都源于语言的模糊不清，因而没有任何意义。他认为在世界中只有事实有意义，在语言中只有那些能够判断真伪的论断才能反映事实。他的结论是：我们的语言受限，因而我们的世界受限。

为什么语言的表达能力受限？用信息论的方法可以看得很清楚。我们大脑接收的环境信息量有多大？一棵树、一块石头、一条狗都包含几十 MB（兆字节）甚至几十 GB（千兆字节）的数据，我们的感觉接收神经元虽然大大简化了这些信息，但它们向大脑传导的信息量仍然非常大，表 1.1 是各个感觉器官每秒钟能向大脑传递的信息量。

表 1.1 人体各个感官向大脑传送信息的速率

| 感官系统 | 比特/秒 |
| --- | --- |
| 眼睛 | 1000W |
| 皮肤 | 100W |
| 耳朵 | 10W |
| 嗅觉 | 10W |
| 味觉 | 1K |

2『人体各个感官向大脑输送信息的速率，做一张信息数据卡片。（2021-07-28）』—— 已完成

资料来源：[Information theory - Physiology | Britannica](https://www.britannica.com/science/information-theory/Physiology)。

3『

意外发现一个资源池：[Encyclopedia Britannica | Britannica](https://www.britannica.com/)，直觉是个大宝藏。（2021-07-28）

[Information theory | mathematics | Britannica](https://www.britannica.com/science/information-theory)

[Mathematics Portal | Britannica](https://www.britannica.com/browse/Mathematics)

[Science Portal | Britannica](https://www.britannica.com/browse/Science)

』

大脑存储这些信息的方式是神经元之间的连接，大脑在存储时可能进一步简化了这些信息，但它们的信息量仍然远远大于我们语言所能表达的信息量。人类语言的最大限制是我们的舌头每秒钟只能嘟噜那么几下，最多表达几十个比特的意思。（比如读书，我们平均每分钟能读 300 字，每秒读 5 个字 = 40 比特。）这样大脑接收和存储的信息与能用语言表达出来的信息量就有 6 个数量级的差别。也就是说极为丰富的世界只能用极为贫乏的语言表达。许多复杂事物和行为只能用简化了的概念和逻辑表达。这就是人类语言的基本困境。

### 1.7 只可意会的「默知识」

由于舌头翻卷速度严重受限，以神经元连接形式存在大脑中的人类知识只有极少一部分可以被表达出来。而绝大部分知识无法用语言表达，如骑马、打铁、骑自行车、琴棋书画，察言观色、待人接物、判断机会和危险等。这些知识由于无法记录，所以无法传播和积累，更无法被集中。

英籍犹太裔科学家、哲学家波兰尼（Michael Polyani，1891-1976）称这些知识为「默会知识」或者「默知识」。波兰尼举了骑自行车的例子。如果你问每个骑自行车的人是怎么保持不倒的，回答会是「车往哪边倒，就往哪边打车把」。从物理学上可以知道，当朝一个方向打把时会产生一个相反方向的离心力让车子平衡。甚至可以精确计算出车把的转弯半径应该和速度的平方成反比。但哪个骑自行车的人能够知道骑车的速度呢？即使知道谁又能精确地把转弯半径控制在速度平方的反比呢？所有骑自行车的人都是凭身体的平衡感觉左一把右一把地曲折前进。世界上大概没有一个人学骑自行车是看手册学会的，事实上也没有这样的学习手册。大部分技能类的知识都类似。

1-3『波兰尼有印象的，之前在 kindle 上买其一本著作「2019891个人知识」。（2021-07-28）』

默知识和明知识主要有以下四点区别：

1、默知识无法用语言和文字描述，因此不容易传播，无法记录和积累，只能靠师傅带徒弟。像大量的传统工艺和技能，如果在一代人的时间里没人学习就会从历史上彻底消失。

2、获取默知识只能靠亲身体验，传播只能靠人与人之间紧密的互动（你第一次骑自行车时你爸在后面扶着）。而这种互动的前提是相互信任（你不敢让陌生人教你骑自行车）。获得默知识必须有反馈回路（骑自行车摔了跤就是姿势错了，不摔跤就是姿势对了）。

3、默知识散布在许多不同人的身上，无法集中，很难整合，要想使用整合的默知识需要一群人紧密协调互动。由于无法言传，所以协调极为困难（比如杂技叠罗汉）。

4、默知识非常个人化。每个人对每件事的感觉都是不同的，由于无法表达，因而无法判断每个人感觉的东西是否相同。

基于对默知识的理解，奥地利经济学家哈耶克（Friedrich Hayek，1899-1992）论证了市场是最有效的资源配置形式。因为市场上的每个人都有自己不可表达的、精微的偏好和细腻的需求，而且没人能够精确完整地知道其他人的偏好和需求，也就是说供需双方实际上无法直接沟通。供需双方最简洁有效的沟通方式就是通过商品的价格。在自由买卖的前提下，市场中每个人只要根据价格信号就可以做出决定。价格可以自动达到一个能够反映供需双方偏好和需求的均衡点。一个价格数字，就把供需双方的无数不可表达的信息囊括其中。这种「沟通」何其简洁，这种「协调」何其有效，这种自发形成的秩序何其自洽。哈耶克根据同样的道理论证了国家或政府永远都无法集中这些不可表达的分散信息。

在机器学习大规模使用之前，人类对于默知识没有系统研究。但现在我们发现机器非常擅长学习默知识。这就给我们提出了三个严肃的问题。

1、默知识在所有知识中占比有多大？

2、默知识在人类社会和生活中有多大用处？

3、如何使用默知识？

第一个问题的简单粗暴的回答是默知识的量远远大于可陈述的明知识。原因是事物的状态很多是难以观察的，更多是不可描述的。人类的描述能力非常有限，只限于表达能力极为有限的一维的语言文字。在所有已经产生的信息中，文字只占极少的比例，大量的信息以图片和视频方式呈现。人类现代每年产生的各种文字大约是 160TB。世界最大的美国国会图书馆有 2000 万册书，几乎涵盖了人类有史以来能够保存下来的各种文字记录，就算每本书有 100 万字，这些书的总信息量也只有 20TB。而目前用户每分钟上传到 YouTube 的视频是 300 小时，每小时视频算 1GB，每年上传的量就是 157 680TB。如果把每个人手机里的视频都算上，那么视频信息是文字信息的上亿倍。今后这个比例还会不断加大。虽然这些视频或图片都是「信息」，还不是「知识」，但我们也可以想象从视频图片中能提取出的隐藏的相关性的量一定远远大于所有的文字知识。

有了第一个问题的答案，就容易回答第二个问题。很显然，用机器学习从视频和图片中萃取知识是人类认识世界的一个新突破，只要有办法把事物状态用图片或视频记录下来，就有可能从中萃取出知识来。如果视频和图片的信息量是文字的上亿倍，那么我们有理由期待从中萃取出的知识呈爆炸式增长，在社会和生活中起到关键甚至主导作用。

人工智能通过观看大量人类历史上的影视作品，可以归纳提取出影视中的经典桥段，创作出新颖的配乐、台词和预告片，供人类借鉴或使用。2016 年，IBM（国际商业机器公司）的沃森系统为二十世纪福克斯电影公司的科幻电影《摩根》（Morgan）制作了预告片。IBM 的工程师们给沃森看了 100 部恐怖电影预告片，沃森对这些预告片进行了画面、声音、创作构成的分析，并标记上对应的情感。它甚至还分析了人物的语调和背景音乐，以便判断声音与情感的对应关系。在沃森完成学习后，工作人员又将完整的 Morgan 电影导入，沃森迅速挑出了其中 10 个场景组成了一段长达 6 分钟的预告片。在沃森的帮助下，制作预告片的时间由通常的 10 天到 1 个月，缩减到了短短的 24 个小时。同样道理，机器学习可以从海量的生态、生产和社会环境数据中萃取出大量的未曾发现的知识。

第三个问题最有意思。由于机器萃取出的知识是以神经网络参数集形式存在的，对人类来说仍然不可陈述，也很难在人类间传播。但是这些知识却非常容易在机器间传播。一台学会驾驶的汽车可以瞬间「教会」其他 100 万台汽车，只要把自己的参数集复制到其他机器即可。机器间的协同行动也变得非常容易，无非是用一组反馈信号不断地调整参加协同的每台机器的参数。

如果用一句话总结默知识和明知识的差别那就是波兰尼说的：We know more than we can tell（知道的远比能说出来的多）。明知识就像冰山浮出水面的一角，默知识就是水下巨大的冰山。这两类知识也包括那些尚未发现的知识，一旦发现，人类要么可以感受，例如第一个登上珠峰的人能感受到缺氧；要么从理性上可以理解，例如看懂一个新的数学定理的推导过程。

### 1.8 既不可感受也不能表达的「暗知识」

既然可以感受的是默知识，可以表达的是明知识，那么机器刚刚发现的，既无法感受也无法表达的知识就是暗知识。我们用是否能感受作为一个坐标轴，用是否能表达（或描述）作为另一个坐标轴，就可以用图 1.3 把三类知识的定义清晰地表达出来。在这张图里，明知识又被分为两类：第一类是那些既可以感受又可以表达的，例如浮力定律、作用力反作用力定律等。第二类是不可感受可以表达的，如大部分的数学以及完全从数学中推导出来但最后被实验验证了的物理定律，以及相对论和量子力学。

2『上面的信息补充进术语卡片「暗知识」。（2021-07-28）』—— 已完成

图 1.3 知识的分类

为了理解暗知识的本质，我们必须先搞清楚「知识」与我们今天常用的「信息」和「数据」有什么不同。稍加研究就能发现关于信息、数据和知识的定义有很多并且非常混乱。笔者在下面给出一组符合信息论和脑神经科学研究结果的简单而自洽的定义。

信息是事物可观察的表征，或者说信息是事物的外在表现，即那些可观察到的表现。在我们没有望远镜时，谈论肉眼以外星空里的信息毫无意义。

数据是已经描述出来的部分信息。任何一个物体的信息量都非常大，要想精确地完全描述一块石头，就要把这块石头里所有基本粒子的状态以及它们之间的关系都描述出来，还要把这块石头与周围环境和物体的关系都描述出来。而关于这块石头的数据通常则少得多，例如它的形状、重量、颜色和种类。

知识则是数据在时空中的关系。知识可以是数据与时间的关系，数据与空间的关系。如果把时间和空间看作数据的一部分属性，那么所有的知识就都是数据之间的关系。这些关系表现为某种模式（或者说模式就是一组关系）。对模式的识别就是认知，识别出来的模式就是知识，用模式去预测就是知识的应用。

开普勒的行星运动定律就是那些观测到的数据中呈现的时空关系。牛顿定律的最大贡献可能不在于解释现有行星的运动，而在于发现了海王星。这些数据在时空中的关系只有在极少数的情况下才可以用简洁美妙的数学方程式表达出来。在绝大多数情形下，知识表现为数据间的相关性的集合。这些相关性中只有极少数可以被感觉、被理解，绝大多数都在我们的感觉和理解能力之外。

2『信息、数据、知识的关系，做一张任意卡片。（2021-07-28）』

人类的理解能力由感受能力和表达能力组成。人类的感受能力有限，局限性来自两个方面。

一是只能感受部分外界信息，例如人眼无法看到除可见光之外的大部分电磁波频谱，更无法感受大量的物理、化学、生物和环境信息。

二是人类的感官经验只局限在三维的物理空间和一维空间。对高维的时空人类只能「降维」想象，用三维空间类比。对于数据间的关系，人类凭感觉只能把握一阶的或线性的关系，因为地球的自转是线性的，所以「时间」是线性的。例如当我们看到水管的水流进水桶里时，水面的上升和时间的关系是线性的，我们凭感觉可以预测大概多长时间水桶会满。人类感官对于二阶以上的非线性关系就很难把握。例如当水桶的直径增加 1 倍时，水桶能盛的水会增加 4 倍，这点就和「直觉」不相符。

2『人类的理解能力由感受能力和表达能力组成，做一张主题卡片。（2021-07-28）』—— 已完成

人类的表达能力只限于那些清晰而简单的关系，例如少数几个变量之间的关系，或者是在数学上可以解析表达的关系（解析表达的意思就是变量之间的关系可以用一组方程式表达出来）。当数据中的变量增大时，或当数据间的关系是高阶非线性时，绝大多数情况下这些关系无法用一组方程式描述。所以当数据无法被感受，它们之间的关系又无法用方程解析表达时，这些数据间的关系就掉入了人类感官和数学理解能力之外的暗知识大海。

我们现在可以回答「一个人类无法理解的暗知识的表现形式是什么样的」，暗知识在今天的主要表现形式类似 AlphaGo Zero 里面的「神经网络」的全部参数。在第三章详细介绍神经网络之前，我们暂时把这个神经网络看成一个有许多旋钮的黑盒子。这个黑盒子可以接收信息，可以输出结果。黑盒子可以表达为一个一般的数学函数：Y=fw(X)。这里 Y 是输出结果，fw(X) 是黑盒子本身，X 是输入信息，w 是参数集，就是那些旋钮，也就是暗知识。

我们如何知道这个函数代表了知识，也即这个函数有用？这里的判别方法和现代科学实验的标准一样：实验结果可重复。对 AlphaGo Zero 来说就是每次都能赢；用严格的科学语言来说就是当每次实验条件相同时，实验结果永远可重复。读完第三章，读者就会从细节上清楚暗知识是如何被验证的。

注意，暗知识不是那些人类尚未发现但一经发现就可以理解的知识。比如牛顿虽然没有发现相对论，但如果爱因斯坦穿越时空回去给他讲，他是完全可以理解的。因为理解相对论用到的数学知识如微积分牛顿都有了。即使在微积分产生之前，如果爱因斯坦穿越 2000 年给亚里士多德讲相对论，亚里士多德也能理解，至少能理解狭义相对论背后的物理直觉。但如果给亚里士多德讲量子力学他就不能理解，因为他的生活经验中既没有薛定谔的猫（用来比喻量子力学中的不确定性，一个封闭的盒子里的猫在盒子没打开时同时既是死的也是活的，一旦打开盒子看，猫就只能有一种状态，要么是死要么是活），他的数学水平也无法理解波动方程。那么我们可以说对亚里士多德来说，量子力学就是暗知识。量子力学因为没有经验基础，甚至和经验矛盾，在刚发现的初期，几乎所有的物理学家都大呼「不懂」，至今能够透彻理解的人也极少。甚至连爱因斯坦都不接受不确定性原理。

人类过去积累的明知识呈现出完美的结构，整个数学就建立在几个公理之上，整个物理就建立在几个定律之上，化学可以看成是物理的应用，生物是化学的应用，认知科学是生物学的应用，心理学、社会学、经济学都是这些基础科学的应用组合。这些知识模块之间有清晰的关系。但是机器挖掘出来的暗知识则像一大袋土豆，每个之间都没有什么关系，更准确地说是我们不知道它们之间有什么关系。

1-2『上面的这段话尝试着融入年中汇报里，收尾是借鉴的《华为数据之道》的四个象限世界，人类认知世界。（2021-07-28）』

我们可以预见一幅未来世界的知识图谱：所有的知识分为两大类界限分明的知识 —— 人类知识和机器知识。人类的知识如果不可陈述则不可记录和传播。但机器发掘出来的知识即使无法陈述和理解也可以记录并能在机器间传播。这些暗知识的表现方式就是一堆看似随机的数字，如一个神经网络的参数集。这些暗知识的传播方式就是通过网络以光速传给其他同类的机器。

暗知识给我们的震撼才刚刚开始。从 2012 年开始的短短几年之内，机器已经创造了下面这些「神迹」：对复杂病因的判断，准确性超过医生；可以惟妙惟肖地模仿大师作画、作曲，甚至进行全新的创作，让人类真假难辨；机器飞行员和人类飞行员模拟空战，百战百胜。

我们在第六章会看到更多这样的例子。人类将进入一个知识大航海时代，我们将每天发现新的大陆和无数金银财宝。我们今天面对的许多问题都像围棋一样有巨大的变量，解决这些问题和围棋一样是在组合爆炸中寻求最优方案，例如全球变暖的预测和预防、癌症的治愈、重要经济社会政策的实施效果、「沙漠风暴」这样的大型军事行动。系统越复杂，变量越多，人类越无法把握，机器学习就越得心应手。无数的机器将不知疲倦地昼夜工作，很快我们就会发现机器新发掘出来的暗知识会迅速积累。和下围棋一样，暗知识的数量和质量都将快速超过我们在某个领域积累了几百年甚至几千年的知识。明知识就像今天的大陆，暗知识就像大海，海平面会迅速升高，明知识很快就会被海水包围成一个个孤岛，最后连珠穆朗玛峰也将被淹没在海水之下。

这场人类认知革命的意义也许会超过印刷术的发明，也许会超过文字的发明，甚至只有人类产生语言可与之相比。请系好安全带，欢迎来到一个你越来越不懂的世界！

## 0201. 榨取数据 —— 机器能学会的知识

### 00. 导读

在深入探讨机器如何学习暗知识之前，我们先要知道机器也能够自己学习明知识和默知识。在这一章我们介绍机器学习的五大流派的底层逻辑和各自不同的先验模型。虽然现在神经网络如日中天，但其他四大流派也不容忽视。

2『机器学习的 5 大流派，做一张主题卡片。（2021-07-28）』

上一章我们说了人类通过感官和逻辑能掌握明知识和默知识，但人类对暗知识既无法感受也无法理解。现在我们要看看机器能掌握哪些知识，并擅长掌握哪些知识。

### 2.1 机器学习明知识

计算机科学家最早的想法是把自己的明知识，包括能够表达出来的常识和经验放到一个巨大的数据库里，再把常用的判断规则写成计算机程序。这就是在 20 世纪 70 年代兴起并在 20 世纪 80 年代达到高潮的「知识工程」和「专家系统」。

比如一个自动驾驶的「专家系统」就会告诉汽车，「如果红灯亮，就停车，如果转弯时遇到直行，就避让」，依靠事先编好的一条条程序完成自动驾驶。结果你可能想到了，人们无法穷尽所有的路况和场景，这种「专家系统」遇到复杂情况时根本不会处理，因为人没教过。「专家系统」遇到的另一个问题是假设了人类所有的知识都是明知识，完全没有意识到默知识的存在。

一个典型的例子是 20 世纪 80 年代中国的「中医专家系统」。当时计算机专家找到一些知名的老中医，通过访谈记录下他们的「望闻问切」方法和诊断经验，然后编成程序输入到计算机中。在中医眼中每一个病人都是独特的。当他看到一个病人时会根据经验做出一个整体的综合判断。这些经验连老中医自己都说不清道不明，是典型的默知识。所以中医诊断绝不是把舌苔的颜色划分成几种，把脉象分成几十种，然后用查表方式就可以做判断的。「专家系统」既不能给机器输入足够的明知识，更无法把默知识准确地表达出来输入给机器。所以，「专家系统」和「知识工程」在 20 世纪 80 年代之后都偃旗息鼓了。

要想把一个领域内的所有经验和规则全部写出来不仅耗费时间，而且需要集合许多人。即使如此，那些谁也没有经历过的情况还是无法覆盖。电脑的信息处理速度比人脑快得多，那么能不能把大量的各种场景下产生的数据提供给机器，让机器自己去学习呢？这就是现在风行一时的「机器学习」。

今天的机器可以自己学习两大类明知识：用逻辑表达的判断规则和用概率表达的事物间的相关性。

#### 2.1.1 符号学派 —— 机器自己摸索出决策逻辑

前面说过，理性主义认为事物间都有因果关系，基于因果关系，通过逻辑论证推理就能得到新知识。在机器学习中这一派被称为符号学派，因为他们认为从逻辑关系中寻找的新知识都可以归结为对符号的演算和操作，就像几何定理的推理一样。这种知识通常可以用一个逻辑决策树来表示。决策树是一个根据事物属性对事物分类的树形结构。

比如冬天医院门诊人满为患，测完体温，主任医生先问「哪里不舒服」，病人说「头疼，咳嗽」，主任医生再听呼吸。感冒、流感、肺炎都可能是这些症状的原因，现在要根据这些症状判断病人到底得了什么病，这种从结果反着找到因果链条的过程就叫「逆向演绎」。

这时候主任医生用的就是一个决策树：体温低于 38.5℃，咳嗽，头痛，可能是普通感冒，回去多喝白开水！体温高于 38.5℃，还剧烈咳嗽呼吸困难，可能是肺炎，咳嗽不厉害就可能是流感。实际情形当然要比这复杂。但原理就是根据观察的症状逐项排除，通过分类找到病因。

这时候门诊新来了实习医生小丽，要在最短时间内学会主任医生的诊断方法。主任医生忙得根本没时间教她，就扔给她一沓过去病人的病历和诊断结果，自己琢磨去！小丽看着几十个病人的各项指标和诊断结果，不知道从哪里下手。这时候刚学了决策树的主治医生小张路过说：我来帮你。咱先随便猜一个主任的判断逻辑，比如先看是否咳嗽，再看是否发烧。把这些病例用这个逻辑推演一遍，如果逻辑的判断结果和主任的诊断结果吻合，咱就算猜中了。如果不吻合，咱就换个逻辑，无非是换些判断准则，比如你可能一开始把体温标准定在了 37.5℃，结果把很多普通感冒给判断成流感了。当你用 39℃ 时，又会把流感判断成普通感冒。几次试验你就找到了 38.5℃ 这个最好的值。最后你找到的逻辑对所有病例的判断都和主任医生的诊断完全吻合。

所以决策树学习就是先找到一个决策树，它对已知数据的分类和已知结果最接近。好的分类模型是每一步都能让下一步的「混杂度」最小。在实际的机器学习中，决策树不是猜出来而是算出来的。通过计算和比较每种分类的混杂度的降低程度，找到每一步都最大限度降低混杂度的过程，就是这个决策树机器学习的过程。所以机器学习决策树的原理是：根据已知结果可以反推出事物间的逻辑关系，再用这些逻辑关系预测新的结果。

在这个例子里的「知识」就是医生的诊断方法，作为明知识被清晰表达为决策逻辑树。而这种计算和比较分类混杂度的方法就是让机器自动学习医生诊断知识的方法。

#### 2.1.2 贝叶斯学派 —— 机器从结果推出原因的概率

符号学派认为有因必有果，有果必有因。贝叶斯学派问，因发生果一定发生吗？感冒是发烧的原因之一，但感冒不一定都发烧。贝叶斯学派承认因果，但认为因果之间的联系是不确定的，只是一个概率。

我们的经验中比较熟悉的是当一个原因发生时结果出现的概率，例如你感冒后会发烧的概率，但我们的直觉不太会把握逆概率，即知道结果要求推出原因的概率，也就是要判断发烧是感冒引起的概率。贝叶斯定理就是教我们怎么算这样的概率。

举个例子，某人去医院检查身体时发现艾滋病病毒呈阳性，现在告诉你一个艾滋病人检查结果呈阳性的概率是 99%，也就是只要你是艾滋病人，检查结果基本都是阳性。还告诉你，人群中艾滋病患者大约是 0.3%，但所有人中查出阳性的人有 2%。现在问得艾滋病的概率多大？你的直觉反应可能是，要出大事了！现在我们看看贝叶斯定理怎么说。贝叶斯定理如下：

```
P（得艾滋病|检查呈阳性）= P（得艾滋病）× P（检查呈阳性|得艾滋病）/ P（检查呈阳性）= 99%×0.3%/2% = 14.85%
```

也就是说即使他检查呈阳性，他得病的概率也不到 15%！这个结果非常违反直觉。原因在哪里呢？在于人群中查呈阳性的概率远大于人群中得艾滋病的概率。这主要是由于检测手段不准确，会「冤枉」很多好人。

所以以后不管谁查出了什么病呈阳性，你要问的第一件事是检查呈阳性和得病的比率有多大，这个比率越大就可以越淡定。所以贝叶斯定理告诉我们的基本道理是：一个结果可能由很多原因造成，要知道一个结果是由哪个原因造成的，一定要先知道这个原因在所有原因中的占比。

1『上面对贝叶斯定律的解释，是目前看到的最通俗易懂的。（2021-07-28）』

一个好的医生知道，要判断病人是否感冒，只看是否发烧这一个症状不够，还要看是否有咳嗽、嗓子痛、流鼻涕、头痛等症状。也就是我们要知道 P（感冒|发烧、咳嗽、嗓子痛、流鼻涕、头痛……）。贝叶斯定理告诉我们计算上面的概率可以通过计算 P（发烧、咳嗽、嗓子痛、头痛……|感冒）获得。

为了简化计算，我们这里假设发烧、咳嗽、嗓子痛、头痛这些症状都是独立的，互相不是原因（很显然这个假设不完全对，很可能嗓子疼是咳嗽引起的），这样：

```
P（发烧、咳嗽、嗓子痛、头痛……|感冒）= P（发烧|感冒）× P（咳嗽|感冒）× P（嗓子痛|感冒）× P（头痛|感冒）×……
```

这里每一个概率都比较容易得到。这在机器学习里叫作「朴素贝叶斯分类器」。这个分类器广泛应用于垃圾邮件的过滤。我们知道垃圾邮件往往会有「免费、中奖、伟哥、发财」这类词汇，这类词汇就相当于感冒会出现的症状，垃圾邮件就相当于感冒。过滤垃圾邮件变成了判断在出现这些词汇的情况下这封邮件是垃圾邮件的概率，也就是通过统计 P（出现「免费」| 垃圾邮件），P（出现「中奖」| 垃圾邮件）等的概率，来算出 P（垃圾邮件|出现「免费、中奖、伟哥、发财」……）的概率。

同样的原理还被广泛应用在语音识别上。一个单词有各种各样的发音，语音识别就是听到一个发音判断是某个单词的概率。如果我们把「吃饭」这个词的天南地北男女老少的发音都收集起来，统计出「吃饭」这个词和各种发音的频次，我们听到一个发音「洽碗」时，就可以判断是否在说「吃饭」。为什么说贝叶斯朴素分类器是机器学习呢？因为它是通过采集大量数据统计出每个单词和它们分别对应的发音的频率来判断一个发音是什么单词的。这些数据越多，判断的准确性就越高。

在这个例子里，「知识」是知道当一个结果发生时是哪个原因造成的。这个知识被清晰地表达为一个条件概率。机器通过统计每种原因的占比来算出从结果到原因的概率。

### 2.2 类推学派 —— 机器学习默知识

我们生活中很多经验来自类比。医生一看病人的面部表情和走路姿势就基本能判断出是普通感冒还是流感，因为流感症状比感冒厉害得多。科学上的许多重要发现也是通过类比。当达尔文读到马尔萨斯（Malthus，1766-1834）的《人口论》（Principle of Population）时，被人类社会和自然界的激烈竞争的相似性所触动；玻尔的电子轨道模型直接借鉴了太阳系的模型。

机器学习中用类比方法的这一派叫类推学派，他们的逻辑很简单：第一，两个东西的某些属性相同，它俩就是类似的；第二，如果它们的已知属性相同，那么它们的未知属性也会相同。开好车上班的人可能也会用苹果手机，喜欢看《星球大战》（Star Wars）的人可能也会喜欢看《三体》等。类比的逻辑可以明确表达，但具体的类比常常是默知识。例如老警察一眼就能看出谁是小偷，但不一定说得清楚原因。

在类推学派中最基础的算法叫最近邻法。最近邻法的第一次应用是 1894 年伦敦暴发霍乱，在伦敦的某些城区每 8 个人就会死 1 个，当时的理论是这种疾病是由一种「不良气体」造成的。但这个理论对控制疾病没有用。内科医生约翰·斯诺把伦敦每个霍乱病例都标在地图上，他发现所有的病例都靠近一个公共水泵。最后推断病因是这个水泵的水源污染，当他说服大家不要再用这个水泵的水后，疾病就得到了控制。在这里这些数据的相似点就是和这个水泵的距离。最近邻法还有一个应用就是在网上搜照片，你对高铁上霸座的人很愤慨，你把他的照片上传，网站给你显示出几张和他长得最像的照片，并且有文字，你一看，天哪，还是个在读博士生！同样的道理，很多智能手机都可以自动进行照片分类，把你手机里的人像都自动归类。

在类推学派中，第一件事是要定义「相似度」。相似度可以是身高、收入等连续变量，也可以是买了某一类书的次数的统计变量，也可以是性别这样的离散变量。总之，只有定义了相似度，才能度量一个分类方法是否最优。人可以感受相似度，但无论是人的感官还是大脑都无法量化相似度。人类在做相似度比较时，甚至都不知道自己在比较哪些特征和属性，但机器可以很容易量化这些相似度。所以只要机器抓准了特征和属性，比人的判断还准。

类推算法可以用于跨领域的学习。一个消费品公司的高管到互联网媒体公司不需要从头学起，华尔街雇用很多物理学家来研究交易模型，是因为这些不同领域问题的内在数学结构是类似的。类推算法最重要的是能用类比推导出新知识，就像我们前面提到的达尔文受《人口论》的启发。

虽然机器可以学习明知识和默知识，但它最大的本事是学习暗知识。

### 2.3 机器发现暗知识

暗知识就是那些既无法被人类感受又不能表达出来的知识。也就是说人类本身无法理解和掌握这些知识，但机器却可以。机器有两种方法可以掌握这些知识：模仿人脑和模仿演化。

#### 2.3.1 联结学派

联结学派的基本思路就是模仿人脑神经元的工作原理：人类对所有模式的识别和记忆建立在神经元不同的连接组合方式上。或者说一个模式对应着一种神经元的连接组合。联结学派就是目前最火爆的神经网络和深度学习，它在五大学派中占绝对统治地位。目前人工智能的高科技公司中绝大部分是以神经网络为主。第三章我们专门讨论神经网络。

#### 2.3.2 进化学派

机器学习中一共有五大学派，最后一个学派是进化学派。他们是激进主义经验派，是彻底的不可知论者。进化学派不仅觉得因果关系是先验模型，甚至觉得类比，神经元连接也都是先入为主的模型。他们认为不管选择什么样的先验模型，都是在上帝面前耍人类的小聪明，世界太复杂，没法找到模型。进化学派的基本思路是模仿自然界的演化：随机的基因变异被环境选择，适者生存。他们的做法就是把一种算法表达成像基因一样的字符串，让不同的算法基因交配，让生出来的儿女算法去处理问题，比爸妈好的留下来配种继续生孙子，比爸妈差的就淘汰。

比如我们要通过进化算法找到最优的垃圾邮件过滤算法。我们先假设凡是垃圾邮件都包含 1 000 个诸如「免费」「中奖」「不转不是中国人」这样的单词或句子。对于每个单词我们可以对邮件施加一些规则，如删除或者怀疑（「怀疑」是进一步看有没有其他垃圾词汇）等。如果规则就这两种，我们可以用一个比特表示：1 删除，0 怀疑。这样要对付有 1 000 个垃圾词的算法就可以表示成 1 000 比特的一个字符串。这个字符串就相当于一个算法的基因。如果我们从一堆随机的 1 000 比特长的字符串开始，测量每个字符串代表的算法的适应度，也即它们过滤垃圾邮件的有效性。把那些表现最好的字符串留下来互相「交配」，产生第二代字符串，继续测试，如此循环，直到一代和下一代的适应度没有进步为止。注意，这里和生物的进化有个本质区别，就是所有的算法都是「长生不老」的。所以老一代里的优秀算法不仅可以和同代的算法竞争，而且可以和儿子、孙子、子子孙孙互相竞争，最后的胜利者不一定都是同一代的算法。

进化算法的问题是「进化」毫无方向感，完全是瞎蒙。在前面的垃圾邮件过滤器例子里，1 000 比特的字符串的所有可能性是 21000，也即 10300，即使用目前世界最快的超级计算机，「进化」到地球爆炸都不可能穷尽所有可能，在有限时间内能探索的空间只是所有可能空间的极少一部分。地球可是用了 40 亿年时间才进化出了现在所有的生物。

图2.1 是美国华盛顿大学佩德罗·多明戈斯（Pedro Domingos）教授总结的一张五大流派「八卦图」。

机器学习中的符号学派、贝叶斯学派、类推学派和联结学派的共同点是根据一些已经发生的事件或结果，建立一个预测模型，反复调整参数使该模型可以拟合已有数据，然后用此模型预测新的事件。不同的是它们各自背后的先验世界模型。符号学派相信事物间都有严密的因果关系，可以用逻辑推导出来；贝叶斯学派认为，因发生，果不一定发生，而是以某个概率发生；类推学派认为，这个世界也许根本没有原因，我们只能观测到结果的相似，如果一只鸟走路像鸭子，叫起来像鸭子，那么它就是只鸭子；联结学派认为，相似只是相关性能被人理解的那层表皮，隐藏的相关性深邃得无法用语言和逻辑表达；最后进化学派认为，什么因果？什么相关？我的世界模型就是没有模型！从零开始，不断试错，问题总能解决！

图 2.1 机器学习的五大流派

图片来源：佩德罗·多明戈斯，《终极算法》，中信出版社，2017 年。

2『已下载书籍「2019716终极算法」。（2021-07-28）』

现在我们终于可以清理一下满天飞的名词了。我们在媒体上最常听到的是这四个名词：人工智能、机器学习、神经网络、深度学习。这四个词的关系如图 2.2 所示，人工智能是最大的一个圆，圆里面分为两部分：一部分叫人工学习，也就是前面我们讲的专家系统；另一部分叫机器学习，就是机器自己学习。机器学习里面包含神经网络，在神经网络里面还要再分，一个是浅度学习，一个是深度学习。在过去芯片集成度低时，我们只能模仿很少的神经元。现在由于集成度在提高，我们可以模仿很多的神经元，当很多神经元被组成多层的网络时，我们就叫它深度学习。所以人工智能、机器学习、神经网络和深度学习的关系，其实就像一个洋葱一样，一层包裹一层，最外面的是人工智能，往里一点是机器学习，再往里是神经网络，最深层就是深度学习。

2『人工智能、机器学习、神经网络、深度学习，这四个概念的关系，做一张任意卡片。（2021-07-28）』—— 已完成

所以这四个词有下面的包含关系：人工智能 > 机器学习 > 神经网络 > 深度学习。

图2.2 AI 中四个概念的包含关系

今天我们说到的人工智能，其实就是机器学习里面的神经网络和深度学习。但是在一般的商业讨论中，这四个概念经常是混着用的。

## 0301. 神经网络 —— 萃取隐蔽相关性

### 00. 导读

在了解了机器学习各个流派的方法后，本书的主角「神经网络」现在闪亮登场。本章将深入介绍神经网络学习的原理和在商业上应用最多的几种形态，以及它们的适用范围。有了这些基础，我们才可以真正理解 AlphaGo Zero 是怎样发现神迹般的暗知识的。对于只想了解 AI 商业前景的读者，也可以先跳过这一章，读完后面描述机器学习神奇应用的章节后再回来弄懂它是如何工作的。

### 3.1 从感知器到多层神经网络

1943 年，心理学家沃伦·麦卡洛克（Warren McCulloch）和数理逻辑学家沃尔特·皮茨（Walter Pitts）提出并给出了人工神经网络的概念及人工神经元的数学模型，从而开了人类神经网络研究的先河。世界上第一个人工神经元叫作 TLU（Threshold Linear Unit，即阈值逻辑单元或线性阈值单元）。最初的模型非常简单，只有几个输入端和输出端，对权值的设置和对阈值的调整都较为简单。

1957 年，一个开创性的人工神经网络在康奈尔航空实验室诞生了，它的名字叫作感知器（Perceptron），由弗兰克·罗森布莱特（Frank Rosenblatt）提出，这也是首次用电子线路来模仿神经元。他的想法很简单，如图 3.1 所示：将其他电子神经元的几个输入按照相应的权重加在一起，如果它们的和大于一个事先给定的值，输出就打开，让电流通向下一个神经元；如果小于这个事先给定的值，输出就关闭，没有电流流向下一个神经元。

1960 年，斯坦福大学教授伯纳德·威德罗（Bernard Widrow）和他的第一个博士生马尔西安·泰德·霍夫（Marcian Ted Hoff）提出了自适应线性神经元（ADaptive LInear NEurons，ADLINE）。他们第一次提出了一种可以自动更新神经元系数的方法（机器自我学习的原始起点）：用输出误差的最小均方去自动迭代更新神经元权重系数，直至输出信号和目标值的误差达到最小。这样就实现了权重系数可以自动连续调节的神经元。自适应线性神经元最重要的贡献是第一个使用输出信号和目标值的误差自动反馈来调整权值，这也为后面神经网络发展历史上里程碑式的反向传播算法奠定了基础。

图 3.1 感知器的电子线路

这个单层的神经网络也被称为自适应信号处理器，被广泛应用在通信和雷达当中。霍夫后来加入英特尔，在 1971 年设计了世界上第一个微处理器 Intel 4004。威德罗教授也是笔者 20 世纪 80 年代后期在斯坦福大学的博士生导师。笔者曾经在他的指导下做过神经网络的研究工作。图 3.2 是笔者 2016 年和他讨论神经网络未来发展时的合影，笔者手中拿的那个黑盒子就是他 1960 年做出的 ADLINE 单层神经网络。这个盒子到今天还在工作，美国国家博物馆曾经想要这个盒子做展品，但威德罗教授回答说「我还要用它来教学」。

图 3.2 笔者和自己当年斯坦福大学的博士导师，神经网络鼻祖之一威德罗教授的合影

威德罗教授在 1962 年还提出过一个三层的神经网络（Multi-Layer Adaptive Linear Neurons，MADALINE），但没有找到一个能够用于任意多层网络的、简洁的更新权重系数的方法。由于单层网络有广泛应用而多层网络的运算速度太慢（当时的电脑运算速度是今天的 100 亿分之一），所以在 MADALINE 之后没有人去继续深入探讨多层网络。

由于缺少对人脑工作模式的了解，神经网络的进展一度较为缓慢，而它进入快速发展期的一个触发点则是医学领域的一个发现。1981 年，诺贝尔生理学或医学奖颁发给了美国神经生物学家大卫·胡贝尔（David Hubel）、托尔斯滕·威塞尔（Torsten Wiesel）和罗杰·斯佩里（Roger Sperry）。前两位的主要贡献是发现了人类视觉系统的信息处理采用分级方式，即在人类的大脑皮质上有多个视觉功能区域，从低级至高级分别标定为 V1~V5 等区域，低级区域的输出作为高级区域的输入。人类的视觉系统从视网膜（Retina）出发，经过低级的 V1 区提取边缘特征，到 V2 区的基本形状或目标的局部，再到高层 V4 的整个目标（例如判定为一张人脸），以及到更高层进行分类判断等。也就是说高层的特征是低层特征的组合，从低层到高层的特征表达越来越抽象和概念化。至此，人们了解到大脑是一个多层深度架构，其认知过程也是连续的。

神经网络学习的本质是大量神经元通过复杂的连接形成记忆。因为分析简单且容易用电子元件实现，一开始人工神经网络就如图 3.3 那样由一层一层组成。其实人脑的神经元连接非常复杂，没有这么一层一层的清晰和有秩序。但我们目前并没有弄清楚人脑神经元的连接方式，先从简单的假设入手是科学的一般方法。

图 3.3 一个多层神经网络（其中每个方块代表一个神经元）

20 世纪 80 年代，神经网络的另一个重大突破是当时在加利福尼亚州大学圣迭戈校区任教的美国心理学家大卫·鲁梅哈特（David Rumelhart）和在卡内基梅隆大学任教的计算科学家杰弗里·辛顿（Jeffrey Hinton）提出的多层神经网络，以及一个普遍的自动更新权重系数的方法。

前面说过，威德罗教授在 1962 年提出过一个三层的神经网络，但功亏一篑，没有找到一个简洁的任意多层网络权重系数的更新方法。这个问题在 1986 年被鲁梅哈特和辛顿解决了。他们借鉴了单层神经网络中威德罗 - 霍夫（Widrow-Hoff）反馈算法的思路，同样用输出误差的均方值一层一层递进地反馈到各层神经网络去更新系数。这个算法就是今天几乎所有神经网络都在用的「反向传播」算法。「反向传播」听上去很「高大上」，实际上就是在自动控制和系统理论里面多年一直在用的「反馈」，只不过在多层网络中反馈是一层一层递进的。因为一个多层的神经网络要通过成千上万次「用输出误差反馈调整系数」，所以运算量非常大。在 20 世纪 80 年代的计算能力限制下，神经网络的规模非常小（例如三层，每层几十个神经元）。这种小规模的神经网络虽然显示了神奇的能力（例如能够识别 0~9 一共 10 个手写体数字），但仍然无法找到真正的商用。

从第一个电子神经元感知器的发明（1957 年）到神经网络的大规模应用（2012 年）整整经历了 55 年的艰辛探索，许多天才科学家不顾嘲讽和失败，坚信这条路是对的。图 3.4 是在这个探索旅程中做出重大贡献的科学家。

图 3.4 1940-2010 年基于神经网络的 AI 发展史上做出突破性贡献的科学家

图片来源：https://beamandrew.github.io/deeplearning/2017/02/23/deep_learning_101_part1.html。

### 3.2 神经网络模型：满是旋钮的黑盒子

在这一节中，我们用最简单的方法介绍机器学习的机理。像图 3.3 这样一个多层神经网络的左端是输入端，即要识别的信息从这里输入。例如要识别一幅图像，每个输入 Xi 就是这张图像的一个像素的灰度值（为了简单起见我们假设图像是黑白的，如果是彩色的，我们可以想象三个这样的网络重叠起来用）。从输入层的每个神经元到下一层的每个神经元都有一个连接，从输入层的第 i 个神经元到下一层第 j 个神经元的连接有一个乘法因子 Wij。每一层到下一层都类似。在输出端，每根线对应一个识别出来的物体。我们可以把每个输出想象成一个灯泡。当机器发现输入是某个物体时，对应该物体的灯泡就在所有输出灯泡里最亮。

像这样一个多层次的神经网络是如何「学习」的呢？我们可以把这个多层网络看成一个黑盒子。盒子外面有许多可以调节的旋钮，如图 3.5 所示。

图 3.5 机器学习：调节黑盒子外的旋钮

我们的第一个任务是训练这个黑盒子能够识别图像中的物体。例如在图 3.5 中，输入端有两张图，一张汽车图片和一张猫的图片。我们训练的目的是只要输入各种汽车的图片，机器就能告诉我们「这张图是汽车」（对应「汽车」这个物体的输出端的灯泡最亮）。同样，只要我们输入猫的图片，机器就告诉我们「这张图是猫」（对应「猫」的灯泡最亮）。

训练的过程是这样的：我们先指定输出的一个灯泡最亮对应于识别出了汽车，第二个灯泡最亮对应猫，等等。我们先找到足够多的汽车图片（例如 1 万张，训练图片越多，训练出的机器判断越准确），一张一张给机器「看」（实际训练是一组一组地给机器看）。在机器没有训练好时，当我们输入一张汽车图片时，输出的灯泡会乱亮。我们此时耐心地调节那些旋钮直到只有对应「汽车」的灯泡亮为止。然后我们输入下一张汽车图片，也调到只有对应汽车的灯泡亮为止，如此一直到 1 万张。然后我们再输入第一张猫的图片，调节旋钮直到对应「猫」的灯泡亮为止，也如此一直到 1 万张猫的图片都输入完为止。如果我们让机器学习 1 000 种物体的图片，那我们对每种物体图片都要如此操作，让输出端对应这种物体的灯泡最亮。所以在机器学习中，「训练」是最耗时的。在训练过程中，这些训练用的图片我们事先知道是什么内容，或者叫作「标注」过的图片。当训练结束后，第二步是测试。也就是拿一些不在训练集里面的图片让机器辨认，如果机器都能辨认出来，这部机器就算训练好了，可以交付使用了。一旦训练测试结束，机器的参数集就不改变了，也就是所有的旋钮都固定不动了。只要是输入训练过的种类，机器都应该能识别出来。

如果一部机器要识别 1 000 种物体的图片，就要至少有 1 000 个输出端（每个输出端对应一种物体）。假设图片分辨率是 100×100=10 000 像素（很低的分辨率），如果这部机器只有三层神经网络（深度最浅的「深度」学习网络），输入端和中间层之间，中间层和输出之间的连接就有 10 000×10 000+10 000×1 000=1.1 亿个。也就是这部机器有 1 亿多个旋钮。截至 2017 年，最大的神经网络已经号称有上万亿的参数，即上万亿个旋钮。这么多旋钮显然无法用人工去调节。

### 3.3 雾里下山：训练机器模型

幸运的是数学上 200 年前就有了「自动」调节旋钮的办法。这个办法叫作「最陡梯度法」，或者通俗地叫作「雾里下山法」。当我们训练一个机器学习模型时，我们事先知道每一张图片是什么物体（汽车、猫等已经标注的图片），我们输入汽车图片时，要求只有对应「汽车」的那个灯泡最亮。在我们调节旋钮之前，灯泡的亮和灭都是混乱的，和我们的要求有很大误差。这些误差是由旋钮的值决定的。如果把这些误差画成一幅图像，就像图 3.6 一样有很多山峰，误差就是山峰的高度，图像的横轴和纵轴就是旋钮的值。

图 3.6 用「最陡梯度法」寻找误差最小的「山谷」

图片来源：维基百科。

当我们输入第一张图片时，我们可能站在一个随机的位置，例如某一座山峰的山顶或半山腰，我们的任务就是走到最低的一个谷底（误差最小）。我们此时相当于在大雾中被困在山里只能看见眼前的山坡，一个最笨的办法就是「最陡下降法」：站在原地转一圈，找到一个最陡的下山方向往这个方向走一步。在这个新的位置上，再转一圈找到最陡的下山方向再走一步，如此循环，一直走到山脚为止。

在「最陡下降法」中每次转圈找最陡下山方向相当于用误差函数的偏微分方程求梯度。简单地讲，旋钮的每一步的调节值是可以算出来的。这样我们根据输出的误差一步一步地算出旋钮的调节值，直到满意为止。这种根据误差回头调节旋钮的方法也叫「反向传播算法」，意思是用输出误差一层一层地从输出端向输入端把各层的权重系数算出来。

### 3.4 AlphaGo 的「上帝视角」

有了上面的基础，我们现在就可以理解为什么 AlphaGo 这么厉害。围棋棋盘有 19×19=361 个交叉点，每个交叉点可以二选一：白子或黑子。这样所有的摆法就是 $2^{361}$，或者 $10^{108}$。人类 2 000 年来一共保留下来的围棋残局中盘大约 3 000 万个。人类下过的棋局相当于大海里的一滴水（即使剔除那些明显没有意义的摆法）。一位棋手即使每天下 2 盘棋，50 年内天天下，一生也只能下 36 500 盘棋。图 3.7 是一张「雾里下山」的示意图。下棋的终极目标相当于在群山中找到最低的谷底（对应于最理想的走法）。如果所有可能的走法是绵延几千里的群山，人类棋手 2 000 年来就相当于一直在同一个小山坳里面打转转。第一位棋手偶然的棋路会影响他的徒弟，以后的徒子徒孙都始终在这个小山坳附近徘徊。而机器学习像个「神行太保」，以比人快百万倍的速度迅速扫遍群山，很快就能找到一个远离人类徘徊了 2 000 年的更低的山谷（可能还不是绝对最低，但比人类徘徊处低）。这也是连棋圣聂卫平都连呼「看不懂」AlphaGo 棋路的原因。（见图 3.7）

图 3.7 机器学习可以迅速扫过群山找到最低处

这个原理可以用于解决许多类似的问题。这类问题的特点是变量非常多，可能解是天文数字，例如经济和社会决策、军事行动策划等。

### 3.5 局部最优：没到山底怎么办

「雾里下山法」会遇到一个问题，就是会走进一个不是最低的谷底而且再也走不出来了。用一维函数能清楚地看到这个问题。图 3.8 是有两个「谷底」：A 点和 B 点的一维函数。当下山走到 A 点时，只要每次的步伐不是特别大，不论往左还是往右再移动，总是会回到 A 点。这在数学上叫「局部最小值」，而 B 点才是「全局最小值」。

图 3.8 有两个谷底的一维函数

但是如果我们从一维扩展到二维，就有可能从一个「局部最小值」中逃逸。在图 3.9 中，假设函数 1 是一个沿 X 轴切下去的一维函数，A 点就是函数 1 的一个「局部最小值」。如果一个小珠子只能沿着 X 轴滚动，就会陷在 A 点出不来。但在图中的二维曲面上，小珠子只要沿着 Y 轴方向挪动一点，就到了 C 点，而从这个 C 点出发就能到达整个曲面的「全局最小值」B 点。当误差函数的维数增加时，这种从「局部最小值」逃逸的机会就会增大。我们无法画出三维以上的图像，但我们可以想象每个「局部最小值」附近都有许多「虫洞」可以方便逃逸。维数越高，这种虫洞就越密集，就越不容易陷在一个「局部最小值」里。

图 3.9 从一维空间扩展到二维空间，误差函数找到「全局最小值」的概率增大

如果图 3.9 不够直观，我们可以用一个数字阵列来表达。首先假设地形是一个一维函数，每个数字表示它的海拔高度。在图 3.10 中，有两个最小的海拔高度 0 和 5，但是无论从哪一边开始下山，每走一步的话，都会被困在高度 5 这个「局部最小值」里出不来，无法走到「绝对最小值」0。

图 3.10 地形函数的数字阵列

但是，如果将这个地形叠加为二维函数，仍然用数字表示海拔高度，我们可以看到，无论从哪一边开始下山，每走一步，当在一维函数中走到「局部最小值」5 以后，在另外一个维度的函数中，则可以继续走到更低的海拔，直到到达「全局最小值」0。同样地，维度越多，在某一个维度到达「局部最小值」后，可以选择的其他维度和路径就越多，因此被困在「局部最小值」的概率就越低。（见图 3.11）

图 3.11 将地形叠加为二维函数

### 3.6 深度学习 —— 化繁为简

为什么深度学习有许多层神经元？这是因为世界上许多信息和知识是可以通过分层表达的。例如人脸是很复杂的一幅图像，但人脸可以先分解成五官，五官的复杂程度就比人脸低了，五官又可以进一步分解为线条。深度学习就是用一层神经元去识别一个层级的信息。在图 3.12 中，左图是第一层网络来识别人脸上的线条，中间的图是第二层网络在识别出线条的基础上识别出器官，右图是第三层网络在识别出器官的基础上识别出长相。同样一个时间序列的信息，例如语音也可以分解为递进的层级：句子、单词、音节等。分层的最大好处是大大降低计算量，把原来的 N 次计算变为 m×logN 次计算，这里 m 是层数。

除了将要处理的信息表达为层级以外，另外一种降低计算量的方法是将「一大块」信息分解为许多小块来处理。例如想要在一张像素很大的图片中识别出一个小三角形，我们只需拿着这个小三角形的模板在大图中滑动比较即可。例如一张图的像素是 1 000×1 000=1 000 000，如果拿一个 1 000×1 000 像素的模板去比较，计算量大约是 1 000 000×1 000 000。如果这个三角形的大小是 10×10，我们用 10×10「模板滑动法」，计算量只要 10×10×1 000 000，是原来的万分之一。

图 3.12 深度学习神经网络学习得到的不同层次的特征

图片来源：维基百科。

机器要处理的信息有些是空间信息，例如图片，有些是时间信息，例如语音。针对不同的信息，神经网络的结构不同。最常见的有两种，第一种是处理空间信息的卷积神经网络（Convolutional Neural Network，CNN），第二种是处理时间信息的循环神经网络（Recurrent Neural Network，RNN）。下面我们一一介绍。

### 3.7 化整为零的卷积神经网络

「卷积」这个词什么意思待会咱们再讲，但现在可以告诉你的是，目前人工智能和机器学习制造的奇迹，从下围棋到自动驾驶再到人脸识别，背后全是卷积神经网络。能知道卷积神经网络的工作原理，你就和周围大部分读了几本人工智能的书的人不是一个档次了。虽然大部分人不会从事人工智能的专业工作，但卷积神经网络解决问题的思路会让我们拍案叫绝。第一个提出卷积神经网络的是前面说的神经网络教父杰弗里·辛顿教授的博士后学生，一位叫岩拉孔（Yan LeCun）的法国人，现在任 Facebook（脸书）人工智能研究所主任，和辛顿同为神经网络四大天王之一。

#### 3.7.1 降低运算量就是降低成本

神经网络每一层的每一个神经元都和后面一层的每一个神经元相连接。如果第一层有 1 万个神经元，第二层也有 1 万个，这两层之间的连接就有 1 亿个。如果像微软那个一举超过人脸识别图像能力的 ResNet（深度残差网络）有 152 层，这些连接就有 151 亿个。也就是说我们要调整的黑盒子上有 151 亿个旋钮。为了识别 10 种动物，要给训练机器看 10 万张动物图片，一张图片就要算 151 亿次乘法和加法，10 万张至少是 1 500 万亿次运算。这才是识别 10 种动物的训练运算量，如果要训练识别 1 万种动物呢？用今天的最快的 CPU（电脑中央处理器）或 GPU（图形处理器），也要算几个月甚至几年。对计算量要求更大的是识别，识别一张图片要算 150 亿次不难，但 Facebook 上每天上传的何止几亿张照片？降低运算量就意味着降低成本。

降低运算量的第一招就是把问题分类，如果只处理某一类问题，针对这些问题的共同特点，就有可能简化算法。我们知道，人从外界获得的信息 90% 以上是视觉信息，视觉信息主要是图像，视频也可以分解成快速闪过的图像。那图像有什么特点呢？

一幅图像的信息量很大，但不管是风景还是人物，画面上总有大部分区域没有什么变化，像天空。引起你注意的东西往往都是一小块，例如人的眼睛、天空中的鸟、地上的花。这个叫作图像中信息的局域性。

图像的第二个特点是可以分解为更简单的元素，例如风景分解为天空、大地、植物、动物，人物分解为五官。卷积神经网络就是利用图像的以上两个特点进行了大幅度的运算简化。

以人脸识别为例，要识别一个人，先要抓住他的特征，比如浓眉大眼高鼻梁。第一步就是把五官找出来。其实警察抓犯罪嫌疑人早就用了这一招。警察局的画师会问目击者犯罪嫌疑人的性别、年龄、身高、种族等，然后问目击者犯罪嫌疑人的五官长什么样，目击者能描述的五官种类非常有限，大眼睛、小眼睛，最多加个单眼皮、双眼皮、高鼻梁、塌鼻梁，根据目击者的描述画师画出一幅人脸，然后目击者再说眼角朝下，没这么大，画师再不断改，直到目击者觉得和记忆基本相符。人脸那么复杂根本无法用语言描绘，但如果变成五官的组合描绘起来就简单多了。假设每个五官都能分 10 种，就能组合出 1 万种脸来，再加上年龄、性别、种族就能组合出几十万张脸，这样把从 70 亿人中找一张脸的任务就分解成了从 10 种眼睛中找出一种眼睛，再从 10 种鼻子中找出一种鼻子这样简单得多的任务。

#### 3.7.2 卷积神经网络是怎样工作的

卷积神经网络就是用的警察局这一招。假如我们现在要从分布在北京大街小巷的摄像头的视频中发现 100 个重要的犯罪嫌疑人，第一步是用这些犯罪嫌疑人的已有照片来训练机器。训练的第一步就是要从这些照片中提取五官的特征。因为五官在一张照片中只占一小块，那我们就做个找五官的小模板，专业术语叫滤波器，用这个小模板在要处理的图像上从左扫到右，从上扫到下，看看能否发现眼睛，另外一个小模板负责发现鼻子等。

什么叫「发现鼻子」？就是负责发现鼻子的小模板是一张像鼻子的图案，这个图案扫到鼻子处时重合度最大。什么叫提取特征？就是一开始这个鼻子图案是个随机图案，像是随手那么一画，扫一遍下来发现没有什么重合度，那就变一变这个图案，最后变得和犯罪嫌疑人的鼻子很像时，重合度就会最大。等负责找出鼻子、眼睛、嘴巴等的模板图案都和犯罪嫌疑人的吻合后就算训练成功了。以后你输入一张照片，机器就可以飞速地告诉你这个是不是犯罪嫌疑人。

在机器学习中，是机器自己寻找特征。一开始机器并不知道要找哪些特征。所以这些小模板并不知道它们要找鼻子或眼睛。这些小模板从开始的一个随机图形到最后一定会演变成五官吗？答案是如果五官是人脸上最重要的特征，这些小模板到最后一定会演变成五官。但神奇的是机器还能发现我们人类都没注意到的人脸上的重要特征。假如我们多加一个小模板变成六个，这六个中会有五个各自对应一个器官，还有一个就会找到一个新的特征，如两眼之间的距离，或者口鼻之间的距离，等等。所以小模板越多，抓到的特征就越多，识别就越准确。

现在你要问，这个小模板发现鼻子和前面讲的神经网络黑盒子的调旋钮是什么关系？其实这个小模板就是一组旋钮，一个有 5×5=25 个像素的小模板就相当于 25 个旋钮，每个像素的颜色浓度对应着一个旋钮的某个位置，调旋钮就是让小模板里的图案越来越像犯罪嫌疑人的鼻子。我们之前讲过，这个「调旋钮」不是人工调的，是算出来的。

现在我们可以看看到底省了多少计算量，如果一张图片是 1 024×1 024≈100 万像素，每个像素对应一个接收神经元，每层有 100 万个神经元，这样一个全连接的神经网络每一层要有 100 万 ×100 万 = 1 万亿次计算。现在只要五个小模板，每个负责找到五官中的一个。每个小模板把图片上下左右扫一遍的计算量是 5×5×100 万 = 2 500 万次，5 个模板就是 1.25 亿次。计算量变成了原来的万分之一！

我现在可以告诉你什么叫「卷积」，上面说的小模板把图片上下左右横扫一遍发现重合度的过程就叫卷积。你看这个唬人的黑科技名词其实就是这么简单的一回事。

上面是对卷积神经网络的基本原理的一个通俗解释。对于想更深入了解的读者可以看附录 1 中一个典型卷积网络的精确描述。从附录 1 中可以看出卷积神经网络不仅是一个高阶的非线性网络，也是一个无法用方程式表达的函数。给定一个训练数据集，最后这些数据之间的相关性都会凝结在网络参数里。或者说神经网络是数据相关性的「萃取器」。但萃取了哪些相关性？为什么萃取这些相关性则是人们未必能理解的。比如人脸识别，机器抓取的用于识别的人脸特征可能是人类不熟悉的那些特征，甚至完全没有意识到的特征。对于那些人类感官无法感受的复杂数据集，比如一个核电厂成千上万个子系统产生的数据以及它们之间的相关性，那更是人类完全无法理解的。

#### 3.7.3 卷积神经网络能做哪些事

首先，几乎所有的图像类的处理，如图像分类、人脸识别、X 光读片，都适合用卷积神经网络。图像分类最著名的大赛就是斯坦福大学李飞飞教授创办的 ImageNet（计算机视觉系统识别项目，是目前世界上图像识别最大的数据库）大赛。这个大赛提供 1 000 种不同物体的几百万张图片让参赛者训练自己的模型，参赛时给大家一些新的图片让参赛者识别，看谁的识别准确率最高。2012 年辛顿的学生亚历克斯·克里捷夫斯基（Alex Krizhevsky）第一次用一个 5 层的卷积神经网络就把多年徘徊在 74% 的准确率一举提高到 84%，震惊了业界。到 2015 年微软的 152 层 ResNet 把准确率提高到了 96%，超过了人类的准确率 95%。从那以后进展就越来越小。有些公司组织大量的人力，采集更多的训练图片，尝试更多的小模板，更精心地微调那些旋钮，最后能达到比现有结果好 0.1%，然后就可以宣称自己是世界第一了。但这个世界第一意义不大，因为没有在网络结构上和算法上有任何创新，当时人家一个研究生 Alex 一举提高 10 个百分点，你扑上去几十上百人提高 0.1 个百分点，不算本事。对不懂卷积神经网络的投资人、股民、政府官员来说，这块「世界第一」的牌子还挺唬人的。但读到这里你以后就不会被忽悠了。

更有用的是通过识别一张图片中所有的物体，甚至发现物体之间的关系来「理解」这张图片。譬如机器看完一张图片后会说出来「蓝天白云下，一位戴草帽的年轻妈妈在草地上教孩子学走路，她们的小狮子狗在旁边卧着」。

X 光读片也是卷积神经网络一个很好的应用。假如要在胸片中发现早期肺癌，就需要拿大量已经确诊的早期肺癌片子来训练机器，这样训练好的机器就可以快速地发现肺癌。随着 X 光仪、CT 机等医疗成像设备的普及，有经验的读片医生非常稀缺。特别是在小城市、县城、乡村更缺乏这样的好医生。如果机器读片能够达到甚至超过北京、上海大医院有经验的医生，将是普惠医疗的一个巨大进展。我们在第六章会专门讲 AI 在医疗健康领域的应用，包括 X 光读片的现状和挑战。

卷积神经网络虽然应用很广，但它解决不了一些重要的问题，如股票预测和自然语言理解。下面我们就介绍可以解决这类问题的另一个很牛的网络。

### 3.8 处理序列信息的循环神经网络

#### 3.8.1 为什么需要循环神经网络

卷积神经网络可以处理图像分类和识别。图像信息处理的特点是一张图像的所有信息同时给你，而且下一张图像和上一张图像可以完全没有关系，就像是吃一盘饺子，先吃哪个后吃哪个都无所谓。但自然界还有另外一类信息和图像不同，信息的先后顺序很重要，不能前后颠倒，像自然语言、股票曲线、天气预报数据等。和图像信息的另一个不同之处在于这些信息是连续产生的，无法分成一块一块的，像一次喝进去一瓶啤酒，你无法清楚地分成几十「口」，你就是这么咕嘟咕嘟连着灌下去的。我们把图像这样不分先后的信息称为「空间信息」，把连续的、有先后顺序的称为「时间信息」或「序列信息」。卷积神经网络每次能处理的信息都是个固定的量，所以不适合处理连续发生的信息。

于是，一种不同的神经网络 —— 循环神经网络就应运而生了，它的结构比卷积神经网络还复杂。但循环网络背后的直觉和道理不难懂，其实掌握一门学科最重要的是理解背后的直觉，有些研究生、工程师可以背很多方程式，写很多程序，但对背后的直觉并不清晰，这就大大限制了他们的想象力和创造力。我们这本书的目的不是要把大家训练成工程师，而是通过弄懂背后的道理来对这个未来的大潮流有高屋建瓴的理解，从而产生全局性的把握。

在介绍循环神经网络之前，我们先看个例子。譬如我们在下面的句子里猜词填空：「我是广东人，会讲_____话。」在这里如果我们没有看到第一句「我是广东人」就很难填空。这就是一个典型的根据前面出现的信息对后面可能会出现的信息的预测。循环神经网络就特别适合处理这类问题。这个网络有两个特点，分别对应时间序列信息的两个特点：一是输入端可以接收连续的输入，二是可以记住信息的先后顺序。

#### 3.8.2 循环神经网络背后的直觉

现在我们看看循环神经网络如何做这样的预测。像其他神经网络一样，第一步是训练机器。我们先一句一句地训练，比如训练的第一句就是「我是上海人，会讲上海话」。一开始训练机器时，给机器一个「我」字，机器会乱预测，比如预测出下个字是介词「但」，可「我但」没意义。机器和训练样本一比知道自己错了，就去调黑盒子上的旋钮，一直调到机器会在「我」后面预测出「是」来。

训练就是这样给机器读大量的各种各样的句子，当机器读了很多以「我」开始的句子时，就会发现「我」后面一定是动词，特别是关系动词或能愿动词，像「我是」「我要」。但「我」后面可以有很多动词，「我想」「我吃」「我喝」，到底选哪个呢？这就需要更前面的信息了。所以循环神经网络要存储前面的信息。当机器读了很多「我是上海人，会讲上海话」「我是河南人，会讲河南话」这类的句子后，就会慢慢发现规律，这时候你让它填「我是广东人，会讲_____ 话」的空时，它就把我是「什么」人那个「什么」给填进去了。

这时候你会问，这好像不用这么复杂的神经网络吧，只要统计每个词后面出现的词的概率，然后预测哪个概率最高不就得了？过去的确是这么做的，但效果不好，像我们前面举的例子，「我」后面的可能性太多了。那你会接着说：「我们也统计前面更多的字不就得了？」那我问你，统计前面多少个字呢？要不要把词组和短句也作为一个单位来统计？但词组和短句多得数不清，你怎么教会机器认识哪些是词组？你会发现越深究问题就越多，而且问题变得无穷复杂，以至于都不知道该提取哪些特征。而神经网络可以自动找到那些人类找不到的或者根本没意识到的前后信息之间的相关性。就像我们之前讲到卷积神经网络不仅能找到人脸的五官特征，还能找到人平时不注意的其他特征如两眼间距等。

有兴趣的读者可以看附录 2 里面关于循环神经网络的技术介绍。从附录 2 里可以看出由于循环神经网络里有反馈回路，整个网络更是一个高度非线性、无法解析表达的网络。循环网络萃取出的数据在时间上的相关性更是人类无法感受和理解的暗知识。因为人脑非常不善于存储很长一段时间的信息。

#### 3.8.3 循环神经网络的神奇应用

循环神经网络的第一个重要应用是机器翻译。机器翻译最早是语言学家手工写一大堆语法，然后根据单词出现的顺序用语法把它们组织起来。这是典型的「专家系统」。我们前面讲过，这样的手工系统无法应付千变万化的自然语言。后来的机器学习翻译就是前面说过的统计方法，统计大量的句子中每个字出现在另外一个字之后的频率，然后挑选最可能出现的那个字。我们前面也说了这种方法的局限性。现在最新、最牛的机器翻译，从谷歌、Facebook、微软到百度统统都是用循环神经网络。翻译和前面的填空例子相比，多了可用的信息。例如英文「I am Chinese，I can speak mandarin」可以翻译成中文「我是中国人，会讲普通话」，机器翻译除了可以根据前面出现的中文词预测后面的中文词之外，还可以根据整个英文句子和整个中文句子之间的对应关系来提高预测的准确性。这就是目前最广泛使用的「编码器 - 解码器」翻译模型。这里用两个循环神经网络，一个网络先把整个英文句子的结构信息都压缩到一个字符中，然后第二个网络在一个字一个字地预测时可以根据这个包含了整个句子的结构信息做辅助判断。机器翻译正处在技术突破的边缘，一旦突破将给我们的生活带来巨变。

机器学习不仅在科学技术的进步上大显神威，也开始进入人文领域。循环神经网络第二个有意思的应用是写诗。我们会在第六章中详细介绍。同样的道理，还可以写小说。只要让机器大量阅读一位作者的著作，机器就会学会这个作者的文字风格，甚至可以写出海明威风格的《红楼梦》，或者曹雪芹风格的《老人与海》。

循环神经网络很神奇，但我们下面要介绍的「强化学习」更神奇。

### 3.9 AlphaGo 与强化学习

机器学习迄今为止最让人类惊奇的表现就是下围棋。下围棋的问题是当我每走一步时，如何使得最终赢棋的概率最大？如果我不走 150 步，只走两步，每步双方只随机选 5 种走法，我走第一步有五种选择，对方对我这五种选择的每一种又有五种选择，我走第二步一共有 5×5×5=125 种选择。但通常走完两步离终局还很远，那我从走完第二步的这 125 个位置上各派出一批「侦察兵」，每个「侦察兵」蒙着头一条道走到黑，看到岔路任选一条，尽快走到终局，如果猜对了，给这个出发点加一分，猜错了，减一分。从每个位置上派出的「侦察兵」越多，从这 125 个出发点到终局的赢率就越准确。这个「有限出发点，随机侦察」的方法有个唬人的专业名字叫「蒙特卡洛树搜索」。蒙特卡洛是摩纳哥的赌场区，所以蒙特卡洛就是「随机」的意思。

但这种下棋策略只能勉强达到一二段的业余水平，与围棋大师相比还差得很远。为什么？

因为「侦察兵」往前走时随机选岔道实际上是随机地替对方选了走法。我们不禁会想到：见到岔路随机选多笨，完全可以根据阳光、藓苔、足迹这些东西做个判断。「侦察兵」很委屈地说：我怎么知道该怎样判断？AlphaGo 寻思说：「人类 2 000 多年下了那么多盘棋，咱能不能先学学？」这时候 AlphaGo 祭出了大法器，就是我们前面讲过的卷积神经网络。

卷积神经网络最适合处理图像，经过大量图片的训练后，你给它个新的图片，它告诉你是猫、狗、汽车的概率分别有多少。对于下棋，问题转化成：给个中盘，要判断哪种走法赢的概率最大。在人类下过的棋局中，每个中盘都对应着一个走法。现在可以把一个中盘看成一幅图像，把对应的走法看成与这个图像对应的物体。现在找到中盘最好的走法就相当于判断这幅图像最像哪个物体。那我就拿人类下过的棋局来训练 AlphaGo 里负责走子的卷积神经网络 —— 决策网络。现在把 3 000 万个人类走过的中盘输入给决策网络，调整决策网络上的旋钮，一直到这个网络的走法和人的走法类似。现在 AlphaGo 已经是七八段的水平了，但还打不过大师，为什么？虽然现在「侦察兵」每一步都是按人类的走法，但「侦察兵」的每一步只是替对方随机选一个。如果能让对方的选择也按人类的走法，这条路对弈下去就更逼真了。AlphaGo 这时候拔了身上一根毫毛，吹口仙气儿，「变！」又「变」出一个一模一样的 AlphaGo。哥俩都是八段，再大战百万回合，又摸索出很多原来人类没有探索过的捷径，又产生了很多数据，继续训练决策网络，没多长时间就打败了李世石，再练一阵子，在网上打出 Master 的旗号，横扫天下高手，无一失手，直至把柯洁挑下马。

前面介绍的无论是卷积神经网络还是循环神经网络都需要大量的训练数据，这也叫「监督学习」。在「监督学习」中通常有唯一或明确的答案，猫就是猫，狗就是狗。但生活中还有一类问题是没有明确答案的。

例如我们学习骑自行车，没有人能说清楚正确姿势是什么，不管你姿势多难看，骑上去不摔倒就是对的。这类问题的特点是答案不唯一但知道结果的对错。这种通过每次结果的反馈逐渐学习正确「行为」的算法就叫「强化学习」。在强化学习算法中有一个「奖惩函数」，不同的行为会得到不同的奖惩。

譬如我们在楼里打电话时，如果信号不好，我们就拿着手机，边走边问对方「能听到吗？」。我们得到的信息并不能直接告诉我们哪里信号最好，也无法告诉我们下一步应该往哪个方向走，每一步的信息只能让我们评估当前的状况是更好还是更差。我们需要走动、测试，以决定下一步应该往哪儿走。AlphaGo 的随机树搜索就是强化学习，通过派出「侦察兵」来测试某种走法的赢率。赢了加一分，输了减一分，这就是强化学习中的奖惩函数，存储各种走法输赢积分的网络也叫「价值网络」。哥俩对战就是站在人类肩膀上的强化学习。所以 AlphaGo 是监督学习和强化学习的混合方式。

在 AlphaGo 的学习过程中，人类的 3 000 万中盘仅仅把它领入门而已，进步主要靠哥俩自己厮杀。相当于你去学围棋，一开始跟着你爸学，你爸就是个业余选手，你两个星期就跟你爸学不了什么了，以后都要靠自己琢磨了。AlphaGo 也一样，想清楚这点，干脆从零开始，人类 2 000 多年积累的东西也许就是老爸那点业余水平，学不学无所谓。AlphaGo Zero 横空出世了，这个「Zero」就是从零学起的意思。AlphaGo Zero 从一开始就是哥俩自娱自乐，和 AlphaGo 不同的是，在下每一步棋之前，不需要随机地选 125 个出发点了，而是根据当前的小路「记号」和打分先在这个中盘选一个最可能赢的走法和「双胞胎弟弟」试走一次到终局，试走过程中每一步双方都用同一个决策网络指导如何走子。

这个决策网络的功能很简单：给我一个中盘，我告诉你所有走法的赢率，这样一次到终局后就对从这个走法出发的路是否能赢多了点信息。一路上边走边做记号，第一，记住有没有走过这条路；第二，等到了终局后根据输赢再记下这条路的好坏。这个「做记号」就是不断更新价值网络。这样在同一个中盘哥俩试走了几万次到终局，基本摸清哪条路好走，哪条路不好走，也就是对于这个中盘我已经估摸出了所有走法的赢率。

此时，我用几万次试走出来的赢率来更新决策网络。更新的方法就是用这个中盘做网络的输入，调试网络权重系数让输出的各走法赢率接近试走测出来的赢率。这一切做完后再根据测出的赢率郑重地正式走一步棋。哥哥下完一步该弟弟走了，弟弟的程序和哥哥完全一样，也是先试走许多次，用测出来的赢率更新决策网络，再根据测出来的赢率走子。以后哥俩就这么不断重复下去。

AlphaGo Zero 诞生后的第一局的第一个中盘，哥俩完全是乱下，但第一盘走完就多了一点点知识，哥俩用这点可怜的知识走第二盘就比第一盘靠谱了一点点，架不住计算能力强大，AlphaGo Zero 每秒钟可以走 8 万步，平均一盘棋不到 400 步，所以哥俩一秒钟相当于下 200 盘棋。每盘长进一点，到第 7 个小时，也就是相当于下了 500 万盘棋后就下得像模像样了。

一天半后，也就是相当于下了 2 600 万盘棋后就超过了战胜李世石的 AlphaGo Lee。3 天后，AlphaGo Zero 就和 AlphaGo Lee 打了个 100:0。AlphaGo Lee 一共学了 3 000 万个中盘，大致相当于 3 000 万 / 400=8 万盘棋，这时 AlphaGo Zero 已经相当于下了 5 100 万盘棋。21 天后就打败了横扫天下无敌手的 AlphaGoMaster，到 40 天后哥俩已经妥妥地称霸天下，独孤求败。

到这里，AlphaGo 团队终于松了口气，放下了原先的一个最大担忧：如果不让人类引进门，从零学起，这哥俩会不会在野地里瞎逛，在林子里迷路，像梦游一样原地绕大圈，永远都走不出来。这证明了在强化学习中只要每一步都知道对错，有惩罚奖励，哥俩很快就会放弃那些明显不通的绝大部分的道路，很快就会找到一条正路。

AlphaGo 用了 1 200 个 CPU，176 个 GPU，而 AlphaGo Zero 只用了 4 个 TPU（张量处理单元）。计算资源的大幅度下降主要来自算法的精简，不需要用人类数据训练了。由此可见，在不同的应用场景下，数据并非都那么重要。在下围棋这件事上，人类的经验反而拖了后腿。AlphaGo Zero 给我们最重要的启示是柯洁说的那句话，「人类下了 2 000 年围棋，连边儿都没摸着」。非常原始的机器在自己摸索了 36 个小时后，就超过了全人类 2 000 年来摸索积累的全部围棋知识。

现在请大家思考三个问题：

为什么 AlphaGo Zero 从零学起反而比人强？

AlphaGo Zero 再从头学一遍，功力还和原来一样吗？

AlphaGo Zero 是不可战胜的吗？

### 3.10 神经网络悖论

读者到这里会发现一个悖论：神经网络是模仿人脑，怎么能够发现和掌握人脑无法掌握的知识？我们知道目前的半导体芯片中的人工神经网络只是对大脑的一个简单模仿，无论是在神经元数量还是在连接的复杂性上都远不如人脑。到底是什么原因使得人工神经网络能够在发现隐蔽的相关性方面远超人脑，创造出如此多的神迹呢？

第一个原因是人的感官和机器的「感官」相比实在太差。人的感官在几亿年的进化中主要是为了在自然界中觅食和求偶。所以只能感受到部分外部世界信息。比如眼睛只能看到光谱中的可见光这一小段，无法「看见」从无线电波到毫米波再到远红外的电磁波，也无法「看见」从紫外线到 X 射线再到伽马射线。人的耳朵也听不到 20 赫兹以下的亚声波和 20 000 赫兹以上的超声波。不仅如此，人类的视觉和听觉对强度的分辨率非常粗糙，只能分出数量级。人类的触觉、嗅觉、味觉分辨率更是粗糙。而机器的「感官」，就是各类物理、化学、生物类的传感器则比人的感官精密得多。不仅可以「感受」到人类感受不到的信息，对信息的分辨率也远超人类。如果有办法把这些传感器信号不经过人类感官直接输入大脑，人类大脑也能和机器一样发现数据间复杂隐蔽的相关性吗？大脑能处理高分辨率的外界信息吗？我们可以合理地推测出大脑的进化应该和感官相匹配。如果感官只能提供低分辨率信息，大脑处理高分辨率信息的能力就是一种浪费，这种功能要么不可能演化出来，要么即使偶然变异出来也会被进化无情地消灭。

第二个原因是电子神经元比生物神经元的传输信号速度快，准确度高。由于人脑神经元在突触部分的信号是通过化学分子传导的（细胞膜内外带电的离子浓度差造成电压差），每秒钟大约只能传导 400 次信号。而电子神经元间的传输速度就是芯片上不同晶体管之间的传输速度，比人脑神经元要快几万倍。人脑神经元突触之间的传输非常不可靠，平均每次传输的成功率只有 30%（这种随机性也许是意识「涌现」的重要条件之一），而电子神经元之间的传输可靠性几乎是 100%。人脑神经元由于结构复杂，不同神经元之间的电信号会互相干扰，而电子神经元之间的干扰可以忽略不计。所以人脑神经元是一个慢腾腾的老出错的系统，而电子神经元是一个高速的精密系统。

第三个原因是目前还没有办法获得大脑内部每一个神经元的连接强度。即使我们有办法把外界传感器信号直接输入大脑，大脑也可以处理这些信息，这些信息也只能被雪藏在一个人的脑子里，成为无法沟通、无法传播、无法记录的默知识。但电子神经网络中的每一个神经元之间的连接强度，也就是两个神经元连接的权重系数都是可以存储、提取的。所以机器获得的暗知识是可以传播、复制、记录的。

所以对这个悖论的回答是，人工神经网络虽然是模仿大脑，但它具备了人类没有的三个优势：能「感受」人类感受不到的信息，与人脑相比又快又准，每一个神经元的状态都是可测量的。

2『人工神经网络与人脑相比的三大优势，做一张主题卡片。（2021-08-02）』—— 已完成

### 3.11 神经网络五大研究前沿

之前介绍的几种神经网络都是目前商用中的主流算法，但机器学习的潜力还远没有被挖尽，现在每年关于机器学习的论文还在呈指数级增长，在研究型的大学里任何关于机器学习的课程都爆满。可以预期在今后 3-5 年中还会不断有新的算法突破，下面介绍的都是目前炙手可热的研究方向，每一个方向的突破都会产生巨大的商业价值。

#### 3.11.1 非监督学习

在前述的机器学习算法中，我们总有一个训练数据集合，即「标注数据」，如所有汽车图片都会标注上「汽车」，所有猫的图片都会标注上「猫」等。这样在训练的输出端，我们就知道结果是否正确，因此可以用正确结果和输出结果的差来训练机器（调整各层的权重系数），就像一个妈妈教孩子认识东西，这类算法叫「监督学习」。

在机器学习中还有一种算法不依赖于「标注数据」，叫「非监督学习」，像一个孩子在没人教的情况下自己学习。非监督学习最常用的情形是分类，例如一个孩子见过许多猫和狗后，如果大人不告诉孩子这两种动物的名字，孩子也许不知道名字，但慢慢会知道猫和狗是两种不同的动物。在商业上有很多应用，例如在营销上面可以根据人群的不同属性将其划分成不同人群进行精准营销；在社交媒体上面，可以根据人们之间的互动次数，划出每个人的朋友圈子；在医疗诊断上面可以根据不同症状之间的相关性更精确地预测还未发现的疾病；等等。

#### 3.11.2 增量学习和连续学习

目前的机器学习算法都是「离线训练」，先用一大堆数据训练模型，训练完测试好就拿去做识别用，在识别过程中，这个模型是固定的。如果发现了新的情况，有了新的训练数据，就要把新数据和原来的老数据合在一起重新训练这个模型，训练完还要重新测试才能使用。许多互联网巨头每个月都要训练几十万个模型，目前的计算量主要在训练上。增量学习就是当有新数据时，只用新数据训练原来的模型，使机器在原有的识别功能之上增加新的识别功能。连续学习就是能够边识别边学习。这两种学习算法都还在研究的早期阶段。

#### 3.11.3 生成对抗网络

监督学习的最大问题之一就是需要大量人工标注的数据。在很多情况下，要么没有数据，要么标注的工作量太大。生成对抗网络（Generative Adversarial Network，GAN）解决了这个问题。因此 GAN 成为目前最炙手可热的非监督学习算法之一。

GAN 减少深度学习训练所需的数据量的方法是：从少量的已有数据出发去创造出更多的新的标注数据 —— 多数情况下是图像数据。

图 3.13 是 GAN 的示意图，图中有两个深度神经网络：G 和 D，其中 G 是生成网络，D 是鉴别网络。生成网络的任务是根据一组真实、有限的数据（例如一组图片）生成更多类似但不同的数据。然后把这些生成的数据和真实数据混在一起喂给鉴别网络。鉴别网络的任务是使用很少的真实数据训练后，分出哪些是真实数据哪些是生成数据。

如果生成网络生成的数据能被鉴别网络认出来不是真实数据，就说明生成网络模仿得不够真实，需要继续调整网络参数，目的是让鉴别网络分不出来。如果鉴别网络分不出来真假，就说明鉴别网络不够好，需要继续调整参数分出真伪。这样「道高一尺，魔高一丈」地持续对抗下去，两个网络就越来越好：生成网络模仿得越来越真，鉴别网络越来越「火眼金睛」。当两个网络打得难解难分时，生成网络生成出来的数据就和真实数据无法分辨。当缺乏足够多的真实数据时这些生成数据就可以用于神经网络的训练了。

图 3.13 生成对抗网络

可以把这个过程想象为一个警察和假币伪造者之间的比拼，伪造者想把假币做得像真的，警察希望看到任何钞票时都能鉴别出真伪。两个对抗网络也在彼此学习，也就是说，当一个网络努力去鉴别假币时，另一个网络就能把假币做得越来越真。

另一个例子是生成对抗网络可以模仿名画。经过训练之后的最终结果是，一个网络可以像凡·高、毕加索一样作画，另一个网络能以你闻所未闻的洞察力鉴别画作。这对于医疗等领域来说非常重要，在这些领域中，由于隐私的需要，可用的数据非常有限。GAN 可以填补缺失的数据，自行制作完全「臆造」的病患数据，而这些数据在用于训练 AI 时和真实数据同样有效。深度生成模型有广泛的应用，包括密度估计、图像降噪（从低分辨率或高噪音的图像中生成高品质图像）、图像修复（从部分残缺的图像中恢复完整图像）、数据压缩、场景理解、表征学习、3D 场景搭建、半监督分类或分级控制等。

相比判别模型（例如 CNN），生成模型更厉害的原因如下：

1、能够从数据中识别并表现出隐藏的结构，例如三维物体的旋转、光强、亮度或形状等概念。

2、能够想象世界「可以是什么样」，而不是仅仅展现世界「已经是什么样」。

3、通过拟合并生成近似真实的场景，可以预见未来。

#### 3.11.4 迁移学习

迁移学习的一个例子是当一个神经网络学会了中文翻译成日文，再让它学德文翻译成英文时就比从头训练要花的时间少得多。这里面的道理在于语言的结构有很多相似的地方，一旦掌握了这些结构，学习下一个就快了。这和人的技能学习类似。可以想象，只要两种任务的结构有相似之处，就可以用迁移学习的方法。

#### 3.11.5 学习如何学习

学习如何学习也叫「元学习」。目前所有的神经网络都是为了一个单一任务而被设计和训练的。换一个不同的任务，例如从识别图片换成学下棋，原来的机器就完全不工作了。目前的所谓「元学习」并非让机器和人一样掌握举一反三的能力，而是让同一个机器适应更多种类的工作。一个办法是训练时用多个种类的任务来训练。另一个办法是把机器分为两个层次：学习任务的机器和观察学习过程的机器。如果后者能够领悟出不同任务之间的相关性，就可以更快地学习新任务。

神经网络可以有许多不同的结构，例如不同的层数、不同的连接方式，等等。把这些结构看成一个可能的空间，让机器自己在这个空间中寻找对给定问题的最佳结构。

### 3.12 深度学习的局限性

上面介绍了一些目前最热的神经网络，例如卷积神经网络、循环神经网络、强化学习、生成对抗网络等，它们有很多神奇的地方，在实际中也得到了相当广泛的应用。但神经网络也好，深度学习也好，都不是万能的，它们有其自身的局限性。

神经网络的一个局限性是，需要依赖特定领域的先验知识，也就是需要特定场景下的训练，说白了就是神经网络只会教什么学什么，不会举一反三。神经网络的这个局限性，是因为神经网络的学习本质上就是对相关性的记忆，也就是说神经网络将训练数据中相关性最高的因素作为判断标准。

打比方说，如果一直用各个品种的白色狗来训练神经网络，让它学会「这是狗」的判断，神经网络会发现这些狗最大的相关性就是白色，从而得出结论：白色 = 狗。在这种情况下，让这个神经网络看见一只白猫，甚至一只白兔子，它仍然会判断为狗。

机器学习的这种呆板行为，用专业术语描述叫「过度拟合」。如果想让神经网络变得更聪明，就必须用各种颜色、各个品种、是否穿衣服等各种场景下的狗来训练神经网络，如此它才有可能发现不同的狗之间更多的相关性，从而识别出更多的狗。人类则不同，一个两三岁智力发育正常的孩子，在看过几只狗之后，就能认出这世上几乎所有的狗了。无须大量标注数据和特殊场景的训练，只需要少量的数据，人脑就可以自己想清楚这个过程。在这方面，目前的神经网络和人脑相比，还有很大的差距。

再如前面提到的汽车和猫的例子，如果一直用正常的汽车来训练这个神经网络，那么当神经网络突然看到图 3.14 的时候，很有可能无法把它认作汽车，而觉得它更像猫。

这个问题在自动驾驶领域显得尤为突出，由于道路交通状况的复杂性，各种交通指示标志的多样性，想把所有的道路交通场景都训练到显然是不可能的。

2016 年特斯拉第一起自动驾驶致死的事故也和这个原因有关。

图 3.14 机器学习会把这辆汽车当成猫

神经网络的另一个局限性是无法解释结果为什么是这样，因为人类无法理解暗知识，所以更无法解释。对于神经网络这个「满是旋钮的黑盒子」，每个旋钮为什么旋转到那个位置，而不是多一点或者少一点，都是无法解释的。这个不可解释性在许多涉及安全和公共政策的领域都是很大的问题。

例如，医疗涉及人的健康和生命，医生的诊断需要根据极为严谨的医学逻辑，因此医疗对于人工智能的可解释性要求远高于其他行业，极少有医院或医生敢把无法解释的诊断结果用在患者身上。然而由于神经网络自身不具备医学逻辑，其输出的结果也缺乏医学上的解释性，因此目前人工智能在医学上的应用，无论是影像识别还是辅助诊断，都需要专业医生的复核，距离取代医生还有较大的距离。

人工智能之所以有上述两个局限性，主要是因为目前的神经网络只有相关性的学习能力，没有因果推理能力，更无法把一步一步推理的过程表现出来。因此，想要克服这两个局限性，我们需要有因果推理能力的人工智能。要实现这件事情，人工智能需要做的，不仅是识别场景，还需要将识别出来的场景和它具体的功能以及想做的事情结合起来，从而实现合理的逻辑推理。

让我们看看人脑是如何理解一个场景的。当人进入一个新的房间时，会很自然地对这个房间的大小，里面各个物品的大小、位置等有一个大致的认识。之后，人脑会把识别出的场景和物品，与其功能一一匹配，例如，床是用来躺的，而且是一张双人床可以躺两个人，椅子是用来坐的，杯子是用来喝水的，等等。然而值得注意的是，上述的几何重建和功能推理，其精度是和具体任务相结合的。

例如，人一开始看到杯子，会匹配它喝水的功能，并看到它放在桌子上，判断距离自己两三米远，这个距离判断是非常不精确的。然而当人真的需要喝水时，喝水成为一个任务，人在走过去拿杯子的过程中，不断地、更加精确地判断自己和杯子的距离，直到非常精确地拿到杯子。这个过程就是一个典型的任务驱动的场景识别和功能推理。

此外，人类对于功能的推理，并非会拘泥于具体的物体，而是能抽象出这个物体和功能有关的物理特性，从而匹配其功能。仍然以喝水为例，如果房间里没有杯子，但是有一个瓢、一个盘子、一根擀面杖，人会很自然地选择瓢作为喝水的工具（如果连瓢都没有则可能选择盘子），因为瓢可以作为容器的物理特点和杯子是一致的。而且，选择了瓢之后，人拿瓢的动作，喝水的动作，都会和拿杯子不一样，这同样是由杯子和瓢不同的物理特性决定的。由此可见，人对于物体的功能推理，是会根据任务的要求，抽象其物理特性，从而推理它的功能并完成任务，因此人工智能的场景识别和功能匹配，是需要基于场景和物体的物理特性来完成的，而不仅仅是识别和标定具体功能。

这种基于任务驱动的因果推理和当前的神经网络的对比如下。（见表 3.1）

表 3.1 神经网络和任务驱动的对比

| - | 神经网路 | 任务驱动 |
| --- | --- | --- |
| 物体识别 | 识别物体是什么，如果没训练过，就无法识别 | 识别物体的物理特性；即使没训练过，也可以识别 |
| 功能匹配 | 通过标定和训练匹配功能，如果没训练过，就无法匹配 | 通过物体特性匹配功能，即使没训练过，也能匹配功能 |
| 驱动本质 | 数据标定驱动 | 任务驱动 |
| 数据数量 | 需要大量数据训练 | 只需要少量数据 |
| 推理能力 | 无 | 有推理能力 |

资料来源：朱松纯，《正本清源》，2016 年 11 月刊登于《视觉求索》。

目前在这个方面探索的代表人物是加州大学洛杉矶校区（UCLA）的图灵奖获得者朱迪亚·珀尔（Judea Pearl）教授以及他的同事朱松纯教授。他们认为可以建立一个基于常识之上的「概率决策图」，也叫「概率语法图」。这个模型把人类的常识和世界模型都包含进来，又采用贝叶斯原理，可以像人类一样不需要许多数据就能学会，在处理许多问题上效率远高于神经网络。

在高科技领域，硅谷一家由斯坦福大学教授威德罗的弟子创办的人工智能公司 Vicarious 得到了著名风险投资人蒂尔（Peter Thiel）、特斯拉创始人马斯克、脸书创始人扎克伯格（Mark Zuckberg）和亚马逊创始人贝佐斯（Jeff Bezos）的投资。他们也是采用了概率决策图的方法。虽然目前他们是少数派，但也许若干年后会异军突起，就像神经网络坐了 50 年「冷板凳」今天突然一飞冲天一样。