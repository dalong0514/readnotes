## 记忆时间

## 目录

0401 函数1：从静态到动态从个别到趋势

0402 函数2：如何通过公式理解因果关系

0403 向量代数1：方向比努力更重要是鸡汤吗

0404 向量代数2：如何通过向量夹角理解不同维度

0405 线性代数：矩阵到底怎么用

## 0400. 代数学：用数量描述世界

1、函数反映出两种变量之间的关系，其中一种变量随着另一种变化。函数让我们从对单个数字、变量的关注，引向了趋势。函数 4 个核心要素：变量、对应关系、确定的对应关系和确定的算法。

2、单变量的函数对应于因果，多变量的函数对应于相关。目前的学术研究只能在几个维度研究其相关性。自然科学里因果关系单向，数学里的因果关系双向。

3、数量 + 方向 = 向量，向量也可以做加减乘除的运算，从向量的方向性可以得到一个自然的推论：做事情要聚焦。

4、从毕达哥拉斯定理出发，建立了角度判定因子 𝚫 和具体角度的关系，将这种关系称作余弦定理。余弦定理可以解决计算向量夹角的问题，当两个向量确定之后，我们可以把它们的起点都挪到原点，它们各自的终点和原点之间，就构成一个三角形。这个三角形的三条边显然是确定的，由此我们可以算出判定因子 𝚫，然后根据余弦定理计算两个向量的夹角。计算向量的夹角有很多实际的应用，看夹角小的比如文本分类、职业匹配，看夹角的大比如信息论里的正交信息向量。

5、矩阵是是向量扩展的结果，是多个 N 维向量的简洁表示方式。矩阵有很多运算，而且都有其实际应用，比如加法和乘法。矩阵的加法可以理解为核心矩阵和增量的关系；矩阵的乘法可以将单个计算变成大批量处理。

## 0401. 函数1从静态到动态从个别到趋势

函数反映出两种变量之间的关系，其中一种变量随着另一种变化，因此在科学史上它提升了人类的认知，将我们从对单个数字、变量的关注，引向了趋势。没有函数，我们其实很难从个别数据样点，体会整体的变化。因此我们的思维方式要从常数思维到变量思维，再到函数思维。函数还为同一类问题提供了具有普遍性的答案。当我们对函数中不同的变量代入不同的数值时，就会得到相应的结果，这就让人们有了一通百通的可能性。

1『思维方式从常数思维到变量思维再到函数思维。』

代数的模块要培养以动态视角看世界的能力，批量处理问题的能力，并且理解因果关系的本质。代数的发展是从列方程和解方程开始的，那些内容我们已经在第二模块中介绍了，因此今天我们就从代数中第二个重要的概念和工具 —— 函数讲起。这一讲的主题是拥有从静态到动态，从个别到趋势的视角。「函数」这个词我们经常听到，在初中数学里也讲过函数的概念，但是我不清楚你是否还记得它的定义。如果不记得了，并非你的水平不行，更可能是我们的教科书编写得有问题，不容易理解和记忆。我从初中数学书里摘录出了函数的定义，很绕口：在一个变化过程中，有两个变量 x 与 y，如果对于 x 的每一个值，y 都有唯一的值与它对应，那么就说 x 是自变量，y 是 x 的函数（因变量）。

这个定义虽然算不上十分严格，但还是比较准确的。不过我估计你如果原来不懂什么是函数，读了这句话后更糊涂了，因为它为了讲述一个概念，又引入了一堆新概念，比如「变化过程」、「自变量」、「对应」等等。这样的定义让我想起了费曼对一些物理学课本的批评，他的大意是这样的，那些看似严谨的定义，不过是用一些词解释另一些词，学生们就算把它们背得滚瓜烂熟，照样体会不了其中的含义。那么函数是什么？其实我们在前面已经讲到了很多函数。比如我们说到的抛物线，笛卡尔坐标系上的一根直线，在数列中位置和相应元素的关系，它们都是函数。此外我们前面还提到过指数函数、对数函数等等。

在生活中，函数也是随处可在，比如在一个单位里，员工和他的工资之间，就是一种函数关系。函数的值也并非一定是数字，可以是其他的数据，比如单位里每一个人的父亲是谁，这也是一种函数。从这些例子中，我们可以发现函数的四个共性：首先，这些函数里面都有变量，函数讲的不是 3+5，或者 2x9 这些具体确定的事情。像 y=x^2 这样的抛物线，x 就是变量。像单位里每个人的工资这样的函数，人就是变量；第二，它们都有一种对应关系。比如一个等比数列 1，2，4，8，16，……，2^n，…… 序号 n，和相应的元素 2^n，就是一种对应关系，2^n 就是 n 的指数。再比如，我们在介绍解析几何时，讲过一个二元一次方程 AX+BY+C=0，它代表一条直线，这也是一个函数，我们每设定一个 X 值，就能算出一个 Y 值，这就有了 X 和 Y 之间的对应关系。至于某某的父亲是谁，也是一种对应关系；第三，上述的对应关系，都必须是确定的，也就是说，在一个函数中，一个变量只能对应一个值，而不是多个值。比如在等比级数数列中，一个位置上只有一个数，第三个元素不能既是 4，又是 8。同样，一个人这一年的年薪不能既是 10 万，又是 20 万。当然你可以说我的工资比去年涨了，但是在一个特定的时间，它是确定的；第四，也是最后一个特性，函数所对应的关系可以通过数学的方法，或者其它方法算出来。比如，在二元一次方程里，给定一个 X 的值，就能算出一个 Y 值。在一个单位的档案里，给定人，就能查出他的工资。

1-2『函数 4 个核心要素：变量、对应关系、确定的对应关系和确定的算法。函数，做一张术语卡片。』——已完成

了解了函数的这四个特性，我们可以看出函数是一种特殊的对应关系，任何一个变量只能对应一个函数值，当一个变量对应了很多数值，这样的对应关系就不是函数。如果我要问你北纬二十度的城市是哪个，你可以找出一大堆，这就不是函数。虽然我们在前面举函数例子时，举了各种各样的函数，但是人们最初研究函数只是用它来描述数学上一些曲线的变化规律。提出函数这个概念的人就是著名数学家莱布尼茨。他在研究微积分时，常常要确定曲线上每一个点的一些性质，比如它附近的点是否连续，或者曲线在这里的斜率是多少。

2『莱布尼兹，函数概念的提出者，做一张人名卡片。』——已完成

当时大家已经普遍利用坐标系（笛卡尔坐标系）这个工具，将曲线画在上面，坐标系的横轴是 x 轴，纵轴是 y 轴，因此，大家通常就把函数关系理解成 y 随着 x 变化的走势。比如说，在一个坐标系里，如果 x 每增加一个单位，y 也增加一个或 k 个单位，那么这种函数关系就是线性的，因为这些点在坐标里画出来就是一条直线。如果 x 每增加一个单位，y 就翻一番，这种函数关系就是指数的，画出来就是一条向上的曲线。

在中文里，「函数」这个词是清末数学家和翻译家李善兰创造出来的。李善兰在翻译西方数学著作时，就根据函数的这种对应变化关系，发明了这个名词，他讲：「凡此变数中函（包含的意思）彼变数者，则此为彼之函数。」意思是说，凡是这个变量中包含另一个变量，这个变量就称为另一个变量的函数。也就是说，如果 y 随 x 变化，y 就是 x 的函数。李善兰的解释并不准确，但是颇为形象。

函数概念的提出在数学史上有划时代的意义。在此之前，人类最初是对一个个的数直接进行计算，后来虽然有了方程式这个工具，但是方程并没有用来表示变量之间的关系，而是作为解题的工具。到了科学启蒙时代，两件事对函数的出现起到了至关重要的作用，一个是解析几何，这让数学家们可以用曲线把一些方程式联系起来，从而大家可以看到一些变量变化的趋势；另一个是天文学和物理学的发展，需要用公式和曲线表示时间和运动轨迹之间的关系。莱布尼茨可以说是生逢其时，他出生得足够早，还没有人提出函数的概念，同时又足够晚，以至于各种准备工作都具备了。

有了函数，人类在认识上有了三方面的进步。

首先，我们就很容易看出两个变量之间是怎样相互影响。比如你看下面这张图，上面有两个长相差不多的西瓜，后一个的直径比前一个大 1/4，从图片上看，它们的差别好像不是很大。我问过很多人，如果第一个西瓜卖 30 块钱，第二个你愿意出多少钱？大部分人给我的答案是，最多多出 50% 的钱吧。其实第二个的重量比前面一个多出了一倍，也就是说大约值 60 元。这个例子说明，我们都知道圆的周长是半径的 2π 倍，这是一种线性关系，比较好理解。不过圆的面积和半径的关系就是平方关系，理解起来就要费点劲了。比如圆的半径从 1 变到 2，面积就从原来的 1 倍变到 4 倍，如果半径再增加到 3 倍，面积就是原来的 9 倍。再往后，球的体积和半径的关系是三次方，半径从 1 变成 2，体积就是原来的 8 倍，这就更难理解了。虽然人有时能够感觉立方关系的变化比线性的快，但是对于到底增长有多快没有概念。人对变量之间关系的感觉其实不准确，而函数帮我们弥补了这个先天不足。

其次，函数的第二个意义是让我们从对具体事物、具体数的关注，变成了对趋势的关注，而且可以非常准确地度量变化趋势所带来的差异。比如我们说，过去几十年中国经济增长较快，经常在 8% 以上，即使是 2017 年，依然有 6.9%。对于这些数据，其实老百姓没有概念。GDP 的增长是时间的一个函数，我用世界银行公布的过去 50 多年的数据画了这样一张图，图中蓝线是中国经济增长率曲线，另外两条是印度和美国的。从图中你可以看出中国整体上增长不仅比美国快很多，而且大部分时候比快速增长的印度也高不少。这是横向对比。如果纵向对比，你会发现中国自从改革开放后，比以前也好不少，60 年代初的三年困难时期，以及文革时期，中国是负增长。但是在改革开放后，这种情况就再没有发生了。很多人平时会对一件事过分敏感，要么因为一个好消息过分乐观，要么因为一个坏消息过分悲观，当我们对函数，而不是一个个具体的数有概念后，我们的见识就容易提高。善于做报告的人都知道，在 PPT 中最好不要直接引用数据，而要把它们变成曲线或者直方图。曲线和直方图其实就是对函数的一种形象表示，它们可以让那些原本对趋势不敏感的听众，实实在在感受到变化。

函数的第三个意义在于帮助我们通过学习几个例题，掌握解决一系列问题的方法。比如我们知道了投掷和抛射一个物体，当初速度一定时，最后它飞行的距离是抛射角度的函数，那么我们就能算出不同角度下，抛射的距离。了解了这个函数关系，无论是对从事投掷项目的运动员，还是炮兵或者狙击手，都有指导意义。特别是对后者，他们能够通过控制角度，决定落点。如果我们找不到这样的函数关系，靠做实验的方法达到目的，是不现实的。事实上，最初设计电子计算机的目的，就是根据弹道的函数，计算远程火炮弹道轨迹的，当然，这个函数中不只有角度一个变量，炮弹的速度、空气的阻力和风向等都是变量。

### 黑板墙

函数是一种特殊的「映射关系」。想象一个有两个开口的「魔盒」，一个口只能放入东西，对应「输入」（自变量）；另一个口只能往外出东西，对应「输出」（因变量）。你往魔盒里放入一颗种子，魔盒的另一个口蹦出一颗树苗；这就对应着，一个函数将自变量「种子」映射到因变量「树苗」的过程。但是，这个魔盒只接受放入「活的种子」，如果你往魔盒里放入一个炒熟的种子，或者不是种子，那么它无法工作。也就是说，这个函数的「定义域」为「活的种子」，而一颗炒熟的种子不在它的「定义域 」里。对同一类种子，这个魔盒只会蹦出同一种树苗 —— 即函数值唯一。此外，无论你放入什么种子，魔盒只会蹦出树苗，不会蹦出果子，更不会蹦出一只鸟…… 魔盒所有可能蹦出的东西构成了它的「值域」，也就是「树苗」，果子和鸟等其他东西不在函数的「值域」中。（当然，数学里函数的值域必须是数）如果你觉得这个魔盒功能太单一，想着要是放入一颗蛋，它就能出来一只小鸡，该多好…… 那就将这个函数的定义域「延拓」到「受精卵」咯。

「刻板印象」就是一个简单粗暴的「函数」；只要输入一个关键词，就能输出一个相应的标签。输入「女博士」，输出「无聊死板」；输入「学数学的」，输出「秃顶白头发」；输入「程序员」，输出「眼镜格子衫」……其实，问题不仅仅出在函数身上，还在「输入」。如果输入的信息量本来就有限，那么函数输出的结果绝不会太「复杂」和「精确」。简单的「函数」，即使只有少量的信息输入，也能给出相应的输出；既可以降低人的认知负担，同时也有一定的可解释性 —— 尽管这个输出可能并不那么准确和可靠。相反，输出越是「精确」的函数，越依赖大量的信息输入，和复杂的「内部结构」，以至于成为一个难以解释的「黑箱」。「简单而粗略」，还是「复杂而精确」，也是如今的人工智能需要权衡的 —— 当然，大多数选择的是后者。相应的，当你认为自己足够了解一个人，以至于可以对他随意「输出」评论和批判的时候，想想你目前「输入」的信息量以及「函数」的「复杂度」是否足够支撑一个准确的「输出」。

2『信息的输入量和函数（算法）的复杂度，做一张任意卡片。』——已完成

自我驱动的方式，就是给自己设置一个好的收益函数。还记得谷歌方法论有一期回信，老师征集大家「知识之外的个人素养」的看法，我那时提出「自我驱动」的能力。不论个人或是组织，都需要有个明确且可执行的激励机制，可以视作一个最大期望值化的收益函数，有人称作经营管理的法则、有人称作公司文化的塑造，其实都是同个道理，明确方向，即使起点低，只要在函数的线上移动，动态发展可预见，趋势也能掌握。函数的概念，国中老师这样比喻：如同随处可见的自动贩卖机。好几个按钮对应到不同饮料，按下每个键都有「相应」的饮料掉下来，这就是运作良好（function）的贩卖机，就是函数（function）。如果按选项后，没有饮料掉下来，那么贩卖机坏了，这是「一对无」非函数；如果按了，反而掉了一堆饮料，那么贩卖机也坏了，这是「一对多」非函数；还有一种情况，好几个按键都卖可乐，所以按下去都掉出一样的饮料，这很常见，是「多对一」属于函数。

函数与大数据。在今天这个「大数据」时代讲函数，比以前任何时代都更容易理解，因为大家对「数据」的认识已经十分具体化了。每个人的每个行为，都在产生数据，你在网页上的每一次点击，在得到的每一次收听，点击手机的每一次亮屏都是一个行为，都会产生数据。从行为到数据，是一个具体到抽象的过程，它不容易，但是这个过程和能力我们在不知不觉中已经完成进化了。进一步说数据和函数的关系。有了数据，获得相应的函数可以说是分分钟的事情。最简单的方法就是画条曲线。比如，健身 app 里面的体重变化曲线，自变量是日期，因变量是体重；得到 app 里面的学习时长曲线，自变量是日期，因变量是每日学习时长；你甚至可以将它们交叉对应，取出不同日期的体重作为自变量，找出对应日期的学习时长作为因变量，画一条曲线，说不定你就找到「体重与学习时长」的对应关系。这就是函数，就这么简单，在生活中，特别是在今天的生活中，它无处不在。从函数的视角再去看看手机中和身边的种种数据，数据已经不再是对过去行为的简单统计，将数据连线构成函数，观察曲线变化的走势，我们就能够预测未来的变化趋势。建议你不妨从今天开始，就用「函数」的视角，重新认识一下我们这个「大数据」时代。

函数与方程有形似的地方，但更有本质的不同。方程是一个代数工具，其中的未知数不分彼此，可以互换。而函数的自变量和因变量在一定情况下是不能相互替换的；方程有一个方程或一组方程组，而函数没有函数组的概念；方程的未知数可以一次，也可以高次，而函数的因变量只能是一次；方程可以无解，唯一解或无穷解，而函数只能是给定一个自变量对应一个因变量；尽管有逆函数，但不是所有函数都可逆。这需要从函数定义的四个特征来分析；函数既可以表示相关性，也可以表示因果性。前者可以互换，如身高与体重的函数关系；后者互换则没有现实意义了，如位移与速度的关系；计算公式与物理表达式是不同的。

## 0402. 函数2如何通过公式理解因果关系

只有一个变量的函数，自变量和函数值之间有因果关系，一个变化导致另一个变化。但是，函数的使用要考虑使用范围，对于任何规律其实都是如此。由多个变量决定函数值的函数，每个变量和函数值有相关性，有些还是百分之百的正相关，但是它们没有决定性，也没有必然的因果关系，切忌把相关性和因果关系混为一谈。今天的学术研究通常只能在几个维度研究相关性，因此对于研究的结论，我们要全面看待。

我们上一讲在讲函数时说，在函数中，一个变量先变化，另一个随着它变化。比如圆的半径 R 增加一倍，面积 S 增加到原来的 4 倍，后者随着前者变化。如果我们把这个关系上升为抽象的逻辑关系，那么就是半径变化是因，面积变化是果。我们用这样一个箭头代表确定性的因果关系 R→S，用下面这样一个函数来表示：S=πR^2。

通常，我们称 R 是自变量，S 是因变量，或是自变量 R 的函数，因变量和函数通常说的是一回事。如果把上面这种函数关系形象地用曲线表示下来，那么它就是半根抛物线：

从这个例子可以看出，函数中的自变量，虽然从名称上来看，似乎自己怎么变都行，但其实它有一些特定的限制条件或者范围，比如圆的半径必须大于等于零就是限制条件。我们在之前讲到的几何数列中每一个数，可以表示成 2^N（或者 r^N），但是，这个 N 必须是整数，比如 1，2，3，4 等等，不能是半个，这就是限制条件。自变量的取值范围或者限制范围，我们称之为函数的定义域。这里面的域，就是疆域的意思，它表明一个函数所描述的变化规律是有范围限制的。当一个函数的定义域确定之后，因变量，也就是函数值也就受到了相应的限制。比如说几何数列 2^N，取值只能是 2，4，8，16…… 这些特定的整数，不可能是 2.5 这样的小数数字，甚至不可能是 3。函数值的变化范围，我们称之为值域，这个名字顾名思义，也很好理解。

类似的，我们上一讲所说的现实生活中遇到的各种函数，也能确定因果关系，定义域和值域。比如班上每一个人的身高，因果关系就是人决定身高，也就是说「人→身高」。函数的定义域是特指班上的人，不是所有的人，他们的身高也在有限范围之内，比如从 1.5 米到 1.9 米，而不是任何的高度。你如果算出一个人的身高是 10 米，说明一定是什么地方搞错了。

对于函数，很多人常犯的错误在于没有考虑定义域，滥用函数关系，比如不能假设圆的半径是负数，然后套用 S= πR^2 这样的函数去计算面积。类似的，在生活中，很多函数使用起来也要考虑定义域。比如对于那些平时成绩在 90 分以上的学生，如果老师每多教 10% 的内容，他们就能多学会 5%，这看似多教是有好处的。但这个函数是有定义域的，对于成绩 70 分以下的人，这个变化规律可能就不成立了，教得越多，成绩越差。因此，使用任何规律之前要看条件是否相符，不能错误地套用了公式。

讲到函数中的因果关系，有两点需要明确指出。首先，数学上的因果关系和生活中的可能不完全相同。在物理学等自然科学上，因果关系常常是单方向的。比如你从比萨斜塔上坠下一个球，它就以自由落体的加速度往下坠落，落地时会有一个速度，这个速度是地球重力加速度导致的，因此加速度是速度的因，而不是反过来，这是非常明确的。再比如，张三在 20 米外观看这件事，那么你先扔了球，他才看见，这也是因果关系，不可能倒过来。

但是数学函数中的因果关系未必如此。在一个函数中，自变量和因变量的角色是可以互换的。我们前面说，给定圆的半径，我们通过一个计算面积的函数 S=πR^2，算出面积，因果关系是半径→面积。但是在现实生活中也有反过来的情况，比如一家四口人到必胜客吃午饭，需要先根据每一个人的饭量，确定面积是多大的披萨饼才够吃，然后根据 R=√（S/π）再算出半径（直径），看看是买 14 寸的、16 寸的，还是 18 寸的。这时面积就是自变量，半径就是因变量了。因果关系变成了面积→半径。我们同样可以用 x 坐标代表面积，y 坐标代表半径，画一条曲线，就是下面这个形状，如果你对比前一图，会发现两条曲线形状相似，只是翻转了一下。更准确地讲，它和原来的曲线是相对 45 度角的对角线对称的。

1『自然科学里因果关系单向，数学里的因果关系双向。』

为了更完整地描述和研究这种把因和果置换后的函数关系，数学家们提出了反函数的概念，比如 y =√(x/π) 和 y=πx^2 就是互为反函数。在笛卡尔坐标系中，反函数的图和原来函数的图就总是相对 45 度角的对角线对称。比如下图是对数函数（蓝线）和指数函数（绿线）的关系图，它们相对对角线红线是对称的。

为什么对数函数和指数函数会互为反函数呢？我们不妨从两个角度看同一件事情就知道了。

比如你购买国库券 10000 元，以 6% 的年息复合增长，请问 12 年后你的本息一共是多少呢？我们知道 X 年后的本息 Y 是一个指数函数：Y=10000*(1.06)^X，代入 X=12，大约是 20122 元。也就是说大约 12 年后投资翻了一番。如果我们倒过来问这个问题，今天买 10000 元国库券，多少年后才能本息翻一番，那么这就是对数函数的问题了，我们把 X 作为若干年后的本息总数，Y 作为时间，这样 Y=log（X/10000），算出来大约是 11.896 年，也就是 12 年左右。因此，指数函数和对数函数互为反函数。

说到投资，这里给大家讲一个计算回报的简单方法 ——72 定律。假如你的投资回报率是每年 R%，那么多少年投资才能翻一番呢？基本上是 72/R 年。刚才的情况是 R=6，大约是 12 年，如果提高到 8%，只要 9 年就够了。别看这 2% 的差异并不显大，如果我们把时间放大到 36 年，也就是一代人的时间，那么回报就是翻番三次和翻番四次的差异了。因此一个人善于理财，还是不善于理财，到退休的时候，财富很容易差出一倍。

接下来我们谈谈数学上因果关系的第二个注意事项，当一个函数的变化由两个，或者更多的变量决定时，单个变量和函数之间的因果关系，并不是函数值变化的必然原因。比如说，我们要计算圆柱体的体积 V，它和圆柱半径 R 的平方成正比，和圆柱的高度 h 成正比，即：V=πR^2*h。

这时，如果高度增加一倍，体积一定增加一倍吗？我们只能说，有可能，但是前提是半径要保持不变。反过来从结果看，如果体积增加了一倍，我们也并不知道是否是高度变化所引起的。如果我们把体积 V，半径 R 和高度 h 的关系画在一个三维的图中，那么大概是下面这张图的样子。从图中你可以看出，决定体积的因素很复杂。

在多变量的情况下，我们只能得到这样的结论，就是体积的变化和高度的变化是正相关的，而且相关性是 100%，也就是说，在其它条件不变的前提下，一个变大，另一个也必然变大。类似的，体积变化和半径变化也是 100% 正相关的。在生活中，很多人经常把正相关性、因果关系和必然性相混淆。比如说，每年的平均投资回报率和最后拿回来的钱总数是正相关的，这点毫无疑问。但是在投资时，总是找那些回报率高的项目或者投资产品，20 年后拿回来的钱一定多么？不一定，因为最后能拿回来多少钱，不仅看平均回报率，还要看投资风险，一些高回报的项目也是高风险的。也就是说，平均回报率高，和拿回来的钱多并不形成因果关系。

很多人看到别人投资高风险、高回报的项目发了财，觉得这种好事情也能摊到自己身上，可是等自己真拿出真金白银投资时，高回报没有起作用，高风险却应验在自己身上了。了解了相关性和必然性的差别，能让我们少犯错误。在上面计算圆柱体积这个例子中，我们还只有两个变量，在很多实际问题中，影响结果的变量非常多。比如在经济学上，美国政府和研究机构公布的各种和经济有关的指标有上万个，试图根据几个指标就预测今后的趋势近乎不可能。在生物体中，情况更加复杂。经济学上的很多指标好歹还是明确的正相关或者负相关，而生物上很多体征和指标，同我们要找的疾病、遗传，或者新陈代谢的相关性是非常模糊的。在这种情况下，我们把相关性误解为有因果关系的必然性，是非常危险的。

但是，我们也不能因为很难确定必然性，就放弃对相关性的探究。只有当我们发现了影响结果的各种变量，并且搞清楚它们和结果之间的相关性，才能对最后结果的走向有一个全面完整的了解。比如，当我们知道了决定圆柱体质量的三个因素，即它的半径、高度，以及材料的密度之后，虽然每一个因素都不构成质量增加的因果关系，但是在不同场合，我们就知道该如何调整尺寸和选取材料来达到目的。

学术研究的主要目的，已经从过去那种寻找确定性，变成了挖掘尚未人知的，能影响结果的变量，并且寻找它们和结果之间的相关性。在研究某一个变量的影响时，我们通常要屏蔽其它变量的作用。比如我们研究体积和尺寸的关系，先要假定半径是不变的，才能知道高度的影响。但这样一来，绝大部分学术研究，特别是人文和社会学科的研究，都不得不集中在几个视角，搞清楚特定变量的影响。这并非研究人员缺乏全局观，而是整个学术界其实给他们的分工就是如此。今天很多学术专著，也是从特定视角看待问题。万维钢老师讲过一句话，人文和社会学科与自然科学领域的特点完全不同，前者更像是江湖，学者们彼此很难互相说服，这其实非常准确地描述了学术界的特点。了解了这个特点，我们在看学术专著时，就不要把它当作对某个结论全面的论述，而把它们当成是揭示某种相关性的著作就好。

### 黑板墙

数学定义的相关性。统计分析中，会用「相关系数」来衡量两个变量之间的相关性：这个系数在 [-1, 1] 之间，绝对值越接近 1，说明两个变量越相关；越接近 0，则越不相关；最常用的是「皮尔森（Pearson）相关系数」，当然还有其他不同的定义；但是它们都有一个共同的思想——「同涨同跌」正相关，「反涨反跌」负相关。然而「相关系数」只是一个量化的指标，给人参考罢了；有时候，可能两个变量很相关，但是算出来的相关系数并不大，甚至是 0 —— 可能是选错了相关性的「指标」，可能是复杂的「非线性相关」，可能是没有「控制变量」。总之，「指标」是会骗人的。但是，有一个指标，也好过没有指标的瞎猜。

然而，我们却无法用数学的纯理性，来定义「因果关系」—— 尽管我们本能地认为因果性更有意义。哪怕「相关系数」绝对值为 1，也可能毫无因果关系。最常见的情况，就是两个「变量」受着同样的「潜在因素」的影响。「冰淇淋的销量」和「被水淹死的人数」存在很大的相关性，其实是背后的「季节」、「气温」作用的结果。两个水平相当的学生，考试成绩会有很大的相关性，难道要说他俩作弊？哪怕存在因果关系，我们还有可能「因果倒置」。学习富人的一些行为只会让我们「显得有钱」，而不会真正变得有钱；很多行为只是有钱的结果。同样的，总结自己或别人的成功「经验」的时候，我们得到的原因，可能是成功的结果。

1『相关不等于因果。』

用函数理解相关和因果。「人是一切过往经历的总和」，说的是，此时此刻的你，就是之前你所有的经历的「函数」。「人如其食」（You are what you eat），你的身体状态，就是你所吃进去的所有食物的「函数」。而食物之于身体，就如信息之于大脑；正如「人如其阅」（You are what you read）—— 你大脑中的想法，就是你接受的所有信息的「函数」。昨晚上写完代码之后，脑子一片空白…… 难道要说，代码看多了，脑子要变傻？但我更愿相信只是困了 —— 看吧，其实「因果」更是一个主观的东西。

1、数学中的 x，y 是平等的。我们时长定性地认为 x 是自变量，y 是因变量，先有了 x 才能推出 y，实际上，x 表示自变量，y 表示因变量只是数学表达中的一种习惯而已，究其本质，x 与 y 是完全平等的。x，y 都是变量，两者的变化都会引起对方的变化，它们的变化是一一对应的，这也是上一讲我们强调的「对应关系」。稍微拓展一下，一个函数 y=2x 和另一个函数 x=2y，甚至 z=2t，w=2v 等等，全都是完全相同的。函数和它用什么字母表示没有关系，表示方式只是一种显性的工具，只要对应关系相同，他们就是相同的函数。

2、控制变量法。相信「控制变量法」这个词大家都是熟悉的，我们在中学物理课程中经常听到这个词。它和我们今天讲的「因果性和相关性」有着紧密的联系。比如：水的沸点（烧开的温度）与气压和其中盐的多少（浓度）都有关系。那么我们就说「水的沸点与气压和浓度都是相关」的。控制变量法是科学研究中最常用的研究手段，它的本质就是将相关性变成因果性。比如，控制气压这个变量为一个定值，改变浓度，这时浓度的变化直接会带来沸点的变化，浓度改变是因，沸点改变是果；相反，控制浓度不变，只改变气压这个变量，沸点的变化就可以归因到气压变化。但是试想：如果浓度变化的同时气压也变化了，这是沸点的改变到底是因为浓度还是气压呢？我们就说不清楚了。所以说，控制变量，也就是本节课说的学术研究只能集中在某几个视角，就是在将相关性变成因果性，只有这样的研究才能归因，才有意义。

因果性与相关性区别有以下八点：1）因果性是确定的函数关系，因此只能有一个自变量；2）当函数可逆时，因变量和自变量可以互换。在具体场景，因果性也可以互换；3）在一些条件下还可以互为因果，如鸡与蛋的关系；4）当变量很多时，只能说自变量与因变量具有相关性；5）相关系数是描述相关性的量度，位于 0 和 1 之间，相关系数越大，相关性越强；6）但是，相关系数为 1，也不能说明二者存在因果关系，如啤酒销量与纸尿裤销量；因果关系是逻辑先后的；7）采用机器学习，人工神经网络，可以对多因素，非线性关系进行学习，训练，从而实现预测，这是大数据的贡献；8）但要实现人工智能，还是要找到因果性，多变量的定量化的影响概率，条件概率等等，从不确定性中发现确定性，即主控因素，并量化它。

2『相关性和因果性，结合函数的知识，结合经济学的知识，写一篇专题文章。』

有句老话，「最了解你的人是你自己」，10 年前说，问题不大。现在再说，可能无法成立。对于一个正常使用互联网的现代人来说，在某些方面，计算机比一个人更了解他自己。借鉴一下海森堡不确定性原理（ΔxΔp>=h/2），`生活便利x个人隐私>=某个值`，在享受科技进步带来的便利同时，也泄漏出一些看似「无关紧要」的信息。但是，仅凭这些信息，就能计算出一些对个人来说很「敏感」的特征（比如性别、年龄、种族、智力、团队协作能力、暴力倾向、有无特殊嗜好等）。

说个流传比较广的早期例子，根据 facebook 上的点赞准确预测一个人的特点。其中关于智力的预测，和高智力相关度高的几个点赞的标题：Thunderstorms（雷暴） 、The Colbert Report（一个电视节目）、Science（科学）、Curly Fries（卷状炸薯条）。如果问一个人，听到高智力最先联想到的几个词，科学可能还能说出来，剩下几个，尤其是薯条的，概率基本为 0。很显然，喜欢薯条卷和高智力不存在因果关系，但是它们之间为什么会有很高的相关性？简单说，相关性来自点赞的「行为」而不是「内容」。人更倾向于和那些与他们有相似特性的人在一起。高智力人的朋友一般来说智力也比较高。最初发起「Curly Fries」页面或者最初喜欢的可能是某个高智力的人。人点赞行为的原因不一定是真喜欢内容，有可能是为了表达关系或者别的。随着社交媒体的传播，薯条卷在高智力人群里被喜欢的比例高于其它人群。例子里的相关性很显然不是因果关系，但是有些事情就没那么明显。如果仅凭相关性就做决定，可能会南辕北辙。

2『已下载论文「2020011Private traits and attributes are predictable from digital records of human behavior」，并存入 Zotero。』

自变量与函数之间存在着紧密的相关性，并且一方改变通常也会引起另一方的变化。这种强烈的「牵连」关系，有时候就被我们视为因果关系。但函数里的因果，与现实中又有很大的区别。函数的因果关系通常取决于我们的定义，到底是 y = e^x 还是 y = ln (x) ，要看我们想把谁当成自变量。但现实中的因果关系往往是单向的，比如很多动物在晨昏时分都会异常活跃，但反过来你却不能说，它们的活跃让太阳「移动」到了地平线附近。然而现实中因果关系的制约，又不仅仅是「方向性」这么简单；它往往不是直观的、必然的。就我观察，因果经常会以这样几种形式呈现：

1、概率的因果：即函数影响的不是结果，而是结果出现的「可能性」。例如癌症，我们用概率去描述其发生的可能性，并且评估不同的「原因」对这个概率的影响。比如吸烟、饮食不健康等会提高患癌概率，但提升概率最显著的，却是年龄的增长。

2、多重因果：核电站会有多道安全措施，出现安全事故，就肯定是所有的措施全都失效，原因不是单一的，而是复合的。现实中「概率」与「多重」经常一起出现，上述癌症的例子就是代表。

3、不同环境下因果的差异呈现：万维钢老师刚解读完《行为》这本书，里面一个例子就很有代表性：催产素通常被人和慈爱联系在一起，但催产素浓度高，有时却也会呈现更高的攻击性 —— 实际上，催产素能让我们更加区分敌我，在「自己人」这里展现慈爱，对待「敌人」则大胆攻击。实际上，因果的差异呈现，更应该被解释为若干不同层次的因果关系的叠加，有些层次是简单因果，有些则是多重的或概率的因果。

此外，在一些领域，我们甚至还需要评估，因果关系本身的可靠性，或者说是「函数关系」本身存在的概率。比如国际癌症研究机构（IARC）就将各种可能的致癌物，按照证据强度来分级。这个分级描述的，就是我们对「这东西能致癌」这件事有多么确定，至于致癌物到底能提升多大的患癌概率，则不在这个分级的讨论范围之内。

## 0403. 向量代数1方向比努力更重要是鸡汤吗

代数学除了给我们带来了方程和函数这两个工具，还揭示了世界上关于数字的另一个规律，就是数字的方向性。大家可能会说，数字怎么会有方向性，我们不妨先看两个例子。

第一个例子。假如你用 40 公斤的力来拉一个箱子，你的同事用 30 公斤的力来推，那么箱子受力是多少？你可能会说是 70 公斤啊，这是小学生学习完加法后给出的答案，但是如果他学习了减法，可能会想到如果两个人用力方向相反，那么就不是 70 公斤了，而是 10 公斤。但是如果两个人用力方向正好呈直角，或者 120 度角呢？这时合力既不是 70 公斤，也不是 10 公斤，具体是多少则取决于彼此用力的夹角。

第二个例子。某个建筑工地要实施爆破，爆破的半径是 120 米，你要赶快逃离。当然能走的道路未必是一个笔直的方向，你有几种选择。一种是先向北跑了 100 米，又向东跑了 50 米，这时你能逃离到安全区吗？如果你只考虑自己跑的路程，你跑了 100+50=150 米，超过了 120 米，但是由于你跑动的方向并非一个方向，你其实离爆破中心只有 118 米，还在危险区内。在另一种情况下，你先往北跑了 100 米后，再往东北跑了 50 米，这时你就离爆破中心 139 米，你已经安全了。最后一种情况，你先往北跑 100 米，再往东南跑了 150 米，这时一共跑了 250 米，却只离开爆破中心 106 米，可以讲是吃力不讨好。

这两个例子虽然是我虚构出来的，但在现实中类似的情况非常多见。我们常说，一个组织，必须形成合力，才能把事情做好，我们还说，一个人如果跑错了方向，再努力也没有用，就和上面两个例子所描述的情况相一致。因此，在这个世界上，对于大部分物理量和在生活中遇到的数量，我们不仅需要关心数值的大小，还需要关心方向。

物理中的力是如此，生活中我们行驶的路径是如此，一个人、一个企业做事的目标和所投入的努力，也是如此。当我们的知识和阅历增加时，认识水平也要相应地提高，特别是如果我们读完了大学，每次看到数字时就必须想一想，「是否考虑了方向？」否则我们就还是停留在小学生对数字的理解程度。

当然，相应的，在数学上也要有工具，来描述带有方向的数字，这种工具被称为向量。类似的，那些只需要关心数值，不关心方向的数量被称为标量。那么在数学上向量是怎么表示的呢？通常有两种表示法。第一种是用所谓的极坐标的表示方法，比如我们常说「前面 100 米，11 点钟的方向」，这就是在极坐标中对向量的一种描述。100 米代表向量的数值，我们通常称之为长度。11 点钟的方向，我们通常称之为向量的方向。在没有参照系的空中或者海上，通常采用这种方法。在世界上一些自然发展起来的城市里，也经常使用这种方式来描述方位，比如在巴黎或者莫斯科，就会以凯旋门或者红场为中心，往某一个方向行进一定的距离。用这种极坐标表示向量的方式在一些城市就不那么方便了。比如在北京或者纽约这种完全是规划出来的城市，街道是横平竖直的，高楼也挡住了视线，没有人会说往 10 点钟的方向走 400 米，因为你要去的点根本没有直通的道路。

实际上，北京和纽约横平竖直的街道本身就是一个笛卡尔坐标，人们通常会这样说：「往东 300 米见到红绿灯往南拐，再走 200 米就到了。」我们如果以所在地为原点，按照上北下南左西右东的概念来确定方位的话，往东 300 米，往南 200 米，目的地的坐标就是（300，-200），也就是说，我们直接用终点的坐标表示向量更有效。而那个目标点离我们的距离可以根据勾股定理算出来，是大约 360 米，和 X 轴的方位角是斜下方 34 度，这和我们用长度与角度的组合表示向量是一回事。我把这两种表示法画在了下面的图中。

通常我们在坐标系中用一个有长度、带箭头的线段表示一个向量。一般来讲，在笛卡尔坐标中我们喜欢将向量的起点放在原点，终点就是坐标系中的某个点，然后我们从原点往那个点画一根带有箭头的线段。不过向量的起始点不重要，重要的是起始点的相对坐标。比如从原点出发指向（a，b）点的向量，和从（10，10）这个点出发，指向（a+10，b+10）的向量，其实是一回事。

接下来，在给定坐标后，向量的长度和方向怎么计算呢？从图中你可以看出，从原点出发指向（a，b）的向量，其实就是以 a，b 为直角边的直角三角形的斜边，因此根据毕达哥拉斯定理，我们很容易计算出这个向量的长度 r 是 a 的平方加 b 的平方后开根号。当然，还可以用余弦三角函数的定义，算出这个向量和 X 轴的夹角。这两个值我也体现在上图中。

3『

[余弦定理 - 维基百科，自由的百科全书](https://zh.wikipedia.org/wiki/%E9%A4%98%E5%BC%A6%E5%AE%9A%E7%90%86)

余弦定理是三角形中三边长度与一个角的余弦值的数学式。当知道三角形的两边和一角时，余弦定理可被用来计算第三边的长，或是当知道三边的长度时，可用来求出任何一个角。余弦是三角函数的一种。它的定义域是整个实数集，值域是 [-1,1]。它是周期函数，其最小正周期为 2π。在自变量为 2nπ 时，该函数有极大值 1；在自变量为（2n+1) π 时，该函数有极小值 -1。余弦函数是偶函数，其图像关于 y 轴对称。

    c^2=a^2+b^2-2abcosß

』

如果我们对比一下极坐标和直角坐标对向量的表示方法，你会发现它们其实是一回事。不过在多维空间中，直角坐标常常更方便。比如三维空间中的一个向量，我们把起点定为原点，它就应该对应一个三维坐标（a，b，c），如果是 N 维空间的向量，就会对应 N 个坐标，我们不妨假设为（k1,k2,k3,……,kn）。

任何数量都可以做加减乘除的运算，向量也可以。向量的加法实际上很简单，如果一个向量是（k1,k2,k3,……,kn），另一个是（j1,j2,j3,……,jn），两个向量加起来，就是（k1+j1，k2+j2,k3+j3,……,kn+jn）。但是由于向量有方向性，向量的长度和角度，并不是原来长度和角度简单相加。

下面我们就用二维空间的向量，说说向量相加后的长度。我们假定有两个向量 V1 和 V2，它们相加后的向量是 V3，即 V3=V1+V2。那么 V3 的长度是多少呢？它遵循一个平行四边形法则，为了说明这个法则，我画了一个简单的图：在图中，V1 和 V2 是两个向量，我们以它们为两条边画一个平行四边形，平行四边形的对角线就是这两个向量之和。

平行四边形对角线的长度，我们可以用余弦定理算出来，这里我们就把公式省略了，转而讨论几个特例情况，这样大家更容易有直观的认识。为了方便起见，我只给出 V1 和 V2 长度相等的情况，而且假设它们都是单位长度，这时当 V1 和 V2 有不同夹角时，V3 的长度如下：

1. V1 和 V2 方向相同，那么 V3 的长度正好是两个向量长度的总和，也就是 2，这是最长的情况。

2. V1 和 V2 呈 30 度夹角，那么 V3 大约是 1.93，也非常长。

3. V1 和 V2 呈 60 度夹角，V3 是 1.73，就已经有点短了。

4. 如果 V1 和 V2 垂直，那么它们相加，V3 的长度正好符合毕达哥拉斯定理，大约是 1.4。

5. V1 和 V2 呈 120 度夹角，那么 V3 的长度只有 1，也就是说等于 V1 或者 V2 本身，这样两个向量叠加后在长度上并没有产生什么效果。

6. 如果 V1 和 V2 呈 150 度夹角，那么 V3 的长度只有大约 0.5，也就是说等于原来 V1 或者 V2 的一半。

7. 最后，如果 V1 和 V2 方向相反，也就是呈 180 度夹角，V3 等于零，也就是说 V1 和 V2 抵消掉了。

从这个结果可以看出，要形成合力就必须方向一致，即便方向不能完全一样，彼此之间方向的夹角也需要尽可能地小。如果两个向量的夹角超过了 120 度，那么两个力加起来还不如一个力的作用。理解了数量的方向性，我们就可以得到一个自然的推论，那就是做事情要聚焦。如果不聚焦是什么结果？你往三个方向使劲，每一次努力其实都是有成本的，但是很多时候努力相互抵消掉了。

一个单位里，特别是那些规模不大的创业公司，如果什么事情都想做，力量不仅分散，而且彼此会产生矛盾，作用就抵消了。即使没有太多矛盾，只要用力的方向不一致，效率就低。比如说如果两个人用力的方向是 120 度，也就是说有时候合作，有时候闹分歧，结果就是两个人工作只产生了一个人原来应有的产出。一些企业迷信把几个牛人堆到一起就能产生好的效果，这其实是小学生的思维方式。如果找来的人不能配合，有时越牛越有副作用。不仅多个人合作会因为方向不一致出问题，一个人自己努力，如果方向总是摇摆，也会出大问题，比如我们前面举的逃离爆破现场的例子中，方向来回换，特别是动不动拐大弯，其实最后是在兜圈子。

### 黑板墙

速度和方向。奇葩说选手艾力有句名言：一艘船在海中航行，如果没用方向，那么任何方向吹来的风都是逆风。今天这个世界，我们经历了太多追赶，看到了太多的年轻有为，造成一种三十岁还不成材这辈子就完蛋了的误解。知识城邦金句大王张潇雨老师说：「要记得，这个世界上并没有什么同龄人，平均值，社会标准。只有我自己，眼前事，脚下路。」

在我看来，每个人必然是不一样的，我们不能要求每个人都以同样的节奏和速度去趋于成功，如果你发现自己比别人慢，千万不要过分苛责自己，谁也没有规定非要在什么年龄干成什么事。在人生的道路上，比速度更重要的是找到自己的节奏和方向。确定了目标，就有了方向，剩下的就是按照自己的节奏，坚持下去！

任何人的成功经验都只能是借鉴，不能照抄，因为它不可能被复制一次。能评判我们对错的，只有我们自己。埋头追赶的时候，请不要忘记时常抬头调整节奏，修正方向。时常问问自己的内心，这是不是我想要的？我有没有被什么东西带跑偏了？一个不能自己掌舵的人生，跑得再快都是随波逐流。欲速则不达，就是因为没有停下来，好好看看方向。

向量的「加减」可以理解成位置的移动，那么，两个向量「相乘」会得到什么？在「内积」的意义下，会得到一个没有方向的数值。（公式见文末）那么这个数值代表什么？如果你还记得中学物理中的一个知识：一个「外力」对物体「做功」的大小，就是代表「外力」的向量与物体的「位移」向量之间的「内积」。只有这两个向量之间的夹角小于 90 度，外力才对物体的移动起到了「正面作用」（做功为正），否则，看起来在使劲，实际上可能起了反作用。

```
a*b = |a|*|b|*cos(a,b)，其中 |a| 和 |b| 分别代表两个向量的长度，cos(a,b) 代表 a 和 b 的夹角的余弦值。
```

同样的，如果眼下努力的方向，和真正的目标方向不一致，甚至「夹角」超过了 90 度 —— 你在消磨你自己。很多时候，焦虑来源于，将目光放在了「与他人的比较」上，而不是你真正的目标。为了克服这种焦虑，「别人会的我也要会」，拼命地学习各种「技能」，最后耗散了自己宝贵的精力，却可能完全偏离原先的轨道。疲于奔命，却从不停下思考：自己的努力，是因为「饿」还是因为「馋」。我们需要一颗「北极星」。时不时地抽身出来，计算一下自己努力的方向和「北极星」方向的夹角；同时，给自己的努力，打上一个「进度条」—— 它足以驱散我们的大部分焦虑和迷茫。

合力最大需要同向，信息最大则需正交。力学上，当两作用力 (a 与 b) 的夹角为 0 度，也就是同方向，合力的量值才等同相加 (a+b)；夹角为 0-90 度，合力则介于 (a+b) 与 (a^2+b^2)^0.5；夹角为 90-180 度，合力则介于 (a^2+b^2)^0.5 与 |a-b|。信息则不然，相同的信息使用两次，不会产生两倍效果，信息要找彼此垂直的。那么什么是正交的信息呢？信息能对应成某空间的一个 vector，两个信息代表的 vector 若是正交，则能提供最多信息、克服最多不确定。我们可以记住三个原则：1）不同信息要来自不同信息源；2）避免反覆使用相互包含的信息，别做无用的功；3）看问题要刻意从不同角度观察，若能找到相互垂直、不重复的角度最好。未来，当孩子们学习到向量的概念时，我会将力学与信息论这两者同时比较，让他们能做到横向学习、启发多元思维。

一个向量概念，简直打开了一扇新世界的大门。大门的另一端有无数美丽的世界，什么线性代数、矩阵论、人工智能、张量分析与场论、连续介质力学（…… 后面几个是不是硬核过头了），而向量就是这些世界里基础中的基础。​比如：

1. ​一个向量是包含大小和方向的量。它在空间里可以表示成一个有确定长度的箭头。比如你打羽毛球时候击球那一瞬间对羽毛球作用的力，就是个向量。

2. 如果引入坐标系的话，在三维空间的笛卡尔坐标系里，一个向量就可以写成​三个分量的形式。比如一个和 x 轴平行的单位向量就可以写成 (1, 0, 0)。你也可以把像这样随便并排列出来的三个数字当成一个向量。

3. 向量其实不用坐标系它就可以在空间中存在。我们人为的规定了一个坐标系以后，向量才在这个坐标系下有了三个分量。​那要是换个坐标系呢？它又有了不同的分量。这就是坐标变换了。所谓横看成岭侧成峰，转一个坐标系，同一个向量就变得它妈妈都不认识。

4. 那有啥是不变的呢？它的长度是不变的。这种在坐标变换下保持不变的东西，是我们认识向量的抓手。可以叫它长度，也可以叫它「向量的模」，或者「范数」。(准确来说是 2 - 范数)

5. 如果一个量不止包含大小，还包含两个以上的方向呢？那这样的量就叫「张量」​。机器学习里很多人听说过的 tensorflow，那个 tensor 就是张量。这可以认为是向量概念的一种「延拓」。二阶张量和向量一样也有不变量，区别在于向量的不变量是一个，而二阶张量的不变量有三个。

6. 那还有没有别的延拓方法呢？当然有。两个数字用括号括起来是个二维空间里的向量，3 个数字就是三维空间的向量；那 4 个数字并排呢？5 个、 6 个呢？延拓一下，n 个数字并排写在一起，也可以看成是「n 维空间中的向量」。这个东西别看它抽象，它已经在推荐算法里用了十好几年。

凡是能提到方向的一般都不是鸡汤，其主要差异在叙述角度的不同。比如在实际管理工作中，总会存在着几种带有方向的力量，即管理的矢量性。他们一方是管理主体发出的正方向的「管理力量」。而这部分力量传导到下面被管理者时，就会变成了两部分。一部分是管理客体的「服从力量」，另一部分则是管理客体的「非服从力量」。理论上这几种矢量对立统一，影响着管理活动的绩效、管理组织的和谐。但如果相互关系不和谐时：管理者就被会称为「没人性」；「服从力量」就会被称为「被洗脑了、打鸡汤了」，而「非服从力量」就是会被称为「不合群、破坏者」。所以，任何时候的观念差异，其实只是不同力量方向上对立。所以，人们需要改变的不是道德观，而是看问题的角度。

惠普曾是硅谷的象征，曾一度是 IT 产业创新的代名词。但如今的惠普正变逐渐变成一家越来越无关紧要的公司，根据管理学家的分析：惠普的创新能力和创新体系之间有一个非常大的冲突，一方面，惠普是一家很能创新的企业；另一方面，它也是一家没有创新体系只有创新行为的公司。虽然惠普一直在进行各种各样的创新，但它是一种「冒泡式创新」: 今天这个人冒个创新的泡儿明天那个部门又冒了一个创新的泡儿…… 整天就看见公司里在冒「创新的泡儿」，但最终，惠普没有一个创新能力。这就如同许许多多方向上向量的叠加，看起来花团锦簇，实际上互相抵消，不同向量想加的结果是 0。这还可以延伸到很多事情上：生活中不乏那种鬼点子特别多的人，他们谈起想法和创意来滔滔不绝，但没怎么下地做过实事儿，结果是想法很多并没有带来真正的认知增量；我们看到一家公司上上下下忙活得不亦乐乎，但大家的努力并没有往一处使，而是各自心怀鬼胎，最终公司倒闭了。

和朋友讨论企业的困境，两人的观点很一致，企业最大的麻烦不在外部，而是在内部。外部市场带来的挑战，都是有办法来应对的，只要内部能够团结一致，向同一个方向努力，总有办法找到出路 。但是团结一致这个前提，特别难实现。企业发展到一定阶段，人多了，想法也就多了。当企业没有一个能够凝聚众人的价值观时，大家就都会认为自己的想法更正确，都想按照自己的方向去努力。结果就像今天吴军老师说的例子一样，努力了半天还在原地打转。更有甚者，一些人能力虽然不小，但是所做的努力是有利于自己而对企业有害，这样的人一旦占据了关键位置，企业的前途就更渺茫了。不过昨天的聊天还是让给我看到了希望，在企业的里，总还是有一些人，有着正确的价值观，坚持做正确的事。有这样的人不断努力，并且越来受到重视，就还有希望。

## 0404. 向量代数2如何通过向量夹角理解不同维度

余弦定理大家在中学都学过，但我估计绝大部分人都忘了，因为你恐怕一辈子也没有用一次。这也不能完全怪大家，因为在中学里，我们教余弦定理时，主要是为了让大家知道在三角形已知两条边的情况下，如何计算第三条边的长度，而这件事在我们生活中几乎用不到。我们的教科书中，对于余弦定理其它的应用根本没有讲。今天，我们就从毕达哥拉斯定理出发，给大家定性地讲讲余弦定理是怎么一回事，看看它除了算三角形的边长外，还有什么用。我们先来回顾一下毕达哥拉斯定理。假如三角形的两条直角边是 a 和 b，那么斜边 c²=a²+b²。接下来我问大家一个问题，如果 a 和 b 的夹角是锐角，也就是比 90 度小，那么 c² 和 a²+b² 哪个更大？如果是钝角呢，也就是比 90 度大的角，情况又如何呢？这个问题其实我们画一下图就一目了然了。

从图中很容易看出，如果 a 和 b 的夹角超过 90 度，也就是图中蓝色的部分，所对应的斜边比较长，c² 超过了 a²+b²。如果不到 90 度，那么就比较短，c² < a²+b²。也就是说，对比一下 c²，以及 a²+b²，就知道夹角是什么样的角了。为了进一步方便起见，我们把毕达哥拉斯定理重新写一下，变成这样一种形式：a²+b²-c²=0，我们将等式左边的部分，也就是 a²+b²-c² 作为一个判定因子使用，我们用 𝚫 表示它。根据 𝚫 和 0 比较的大小，就可以判断夹角。具体的判别如下：判定因子小于 0 为钝角，等于 0 为直角，大于 0 为锐角。

如果我们回顾一下函数的概念，就会发现 𝚫 是 a，b，c 三个变量的函数。对于同样一个角，如果三角形边长都比较长，那么 𝚫 的动态范围很大。如果边长很短，𝚫 的动态范围就很小。为了消除边长的影响，我们将 𝚫 再除以夹角的两个边长（a 和 b）的积，这样可以保证处理过的 𝚫 的动态范围就在 - 2 到 + 2 之间。如果 𝚫=-2，那么夹角最大，就是 180 度。如果是 0，就是 90 度。如果是 2，就是 0 度角。当然我们还可以再除以 2，将这个值的范围规整为 -1 到 1 之间，事实上它就等于夹角的余弦。

这样一来，我们就从毕达哥拉斯定理出发，建立了角度判定因子 𝚫 和具体角度的关系，然后我们将这种关系称作余弦定理。余弦定理的思想最初出现在欧几里得的《几何原本》中，但是由于当时并没有成体系的三角学，因此并没有把这个判定因子和角度的函数用余弦表示出来。到了 15 世纪，波斯数学家贾姆希德·阿尔卡西正式提出了余弦定理。

今天，我们之所以花了不少篇幅讲解余弦定理的来龙去脉，是让你再次体会数学体系的重要性，因为它可以从已知的定理推导出新的定理。由此，我们可以体会各种数学概念之间的关联。当然这只是我们讲述余弦定理的附带目的，主要目的是介绍向量夹角的计算。回到向量夹角计算的问题，当两个向量确定之后，我们可以把它们的起点都挪到原点，它们各自的终点和原点之间，就构成一个三角形，如下图所示。这个三角形的三条边显然是确定的，由此我们可以算出判定因子 𝚫，然后根据余弦定理计算两个向量的夹角。

接下来的问题就是，算出两个向量的夹角有什么用？它其实有很多的应用，比如可以对文本进行自动分类。这两件事情看似不相干，怎么会联系到一起呢？下面我们就大致介绍一下计算机进行文本自动分类的原理。我们知道一篇文章的主题和内容，其实是由它所使用的文字决定的，不同的文章使用的文字不同，但是主题相似的文章使用的文字有很大的相似性。比如讲金融的文章里面可能会经常出现「金融」、「股票」、「交易」、「经济」等词，讲计算机的则会经常出现「软件」、「互联网」、「半导体」等词。假如这两部分关键词没有重复，那么我们很容易把这两类文本分开。假如它们有重复怎么办？那么我们就要看这两类文章中，各个词的频率了。根据我们的经验，即使在金融类的文章中混有一些计算机类的词，那么它们的词频不会太高，反之亦然。

为方便说明如何区分这两类文章，我们就假设汉语中只有「金融」、「股票」、「交易」、「经济」、「计算机」、「软件」、「互联网」和「半导体」这八个词。假设有一篇经济学的文章，这八个词出现的次数分别是（23，32，14，10，1，0，3，2），另一篇是计算机的文章，这八个词出现的次数是（3，2，4，0，41，30，31，12），这样它们就各自形成一个八维的向量，我们称之为 V1 和 V2。如果我们能够在八维空间中将它们画出来，你就会发现它们之间的夹角非常大。我算了一下，大概是 82 度，近乎垂直，或者说正交。由于这些向量每一个维度都是正数，因此它们最大的夹角就是 90 度，不会更大了。这说明两类不同文章所对应的向量之间的夹角应该很大。

如果我们再假设另有一篇文章，八个词的词频是 V3=（1，3，0，2，25，23，14，10），那么它和上述第二篇文章对应的向量的夹角只有 7.5 度。我用二维的坐标将这三个向量的关系大致示意如下。图中可以看出第一个和第二个向量的角度很大，而第二个、第三个的夹角很小。由此，我们大致可以判定第三篇文章应该和第二篇主题相近，也属于计算机类的。

接下来我们需要思考一个问题，什么样的向量之间夹角会比较小，什么样的会几乎正交呢？如果你对比上面三个向量，就会发现这样一个特点：当两个向量在同样的维度上的分量都比较大时，它们的夹角就很小。反之，当两个向量在不同维度上分量较大时，就近乎正交。比如第二个、第三个向量，它们在后四个维度分量值都较大，因此它们的夹角就小。而第一个向量在前四个维度的分量较大，在后四个很小，和第二个向量的情况正好错开，因此就近乎正交。关于向量的夹角，有两个特殊情况大家需要留心一下：如果两个向量在各个维度的分量成比例，则它们的夹角为零；如果一个向量在所有的维度都相等，比如像（10，10，10，10，10，10，10，10）这样的向量，它可能和任何一个向量都不太接近。这个性质我们后面还要用到。

当然，在真实的文本分类中不止这 8 个词，有 10 万这个数量级的词汇，因此每一篇文章对应的向量大约有 10 万维左右，这些向量我们称之为特征向量。通过利用余弦定理计算特征向量之间的夹角，我们就能判断哪些文本比较接近，该属于同一类。

向量不仅可以对文章进行分类，而且还可以对人进行分类。今天很多大公司在招聘员工时，由于简历特别多，会先用计算机自动筛选简历，其方法的本质，就是把人根据简历向量化，然后计算夹角。具体的做法常常是这样的：首先，它们会把各种技能和素质列成一张表，这就如同我们在做文本分类时会把词汇列成一张表一样，这个表有 N 个维度。对于不同岗位人员的要求，体现为某些维度权重很高，某些较低，一些无关的就可以是零。比如说对开发人员的要求主要是六个方面，权重如下:

```
编程能力 40
工程经验 20
沟通能力 10
学历和专业基础 10
领导力 10
和企业文化的融合度 10
```

对销售岗位的要求会有所不同。这样每个职位都对应一个 N 维的向量，我们假设是 V。接下来计算机会对简历进行分析，把每一份简历变成一个 N 维的向量，我们假设是 P。然后我们就计算 P 和 V 的夹角，如果夹角非常小，那说明某一份简历和某一个岗位可能比较匹配。这时简历才转到相应的 HR 部门，HR 人员才开始看简历。如果某份简历和哪一个岗位都不太匹配，这份简历就石沉大海了。这种做法是否会有误差，让一些好的候选人永远进不了 HR 人员的视野呢？完全有可能，但是这种概率并不高，因为计算机做的只是初步筛选，标准是比较宽的。

要知道今天像 Google、Facebook 或者微软这样的公司，一个职位常常有上百个求职者，最少也有十几个，合格的多则有十个、八个，少则有三五个，漏掉一两个合格的人，对公司来讲没什么损失。但是这对于求职者来讲，就是 100% 的损失。因此，除非有非常强的推荐，否则简历写得不好经常连第一关都过不了。

很多人在写简历时常犯的一个毛病就是重点不突出，他们所对应的向量其实就是一种每个维度数值都差不多的向量。我们在前面讲了，这种向量和其它向量的匹配度都不高。很多人喜欢在简历中把自己有关或无关，所有的经历都写进去，然后把自己描绘成全能的人，其实在计算机匹配简历和工作时，这种简历常常一个职位都匹配不上，因为这就像我们前面说的每个分量都是 10 的向量，和谁的夹角都小不了一样。很多人觉得多写点东西没坏处，这种认识是错误的，这些画蛇添足的内容其实稀释了求职者的竞争力。那么好的简历应该是什么样的呢？如果你在求职单位有熟人，不妨问问他们对某个职位的要求，然后根据这个要求写简历，这样在他们看中的维度你的得分就高，在他们根本不在意的维度，你也不需要强调。

### 黑板墙

为什么要用 𝚫 除以 2ab？简单说是为了将「判定因子」𝚫「规范」到 [-1, 1] 区间内。可是为什么偏偏要除以 2ab 呢？按照文中的符号表示，并且假设 a > b，c 为三角形的第三条边，它的长度范围只能在 a-b 到 a+b 之间。（可以由「两边之和大于第三边，两边之差小于第三边」得出）；那么 c^2 的取值范围就是 (a-b)^2 到 (a+b)^2 之间，展开就是 a^2 + b^2 -2ab 到 a^2 + b^2 +2ab 之间；于是「判定因子」𝚫 = a^2 + b^2 - c^2 的范围就在 -2ab 到 2ab 之间；将 𝚫 除以 2ab，这个范围自然就「规范」到了 -1 到 1 之间。本质上，判定因子的规范化，就是将不同的事物放到同一个尺度下进行比较，防止「作弊」。

用「投影」理解余弦值。想象面前有一个桌面和一支笔，桌面正上方有一盏灯，发出垂直向下的平行光线。将笔的一头固定在桌面，用手将笔的另一头慢慢提起，你会发现，这支笔在桌面上的影子逐渐变短，当笔与桌面完全垂直的时候，笔的影子变成一个点（长度为 0）。在笔头逐渐抬起的过程中，这支笔在桌面上的「投影」从它的「原始长度」变化到 0；而数学上，它与桌面的夹角逐渐从 0 度到了 90 度，对应的「余弦值」从 1 变到了 0。事实上，对于两个长度均为 1 的向量，二者夹角的余弦值（绝对值），就是一个向量在另一个向量方向上的投影长度。由于「余弦值」只与向量夹角有关，与向量的长度无关，因此对于任何两个向量，我们都可以想象它们的长度为 1，然后再应用上一句结论。

从真实世界到向量空间。事实上，向量的概念不只是「有长度和方向的箭头」，它更是「对现实事物的一种数字化编码」，是对真实世界的数学式刻画。除了文中提到的文本和简历，任何一类事物，都可以从中抽取合适的「特征」，表示成 n 维向量的形式。因此，每一个事物，都可以看成是 n 维空间中的点。（当然这个过程可能会损失很多信息）为什么要将现实事物表示成向量？因为计算机只认「数」。而一种合理的「向量化编码」，正是实现人工智能的第一步 —— 它相当于 AI 的「食物」。我们看不到的 n 维空间，却时时刻刻环绕着我们。假如我是 AI，那么我会看到一个怎样的世界？一切都是向量！

以前学习数学，将数学学习和数学应用是割裂开来的，学余弦定理时，觉得它的用处就是「知道向量长度求向量夹角」或是反过来「知道向量夹角求向量长度」，却从不知道「夹角的大小」可以作为两个向量「匹配程度」的度量。而世界上的一切事物，都可以由一个或几个特征维度构建成「向量」。这样，世界万物统一于向量，向量与向量之间靠夹角相关联，简直有一种「大一统」的感觉。我甚至感到，专门研究「向量空间和 n 维矩阵」的线性代数即将发挥的重要作用。这种冲动，让我想要再学一遍线性代数，重新认识一下这个学科，它一定不是原本那个教会我「怎么求行列式，怎么解线性方程组」的线性代数，而是一个可以「联系世间万物，研究各种事物之间关联性」的有力工具。对计算机科学知之甚少，但是吴军老师通过讲数学课，让我明白了一些计算机的工作原理，这就是数学这个基础学科在专业领域学科中的基石作用，也是为什么吴军老师在本课程最开始就说：「无论你的专业和工作是什么，数理化决定了知识结构能搭多高，在专业上能走多远，尤其是数学」。

一篇新闻里会有很多词，像「之乎者也的」这种虚词，对判断新闻的分类没有太大的意义。而像「股票」「利息」这种实词，是判断新闻分类的重点词。科学家精选了一个词汇表，这里面收录着 64000 个词，每个词都对应一个编号。他们先把大量文字数据输入计算机，算出每个词出现的次数。一般来说，出现次数越少的词越有搜索价值，比如「爱因斯坦」「数学之美」；而出现次数越多的词，越没有搜索价值，比如「一个」「这里」等等。根据这个标准，把词汇表里的 64000 个词都算出各自的权重，越特殊的词权重越大。然后，再往计算机里输入要分类的新闻，计算出这 64000 个词在这篇新闻里的分布，如果某些词没有在这篇新闻里出现，对应的值就是零，如果出现，对应的值就是这个词的权重。这样，这 64000 个数，就构成了一个 64000 维的向量，我们就用这个向量来代表这篇新闻，把它叫做这篇新闻的特征向量。不同类型的新闻，用词上有不同的特点，比如金融类新闻就经常出现「股票」「银行」这些词，所以不难判断，同类新闻的特征向量会有相似性。这样的话，只要算出不同新闻特征向量之间夹角的大小，就可以判断出它们是不是同一类新闻。这时就要用到余弦定理，来把两则新闻的特征向量之间的夹角算出来。科学家可以人工设定一个值，只要两个向量之间的夹角小于这个值，这两则新闻就可以判定成同一类新闻。一个简单的数学定理，通过科学家们的巧妙应用，再次举重若轻地解决了一个难题。

余弦相似度算法简单实用，但也有局限性。向量有长度和方向，余弦相似度算法关注的是 2 个向量方向间的差异，而不去管长度。这个直观上应该比较容易理解，随手画 2 条线（向量 a b)，使得它们的长度差不多，夹角很小。从几何上理解，向量 a b 很接近。按照余弦相似度，a b 也比较接近。如果把 b 的长度放大 100 倍呢？这时，它们的余弦相似度还是很高。但是从几何上看，a 和 b 就差得有些远了。

这样会导致什么问题？比如，针对不同的产品，不同的用户会打出不同的分。假设分值从 0-10（越高越好），用户 a 对产品 (i,j) 打分是 (1,2)，用户 b 对产品 (i,j) 打分是（9,10)。那么 a 和 b 在针对 (i,j) 的偏好上相似度是多少？按照余弦相似度的定义：

```
相似度 = (1*9+2*10)/(sqrt (1^2+2^2)*sqrt (9^2+10^2)) = 0.964
```

只看这个数值，a 和 b 应该是很接近的。但是实际上，a 和 b 的喜好是相反的。如何解决？考虑长度的影响。余弦相似度公式：

```
Σ(xi*yi)/(sqrt(Σ(xi^2))*sqrt(Σ(yi^2)))
```

只需要用 xi yi 分别减去对应的平均值，`xi'=(xi-avg (x)) yi'=(yi-avg (y))`，用 `xi'` 和 `yi'` 替换掉原来的 xi yi 即可。这种算法，叫调整余弦相似度。按照这种方式计算 a b 的相似度，假设 i j 在不同用户间的评分平均是 5，a 和 b 的相似度为 -0.968。

面对一个人、一篇文章，或者其他种种事物，我们经常会遇到一个难题，就是如何通过量化的方法，来对不同的对象进行科学分析。这个问题的难点就在于，研究的对象往往包含多维度的信息，而我们的选择决策，又要同时兼顾多元化与特定偏好。比如组建团队，既保证各种能力搭配均衡，也要让成员的性格能够相互协调。这时候，特征向量就是个很好的工具。打游戏的朋友可能见过，一些游戏里，尤其是在运动类与某些 RPG 游戏中，球员、角色、赛车等等，除了用丰富多样的参数来描述特点，也会给一张更加直观的「玫瑰图」。比如某款足球游戏里，就是以盘带、传球、射门、速度、身体、防守六个基本维度画了一张图，每个维度的能力，又是根据几个具体的能力值加权算出来的。想要某方面出众的球员，哪怕不去看具体的能力参数，看一看玫瑰图就能做出最初的判断。听完这一讲就知道了，其实在这两种工具之外，玩家对球员的筛选，还可以加入自己的偏好，去算一算具体球员与玩家需求之间的「夹角」。但是这里的玫瑰图也有缺陷 —— 更准确的说，这其实是我们在使用特征向量时应该注意的地方。比如还是这款足球游戏，六个维度的参数对不同位置或风格的球员，描述能力是不一样的。比如中场球员很容出现「六边形战士」，就可能看不出具体球员之间的差异；前锋的「防守」一栏基本没必要去看；对于门将，这张图更是几乎没有任何参考价值。这其实就提醒了我们，实用特征向量，选择关键的特征参数，并给出一个相对公平的标度至关重要。比如招聘的时候，明明想招一个文字编辑，却偏偏要对人家的颜值打分并纳入考评，这就是多此一举，反而会筛掉本来更可靠的应聘者。

信息与能量的不同，以及如何找到正交的信息。那么信息与能量的区别在哪儿？首先，相同的信息使用两次，不会产生两倍的效果。而能量可以，比如你反复撞门，门会被撞开。但是，你使用同一条信息后，第二次使用它就没有用了，你使用一万次，结果还是一样。其次，我们在做机械运动时，为了获得最大的加速度，用力的方向要一致（向量重合），而在利用多种信息消除不确定性时，所采用的信息是正交的（垂直的）时候，效果最好。

什么是垂直的信息呢？任何一种信息都可以对应到某个空间中的一个矢量，如果你把上述两种信息在空间中画出来，就会发现它们之间的夹角是 90 度，也就是说两种信息是正交的。也就是文中金融学和计算机科技的例子。比如：语音识别。语音识别问题其实可以被看成是一个 N 选一的问题，就如同猜测世界杯足球赛冠军那样。比如说汉语里大约有 1260 个左右的拼音读音，对每个音节的识别就是 1260 选 1 的问题。要消除这其中的不确定性，用到的最有效的信息是两类，第一类是所谓语音的信息，也就是说每一个读音和各种语音之间的相关信息。第二类是语言信息，也就是一种读音在上下文中出现的可能性。这两种信息就是正交的。

还有就是是名片的识别。就是把纸质打印的名片扫描一下，储存成电子信息，今天市面上大部分的软件识别率在 98% 左右，这其实已经很高了。但是总有 2% 左右的错误会发生的话，还是让人有点烦，因为总得手工更正。如果遇到懒人不检查就直接放进通信录，有时会搞错对方的电话或者邮箱。以前大家解决这个问题的思路比较单一，总是想着提高图像的识别率，虽然各种办法都想了，总是有些情况难以通过图像识别解决。2012 年，加州大学洛杉矶分校的一位华裔教授通过大数据的方法解决了这个问题。她能够将名片识别的准确率提高到 99.9%。她是怎么做的呢？说起来非常简单，就是把互联网上能找到的各个单位的信息找到，然后用那些公开的信息验证图像识别的结果。之前人们通过图像扫描得到的信息，和她从互联网上找到的信息，不仅属于不同的维度，而且是彼此近乎正交的。

那么怎么才能找到正交的信息呢？有三个原则。首先，不同的信息要来自不同的信息源。比如医生给你看病，会让你做血项检查和医学影像扫描，因为这两种也属于不同的信息来源。它们放在一起使用，信息带来的好处就可以叠加。第二个原则是，避免反复使用相互嵌套或者相互包含的信息，即使它们来自不同的来源，因为那些信息即便不完全相同，但是可能一个覆盖了另一个，或者相似性太高。比如简历中提供的都是相互覆盖的信息。比如最重要的两段工作经验本身已经证明专业能力了，还罗列了一大堆无关紧要的工作经历，以及可有可无的专业证书。这些对别人了解自己不会有更多的帮助。最后一个原则，看问题要刻意改变一下观察的角度，从几个不同的角度看。

余弦定理是揭示三角形边角关系的重要定理，直接运用它可解决一类已知三角形两边及夹角求第三边或者是已知三个边求夹角的问题。事实上，理解了余弦定理以及夹角的重要性，对我们的人生其实也有非常重要的意义。首先，我们应该认识到，每个人都有长处、也有短处，与其想尽一切办法补足短处，不如将自己的长处发挥到极致。对于大多数人来说，补短是一件难事，虽然有句老话叫做「勤能补拙」；但是，在现实世界中，勤奋和努力并不一定能够弥补短处。相反，发挥长处则是要容易得到。一个人做五件事都能得到 80 分，另一个人做其他事情都做得只有 60-70 分，而唯独在自己擅长的一件事情上能做到 100 分。后者往往比前者更能够在特定领域取得更高的成就。其次，理解了人需要扬长避短，我们在做人生规划的时候，就要找到那些和自身特长相关性较高的领域。在社会分工已经如此精细的今天，什么事情都想自己做、认为自己能够把每件事都做到做好的思维方式，已经注定是行不通了。对于个人而言，要做自己擅长的事情，也就是你所要做的事情和你的特长，两个维度之间的夹角要尽可能的小，这样才能够将自己的长处运用好、发挥到极致，从而提高成功的概率。

## 0405. 线性代数矩阵到底怎么用

我们讲了矩阵这个人们虚构出来的一种工具，利用这种工具，我们能够让计算从单个的，变成批处理的。矩阵有很多用途，我们只讲了一点点，从它的加法，我们可以理解核心矩阵和增量的关系；从它的乘法，我们看到了它在金融中的应用。要再次强调的是，将单个计算变成大批量处理，这是我们今天在信息时代要有的思维方式。

在结束本模块之前，我们要回答最后一个问题。为什么讨论矩阵运算这样问题的数学分支被称为线性代数？我们回顾一下矩阵和向量的乘法就知道答案了。在运算时，左边的那个矩阵里的数字可以被看成是一组常数系数，右边竖着的向量中的数字则是未知数变量，这样矩阵和向量的乘法就变成了一组线性方程。如果把它们画在空间中，就是直线、平面或者立方体，都是线性的，不会有任何曲线。因此涉及到这一类的代数运算被称为线性代数。当然，自然界中很多数学问题并非线性的，但是我们在解决它们的时候经常将问题近似为线性的问题，这样可以利用很多线性代数的工具来解决。有了解析几何以及代数的基础，我们就可以正式开始讲高等数学中最为重要的微积分的问题了。

如果你问一个大学老师，什么是高等数学的基础课？他可能会和你说，微积分和线性代数。对于一个非理工专业的大学生来讲，如果在大学里只学两门数学课，恐怕就是这两门了。微积分主要是训练我们的思维方式，而线性代数，大家在工作和生活中真的用得上。关于线性代数，我们其实已经讲了两讲了，只是我没有用这个名词罢了。我们讲的都是向量代数，它其实就是线性代数中最基本的内容。在线性代数中，用到的最多的概念是矩阵。矩阵是怎样一回事，它有什么用途呢？让我们先来看一个具体的矩阵：

\[ 
A = \begin{pmatrix}
3 & 2 & 5 & 0 \\
4 & 2 & 3 & 1 \\
-1 & 5 & 4 & 6 
\end{pmatrix}
\]

从这个矩阵中你可以看出，它无非就是把数字按照横竖排起来，每一行、每一列数字的数量都相等。比如上面一个矩阵有 3 行，每行有 4 个数，我们称这种矩阵为 3x4 的矩阵。了解了矩阵的形态，你可能紧接着就有一个问题：把数字这么横平竖直地排列起来有什么用？事实上，把数字这么横平竖直地排列不是原因，而是结果，矩阵产生的原因是向量的扩展。

1『矩阵是结果而非原因，是向量扩展的结果，是多个 N 维向量的简洁表示方式。』

我们在前面讲了，向量是横着的一排数字，每一个数字代表一个维度的分量。比如一个企业在招聘员工时把所有考核的项目总结为 N 个维度。每一个岗位对各种能力的侧重点就是一个 N 维向量，比如办公室部门对人的要求是能力、沟通、协作、健康四个维度，写成 V1 = (3, 2, 5, 0)。我们上一讲讲了，可以用它来算算和某个候选人的相似性。当然公司不仅仅有办公室一个部门，还有比如销售部门、研发部门，等等。每一个部门可能又有不同的岗位，每一个岗位的要求就是一个向量。于是，我们就会有 V2，V3，V4，……，VM。这么多向量如果把它们放在一起，怎么表示比较好呢？显然最直观的方式，就是把它们一行行排起来，这形成了一个有 M 行 N 列的矩阵。这就是矩阵的由来。

今天「矩阵」这个词无论是在数学上还是生活中都经常用，但是它在数学史上出现的时间非常晚，直到 1850 年才由英国数学家西尔维斯特（James Joseph Sylvester）发明，而构成它的向量其实出现的时间也很晚，是 1835 年才被提出来的。当然，你如果读一些文章会提到早在 3 世纪的时候，中国数学家就发明了矩阵的原型，类似的话日本人、意大利人和阿拉伯人也都这么说，但是那些所谓的发明和今天的数学发展没有半点关系。因为对于一个矩阵，不仅仅是把数字一行一列地排起来，更重要的是每一行、每一列需要能够被赋予特殊的含义，而且需要发明出一系列相应的计算，让这个工具能够解决很多问题。西尔维斯特所提出的矩阵则满足了这些要求。关于矩阵的运算有很多，我们接下来就介绍两种最简单的，即加法和乘法。

首先讲讲矩阵的加法。我们可以把一个 M 行 N 列，或者说 MxN 的矩阵想象成一个公司的 M 个岗位，每个岗位有 N 种技能。我们假设这个公司是一家跨国公司，它会对人员有一个总体上的要求，但是对于不同国家的员工在要求上也会有不同的调整，比如对英语水平的要求。我们把总体要求用矩阵 A 来表示，某个国家相应的调整用矩阵 B 来表示。那么矩阵 A+B，就是在某个国家具体的要求。为了直观起见，我们就假设矩阵 A 是上面那个 3x4 的。矩阵 B 也需要是一个 3x4 的矩阵。我们随便写一个 B 矩阵，比如像下图这样。当我们进行 A+B 时，只要把两个矩阵中相应位置的元素逐一相加即可，也就是说矩阵 A 加矩阵 B，会得到下面的结果。

\[ 
B = \begin{pmatrix}
0 & 1 & -1 & 0 \\
0 & 0 & 1 & 1 \\
-1 & 0 & 0 & 1
\end{pmatrix}
\]

1『两个矩阵相加，行数列数必须相等；把一个「调整变量」直接做成一个矩阵，这个思维以后会有应用场景。』

今天在生活和工作中，经常需要有相对固定的大的原则，以及针对各种情况的小的变动，这时候就需要有一个相对固定的核心，再加上一个增量，而不是复制一大堆，拷贝以后逐一修改。

相比矩阵加法，用途更大的可能是矩阵乘法。我们先来说说一个矩阵和一个向量是如何相乘，然后再扩展到矩阵和矩阵的乘法。我们来看一个实际的例子，假如第一家投资银行的股票基金、债券基金和高风险基金的回报分别是：7%、3% 和 10%，第二家投资银行三类金融产品的回报分别是 8%、2%、9%。当然，这些都是历史数据，只能作参考。你现在有 1 万元要投资，你是找第一家投行，还是第二家投行给你管钱呢？我们不妨把这两组数放到下面这个矩阵中：

\[ 
R = \begin{pmatrix} 
7\% & 3\% & 10\% \\ 
8\% & 2\% & 9\% 
\end{pmatrix}
\]

然后我们根据自己对各种投资的喜爱和对风险的承受能力，分别测算在不同情况下的回报是多少。比如在第一种情况下，1 万元按照上述投资类型的分配方式如下：7000、2000、1000。因为这 1 万元分到了三个维度中，我们把它写成一个向量，不过为了等会儿方便做乘法，我们将向量竖着写。

\[ 
P_1 = \begin{pmatrix}
7000 \\
2000 \\
1000
\end{pmatrix}
\]

这时，如果把钱交给这两家公司，总的回报就是矩阵 R 和 P1 相乘的结果，我先把结果给大家看看，然后再说说是如何计算的。

\[ 
R \cdot P_1 = \left( \begin{array}{ccc}
7\% & 3\% & 10\% \\
8\% & 2\% & 9\%
\end{array} \right) \cdot \left( \begin{array}{c}
7000 \\
2000 \\
1000
\end{array} \right) = \left( \begin{array}{c}
650 \\
690
\end{array} \right)
\]

1『竖着写成一列，是个关键点。要乘的只是一个向量时只有一列，如果要乘的是多个向量，还是得按矩阵的形式写（矩阵的每一列代表一个向量数据）。』

我们可以看到，第二家投行带来的投资回报更高。那么这两个数是怎么计算的呢？抛开矩阵和向量，这个问题其实也能算清楚。就以第一家投行为例，7000 元 7% 的回报是 490 元，2000 元 3% 的回报是 60 元，1000 元 10% 的回报是 100 元，加起来是 650 元。我们把这个式子列一下：

```
7%x7000+3%x2000+10%x1000=650
```

你如果注意一下上面的矩阵和向量，你会发现这就是矩阵第一行每一个数字，分别和向量的每一个数字相乘之后再相加。为了清楚起见，我把矩阵和向量中参与运算的数字用红颜色标了出来：

类似的，第二个结果 690，就是矩阵第二行和向量各个元素相乘后再相加的结果。当然，可能有朋友会说，这不就是算术中加权相乘后的连加吗，为什么要搞出矩阵这样一个工具？如果只有三个维度，可能不需要用矩阵，但是如果是 1 万维、1 百万维，人通常就想不清楚了，矩阵就非常直观，使用它既方便又不容易出错。我们可以这样理解矩阵和向量相乘，它是批处理解决问题的思路，而过去我们学的乘法和连加是单个解决问题的思路。

接下来我们再看另一种情况，假如你这时对风险的承受力比较强，愿意将更多的钱放在高风险、高回报的基金中。比如你按照 3000、2000、5000 来分配投资，我们把这个向量称为 P2，这时哪家的回报更高呢？我们再用矩阵和向量的乘法做一次，得到下面的结果。

\[ 
R \cdot P_2 = \begin{pmatrix}
7\%, & 3\%, & 10\% \\
8\%, & 2\%, & 9\%
\end{pmatrix} \cdot \begin{pmatrix}
3000 \\
2000 \\
5000
\end{pmatrix} = \begin{pmatrix}
770 \\
730
\end{pmatrix}
\]

你可以看出，这时第一家投行给的回报更高了。当然，你还可以尝试其它的投资方式，对应的向量就是 P3，P4，P5……

今天，你如果带着一大笔钱找到高盛或者摩根士丹利，问它们会打算怎么帮你投资，它们为你做的第一件事情就是根据历史数据，帮你推算出在不同的投资配比情况下，回报是多少，也就是做我们刚才做的事情。因此，如果你想在投行找工作，用到最多的数学工具就是线性代数中的矩阵运算。下面，我们把 P1，P2，P3…… 这些向量一字排开，其实就得到一个矩阵 P。我们可以写成下面的形式。

\[
P = \begin{pmatrix}
7000 & 3000 & \ldots \\
2000 & 2000 & \ldots \\
1000 & 5000 & \ldots
\end{pmatrix}
\]

注意，矩阵 P 的每一列，就是一个个向量 P1，P2，P3……接下来，我们就可以定义矩阵 R 和矩阵 P 的乘法了。我们把矩阵 R 和 P 中的第一列，也就是向量 P1 相乘的结果，放在结果矩阵的第一列，把矩阵 R 和 P 中第二列向量 P2 相乘的结果放在结果矩阵的第二列，以此类推。我们就得到了两个矩阵相乘的结果，它也是一个矩阵：

\[ 
R \cdot P_2 = \begin{pmatrix}
7\%, & 3\%, & 10\% \\
8\%, & 2\%, & 9\% 
\end{pmatrix} 
\cdot 
\begin{pmatrix}
7000, & 3000, & \ldots \\
2000, & 2000, & \ldots \\
1000, & 5000, & \ldots 
\end{pmatrix} = \begin{pmatrix}
650, & 770 \\
690, & 730
\end{pmatrix}
\]

在图中，我特意标红了第一个矩阵的第二行，和第二个矩阵的第二列，以及结果矩阵第二行、第二列的数值，因为红色的行和红色的列，元素两两相乘再相加后，就是结果矩阵中的那个结果。对于一般的情况，第一个矩阵中的第 i 行，和第二个矩阵的第 j 列，相乘相加，结果就是结果矩阵中第 i 行、第 j 列位置的数值。那么从矩阵和向量相乘，到矩阵相乘有什么好处呢？前一种情形我们可以理解为小批量处理，后一种则是大批量处理。

1『两个矩阵相乘，第一个矩阵的列数一定等于第二个矩阵的行数。结果矩阵的行数等于第一个矩阵的行数，其列数等于结果矩阵的列数。』

### 黑板墙

将多个数字排成一行或一列，我们得到「向量」。将多个「相同长度」的向量排列起来，我们得到「矩阵」：当我们考虑向量的时候，会用一个粗体字母（例如 a b）来「打包」向量里的所有「数字分量」。它们之间的运算，就好像是一个个「数」的运算一样，不过是遵循着另一套计算规则；同样的，当我们考虑矩阵的时候（通常用大写字母表示，如 A B），也会将它们看成一个个「数」，遵循着「矩阵世界」的运算规则。

有什么好处呢？当数据被一层层「打包」的时候，我们的注意力，就会更多的集中在「打包」后的「整体」上，而更少的注意每个数字分量之间的作用。这不仅仅有利于计算机的「批处理」，也更方便数学推导，排除细节上的干扰之后，数学家们就更容易纵观整体。程序员写代码的时候，也是将一个个小的功能「打包」成一个更复杂的功能，再将多个复杂的功能「打包」成一个更复杂的功能，层层封装…… 直到最后的一行命令，实现千万行代码 —— 这感觉像是，推倒了第一块多米诺骨牌。当我们欣赏一幅图片的时候，不会关注每一个像素点；当我们观看一部电影的时候，不会纠结于每一帧画面。当我们研究天体运行的时候，不会关注上面的尘埃；当我们探索星系的时候，不会关注执着于每一个天体；而当我们回答「宇宙起源」的时候，我们更在意的是，物理公式的推导……层层「打包」，让我们暂时忽略上一层的细节，关注当前的「局势」。

1『从数到向量到矩阵。一层层往上抽象，分层的思维。（2020-10-06）』

矩阵运算：矩阵的加减，就是简单的「对应位置的元素相加减」；矩阵乘法满足结合律：A (BC) = (AB) C；矩阵乘法不满足交换律：AB 通常不等于 BA；不是所有矩阵都可以相乘，只有「左边矩阵的列数」=「右边矩阵的行数」，二者才能相乘；矩阵的「除法」（其实严格意义上不能叫除法）条件更加苛刻，不是所有矩阵都可以当「分母」的，除非它「可逆」。

用矩阵刻画「关系」：有什么事物，是矩阵可以表示，而单用向量却很难刻画的呢？矩阵可以更方便地表示各个「对象」之间的「相互关系」。一个典型的例子，就是网络：每一个人就是网络中的一个「节点」，对两个相互认识的人，在他们之间连接一条「边」，于是形成了一个「社交网络」。如何表示？由 n 个人组成的网络，可以用一个 nxn 的方阵表示：先给每个人标上一个固定的序号（从 1 到 n），如果第 i 个人与第 j 个人相互认识，那么矩阵的「第 i 行，第 j 列」的位置就是 1，否则就是 0。从人类的角度，看到这样一个由 0 和 1 组成的矩阵，毫无感觉；而矩阵的表示对计算机却更加友好。AI 看不懂你画的思维导图，但它能读懂矩阵。数学世界里，矩阵只是一个个整齐排列的数字而已；它们能代表什么，就看我们的想象力了。

不得不说，矩阵有用最多的就是我们行业了，因为我所处的机器人行业，机器人运动学就是建立在矩阵的基础上。很多人问我，矩阵在机器人学到底有什么用，实际矩阵之所以有用，是因为它可以直观去表示机器人所处笛卡尔坐标系下位置和姿态（角度）。我们知道机械手负责搬运就是需要知道被搬运物体的空间位置和角度，所以翻译在机器人这里就表示机器人的位置矩阵和姿态旋转矩阵。所以矩阵在工程行业是一个很重要的数学基础！同样，游戏开发也会用到矩阵，一个角色的姿态和位置，也是通过矩阵去表示。

线性代数可以说是大学最重要的必修课之一，而理解矩阵则是学好线性代数最重要的一把钥匙。事实上，绝大多数人在学习线性代数的时候，只是掌握了矩阵的加法和乘法的运算规则，目的只是为了通过考试。其实，矩阵在我们每个人的工作和生活中一直扮演着不可或缺的角色，影响非常深远。比如说，对于制造业企业来说，需要对生产过程中产生的很多数据进行统计、处理、分析，而这些原始数据不仅纷繁复杂，更有可能涉及好几个维度。比方说某个企业生产三种产品，每种产品的单位成本都涉及原材料费用、人工工资、其他费用三个维度；这三种产品在春、夏、秋、冬四个季节的销量又各不相同。这个时候，我们就可以引入矩阵对这些数据进行批量处理；我们可以把三种产品的单位成本设置成一个 3×3 的矩阵，而把三种产品在四个季节的销量设置成一个 3×4 的矩阵。通过对两个矩阵做乘法，就可以 3×4 的矩阵；把每一行的数字相加，就是每一类成本的年度总和，而把每一列的数字相加，就是每一个季度的成本总和。当然，也可以非常方便的计算出企业一年的所有成本总和，企业的成本费用情况就一目了然了。同样，矩阵还被广泛应用于经济和军事领域，1929 年，希尔通过矩阵理论对信息传输进行加密处理，提出了在密码学历史上有重要地位的希尔加密算法。同样的例子在现实世界中还有很多，由此可见，数学应用的领域确实遍布我们生活的每个领域。可以说，掌握数学的思维方式，学会运用数学的工具，是我们每个人的必修课。

矩阵是个工具。一方面，对于大量需要进行相同操作的数据，考虑对数据进行向量化，利用矩阵来批量处理，效率比用循环的方式单独处理每一个要高。另一方面，如果一个矩阵非常大，运算和存储的成本（时间和空间）比较高，可以对矩阵进行化简。这里不得不提的是，SVD（Singular Valve Decomposition）奇异值分解。

1『同感，Python 里用 for 循环处理数据，借用第三方库 numpy 里的矩阵处理，后者的效率远高于前者。SVD 的细节去看原文或者找相关论文。』

三门数学分支：微积分、线性代数和概率论。数即一维的研究对象，向量即多维的点，矩阵则是由点组成的面。面则代表了现实世界，如影像由像元组成，视频由多帧影像组成，电路板由元器件组成，二维码由黑白块组成，等等。矩阵是现实的数学表达，也是研究现实的数学工具。一旦组成矩阵，就可以研究其特征：行列式、秩、迹、范数、特征值、奇异值等等，由此更能看到世界的本质。

简言之：方程组求解、图像变化检测、视频压缩等等都离不开矩阵这一工具。对我们的启发是：当从整体看待一个个目标时，要借助矩阵思维，每一个成员，每一项任务都有其坐标，不能孤立来对待。要从矩阵的特征值分析其特性，要从其特征向量看其方向。要抓住主要特征，要调整正确方向。看其平凡的数字，一旦排列在一起便赋予新的功能。对于每个人如何找到有价值的矩阵？即人生定位不仅仅看自己，还要看与你组成矩阵的其他人的排列。

想起谷歌方法论中的计算机思维之一，就是大数思维，这种批量处理的方式也只有计算机能完成，小批量，小维度，的确由人完成很简单，但是大数，大批量就不是简单想想就行了，回到无穷大无穷小那几讲，高低阶的无穷对于算法的影响也是巨大的。补充一些小知识：矩阵是一个表格，行数和列数可以不一样；而行列式是一个数，且行数必须等于列数。只有方阵才可以定义它的行列式，而对于长方阵不能定义它的行列式；两个矩阵相等是指对应元素都相等；两个行列式相等不要求对应元素都相等，甚至阶数也可以不一样，只要运算代数和的结果一样就行了；两矩阵相加是将各对应元素相加；两行列式相加，是将运算结果相加，在特殊情况下（比如有行或列相同），只能将一行（或列）的元素相加，其余元素照写；数乘矩阵是指该数乘以矩阵的每一个元素；而数乘行列式，只能用此数乘行列式的某一行或列，提公因数也如此；矩阵经初等变换，其秩不变；行列式经初等变换，其值可能改变：换法变换要变号，倍法变换差倍数；消法变换不改变。

谷歌 PageRank 网页排名算法就包含了矩阵相乘的具体运用。谷歌 PageRank 网页排名算法的核心思想，是一个网页获得链接越多，可信度就越高，那么它的排名就越高。具体思维过程如下：整个互联网当做一个整体来看待，就像一张大的图，每个网站就像一个节点，而每个网页的链接就像一个弧。用一个图或者线性代数的矩阵来描述互联网，这就将无从下手的网页相连问题变成了一个二维矩阵相乘的问题，并通过迭代，算出了网页排名。

将数字排成「方阵」，或者将线性计算引入这个数字方阵，看上去只是换了一种展示的形式，似乎「并没有什么不同」。但这种观点的背后，实际上是对「量级」的感知不够。像是矩阵运算这样的操作，实际上是在将一个简单的规则，套用到大量有规律的数据中，是一种对简单数据处理的批量操作；如果引入更复杂的规则，还能够实现更加丰富的数据处理。工作和生活中，一个很容易想到的用法，就是进行批量的加权运算与比较。我试着在 Excel 里做了一下，像是这样的矩阵乘法，如果用 MMULT 这样的矩阵函数，出来就是一下子的事情，但如果要手动输入线性计算的公式，不仅操作繁琐，大量操作还可能「手滑」出错。看似原理非常简单的一个工具，放在计算机处理大批数据的场景中，就能够实现计算机替代人力重复操作的过程。虽然发明矩阵工具的时候还没有计算机，但这个工具的确给当今的人类社会，带来了更多的便利。

2『 Excel 里的 MMULT 矩阵函数，以后去研究下，mark。』

线性代数在数学、物理学和技术学科中有各种重要应用，因而它在各种代数分支中占居首要地位。在计算机广泛应用的今天，计算机图形学、计算机辅助设计、密码学、虚拟现实等技术无不以线性代数为其理论和算法基础的一部分。线性代数所体现的几何观念与代数方法之间的联系，从具体概念抽象出来的公理化方法以及严谨的逻辑推证、巧妙的归纳综合等，对于强化人们的数学训练，增益科学智能是非常有效的。随着科学的发展，我们不仅要研究单个变量之间的关系，还要进一步研究多个变量之间的关系，各种实际问题在大多数情况下可以近似线性化，而由于计算机的发展，线性化了的问题又可以被迅速计算出来，线性代数正是解决这些问题的有力工具。线性代数的计算方法也是计算数学里一个很重要的内容。「以直代曲」是人们处理很多数学问题时一个很自然的思想。很多实际问题的处理，最后往往归结为线性问题，它比较容易处理。因此，线性代数在工程技术和国民经济的许多领域都有着广泛的应用，是一门基本的和重要的学科。

如果进入科研领域，就会发现，只要不是线性的东西，我们基本都不会。线性是人类少数可以研究得非常透彻的数学基础性框架。学好线性代数，我们就掌握了绝大多数可解问题的钥匙。有了这把钥匙，再加上相应的知识补充，我们就可以求解相应的问题。可以说，不学线性代数，我们就漏过了 95% 的人类智慧。非线性的问题极为困难，我们并没有足够多的通用的性质和定理用于求解具体问题。如果能够把非线性的问题化为线性的，这是我们一定要走的方向。

事实上，微积分「以直代曲」的思想就是将整体非线性化为局部线性的一个经典的例子，尽管高等数学在定义微分时并没有用到一点线性代数的内容。许多非线性问题的处理 —— 譬如流形、微分几何等，最后往往转化为线性问题。包括科学研究中，非线性模型通常也可以被近似为线性模型。随着研究对象的复杂化与抽象化，对非线性问题线性化，以及对线性问题的求解，就难免涉及到线性代数的术语和方法了。从这个意义上，线性代数可以被认为是许多近、现代数学分支的共同基础。