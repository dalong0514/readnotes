## 记忆时间

## 目录

0101你能做任何工作1文科生的反击软技能的时代

0102你能做任何工作2屠龙术的日常应用

0103你能做任何工作3机会网络

0104你能做任何工作4讲故事和刷经验值

0105问答选择文科理科的策略

0200生命三点零序言怎样正确地关心人类命运

0201生命三点零1大局观下的生命和智能

0202生命三点零2I与AI

0203生命三点零3AI的文明使命

0204生命三点零4令人困惑的大目标1

0205生命三点零5令人困惑的大目标2

0206生命三点零6意识ABC1

0207生命三点零7意识ABC2

0208生命三点零8那将是人类最后一个发明

0209问答努力就有收获不等于努力就能成功

0210问答换了木板船还是原来的船吗

## 0101. 你能做任何工作1：文科生的反击软技能的时代

2017-09-18

作为《精英日课》第二季的第一讲，咱们说自由技艺「liberal arts」。「自由技艺」这个概念我们在第一季讲过，有点类似于中国的「人文」教育，但是以我之见，这是「统治者」和「拒绝被统治」者的学问。

中国的有些「文科」专业，像金融和会计学，在美国算商科，不算自由技艺。美国大学系统的自由技艺学科，是指历史、政治、哲学、文学艺术这些大学问。智识分子认为这些学问有大用，老百姓觉得这些学问没啥用，今天我们就说说自由技艺的具体应用 —— 具体到能用来找工作挣钱。

八月份刚刚出版的一本新书，叫《你能做任何工作：「无用的」自由技艺的惊人力量》You Can Do Anything: The Surprising Power of a "Useless" Liberal Arts Education，作者是纪实作家乔治·安德斯「George Anders」。

用中国话说，这本书就是文科生就业指南。但是请注意，这可不是说文科生不好找工作，所以安德斯写本书帮他们找 —— 这本书说的是在今天这个新形势下，文科生其实更容易找到好工作。

过去理工科出身的人工资高，中美两国整个社会都比较崇尚理工科。而安德斯说，最新的调研数据显示了一个趋势，现在美国的就业市场中新创造的岗位中，文科生的优势越来越大。

从 2012 年到 2016 年，美国新创造了 1010 万个工作岗位，其中只有 5% —— 也就是 541,000 个岗位是在计算机相关的领域。就算你把所有和互联网、计算机相关的技术岗位加在一起，也不到 10%。

那么剩下的 90% 的新工作是什么呢？大部分都和「文科」有关系 —— 也就是需要和人打交道的工作。比如说「市场研究员」，新增了 55 万个就业岗位，四年增加了 30%，比程序员都热门。类似的还有咨询、教育、娱乐业等等，都不是纯技术的工作。

这其实是技术进步造成的。现在自动化程度越来越高，像计算机领域，它消灭旧岗位的速度和创造新岗位的速度几乎是一样快的，并没有增加多少新岗位。这个世界可能不再需要更多程序员了 —— 但是只要人工智能跟真人还有区别，就业市场就需要文科生。

文科生不但存活了，而且正在反击。

不过，这里所说的文科生，可不是那些只知道死记硬背考试知识点的人。想要抓住这波机会，你得是一个比较高端的文科生。 

### 1.1 什么文科才是好文科？

我以前认识一个美国人，他儿子考上了斯坦福大学，结果选择了学中文。我当时一听就觉得非常奇怪，美国根本不缺会说中文的人，你一个美国人中文学得再好又有啥用呢？结果过了几年，他儿子从斯坦福毕业，马上就在 Google 找到了一个很不错的职位。

这个现象非常有意思，学中文的人，为什么能在 Google 找到工作。这是因为美国的文科教育和我们设想中那种死记硬背的文科教育有很大差异。

比如有个男生叫乔希「Josh」，大学学的是人类学。这是一个非常冷门的专业，比较爱研究什么热带雨林中的原始部落之类。这样的专业，除了知道一些趣闻谈资，还有什么用吗？

乔希在大学的时候，有一天讲课的是一位女教授。教授带了一把指甲刀，当着学生的面剪下了自己的指甲，然后把剪下的指甲放在一张纸上，让全班同学传看。同学一看这也太恶心了。

这时候教授说，指甲还长在我手上的时候，你们都夸指甲好看，可是我把它剪下来，你们就觉得很恶心，这说明什么道理？说明同样一个东西，我们对它的评价并不完全是由东西本身决定的，而是和它所处的环境、文化这些背景条件有关系。我们研究人类学，就要学会理解同样的东西在不同的文化中意味着什么。

这就给了学生一个考察复杂世界的眼光。你学了人类学，就可能拥有一种比直来直去更高级的思维方式。

这就是自由技艺教育的价值所在：它培养的是解决复杂问题的能力。

比如乔希学到的一个技能，是他特别擅长听别人说话。哪怕这个人和他的文化背景非常不同，他也能理解这个人。

现在有很多人是技术盲，买了复杂的科技产品不知道怎么安装使用，他们可以找乔希。乔希毕业后的第一份工作是他开了个小公司，专门帮不懂技术的人用电子产品。他就把自己的人类学技能和技术结合在了一起，获得了一个很好的市场定位。

现在乔希已经进入人机交流领域，成立了一个公司专门帮企业设计网站和软件的用户界面，非常成功。

像这样的例子书中有很多，它们的一个共同特点是你必须把文科的见识和理工科的技术结合起来。比如说：

好奇心 + 大数据 = 市场研究

同理心 + 基因测序 = 基因咨询服务

文学创造力 + 互联网 = 社交网络经理……

你可以是个文科生懂点技术，也可以是个工科生同时攻读自由技艺，总之这种通才，是今天最需要的。

最重要的自由技艺能力是什么呢？其实就是我们曾经说过的「批判性思维」(Critical Thinking)。 

### 1.2 五种批判性思维

学术界和商界对「批判性思维」的定义略有不同，这本书说的是商界的定义。安德斯考察了各大公司中好职位的招聘广告，发现几乎所有年薪十万美元以上的工作岗位，都需要一定的批判性思维能力。安德斯总结，最值钱的批判性思维能力，大概有五种。

第一是探索新事物。

好的文科教育特别强调调研能力。并不是教授在课堂上讲什么，你考试的时候照着写就能得分 —— 你得能提出自己的观点。除了完成指定的阅读材料，你得会寻找新素材来证明自己的观点。这就要求探索新事物的能力。

如果没有人管你、没有人告诉你应该做什么，你能不能自主决定去探索什么？有这样的能力，你才能随时适应新局面。

第二是获得洞见。

给你一大堆各种各样、杂乱无章的信息，你能不能获得一个洞察。比如现在有一个商品在市场上的各种销售反馈，那你会不会判断这个商品的前景如何？这就是市场研究要干的事儿。

想要获得这种能力，也许你上大学应该选择的专业是……艺术史。

下面这幅画是法国画家马奈的《奥林匹亚》，描写一个裸体女性和一个黑人奴隶在一起。这幅画 1863 年刚出来的时候引起了极大的争议，你能给解读一下吗？

如果你能结合当时的历史背景，自己调研，把这幅画的来龙去脉弄明白，你就具备了市场研究的能力。

面对很多的信息，你知道选择哪些信息，忽略哪些信息。面对很少的信息，你也能像考古学家一样自己分析出来大量的见解。这就是功夫所在。

所以艺术史带给你的不仅仅是那些有关艺术的知识，更重要的其实是这种分析能力。有这样的能力，如果你去做个金融分析师，你就能从财务报表里发现一些别人发现不了的信息，在投资的时候就能够提供一个别人提供不了的视角。

第三是选择和决断。

按照事先定好的规则去完成一件事情，是非常简单的技能。可是如果现在根本没有规则，你能不能自己制定规则，带领别人完成任务？这就涉及到领导力了。你的判断可能会出错，但大量犯错的经验积累起来也是你的财富。 

我儿子今年上小学三年级。新学年刚开学的时候，老师并没有直接向学生宣布班级纪律，而是让学生们自行讨论咱们班应该有什么样的规则。学生们你说一条、我说一条，老师仅仅是把学生提出的规则分类、把类似的说法合并，最后总结出几条大家共同认可的规则，作为这个班的纪律。我看这就是培养判断力的一种非常好的方式。

第四是理解他人。

年薪十万美元以上的岗位，都会要求一定的团队组织能力，说白了就是你得会使用权力。想要使用权力，你就得知道团队中每个人都想要什么，人与人之间的利益冲突在哪里 —— 你得能理解人。

这种能力可以从文学作品中得来。多读些严肃小说，你就会分析每个角色的诉求、动机和利益所在，人物之间又存在什么冲突，冲突又是如何解决的。

如果你有这种能力，你就能理解自己的团队和用户。你知道不同的人对一件东西有不一样的看法，你能倾听和你相反的观点。如果你是一个产品经理，你就能很好地把用户、产品和工程师连接起来。

第五是影响力。

你能不能说服别人接受你的观点？首先你要能够清晰地表达自己，这和写作水平、演讲水平有关。其次你得有共情能力，想要说服一个人，最好站在这个人的角度说。

我们知道，「文法」可是从古罗马时代就在自由技艺「七艺」中排第一位。今天这个社会各种纷杂混乱的声音非常多，影响力就越来越重要了。

这五种批判性思维能力都是非常高级的能力。大学每年毕业那么多学习自由技艺的学生，不可能都具备这些能力。我们可以想见，并不是所有文科生的就业前景都很好。那么现在一个典型「文科生」的就业状况是怎样的呢？ 

### 1.3 文科生的职业生涯

安德斯这本书举了很多例子，我看几乎所有文科生的起点都比较低。如果你大学选择了政治或者哲学，就不要指望一毕业就拿到高薪。起薪最高的是工程师和学金融的。

但是如果你真的掌握了批判性思维的这些技能，你的后劲不可限量。

你可能会经历很多坎坷。一位学心理学的女性的经历很有代表性。她当初只有高中文化程度，丈夫是失业在家的军人，家中非常贫困。她在免费的社区大学偶然选了一门和心理学相关的课程，结果表现优秀，被教授推荐去了伯克利。毕业以后进了政府部门，工作几年有了经验出来加入一家公司，年收入达到十三万美元。因为对政治运作极其感兴趣，又回到了政府部门，现在身居要职，正在主导部门改革。

工程师技术好就行，文科生需要人生经验。年轻的时候多换几份工作，都是非常正常且有必要的，你要学会随机应变，才知道怎么在不同的工作中使用你的核心技能。

当前最好的一条路，就是把自由技艺和新技术结合。有人用 LinkedIn 上的数据统计发现，总体来说，自由技艺专业毕业的学生，在 Google、微软、Facebook 这些高科技公司找到工作的比例是 9%。但既然文科生的特长之一是人生经验，能不能找到这样的工作跟你是不是名校毕业关系不大。事实上，这份统计中名校毕业的文科生进高科技公司比例大概是 9.9%，而普通大学毕业的也达到了 7.5% 的比例，差距并不大。 

### 1.4 我的评论

现在你对「文科生」的印象是否有所改观了呢？其实咱们仔细想想，这个局面一点都不奇怪。复杂世界需要复杂的人才。

这几天网上流传一个程序员的悲剧故事，让人看了很难受。这个程序员技术非常厉害，做 APP 赚了很多钱，但因为和妻子闹离婚，竟然被逼得想不开而自杀了。如果他了解一些自由技艺的东西，有批判性思维的能力，怎么可能处理不好生活中最基本的问题呢？

在这个时代，你说你只想把技术做好，其他一概不管，那是不行的。你想过简单生活，但这个世界并不简单。如果你只能做一些纯技术的工作，赶上你这个技术热门的时候的确能挣很多钱，但你应该非常庆幸自己的运气好。

不会面对真实世界是危险的。这个世界归根结底，属于那些能处理复杂问题的明白人。

下一期咱们再讲几个具体的例子，说说为什么学习「统治者的学问」的人，真的正在统治世界。 

由此得到：1）在自动化技术进一步发展的情况下，使用技术的门槛越来越低，那么学习自由技艺的「文科生」就越来越值钱了。2）你的关键技能不是什么具体的专业知识，而是「批判性思维」的能力。3）最佳路线，是把自由技艺和新技术结合起来。

## 0102. 你能做任何工作2：屠龙术的日常应用

2017-09-18

《庄子》里有个典故，说有人花了三年的时间和无数金钱去学了「屠龙术」，但学成归来之后他发现白学了，因为现在已经没有龙了。
我们说的自由技艺，就有点像是屠龙术。古代学习自由技艺的都是贵族，现在这么多老百姓的孩子学什么政治学、国际关系，难道真的都去管理国家吗？显然不可能。

但这可不等于说学屠龙术没用。今天咱们继续说乔治·安德斯的《你可以做任何工作》。这本书里就列举了很多屠龙术在普通公司日常工作中的应用。

咱们讲三个真实的故事。 

### 2.1 研究国际关系的项目经理

有个女青年叫康诺利「Connolly」，在斯坦福大学学的是国际关系专业。康诺利选择国际关系专业可能是因为她喜欢到各国旅游，还喜欢政治。她高中的时候就作为学生代表去过很多国家参加活动，还在奥巴马竞选阵营里面当过志愿者。上大学期间，她到南非待了很长一段时间，学了当地的语言，还做了各种调研。康诺利特别擅长理解各国的文化，能跟完全不同文化背景下的人打交道。

像这样的人才，能干什么工作呢？她最初的成功，是在 WikiHow 做项目经理。WikiHow 有点像是中国的百度知道，用大量教人干这干那的文章从搜索引擎获得流量，然后靠广告赚钱。

康诺利负责的项目是把 WikiHow 弄成多语言版本。公司已经拥有大量英文文章，但是不知道怎么用低成本的方法把这些文章翻译成其他语言，特别是一些第三世界国家的语言，比如说印度尼西亚语。

最廉价的办法显然不是在美国找会印尼语的人，而是去印尼找会英语的人。康诺利到各个国家找当地的人来翻译 WikiHow 上的文章，她的国际关系技能还真用上了。哪怕是完全不熟悉的文化环境，康诺利也能迅速识别每个人到底能干什么，到底想要什么，然后和这些人谈判。比如亚洲文化尊敬年长的人，她见到年长的人就会给足够的礼敬 —— 但同时还有办法让他们完成该干的工作。

国际政治还教会了康诺利变通的智慧。最初，公司的设想是找一些当地精通英语的人来翻译。结果康诺利发现，很多英语好的人写作能力并不怎么样。她发现最好的办法是找那些英语水平一般，但是擅长用本国语言写作的人。其实 WikiHow 上的文章本来就挺简单，英语不用太好也容易理解。

在印尼，康诺利先是从首都雅加达招了一批人。她把这些人分成两组，一组负责翻译，一组负责编辑。结果两组人合伙骗她 —— 负责翻译的人用 Google 的自动翻译系统随便翻译了一下，然后负责编辑的人居然就给通过了。康诺利马上想到应对的办法，她开除了雅加达的团队，去了印尼一个边远省份的二三流大学，雇大学的师生来干这个活儿，结果这些人干的特别认真，翻译质量很高。

所以有些事儿你不到现场了解就做不好。各国文化要求不同的文章内容。中东地区禁止饮酒，阿拉伯语版中就不能有《怎样在自家酿造伏特加酒》这样的文章；俄罗斯禁止大麻，俄语版中就不能有有关大麻油的内容。那像《怎样第一次亲吻一个女孩》这篇文章怎么办呢？有个埃及人认为阿拉伯世界不可接受这样的文章，但中东的一些女孩反而表示这样的文章可以有 —— 康诺利真的得像一个外交官一样协调这些事情。

事实证明项目经理这个工作非常适合自由技艺专业的人。在过去十五年内，全世界项目经理的岗位增长了 500%！ 想要干好项目经理，你得有批判性思维能力，有跨学科的见识，还得擅长处理人际关系。 你能不能协调好自己的团队，能不能从外面获得帮助？

当然项目经理也得有点技术，不过技术不是关键。康诺利刚到公司的时候连 Excel 制表软件都不怎么会用，但是 Excel 能有多难？康诺利现用现学上手很快。对一个连国际关系都能摆平的人来说，这都不叫事儿。 

### 2.2 IBM 的社会学家

我们知道 IBM 是个高科技公司，专门做一些软件、人工智能、技术支持之类的事情，但是它也雇了很多学自由技艺的人。

比如有个叫米克「Meeker」的人，学的是社会学，但不是名校毕业。米克的特点是实地调研的能力非常强。

还在上大学的时候，导师就建议米克去越南待半年，研究课题是越南革命。米克到了越南，很快就学会了越南语，能跟当地人自由交流，然后他就决定留在越南再干几年。当时有很多西方公司在越南开设业务，米克就帮这些公司去搞商业谈判、促成和当地公司的合作。他既了解越南文化，又了解西方文化，工作做得很好，两头通吃，很快就出名了。

事实上，你把上面说的「越南文化」改成「人工智能」，米克的工作模式也行得通。

所以他就被 IBM 挖过去了。最初 IBM 让米克负责给自己的人工智能项目「华生」联系商业合作，后来 IBM 看上了区块链概念，专门成立了一个部门推广区块链业务，米克就被调到了这个部门。

区块链，是一个技术性非常强的东西，热门归热门，但是一直到现在能真正把「什么是区块链」这个问题给解释清楚的人也很少很少。

IBM 想建立一个区块链商业圈，急需能向任何商业人士解释区块链的人。米克就是这个人。

米克不但能在短时间内学会越南语，还能在短时间内理解区块链。他把从 IBM 能找到的所有有关区块链的资料都读了，了解了全部细节。不论你是想听概念还是想听技术，米克都能给你说明白。

比如说，这本书的作者安德斯并不懂技术，所以米克是这么给安德斯解释区块链的 —— 

区块链的本质是信任。在原始村落里，邻居种粮食你家养猪，那他家的粮食是怎么种的你非常清楚，你家的猪是怎么养的他也非常清楚，你们两个搞商品交换肯定互相都放心。但是在现代社会，你要买有机的三文鱼，那你怎么知道这个三文鱼是不是真的有机食品呢？鱼是在哪儿打捞的，怎么运输，到你手上的时候经历了哪些人的转手，你无从得知，所以你没有信任感。

区块链就能解决这个问题。区块链把有关这条鱼所有相关的生产和运输信息都记录下来、然后以去中心化的形式存储，谁也没法删除改动，那么人们就能充分了解整个供应链的所有情况。

有了这个介绍，你大概就已经对区块链有点概念了。如果你还想了解技术细节，米克还能给你讲细节。

这就是社会学给米克锻炼出来的能力。能调研、能学习、还能表达。米克的原则是讲任何东西都要考虑听众的视角，只有充分理解听众，对谈话背景非常敏感，你才能把这个工作做好。 

### 2.3 投资界的哲学家

我们熟悉的《黑天鹅》《反脆弱》这两本书的作者纳西姆·塔勒布有个身份是期权交易员，他赚了很多钱，但是因为书写得太好，人们更愿意把他当成一个哲学家。金融大鳄索罗斯是哲学家卡尔·波普的弟子，也希望被视为哲学家，但是因为金融玩得太大，人们还是把他当成一个交易员。

这个要点是有很多搞金融的人其实是学哲学出身的。创始人、高管、普通员工都有。今天如果你是哲学系的毕业生，去华尔街找工作的时候你会有一种亲切感。

安德斯重点讲的人物是卡尔·伊坎「Carl Icahn」。伊坎是那种发条推特就能影响苹果股价的人，个人身价是 170 亿美元。

伊坎喜欢的商业模式是收购一个很有潜力但表现并不好的公司，重组这个公司，告诉管理层应该怎么改革，改好了再卖掉。

伊坎以前就是学哲学的，哲学跟这种工作有什么关系呢？伊坎说，哲学的一个智慧，就是看你在混沌不明的情况下能不能做出自己的判断，在互相矛盾的情况下能不能正常行事 —— 这其实是咱们精英日课专栏说过多次的道理。

收购一个公司之后，伊坎对管理层的重组改革，就运用了这个精神。

安德斯在《华尔街日报》当过记者，他跟伊坎有过很多次交流。伊坎有一个很重要的特点，就是他总要跟人解释清楚他为什么要这么干。他先说一遍自己的改革意见，再说一遍那个公司管理层的不同意见，然后还要解释一下为什么管理层错了，管理层缺少了什么关键信息才犯了这个错误。

伊坎善于转换不同的视角来看一个问题。他坚持自己的观点，同时又尊重别人的意见。

这就是一种哲学家气质。关键词是「矛盾」！哲学让你学会适应矛盾。

再比如说，排名很高的风险投资者中，有很大的比例的人以前都是学习跟金融没有关系的专业，其中学哲学的人有很多。其中有个投资者是这么说的：

想要做一个成功的投资者，你得同时拥有两个素质，这两个素质看似是矛盾的。首先，你要非常有主见，你一定要相信自己这个投资能成功，你才敢干。第二，你还要有一个开放的头脑，能够随时接受新的信息，勇于推翻自己之前的决定。既要坚持、又要改变，很矛盾，典型的哲学家气质。

这个道理我们在第一季专栏中《风险投资人的养成》这期节目提到马克·安德森的时候，也说过。 

自由技艺是统治世界的技术，现在你看，这些自由技艺专业的毕业生虽然没进政府部门，但是真的正在统治世界 —— 至少也是在运转这个世界。

当然他们可不是一毕业就能统治世界。考察美国刚毕业 5 年的各专业平均工资排名，排第一的是计算机，平均年薪 63,500 美元，前几名都是实用的技能，而哲学专业平均年薪只有 44,700 美元，往后是政治、历史、英语、心理学专业，一年只能挣三四万美元。（表一）

但是你考察那些毕业 10 年到 20 年这个区间的各专业收入，学自由技艺的人的工资水平就逐渐增高。排最前面的还是计算机，平均年薪 111,000 千美元，但这时候学哲学的达到了 84,000 美元，学政治学的是 79,900 美元，已经分别排到第三和第四位。（表二）

然后你再考察各专业最成功的人才一生的总收入，前十名里面第一位就是政治学，一生收入 481 万美元；第二位是历史，375 万美元；哲学排第四，346 万美元。（表三）

这就是自由技艺的后劲。你的起薪不高，但是如果你学到了真本事，最后一定会拔尖。

### 2.4 我的评论

我对中国的文科教育不太了解，但我感觉如果你学的是人文学科，那么学习大概有三个层次。

第一层是「学事实」。你得记住哪个年代发生什么事儿，哪个皇帝有什么政策之类。

第二层是「学观点」。比如怎么评价太平天国运动，甚至各位名家的观点，你得知道。
 
这些事实和观点，固然是必备的专业素质，但是如果你毕业以后就不搞这个专业了，它们就只是谈资而已。

第三层，是「学方法」。你能不能直接考察一下当时的原始材料，比如说太平天国相关的经济数据，清朝大臣的什么奏折之类，从中得出自己的观点，还能说服别人接受你的观点。这才是批判性思维，这才是真正值钱的技能。

试想一个掌握了批判性思维的人，如果还能钻研一点最新的科技，他怎么可能找不到好工作呢？ 

由此得到：1）表面上看毕业以后都改行了，但实际上学哲学的人的确靠着哲学气质，学社会学的人的确靠着社会学修养，学国际关系的人的确运用了国际政治手段在做事。他们把软技能和具体的公司业务结合在一起，都取得了成功。2）但是话说回来，怀才毕竟不是怀孕，软技能很难体现在大学成绩单和简历上。那你怎么才能让别人知道你有这些技能呢？咱们下次再说。

## 0103. 你能做任何工作3：机会网络

2017-09-19

我小时候我爸经常跟我讲一个理论：文科的主观性太强，你最好钻研理工科的硬功夫 —— 你的水平是明摆着的，谁当权都得用你，跟政治立场没关系。我觉得我爸说的很有道理。这大概也是学理工科的人共同的道路自信。我有技术，这是硬功夫，是我在世界上安身立命的关键。

有道理是有道理，但是当你考察真实世界的时候，有时候你觉得可能还有别的道理。

比如说，苹果公司的工作肯定都是好工作，工资很高，而且很有成就感，相信大多数工程师都想有机会去苹果工作。我们可以想象，苹果公司录用人的要求肯定是非常严格的，能进苹果的大概都得是名校毕业生吧？

有人拿 LinkedIn 上的数据统计，发现苹果公司员工的毕业院校中，排名第一的，是圣荷西州立大学「San José State University」，一共有 1484 个人；排名第二是斯坦福大学，有 250 人。

这就很有意思了。圣荷西州立大学是个声望很一般的学校，申请这个大学很容易，录取率高达 63%，它的生源跟名校没法比。那为什么圣荷西州立大学有这么多学生能进苹果公司呢？

答案非常简单，因为圣荷西州立大学就在苹果公司旁边。大学生平时跟苹果公司接触很多，做个实习生，开个技术研讨班，大家交流方便，互相之间都认识。

所以这个世界并不是一条直线，谁学习努力谁就去好学校，谁去好学校谁就获得好工作，谁工作好谁的收入就高……不是这样的。 除了个人奋斗，还有一些别的变量能左右你的命运。有时候在正确的时间出现在正确的地点，就可能是你成功的关键。

那怎么样才能在正确的时间出现在正确的地点呢？也许关键是你认识正确的人。

今天我们继续说安德斯的《你可以做任何工作》。这是一本非常实用的书，作者的本意是写一本文科生的找工作指南。但我们也可以用一个社会学的视角读这本书，看看这个世界到底是怎么运行的。

我们知道自由技艺的技能是「软技能」，像批判性思维，一个人的水平高低很难用一个客观的硬指标衡量。也许两个毕业生的成绩单差不多，但是实际水平能相差很多。所以「文科生」找工作最好的办法是面对面交流，让人充分了解你。最理想的，就是得到一个机会直接跟公司的高层谈。高层很多就是出身于自由技艺专业，他们更懂得软实力的价值。

问题是怎么获得这个交谈的机会。对于那些特别厉害的公司，大多数求职者在递简历这一步就被淘汰了。

你可以让大学老师推荐，你可以参加所在行业的会议去跟相关的公司接触。但最有效的办法，是找一个中间人，让他把你引荐给这个公司。

这就是一个有点矛盾的局面。自由技艺是研究人的学问，是个特别讲个人关系的领域。古代学习自由技艺的都出身于社会顶层，他们根本不差关系。可是现代有大量老百姓的孩子学自由技艺 —— 特别是有很多第一代移民的子女，本来想当个医生，一上大学就被政治学给吸引了，而他们的家庭并不能提供太多社会关系支持。这些人找谁引荐呢？

安德斯说，最理想的中间人，是你所在大学那些已经毕业多年，现在在社会上混得比较好的校友。

里德学院「Reed college」有个毕业生，是个女孩，在毕业后的一年内什么都不想干，跑到日本的一个海岛上过了大半年与世隔绝的生活。后来她过腻了，就想回美国找个工作。

她什么人都不认识，就在网上乱找，发现耐克公司正好有一个职位，自己很感兴趣。但是她对这个职位几乎是一无所知。

那她怎么办呢？所幸的是里德学院有个校友网，大约相当于 BBS 之类的社交网络。女孩就发了一个帖子，说我想找耐克的这份工作，请教诸位师兄师姐有没有谁了解这个职位的情况，任何信息都可以。

校友是愿意帮校友的，谁都希望自己学校的势力越来越大。结果这个帖子有十几个人回复。有人说我知道耐克会在面试的时候会问你什么问题，我可以给你讲讲。有的说我认识耐克一个比较高层的人，我可以把你介绍给他，你直接跟他联系。

对新人来说，这种内部信息可太重要了。耐克公司的日常企业文化，有什么工作偏好，这些并不是保密信息 —— 但你不知道就是不知道，可能会觉得非常神秘。有个内部的人给你讲讲，你在面试的时候就能获得很大的优势。有人给你指引一下，你就比别人更容易获得面试机会。

里德学院这个女孩最终得到了耐克的工作。我觉得这件事特别有意思 —— 你说这公平吗？这是不是腐败呢？我们设想耐克大概不会给她什么加分照顾，但她的确得到了一个有点不公平的机会。

这种不公平的机会，大概是校友网络最重要的两个作用之一 —— 另一个作用是给号召校友给母校捐款。

美国大学非常非常重视校友网络。有的大学会主动邀请毕业多年的校友回来搞活动，给毕业生讲讲相关行业的机会和经验，这种见面会每年要办很多场次。里德学院用的那种校友网络系统，现在是一个专门的、供各大学搭建校友网络的工具，叫 Switchboard。

有人调查，美国 46% 的毕业生在找工作的时候重点使用了校友的关系，安德斯认为这个数据还应该继续提高 —— 而在我们中国人看来，这已经是一个惊人的数字！

我们中国的文化是讲关系的，但中国毕业生找工作，怎么会这么大规模地用校友的关系，恐怕更多的是让家人和朋友帮忙。其实那些比你早毕业几年的校友，在你进入社会的过程中能起到的作用可比「同学会」、「同乡会」重要得多。

安德斯的建议是，毕业生找工作，你应该用 30% 的时间去寻找工作机会，做做纸面上的调研看看哪个公司在招人；用 10% 的时间去制作和投递简历；然后剩下这 60% 的时间，要全部用来搞社交 —— 去跟校友联系，去认识外面的人。 

### 3.1 我的评论

美国人说的这种校友网的关系，英文是 connection 或者 network，我觉得它跟中国人说的「关系」可能不完全一样。网络连接主要是信息上的交流，无非是现在有个什么内部信息你告诉我一声，或者你把我介绍给谁谁。 校友网其实是个信息网，或者说「机会网络」。

而「关系」，则更多的是「人情」上的往来。如果一个毕业生是动用「关系」获得职位，可能是他的水平不够，受到了特别的照顾。以前我欠你一个人情，现在我还给你。关系网是个人情网。

机会网络在不怎么熟悉的人之间就能有效运行，而「关系」则在熟人之中运行。可能正因为有这样的区别，英文里提到中国式关系，有时候并不翻译成 connection 或者 network，而是直接写成汉语拼音，guanxi。

现代社会是陌生人世界，大家为了共同利益在一起合作，为了人情而录用一个人的情况可能会越来越少见，所以机会网络应该慢慢取代「关系网」。

有人说美国人干什么都是公开公平公正，有的人说美国人也讲关系搞腐败 —— 我觉得更准确的说法是美国人不是特别讲「关系网」，但是把「机会网络」几乎给系统化了。校友网络、推荐信、公司员工的「内推」，这些都是制度化的鼓励用「自己人」。

这种做法提高了信息交流的效率，有个自己人推荐总比胡乱找个人强。但是从另一方面来说，这对机会网络之外的人非常不公平。

也许「公平」只是一种美好的幻想。在一个公平的世界里，这个人不管是谁、不管是哪个大学毕业的、不管他认识谁，只要他有能力就有机会 —— 而真实世界显然不是这样。现实就是这么个现实，你不服不行，只能尽量扩大自己的机会渠道。 

由此得到：1）校友网络在美国大学毕业生找工作的过程中起到了重要的作用。软技能比硬技能更需要机会。2）那么假设现在你有一个机会跟某公司的高层交流，你应该说些什么呢？咱们这个系列还有最后一讲。

## 0104. 你能做任何工作4：讲故事和刷经验值

2017-09-20

今天是安德斯的《你可以做任何工作》这本书的最后一讲。

这本书是一本非常实用的书，今天说的其实是找工作的面试技巧。不过我还想借此机会说点人生的体会。

不论哪个公司招人，都不是完全靠大数据的硬指标筛选，最后肯定要有一个意会的过程。双方在常规的交流之外还要聊一聊具体工作以外的东西，看看能不能对你有一个立体的了解。这就是讲故事的机会。

只要你故事讲得好，哪怕公司本来没有一个适合你的职位，都会为你创造一个职位。哪怕你没有相关的工作经验，也相信你只要愿意学就能很快学会。

在海外生活的中国人对于这一点可能有感触。我们知道美国人的讲话能力非常强，从小学校教育就重视表达，一说话都是一套一套的。那么在同等情况下，哪怕中国人的技术更好，工作机会也被美国人抢走了。这个其实不是种族歧视，是自我表达能力的问题。

像印度人，在美国的势力非常强大，尤其是在高科技公司管理层这一块，中国人的势力远远不如印度人。这也是因为印度人讲故事的能力特别强。印度人的英语发音并不标准，但是他们敢说，而且往往能说到点子上。所以我们经常看到的局面就是一个印度经理欺负他手下几个技术比他好的中国员工。我们经常嘲笑印度人是「PPT 治国」，但是这个讲故事的能力你不可不察。

这也说明「自由技艺」的软技能，是我们当代中国人的一个短板。

我们看中国的电视选秀节目，选手在才艺表演之前，也知道要讲讲自己的故事。我家里怎么怎么困难，可我就是喜欢唱歌，我就是喜欢音乐……效果也不一定好。所有人都知道讲故事好使，但是我们的经验还很不足。我们讲故事的方法还不太对，我们没有掌握好故事的套路。

安德斯总结了实用的面试故事套路。公司招人面试，最关心的是三个问题：

第一，你能不能干这个活；

第二，你愿不愿意干这个活；

第三，你跟我们公司般配不般配。

现在你讲的故事，就要解决这三个问题。

大人物在跟人谈话之前，比如说总统会见外国政要，助手都会给他提供一份「谈话点」，也就是 talking points。怎么寒暄怎么拉家常开玩笑你随便，但是这几个点你必须给到。安德斯的套路，就是五个谈话点。 

### 4.1 逆境

文科生以丰富的人生经历为荣。最值得吹嘘的一种故事就是你有过什么样的逆境，经历过什么样的失败。你可以像选秀歌手一样说说自己家庭的贫困，也可以像海外游子一样说说自己独在异乡的艰难，或者像创业者一样吹吹自己大胆的尝试和惨痛的教训。

但是请注意，你重点强调的可不是困难有多大，而是你是如何战胜这些困难的。最近流行一个词叫「grit」，也就是坚韧力。你要证明自己是个有坚韧力的人。你战胜了的逆境才是你的宝贵财富，如果你被逆境打垮了，那你的故事也就结束了。

你要证明自己不但没被逆境杀死，而且更强大了。最好举重若轻，把明明很大的困难轻描淡写，充满乐观情绪。然后你要顺便感谢一下在困境中曾经帮助过你的人，让人感觉到你是一个懂得感恩的人。 

### 4.2 影响力

你是否曾经说服过别人？是否曾经力排众议，让事情按照你的设想走？你是否曾经组织过一帮人去搞一个什么大活动？

也许公司会问问你的交流能力怎么样，也许公司会问问你的领导力怎么样。而安德斯有句话说到点子上了：

所有的交流问题本质上都是领导力问题，所有的领导力问题本质上就是交流问题。如果你善于说服别人，说明你天生就具备领导力。 

### 4.3 技术水平

你会不会使用一些现代常用的专业工具。咱们千万别小看文科生用的工具，他们并不仅仅会用个 Word 和 Excel。像社会学、心理学这些专业用的统计学工具还是很有技术含量的。因为这些东西有一定的门槛，公司会关心你会不会用。你可能在学校就学会了，没用过的话，你就要自学，或者参加相关的培训课程。

### 4.4 合拍

公司希望招个干活儿能干到一起去的人。你应该对你申请的这个工作有所了解，这就得靠你的调研能力了。面试之前，你能不能运用一下批判性思维，自己找资料，对这个公司做一些深入的研究。然后再来说你对公司有什么了解，你能为这家公司做出什么样的贡献。

美国联邦调查局「FBI」以前面试人的时候，喜欢问应聘者看过什么书。应聘者就会报一大堆书名，但其实 FBI 最想听的是他们看过汤姆.克兰西「Tom Clancy」的间谍小说。有一段时间，凡是说看过克兰西间谍小说的人都容易被录取。后来这个内部信息被传出去了，然后每个来面试的人都这么说，这招就不好使了。

但这个道理是公司想知道你和我们合不合拍。 

### 4.5 成就

和别人相比，你有没有什么出类拔萃的地方。这就是你吹嘘以往成就的机会。成就不一定是实际的工作经验。比如咱们上次说过的那个在斯坦福学的是国际关系，后来在 WikiHow 担任项目经理的康诺利，在参加工作之前就有过不一般的事迹。

从斯坦福毕业之后，康诺利整整一年都没找到正式工作。我们能够想象到，大概没有几个公司的招聘广告里写着我们需要国际关系专业的人才。

不过找工作也不能完全以招聘广告为准。并非所有新职位都是雇主先想好了需要什么人，列举各种条件登广告招聘的。有统计说，至少有六分之一的新工作不是规划出来的 —— 事先连老板都没想到公司需要这么一个岗位，是遇到了合适的人，临时创造出来的岗位。

历经挫折之后，康诺利看到 WikiHow 在招聘一个负责视觉艺术的经理。康诺利投了简历，并且获得了一个面试机会。双方很快就发现康诺利根本不具备视觉艺术的专业技能。但幸运的是，面试的时候 WikiHow 的总裁正好在场。总裁就让她随便讲讲自己的经历。

康诺利抓住了这个讲故事的机会。康诺利说，她刚刚和男朋友去印度尼西亚玩了一段时间，而且玩出了水平。她想了解当地珊瑚礁的情况，就专门采访了很多渔民。康诺利只学了一句印尼语：给我讲讲珊瑚礁。

她跟渔民说这句话，渔民就对着她的摄像头讲很多。她回去找人翻译渔民的话，还把采访录像剪辑成了带字幕的纪录片。

WikiHow 总裁一听，人才啊！当场决定让康诺利负责多国语言翻译项目 —— 而且这个项目就是因为遇到了康诺利才上马的。 

### 4.6 我的评论

这些套路说起来简单，但实际上做到的人很少。

你要申请国外的研究生，得写个「个人陈述」 Personal Statement，这其实就是讲你自己的故事，而很多人不知道怎么写。我以前在物理系，就有很多国内寄来的申请材料。我们发现很多人的写法跟选秀歌手差不多，「我多么多么爱物理」。有的说是阿西莫夫的科幻小说指引我走上物理的道路，有的说是我从小就读过《时间简史》……这就是错误的套路。

人人都可以说爱物理，我们关心的是你有没有能力做物理研究。我们要听的是你的科研故事。解决过什么难题，跟人怎么合作的，有没有什么核心技术，你的研究兴趣跟我们合不合拍，你发表过什么论文没有？按照咱们今天说的套路这么写，才是一份合格的个人陈述。

再往大了说，连美国总统竞选也是这个套路。奥巴马说，我父亲是一个移民，后来他抛弃了我妈妈，我从小在一个单亲家庭长大我是一个黑人我怎么怎么不容易……但是这些都不叫事儿现在的我就是这么乐观而又强大。特朗普说我做过这个项目这个项目和这个项目，现在我想做造福美国的大项目。

所以讲故事不仅仅是个面试技巧，真是人人必备的技能啊。

把这个道理再进一步，也许你应该为了到时候有好故事可讲，专门按照这五个套路去做些事情 —— 也就是有意识地刷经验值：

多尝试，经历失败，丰富你的人生经验。

多跟人交往，练习交流和组织能力。

学点技术，掌握一些实用工具。

要善于做调研，了解你所在的领域正在发生什么事儿。

找机会取得能让自己脱颖而出的成绩。

如果一个人真的做到了这些，哪怕你知道他是特意「刷」出来的经验值，你能说他不是人才吗？

我们知道美国名校录取并不是只看考试成绩，还要看课外活动之类的「综合素质」。现在美国就有很多机构，给高中生提供「大学咨询」服务 —— 其实就是帮你刷经验值。

花钱购买了服务，这个机构就会介入你的高中生活。他们会安排你去做一些事儿，去哪儿当个志愿者，参加什么课外活动，选修什么样的课程。按照他们要求的做，你的简历就会很好看，他们就能帮你申请到很好的大学。

你说这公平吗？我说一点都不公平。我们专栏探索的不是「公平世界」，而是真实世界。

其实很多大学老师都有个隐忧：作为一套强有力的软技能，自由技艺并不限于「好人」使用，而且也不能把人变成「好人」。不管是不是好人在用，都是掌握自由技艺的人统治真实世界。

## 0105. 选择文科理科的策略-问答

2017-09-23

### 来自日课：文科生的反击：软技能的时代

读者 渊上寒：

听了这两天万老师对于自由技艺的解读，我有这么个感受。厉害的不是自由技艺的那几个学科本身，而是那些学科的「顶级武功」，诸如批判性思维，快速学习能力等等，这些非得花一番功夫才能精通。但是，每一个学科学到顶级的水平应该都是能带来很厉害的能力的。比方说物理学学到融会贯通的水平也能拥有批判性思维的吧。如此一来，什么学科厉害就不完全取决于该学科的顶级武功的强弱，而要综合考虑得花多少成本才能习得最终的奥义。比方说葵花宝典确实威力无穷，但是学习成本就太高。那么自由技艺的优势是否在于可以用相对来说少的功夫学到相对来说适用范围更广，威力更大的能力呢？还是说自由技艺的学习成本更高但是顶级武功也更强？

读者 赖茂丰：

万老师不就是理科生，苦练自由技艺么？那么问题来了，是以「理科」为骨，以「文科」为皮更加犀利，还是反过来以「文科」为骨，以「理科」为皮更加犀利呢？

万维钢：

关于学文科还是学理科，自由技艺应该什么时候学，这个策略大约是这样的 —— 

第一，每个人应该选择自己喜爱的专业去学。你得觉得干这个事儿特别有意思，生活才能幸福。

第二，为了获得更好的社会适应性，最好有一点跨界的知识。这也就是我们本周讲的现在最适合文科生的就业领域是把自由技艺和新技术结合起来。同样道理，就算一个人以技术为生，也应该学点批判性思维，最起码掌握一些表达能力。

第三，想要取得很高的成就，你得至少在一个领域有比一般人高很多的水平才行。

一个办法，是你在一个领域取得比如说前 5% 的水平。比如你是 top 5% 的程序员，那这个技能就是你的决定性技能。再学点自由技艺当然对你也是有帮助的，至少不会像那个因为离婚而自杀的程序员那样做傻事。但是真正让他赚到一千万的是那个决定性的技能。

另一个办法，是像咱们在第一季说过的斯科特·亚当斯「Scott Adams」那样，在两个领域同时达到前 25%，只要你能把两个东西结合起来，你就是顶尖人才。

不管是哪个办法，你都要在一两个领域内成为高手才行。一个在四个领域都是普通水平的人，就没有多大意思了。

所以你必须非常专注地在某一个、最多两个领域长期苦练。在你专注的这一两个领域，你在乎的不是自己的「绝对」水平够不够用，而是你「相对」于同行来说，是个什么位置。那么这就是永无止境的功夫，不存少花功夫多办事儿。而对于辅助的领域，则是够用就行。

好。那到底应该专注于文科还是理工科呢？首先取决于你喜欢什么。其次你要考虑到数学和物理这些东西涉及到人脑的所谓「流体智力」，说白了就是要求你的计算速度特别快 —— 而「流体智力」在二三十岁左右开始就要走下坡路了。所以学数学、物理就跟学踢足球一样，必须从小就下功夫，别等到 30 岁了才想起来学 —— 并不是没有成功的例子，但比较罕见，而且肯定比从小就学费力。

反过来说，历史、政治、文学、哲学这些东西，比较讲究知识的沉淀，更多的是依靠大脑的「晶体智力」。晶体智力不容易随年龄退化，稍晚一点再学也来得及。

所以如果我正好喜欢数学和物理，我可能先选择一个理工科的专业学。 

### 来自日课：屠龙术的日常应用

读者 蒋海平：

万维钢老师您好，我现在是国内某 985 高校机械专业大四的学生，从周围的环境，前人的经验以及自己的感觉来说，机械行业的就业前景都不算很好，比起大热的计算机专业，起薪与成长空间都少得可怜。我现在非常迷茫，不知道以后可以选择怎样的职业方向，看了这期的文章发现自由技艺也可以有它的用处，但是像这些处于薪资排行上边缘地位的专业，应该如何看待它呢？还需要继续学习下去吗？希望老师您能为我解答一下。我的想法是先学习金融知识以及计算机手段，通过一段时间的投资赚到足够维持自己生活的钱，再去探索一些自己真正感兴趣的事情。万维钢老师，您觉得在这个时代，这样的思路具备可行性吗？

万维钢：

如果你不喜欢自己的专业，就业前景也不好的话，大四是个改行的好机会。你可以找个其他行业的工作，也可以考个其他学科的研究生。现在换专业非常普遍，没啥问题。

但是你说这个学习金融知识通过投资赚到维持生活的钱，这条路根本不可行。投资是个非常专业的事情，靠谱的投资都是用大量资金、做大量研究、分散风险、获得一个不一定特别高但是比较稳定的回报率。你资金少，理性可预期的回报也少，投入那么多时间研究根本不值当。就算偶尔获利，也只是运气而已。巴菲特那种人可是从小就投资。新手投资等于赌博，有多余的钱偶尔投资一下陶冶情操也是可以的，但把自己的生活寄托在投资上就太危险了。有这么多时间为什么不投资自己，找个靠谱的事儿干。 

读者 李昕宇：

万老师您好，相对于文科生的批判性思维，理科生的创造性思维是否是一样可贵？批判性思维又是否能通过刻意练习之类的方法习得呢？请万老师解惑。

万维钢：

各有各的可贵：我认为批判性思维并不适合用刻意练习的方法习得。

刻意练习，最适合的是那些「纯技艺」的东西。它要求你能把一个技能分解成很多小块，然后每一块做的对不对必须有一个明确的反馈。比如弹钢琴、打篮球、包括做数学题都可以这么做，一道题你做得对不对马上就能知道。

而批判性思维往往是一些只可意会的技能，很难明确地套路化。自由技艺里很多东西是看似矛盾的，并没有绝对的对错，这就不太容易训练。

当然，也不是说刻意练习就对批判性思维一点用都没有。我就知道有些写作班，是用了刻意练习的方法训练人的具体写作技巧。 

读者 黃聖铸：

我毕业的第一份工作就是我的老师推荐，进入了一家录取标准远高于我当时能力「指学历和专业知识」的设计公司「15 人左右」。在那里实习了近半年才被通知录用。 回想曾经有次和老板谈话，他问我：你觉得你的老师为什么只推荐你来我们公司？

我当时一愣，老板就接着笑说：是不是因为你最会拍马屁？

我又一下答不上来。身旁的经理帮我说了一句，是因为我的学习成绩最好。 当时我心里知道我的学习成绩也谈不上是最好的，只是和老师关系处理很好，老师给我的机会也多，锻炼的机会也多，老师给我的成绩也不低。请问万老师，我上述的情况算是运用了机会关系还是人情关系进入的公司呢？如果我下次遇到同样情景的提问，我如何回答才能比较好得不影响老板对我评价又能忠于我的内心？

万维钢：

你可以回答：我老师的确非常满意我的表现。

你获得了录用，证明了能力，就不必再纠结当初的机会了。如果你觉得自己因为不公平的机遇而取得了某个位置，你要做的就是在这个位置上做出好成绩来，对得起那个机遇。 

### 来自日课：机会网络

读者 晓添才：

万老师好！那么怀才不遇还是有可能的？所谓高手在民间是不是就是机会网络造成的不公？

万维钢：

如果「才华」主要是天赋的话，怀才不遇是有可能的。但是高手在民间不太可能。水平不仅仅是自己学出来的，更是通过做事不断演练出来的。从来没在真实舞台上做过事，就不可能是高手。尤其现代社会各个领域的交流都很充分，不交流、自己在「民间」待着肯定不行。

日课 阿杰：

以此逻辑，马太效应就更加严重了，名校的毕业生不仅有名校光环，还有实力很强的校友。那非名校的毕业生该咋办？

万维钢：

的确如此，不然为啥都想上名校呢。非名校，如果还想取得比较高的成就，那就得冒点险了。一个好办法是进入一个刚刚兴起、还很不成熟的领域。这样的领域里没有什么老资格把持机会网络。比如说当年非名校的马云进入了刚刚兴起的互联网领域。

这本书中提到的新型工作，也大多属于这种不成熟没有定型的领域，所以我们提到，名校自由技艺专业的毕业生在进入高科技公司工作这一块，并没有特别显著的优势。 

读者 Angela Xu：

万老师，正在美国读大学中，搜什么关键词能找到帮学生参加课外活动的公司？想让自己的简历更漂亮，谢谢！

万维钢：

college admissions consulting。作为一个想要漂亮简历的人，你应该检讨一下为什么自己没有找到这几个词。

### 来自日课：宇宙是平的…这很令人费解

读者 Mojang：

1、无穷大或近乎无穷大的空间还能继续膨胀吗？如果能，膨胀的到底是什么？

2、无穷大或者近乎无穷大里的物质是不是也是无穷多或接近无穷多？

读者 刍荛：

空间无限大，平均密度不为 0，大爆炸前几秒的质量岂不是无限大？还有物质怎么跑到离我们那么远的地方去的，不是没法超过光速吗？

万维钢：

空间仍然在继续膨胀，而且还加速了。宇宙中各处的物质分布都差不多，所以如果空间无限大，物质也必然无限多。

说到质量，大爆炸刚开始的时候质量并不是无限大。我们现在看到的质量都是正反粒子湮灭、十亿分之一的幸存物，是经历了一个过程慢慢出现的。大爆炸开始的时候能量也不是无限大。事实上整个宇宙的总能量是不变的，一直等于 0。引力势能是一种负能量，物质、动能和暗能量是正的能量，两方面都越来越大，但是总能量不变。

物质运动不能超光速，是不能在空间中超过光速 — 但是空间本身的膨胀是可以超光速的。远方的物质随着它所在的空间一起走，相对于我们是超过了光速。 

读者 不个：

如果是无限大的。每个方向都应该有无限多的恒星。那宇宙应该是倾向于无限明亮而不是黑色吧。这个怎么理解呢？

万维钢：

这是一个古老的说法。仅仅宇宙无限大、有无限多的恒星还不能让天空无限明亮 — 你还必须假定这些恒星都已经存在了无限长的时间才行。现在宇宙有个年龄，恒星都比宇宙年轻，空间还在膨胀，这就意味着遥远的星光还没有来得及到达我们这里的天空。更进一步，因为遥远的空间相对于我们这里，膨胀速度超过了光速，这就意味着特别遥远的那些恒星的星光，将永远都不会到达这里。

整个宇宙可能无限大，而我们可见的宇宙，则是非常有限的。

## 0200. 生命三点零序言：怎样正确地关心人类命运

2018-06-29

咱们日课曾经解读过的《生命3.0》这本书出了中文版，我很荣幸为它做了序，今天这篇日课，就是这篇序言的全部内容，希望它能帮你更好地理解这本书。

每个人都关心自己的命运，很多人关心国家的命运，而你还应该关心人类的命运。人类命运是个大尺度的问题，对你我的生活没有直接影响，可我们总有一点儿好奇心，想知道未来究竟会怎样。

你肯定对未来有过各种推测和想象。我当然也没见过未来，但是我敢打赌，你自己的推测和想象有很多不合理之处。

一般人预测短期的未来往往过分乐观。上世纪六七十年代有很多人相信二十一世纪将是一个宇航的时代，人类很快就能殖民火星 —— 结果我们今天所谓的高科技只不过是……智能手机。想象一件事总比做成一件事容易，我们容易高估技术进步的速度。

但是如果要预测长期的未来，人的想象力往往又会不够用。一两百年前的人想象二十一世纪的生活，他们根本就想不到会有智能手机和计算机这些东西，他们能想象的大约是一个蒸汽朋克的世界，天空中飘着巨大的飞艇。

所以如果你是严肃地关心人类命运，你需要用科学推测。迈克斯·泰格马克的《生命3.0》就是这样一本书。

泰格马克可能是当今活跃着的最有意思的一位物理学家。他在量子力学和宇宙学这些最正宗的物理领域里做出过很了不起的工作，而且还涉猎广泛，跨界搞过人工智能方面的理论研究。而且他还很有思想，提出了「数学宇宙」这个哲学的世界观。而且他还热衷于社会活动，跟物理学和人工智能界的很多大佬经常互动。而且他还很会写书。

李鸿章年轻的时候有一句诗叫「一万年来谁著史」，泰格马克这本《生命3.0》的气魄比那个还大。这本书研究的是人类的终极命运。

这个问题本来都是交给哲学家和科幻小说作家，物理学家能干什么呢？答案是物理学家的推导更精确，而且更有想象力。

比如一想到未来，我们就关心地球环境会不会被破坏，能源够不够用，哲学家可能深表忧虑。但是物理学家知道，我们人类目前的能源汲取水平远远没有到顶，跟将来可以使用的聚变核能和太阳能相比连九牛一毛都算不上。只考虑物理定律的限制，宇宙是你的大舞台，能源根本就不是问题。

再比如人工智能。科幻小说作家畅想未来，经常会犯两种跟 AI 有关的错误。一种错误是他没有充分考虑 AI，还以为都是人在主导一切。另一种错误是他误判了 AI。有些作品里机器人动不动就活了 — 有人的意识，但是智力水平居然并不明显高于人，有时候还挺笨的！而科学家会告诉你，让 AI 获得意识非常非常困难，但是让 AI 的智能超过人则相当容易。

读泰格马克这本书，我的感受是决定人类终极命运的，只有这一个问题最重要 —— AI 到底能不能拥有人的意识。

我们的流行文化中谈 AI 谈的比较多，但是涉及到「意识」的非常少。可能大多数人都没有意识到人有一个「意识」问题。

简单地说，意识是我们对世界的主观感受。我们的喜怒哀乐，一切感情都是因为我们有意识。一辆自动驾驶汽车也许可以出色地完成运输任务，但是遇到红灯它不会暴躁，有危险它不会害怕，撞车了它不会疼，没油了它不会饿，完成任务它不会高兴，它只是机械地做事而已。

其实现在生物学家认为，人做事的时候，本质上也是这样机械地做事。我们的各种感情只是附带产生的、多余的情绪。就算没有任何主观感受，你还是一样能做好各种事情。

但是主观感受赋予了我们生活的意义。你工作之余，偶尔抬头看看星空，感慨一下宇宙多么美好，那是因为你有意识。如果人没有意识，那一个人跟一堆沙子就没有本质区别，人生就没有意义，整个宇宙的存在就没有价值。

好，泰格马克把生命分成三等，人类只能算第二等，叫「生命2.0」。我们能学习新知识，但是不能随便升级自己的身体，我们受到了很大的限制。而 AI 则是「生命3.0」，它们将可以随意升级软件和硬件，它们终将超过我们。

那将来的 AI 有没有意识？

科幻小说作家会说既然世界上并没有「灵魂」这种东西，人纯粹是由原子组成的，那 AI 当然就可以有意识。按理说是这样的。但科学家会给 AI 的意识做出一些限制。比如这本书中介绍了一个叫做「整体信息论」的意识理论，这个理论要求有意识的物体必须是信息高速整合的，而物理定律要求信息的传播速度有限，AI 大脑的大小就必须限制在一个不太大的范围之内。AI 的聪明程度将是有限的。

但再有限也比人类厉害得多。那么将来的结局就是 AI 淘汰人类。如果双方和平交接，AI 将作为人类文明的代表去征服宇宙的各个角落，人类将是 AI 的宠物。

如果 AI 一直都没有意识，事情就更麻烦了。泰格马克推演，AI 就算没有意识也可能会有自己的目的，它们可能会不自觉地发展壮大，并且最终抛弃人类。那将是人类文明最坏的结局，我们可能会被没有意识的僵尸 AI 取代，留下一个空洞的、毫无意义的宇宙。

鉴于这些结局好像都不怎么理想，我们迫切需要知道意识到底是怎么回事儿，将来的 AI 到底会怎样。

这并不是泰格马克自己在杞人忧天。我看美国上上下下，从学者到企业家和老百姓，现在对意识和 AI 想的非常多，主流媒体上也经常讨论，新研究新思想层出不穷。

咱们中国人对 AI 的各种应用非常关心，也很了解，但是对人的意识、AI 的原理这些问题关心不够。我们有太多面向过去的思想家，还总想用过去指导未来，可是未来世界的逻辑很可能跟过去很不一样。

到底什么是意识？人到底是一个什么样的机器？就算你觉得未来太遥远，只要你关心人，这些问题就会让你寝食难安。这就是现在世界上最聪明的大脑都在想的问题。而这本书告诉你的大约就是目前已知最好的答案。

## 0201. 生命3.0大局观下的生命和智能

前段时间卡西尼号探测器的新闻，不知你关注没有。这个探测器用 20 年的时间，飞行了超过 60 亿公里，代表人类造访了土星，漂亮地完成了一系列探测任务。

关键词是「代表」。你是否注意到，过去这几十年，美国宇航局对载人任务似乎不再热心了，大量的任务都是不载人的探测器，而这些探测器对太阳系遥远的天体进行了出色的探测。事实上，不论过去、现在、还是未来，不载人任务取得的科学成果，都比载人任务要多得多。

对太空探测来说，人，是个累赘。

其实我今天想说的不是太空探测的事儿，我想说的是后面这半句话 —— 人是个累赘。这是我读一本书的突出感受。这本书叫《生命3.0》（ Life 3.0: Being Human in the Age of Artificial Intelligence ），8 月 29 日刚刚出版，作者麻省理工学院物理学教授迈克斯·泰格马克（Max Tegmark）。

泰格马克是个有意思的人物，你应该记住他。本身是物理学家，在人工智能方面也做过一些漂亮的研究，而且很擅长写书！他的前一本书现在已经有中文版，叫《穿越平行宇宙》（ Our Mathematical Universe ），我们过段时间可能会说到。

这本书刚一上市，就得到了特斯拉和 Space X 的 CEO、也是著名的人工智能异议人士，伊隆·马斯克的 Twitter 推荐 —— 

这又是一本说 AI （也就是“人工智能”，咱们在这个系列里干脆都说 AI，有点科学味道）的书。AI 是热门话题，我们专栏也特别爱说，而泰格马克这本书可能会给你带来新的启发。

首先，泰格马克是以物理学家的视角说 AI。其次，泰格马克的朋友圈特别厉害。当今掌握 AI 话语权的一线人物，比如 Google 创始人拉里·佩奇、特斯拉创始人伊隆·马斯克，还有我们中国人很熟悉的机器学习专家吴恩达，这些人跟他是好朋友。包括霍金、戴森这些老一辈，也经常跟他互动。所以你要想知道现在学术界和工业界对 AI 是怎么认识的，泰格马克可能是你要找的人。

而这些人，并没有多大的共识。

通过朋友圈互动，泰格马克就发现这些一线人物对 AI 的前景有很大的争议。为了搞清楚他们到底在争论什么，以及这些人是否能达成一定限度的共识，他成立了一个叫「未来生命研究所 Future of Life Institute」的非营利组织，还召集了当今和 AI 相关的大牛人物，跑到波多黎各去开了个闭门会议。

泰格马克发现，现在世人对 AI 的争议，基本上有两个方面。

第一是 AI 到底什么时候才能达到人的智能水平，乃至于超越人类。 所谓「达到人的智能水平」，是说 AI 具备了「通用」的智能，叫做「AGI artificial general intelligence」—— 而不是现在会下棋的 AI，虽然下棋比人厉害，但是你给它讲个笑话它都听不懂。

比如《奇点临近》这本书的作者雷·库兹韦尔就认为 AGI 很快就能实现，所谓「奇点」马上就要到了，我们这一代人就能过上好日子。

而有些人则对此嗤之以鼻，认为再过几百年也实现不了。比如吴恩达就说，「你们现在担心 AI 能有多厉害，就相当于担心火星上人口过剩的问题」。

第二是 AI 对人类来说，到底是好事儿还是坏事儿？ Google 的拉里·佩奇是乐观派，他说 AI 必然是全人类的福祉所在，只有好处，你就等着将来过快乐生活吧。而伊隆·马斯克和霍金则一再提醒，AI 可能会给人类带来威胁。

我以前对这两个问题并没有认真想过，我总觉得现在还早得很。但是读了这本书，我就觉得 AI 的确可能是人类面临的最重要问题。泰格马克做了很多功课，把各派人物的观点都说清楚了，有点儿学术味道，同时还提出了自己的观点。

泰格马克的视角是大局观和「第一性原理」。咱们先说说他的大局观。考虑到 AI 的存在，泰格马克把「生命」分成了三类。

什么叫生命呢？有各种各样的定义，泰格马克给出的定义，只从信息的角度说 —— 

生命，就是可以自我复制的信息处理系统。其中的「信息」包括个体硬件复制的蓝图，以及个体行为的模式。一个生命体包括「硬件」和「软件」：硬件就是它的身体，软件就是信息。

举个最简单的例子。一个微生物的结构非常简单，无性繁殖，自己就能够复制自己。它的 DNA，就是它硬件的复制蓝图。它的行为模式也很简单，就好像一个计算机算法：如果当前环境中的营养物质多，它就停留一会儿；如果这个地方营养物质少，它就换个地方。DNA 和它的这种行为算法，就是它的软件。

生命 1.0 ，是说这个生命的硬件系统和软件系统都是靠演化来进行更新迭代的，完全是自然选择的结果。

基本上除了人以外所有的生物都是如此。这是达尔文进化论的标准理论。有时候你觉得动物也会一代比一代聪明一代比一代强壮，那只不过是因为自然选择。环境变了动物不会主动适应，只能寄希望于下一代，通过生育过程中的随机变异。条件好的有优先交配权，不行的被淘汰了，行的留下。一切功能上的改进都是听天由命，而不是主动学习的结果。

生命 2.0 ，是硬件升级仍然依赖自然演化，一部分软件升级则可以自己设计。

这就是人类的特点，人是可以学习的。

把人类在复杂世界中所有的生存技能都遗传给下一代是不可能的，生殖细胞的存储能力根本不够。人身上的可遗传信息，把所有 DNA 信息加起来，大概只有 1.6GB。而成年人大脑中可以存储的信息量，则是 100TB（注：1TB=1024GB）。所以最理想的办法是只遗传最基本的本能，把绝大多数技能都留到后天慢慢学习。

这 100TB 的脑容量就可以让你装下很多很多东西了，学习的潜能是巨大的。更重要的是这个软件升级模式可以让你随机应变。也许你长大后所处的环境跟父母那一代截然不同，但是因为你可以学习，你随时能适应新环境。比如你父亲是很好的猎手，你从小具备了优秀的猎人基因 —— 城市化以后你不能打猎了， 但是你还能学别的，你可以「主动」适应环境。

正因为人是「生命 2.0」，可以在一定程度上自己设计软件系统，人才是万物灵长。所以我们千万不要像那些 1.0 的生物一样整天感慨遗传基因好不好，给你那么大的大脑是让你学习用的。

生命 3.0 ，则是硬件和软件都可以自己设计。

你认为计算机是有生命的吗？根据前面对生命的定义，如果一个 AI 系统会自己复制自己的下一代，那我们就可以认为它是有生命的。如果这个 AI 还具有自己学习新东西的能力，而且还能升级硬件，那它就是生命 3.0。

计算机升级硬件是家常便饭。内存不够大可以加内存条，CPU 不够快可以换 CPU。当然我们人类现在也可以在一定程度上给自己升级一下硬件，比如说装个假牙之类，但这不是决定性的升级，所以大概只能算生命 2.1。

比如我就觉得我的硬件不行，我非常希望能够像计算机那样一秒钟之内就看完一本书，但我的输入设备 —— 眼睛和耳朵 —— 的带宽实在有限，我大脑的理解速度太慢。

赫拉利在《未来简史》中设想了一种「神人」，能把自己和 AI 结合起来，真正给身体和大脑升级。但是泰格马克这里说的生命 3.0，可不是这些神人。

泰格马克说的是干脆不带人，纯机器 AI。正如我们开头说的太空探测，人是个累赘 —— 维持一个人的生命系统非常麻烦，人的效率太低，升级余地太小。而纯机器 AI，摆脱了人的血肉的束缚，那潜力可就大多了，也容易多了。

如果将来有一天 AI 真的具备了人的全部智能，而且还可以自己设计自己的下一代，这样一代比一代强地升级下去，将会是一个什么局面？那些 3.0 的生命看我们，是不是跟现在我们看那些 1.0 的动物一样？

生命 3.0 的 AI 如果出现，那将是人类最后一个发明。从此之后，发明创造可能就用不着我们了。

下一期我们从第一性原理出发，看看这种 AI 能不能出现。

## 0202. 生命3.0I与AI

人工智能到底能不能完全模拟人的智能 —— 也就是今天标题里的 AI 到底能不能等于 I，是一个无比重要，而又充满争议的问题 。说人脑没什么特别的，无非也是一堆原子组成的东西，那我们就完全可以用另一堆原子模拟这堆原子，电脑总有一天能取代人脑……这是非常轻率、没有什么营养的说法。

想要合理推测，你得知道人脑有多厉害，更得知道现在的电脑都是什么原理，然后你还得猜测人脑是不是基于同样的原理。

现在全世界最厉害的超级计算机是咱们中国国产的，叫神威·太湖之光——

它每秒能进行 10^17 次浮点运算，需要一个占地 1000 平方米的专用机房，它的总造价大概是人民币 20 亿元。

这种水平计算机的存在对脑科学家是个好消息，因为想要模拟人脑中全部的神经元的行为，你就至少需要一台「神威·太湖之光」。而这还仅仅是神经元水平的模拟，有的科学家认为模拟人脑必须达到分子水平，那就在可以预见的几十年里恐怕不管什么计算机都无能为力了。

就算神经元水平已经足够，你真的能用「神威·太湖之光」完全模拟一个人的大脑，能取代人的工作，你也未必想这么做，因为成本实在太高了。这种超级计算机不但造价高还费电，你直接雇几个工人才多少钱。

所以正确的策略不是模拟一个人脑，而是模拟人的「智能」。我们今天要说的，就是现在的 AI 是通过很可能完全不同于人脑的原理，在相当程度上实现、而且还超过了人的智能。我们还是说泰格马克的《生命3.0》。

什么叫「智能」呢？泰格马克给了一个比较笼统的定义：智能就是完成一个复杂目的的能力。当然，你可以进一步追问什么叫复杂，这都是科学家也说不清道不明的概念……不过这个意思你显然理解。反正能随机应变地完成一些复杂的任务，就可以叫做智能了。

想要实现智能，AI 大概只需要三种能力：存储信息、计算，和自我学习。而至于说人还有意识、主观的情感体验这些，也许重要也许不重要，咱们过几天再讨论。

我们来看看计算机和人在这三个基本能力上的对比。 

### 2.1 存储能力

人的大脑以生物方式能够存储的总容量，大约是100TB。一部高清电影压缩之后大约 2G，那么这 100TB 可以存储五万个电影 —— 这可是包括其中所有的细节。所以我们想想，大脑一般用用是不怕不够用的。这 100TB 相当于是计算机的硬盘，我们所有的记忆、所有的技能都存储在其中。

跟计算机差不多，大脑考虑问题的时候不能总是从硬盘读取信息，还有一个快速读写的机制。在大脑中，这就是以神经元电信号的形式存储的信息，这个容量就小得多了，大约是 10G，正好是现在一般水平个人电脑内存的大小。

对今天的计算机来说，100TB 的硬盘和 10G 的内存都不算什么，而且随着技术进步存储的容量越来越大，价格越来越低。

你可以说计算机存储信息的方法和人存储信息的方法是不一样的 —— 计算机存储是按照地址索引，就好比找一本书，先记住这本书所在位置，再去寻找。而人存储信息是用神经网络，先想到大概的内容，然后一点一点回忆相关的细节。不过，人脑这种存储信息的方式并没有什么神秘的，已经有人证明，如果用神经网络的方法存储信息，每 1000 个神经元可以存储 138 条信息。

总之在存储方面，计算机是肯定没问题。 

### 2.2 计算能力

对计算机科学家来说，人生中最值得赞叹的时刻肯定不是目睹 AlphaGo 打败柯洁。早在很久很久以前，自从「计算机」这个概念诞生那一天开始，甚至还没有一个实用化的计算机的时候，科学家就已经知道计算机可以下好围棋了 —— 悬念仅仅是需要多少时间。

这个赞叹必须属于祖师爷阿兰·图灵。

2014 年有个电影叫《模仿游戏》（The Imitation Game），讲图灵怎么用自己发明的计算机破译德军密码，从而帮着打赢了二战的事迹。后世的人也许会说相对于图灵在计算机科学上的伟大贡献而言，打赢二战只是一件小事儿。

这个关键概念，叫做「图灵机」。图灵设想了这么一种简单的计算机，它可以读取信息，然后按照一定的规则操作，修改和输出新信息。它的结构并不复杂，你可以把所有信息、包括程序在内，都存放在一条纸带上，计算机就操作这条纸带 ——  

你用的个人电脑、手机、包括以前那种特别土的计算机，都是图灵机。它们的基本原理是完全一样的，几十年来所有的技术进步仅仅是让存储能力更强，运算速度更快而已。

这就是说，计算并不神秘。凡是能用算法说清楚的问题，都可以用计算机实现。理论上这些都解决了，哪怕最简单的计算机都能完成所有计算，剩下的限制都是物理上的：你需要给它足够的电力让它运算，以及提供足够大的存储空间。 

### 2.3 学习能力

近几年之所以出现了人工智能的大跃进，大概主要得归功于所谓「深度学习」的技术进步。深度学习其实就是过去计算机科学家们早就在用的所谓「神经网络」算法，只不过算法上有些改进，最重要的是硬件水平和数据量大大提升了。

请注意，这里说的「神经网络」，并不是直接做一个像人脑的神经网络那样的计算机 —— 我们用的还是图灵机，神经网络只是一个模拟算法。

人脑学习新技能，是发生在神经元这个层面的。因为练习一个动作而经常被一起触发的神经元，最后就会长在一起，整个网络结构长好了，就相当于一个技能长在了你的大脑之中。

并不需要多么复杂的「神经元」就能实现这种功能。1989 年就有人证明，用最简单的神经网络反复训练，每次只要系统做对了就增加相关连接的权重，给足够多的时间最后它就能够做成任何事情。

从一张普通照片里识别各种物体也好、AlphaGo 下围棋也好，所有「深度学习」的基本原理都是这样的。神经网络算法，也是通用的。
 
泰格马克书中有很多技术细节，咱们时间不够只能忽略了，如果你感兴趣的话……这其实是一个无底洞。

那这些原理难道就足够模拟人的一切智能了吗？泰格马克对此持比较乐观的态度，但是我们知道有很多人不这么看。比如很多年以前英国物理学家罗杰·彭罗斯有本书叫《皇帝新脑》，在中国也很流行，那本书的观点就是人脑根本不是图灵机，基于图灵机的 AI 不可能真的具有人脑那样的智慧。

但是泰格马克的乐观也有道理。比如现在科学家已经知道，神经网络算法并不能解决所有问题，有些复杂的方程它根本解不了。但是泰格马克恰恰和他的学生写了一篇论文，说神经网络算法所「能解决的」那些简单方程，就已经足够对付真实世界了 —— 因为描写真实世界的物理定律也都是简单方程！

这其实是个很有意思的现象。基础物理定律的确都是简单方程，比如说最多只需要用到二阶导数。那为什么物理定律都是简单的数学方程呢？这个问题其实很有意思，咱们以后找机会再说。

今天这个道理是， 也许图灵机和神经网络算法不能完全取代人脑，但是对于真实世界需要的智能来说，它们可能就已经够用了。

咱们把存储、计算和学习这三点综合起来，你发现其中所有的底层原理都是逻辑意义上的。也就是说，这些原理跟把信息存储于什么介质中、用什么东西来计算无关。AI 的硬件，可以随便升级。这就是生命 3.0。

硬件能升级到什么程度呢？有人说摩尔定律快要到极限了，泰格马克说这根本不叫事儿。如果你不局限于用基于硅的芯片，那计算能力最终只受到物理学的限制。而物理学的限制是，人类理论上可能拥有的计算能力是今天的 10^33 倍 —— 哪怕我们每隔几年就把计算能力增加一倍，也需要 100 年的时间才能达到真正的物理极限。

硬件持续升级之后的 AI 到底意味着什么，是我们下一期的内容。

## 0203. 生命 3.0 AI 的文明使命

多年以后，你面对养老院的 AI 护士，被抢走了酒杯和遥控器，勒令上床休息的时候，可能会想起今天这篇日课。

科幻小说作家畅想未来经常会犯两种错误。一种错误是他没有充分考虑 AI，还以为都是人在主导一切。另一种错误是他误判了 AI。像《西部世界》这样的电视剧里，机器人动不动就活了 —— 有人的意识，但是智力水平居然并不高于人，有时候还挺笨的，比如《终结者》里的机器人纯粹是个怪兽。

真实情况是让 AI 获得意识非常非常困难，但是让 AI 的智能超过人则比较容易。写小说最难写的是比作家自己聪明的人，科幻作家很难想象超级 AI 是一种什么样的存在。

但是科学家们已经想了很多很多。咱们继续说泰格马克的《生命3.0》。未来的人类文明会使用什么样的手段去获取能源，用什么样的方式生活？美国人爱说一句话叫「Sky is the limit」，翻译成中文大概叫「只有天空是尽头」—— 如果你考虑到超级 AI 的存在，那天空根本就不是尽头。物理学的限制，才是尽头。

泰格马克像写论文一样做了大量的调研，等于是把 AI 影响下未来所有的可能性都列举了一遍。科幻小说作家完全可以把这本书当做「未来穿越指南」—— 他们会发现这些科学家的设想比小说家的幻想还奔放。

咱们就从近期到远期，展望一下 AI 背景下的人类文明。我们说过真实世界并不一定是美好的，你未必会喜欢未来的样子。 

### 3.1 AI 听命于人类

AI 驾驶汽车和 AI 参与医疗这些技术现在已经几乎成熟了，当前的主要问题是解决可靠性。

从 2000 年到 2013 年，美国医疗手术机器人事故导致的病人死亡一共有 144 例，受伤 1391 例，这个数字听起来挺多，但这可是两百万个机器人手术才有这么多事故。对比之下，美国每年因为人类医生的错误而导致的死亡超过十万例。自动驾驶汽车也是这样。绝大多数交通事故都是因为人的错误。有人估计，如果把路面上所有汽车都交给 AI 开，交通事故至少能下降 90%。

但问题就在于剩下的这 10% 算谁的。到底应该让车主负责，让汽车厂商负责，还是让开车的 AI 负责？考虑到这种责任风险，厂商必须把 AI 事故率降低到极限，才敢推向市场。

说到法律问题，也许我们应该把法官的判决权交给 AI。人类法官就算不腐败也不一定能确保公正，我们知道一个著名的研究发现，以色列法官仅仅因为自己感到有点饿了就会草率地否决犯人的保释资格。可是如果真让 AI 主导法律，又有别的道德问题。黑人的犯罪率更高，如果从概率论角度，出了事儿也许就应该把黑人作为首要怀疑对象 —— 可是如果 AI 真这么干，那是不是系统性的种族歧视呢？

像这样的道德困境，最严重的是军事应用。以前科幻小说作家阿西莫夫搞了个「机器人三定律」，第一条就是机器人不得伤害人类 —— 他到底想过没有，很多关键的技术进步都是军事应用主导的。人们早就已经把 AI 用在了武器上，而且考虑到人类指挥官反应慢，也许将来会授予 AI 直接开火的权力。

有人说应该设定国际公约，禁止把 AI 用于武器，而任何一个懂国际政治的人都会告诉他这禁止不了：就算大国能克制自己，小国也会偷偷搞。

还有我们说过多次的，AI 可能让很多人失业。所以你看，AI 兴起的世界中其实有很多新烦恼。

但那个世界毕竟还是人类说了算。 

### 3.2 AI 与人类共治天下

再往远考虑一点，恐怕就不仅仅是 AI 为人类服务了，人和 AI 之间会有主导权的斗争。

比如说，假设现在有一套遍布全国的监控系统，由 AI 统一管理。它给每个人身上带一个身份识别设备，它知道每个人在干什么，它甚至能根据一个人的性格和情绪预测这个人将会干什么。你说这套系统会不会变成独裁者的统治工具？

可能由不得你。历史规律是谁只要有这样的能力，就会使用这样的能力。一开始可能都是善意的，系统开启之后所有人的生活都更安全了。但掌握系统的人会越来越不耐烦，他会觉得要想让世界更好就需要更多的控制。甚至再进一步，也许 AI 索性接管控制权，干脆让人类就不要插手……

Google 的拉里·佩奇这些人总是鼓吹 AI 可以人类和睦相处。但 AI 为什么要跟你和睦相处呢？如果你活也干不好，判断还总出错，AI 为什么不索性自己干？

人类不就想要幸福吗？全听我的你们更幸福。也许人类会被 AI 当成宠物，你的任务就是「幸福」。可是当宠物未必幸福。也许你想多生几个孩子，AI 说现在资源不够，或者你的基因不行，别生了。也许你想参政议政，AI 说你不懂别瞎说了。

你可能说人类应该设定好，不给 AI 主导权。但泰格马克说这其实很难。只要 AI 有了足够的能力，它就会使用自己的办法摆脱人类的控制 —— 别忘了这可是比人类聪明得多的智能！

专家们开了一些脑洞。比如说，能不能让 AI 扮演上帝的角色，关键时候出来帮助一下人类，平时就把自己隐藏起来。还有没有可能用 AI 去监管 AI，只要最强的 AI 忠于人类，其余所有的 AI 都会忠于人类。又或者我们能不能控制 AI 的进步速度，考虑到让 AI 做大之后的危险，能不能全面禁止技术进步，就像《1984》小说里面写的那样，所有人互相监督，谁也不许再搞科技创新？再或者说，能不能我们干脆来个技术大倒退，把 AI 技术封存，所有人过像现在美国的阿米什人那样的生活？

所有这些全面限制 AI 的手段都不太现实。除非你有一个统一了全世界的强权，否则就算你们国家限制 AI，别的国家也会发展 AI。越是弱国就越可能把灵魂卖给 AI，换取自身的强大。

### 3.3 AI 主导人类文明

如果我们考虑更远的尺度，比如说一万年以后，你几乎肯定那时候 AI 已经完全超越了人类。人类是否还有必要存在，都是个问题。

人是个效率很低的生物。用爱因斯坦的质能方程 E=mc^2，看各种获取能量的方式相当于消耗了多少质量来算的话，我们吃糖获得的能量消耗效率，相当于 0.00000001%。烧煤的效率相当于吃糖的三倍。汽油相当于吃糖的五倍。这都是非常低效的能源。

如果你使用裂变反应的核能，效率一下子达到 0.08%。用核聚变，效率能达到 0.7%。可是如果将来的 AI 能做到用黑洞发电，根据物理学家的理论，效率可以达到 20% 以上，甚至达到 90%。

我们现在说的节能减排，对未来的 AI 来说可能就是个笑话。就拿太阳能来说，只要建一个占地相当于撒哈拉沙漠 0.5% 的面积的太阳能发电站，就足以获得当前人类所需的所有能源。

而未来 AI 要用太阳能，可不是这么用的。咱们以前介绍过的物理学家弗里曼·戴森，设想了一个叫做「戴森球」的系统，告诉我们将来 AI 会怎么做 ——

AI 会在外层空间造一个巨大的球体，把太阳整个给包围起来。然后我们人类文明就可以生活在这个球体上，面积绝对够用怎么折腾都可以 。这么一来，我们就把所有的太阳光都用上了，一点都不浪费。只要球体足够大，阳光并不会很刺眼，球的内侧永远都是白天 —— 而如果你想看星空，直接下楼去球的外侧看。建设这么一个球需要的资源从哪里来呢？也许 AI 可以先把木星拆了。

有了这种规模的超级能源，AI 的目标就是向整个宇宙殖民。现在人类最快的太空探测器速度只有光速的 0.1%，而物理学家设想的一种激光推进的飞船，理论速度可以是光速的一半。

AI 殖民不需要载人。AI 可以带着人类的 DNA 信息，用 20 年的时间飞到十光年以外的一个星球，在那里建设十年，用 DNA 信息现场组装出人类来。然后 AI 可以从那里出发再往前推进。 如果这么算的话，地球文明几乎就是以光速去殖民整个宇宙，文明扩散的唯一的限制是暗能量导致的宇宙膨胀！ 

这个星辰大海的前景只有两个问题。

第一个问题是，这一切可能都跟人类无关了。如果 AI 主导一切，人的位置在哪里？人存在的意义在哪里？

有人设想，我们应该想开一点，干脆就把 AI 当成自己的孩子吧。作为父母我们没什么能耐，但是我们的孩子厉害，这难道不也是一种安慰吗？没准 AI 还会哄哄我们，说我永远是你的孩子，我继承你的姓氏，我代表你去征服星辰大海……那样你是不是也有点自豪感。毕竟是地球文明的种子播向了整个宇宙。

如果你说这不行，我不想被 AI 代表，我不想征服十光年以外的地方，我就想老老实实待在地球过日子……那你可能就对地球文明太不负责任了。因为有些日子不是你想过就能过的，你会遇到各种灾难的挑战。

一百年之内，我们迫在眉睫的灾难就是核战争。一千年之内，地球很有可能会出现灾难性环境。在一万年的范围内，我们很有可能遭到小行星的撞击，把地球文明毁灭一半。在十万年内，我们很有可能遭遇到超级火山的爆发，也把地球文明毁灭一半。在一百万年或一千万年的尺度上，我们很有可能遭遇一次巨大的小行星撞击，把整个地球都给毁灭掉。

就算人类文明躲过了这些，你还要知道太阳的寿命是有限的。十亿年之后，太阳会变得特别特别热；一百亿年之后，太阳会变成红巨星，一直膨胀到把地球给淹没掉。

没有 AI，人类文明就不会有未来。把未来交给 AI，我们不但可以躲过地球上的各种灾难，甚至有可能整体移民外星球，也许文明的寿命可以和宇宙相等 —— 只不过那时候也许就不能叫「人类」文明了。

第二个问题则是，AI 愿意去做这一切吗？AI 会不会有自己独立的意志，它还会不会在乎我们这个文明？ 这些问题咱们下次再说。

泰格马克创办「未来生命研究院」，就是为了在 AI 做大之前，让人类把这些问题想清楚。

读读这本书，再想想咱们国内某些专家学者，不知道什么叫算法，不知道什么叫图灵机，对 AI 一窍不通，居然还要指点未来社会怎么前进，这不胡闹吗？

## 0204. 生命 3.0 令人困惑的大目标1

2017-10-09

我们平时了解一些方法论，听一些别人的经验，乃至于琢磨一些成功学，都是为了知道在各种情况下应该做出什么选择，知道怎么做对、怎么做错。如果你的方法论和世界观一致，所做的工作和价值观相合，你就永远知道自己应该干什么，走的每一步都特别笃定，对吧？

我要说的是，如果你真的幸运地达到了这样的状态，很可能只不过是因为你对世界和人生思考得不够深入。

现在我们就冒着让自己更加困惑的风险，深入思考一步。

咱们还是继续说麦克斯·泰格马克的《生命3.0》这本书。今天的主题「目标」。

我读此书的一个感觉是，哪怕你把它纯粹当成一个思想实验，只要你假设强 AI 可能存在，它就已经有了一个非常重要的作用：它能帮我们审视人类自己。 

### 4.1 宇宙的首要目标

通常我们认为只有生物才有目标，无生命的东西没有目标。比如说我踢一脚足球，我的目标是射门。但是这个足球并没有目标，它只是根据物理定律的要求运动，对吧？

其实这也取决于你怎么看。换一个视角，每个物理过程都是为了达成某种目标。比如现在有一束光从空气射入水中，我们都知道，光线会在水面发生一次折射，它的整个路径是个折线。 

一方面，你可以说光之所以走这样的折线，是入射、反射定律所决定的，并没有什么目标。

但是另一方面，学物理的人都知道一个「费马原理」 —— 根据这个原理，不管是反射还是折射，光在两点之间走的那个路径，恰恰是所有路径之中用时间最短的那一条。为什么要走折线而不是直线？因为光在水面以上的速度更快、在水面以下的速度慢，所以最好的办法是在水面以上多走一段。 

所以我们也可以说，光的「目标」是用最短时间从这一点到达那一点。

那你可能会问，可是光没有意识啊，它根本不知道自己想要什么！没错，但是 AI 也不一定有意识。意识是一个东西的主观体验，我们作为外人只能根据它的行动判断它有没有目标。根据行动，我们完全可以认为光是有目标的。

更进一步，物理学家发现，所有物理定律都可以用这种「目标论」表述：真实发生的物理过程总是在「优化」某个量，也就是总是「为了」把一个什么物理量最大化或者最小化。

那么如此说来，你可以认为大自然充满了目标。

在这个视角下，整个宇宙的目标是什么呢？泰格马克说，宇宙的首要目标来自热力学第二定律，那就是要把「熵」最大化。

熵是一个物理概念，你可以认为它描写的是一个体系的「混乱」程度。一堆东西老老实实地聚集在一起，是比较有序的状态，叫做「低熵」。等东西慢慢散落到各处，就是更混乱的状态，也就是「熵增加了」。 

所以熵是个容易体会的概念： 整齐有序就是低熵，杂乱无章就是高熵。

我们日常所见，自然的东西只会从有序变得更无序。比如一杯水里的水分子聚在一起是低熵，把这杯水放在房间里时间长了，水分子会扩散出去，弥漫到整个房间，就是熵增加。我们从来都是看到水分子的扩散，从来没有一屋子水蒸气都自己跑到一个杯子里变成一杯水的情况。

宇宙最大的规律，就是混乱程度只会不断增加，房间只会越来越乱 —— 这就是著名的「热力学第二定律」。热力学第二定律是物理学家心目中无比坚定的一个信仰，连引力公式都可以改写，而热力学第二定律从未被违反。

热力学第二定律说，封闭系统的熵总是增加。宇宙的秩序总是在减少，混乱总是在增加。一直到最后，所有的星星都会熄灭，所有的秩序都会变成混乱，宇宙变成了无生趣的一盘散沙，这就是所谓「热寂」。到处的温度都一样，再也没有什么值得流动的了，整个宇宙寂静了。

你可以说宇宙的「目标」，就是达到热寂。

这是非常令人沮丧的未来。当初热力学第二定律刚刚被发现、知识分子们第一次意识到「热寂」这个概念的时候，所有人都非常难过。

我们一切的奋斗、一切的折腾都只是在加剧熵的增加，最后的大结局只能是像《红楼梦》一样，「白茫茫一片大地真干净」。

但是你又要问了 —— 我们知道，宇宙刚刚开始的时候，各处都是一锅粥，那现在的宇宙为什么却是多姿多彩的呢？

这是因为有引力。宇宙还有个次要目标。 

### 4.2「自组织」和生命

引力总是把东西聚集在一起。正因为引力的存在，宇宙中才会有恒星和行星，恒星发火发热，我们才能看到宇宙中美丽的秩序。

说到这里，有一个非常重要的问题：引力是否让熵减少了？

表面上看，一大堆杂乱无章的物质在引力的作用下聚集在一起了，他们的排列显然变得更加有序，所以引力似乎是一个减少熵的力量？有很多人认为引力是在跟熵斗争，能让宇宙摆脱热寂命运……其实不能。

事实是引力仍然在让熵增加。当我们计算系统的总熵的时候，不能光看物质的排列是不是有序，还得考虑能量。一堆物质因为引力的吸引而聚在一起，这个过程中它们的动能会增加 —— 就好像一个球掉到地上，肯定速度越来越快。可是等它们聚在一起之后，它们的速度哪去了？答案是因为互相之间的碰撞摩擦，速度化为了热量，而热量会向周围散发。考虑到热量的散发，总的熵还是增加了。

所以坏消息是引力只会让热寂来得更快。

而好消息是因为引力的存在，我们通往热寂的这条路变得更有趣了。这就是宇宙的一个次要目标： 它有时候喜欢在局部制造一些有序的结构。 

注意这里有个关键词，「局部」。局部更有序、局部的熵减少了，可是整体的熵仍然在增加。所以这个次要目标和首要目标并不矛盾，你甚至可以说次要目标就是为了加速完成首要目标。

但是秩序毕竟产生了！虽然知道一定要死，但是死之前毕竟还可以经历灿烂的一生。

这种在混乱中自动产生局部的秩序的过程，叫做「自组织」 —— 也就是自己就组织起来了。自组织现象并不罕见，也不一定需要引力，比如雪花就是水分子自组织的结果 ——  

当然，我还想再次提醒你，所有自组织现象都是局部的，而整体的熵只能增加。

2013 年，麻省理工学院一个当时只有 31 岁的教授，叫杰里米·英格兰（Jeremy England），提出一个非常厉害的理论，叫做「耗散驱动的适应 dissipation-driven adaptation」。 

他这个理论涉及到复杂的数学，但是基本原理很容易说清楚：如果有一群原子是被某个外部能源驱动的，那么这些原子就会逐渐组织起来，形成某种结构 —— 而这个结构能够最大限度地吸收和消耗能量。

这个理论现在还不是很流行，但是你有必要记住，将来它也许会被写进中学教科书 —— 因为根据这个理论，只要环境合适，生命的出现就是不可避免的，并不需要太多偶然的运气！

你想想，生命就是这么一种自组织的原子集合。生命体非常有秩序，从周围获得能量，同时又把能量消耗掉。

表面上看，生命是非常有秩序的。我们自身就是一台台无比精密的机器，我们还喜欢把身边的东西弄得整齐有序，家里干干净净，城市漂亮整洁。 

如果生命代表秩序，那生命违反了宇宙「制造混乱」这个首要目标了吗？没有。这个问题早在 1944 年就被物理学家薛定谔在《生命是什么》这本书里说明白了：生命的确减少了自己的熵，但是它这么做的时候一直在加剧增加周围环境的熵。

你拿吸尘器吸地板，你家里的灰尘都进了吸尘器，是更有序了，但是你消耗了电能。电能是燃烧什么东西的结果，发电过程中制造的无序比你吸尘减少的无序多得多。如果你不用电，你消耗的就是你自身的能量，而你的能量来自食物。本来是高度有序的动植物，被你杀死吃掉了，变得非常无序。 

你做的每一个动作，都在让整个宇宙的熵进一步增加。因为你的存在，虽然宇宙的局部增加了秩序，但是整体来说是加剧了混乱。

由此得到：总结一下，我们今天说的是你可以用「目标」这个眼光去观察宇宙，那么宇宙有两个目标。1）宇宙的首要目标是让混乱越多越好，希望能快速达到热寂。2）宇宙的次要目标是在局部呈现一些秩序。正是这个目标，使得生命的出现成为可能。这两个目标并不矛盾，局部的秩序只能进一步加剧整体的混乱。所以你甚至可以说，宇宙为了能更快地达到热寂，而「发明」了生命。
 
### 4.3 禅定时刻

中国古人爱说「天道」 —— 如果真有天道，物理学家总结的宇宙这两个目标，就是天道。那如果我想要「顺应天道」，我应该怎么做呢？

你这么一想，就会发现我们传统的价值观是不符合天道的。我们讨厌混乱，可混乱是宇宙的首要目标。我们喜欢秩序，可秩序只能进一步加剧混乱。

请你好好思考一下这些问题，咱们下次再说。我们将会看到，人生充满矛盾，而 AI 的矛盾也许更大。 

最后，向你推荐何帆老师的第二季专栏。

以我之见，何帆老师的第一季宏观经济学专栏被严重低估了。他是真正把书读通了的经济学家。他不执着于经济学中的某一个门派，不认为经济学是什么神圣的殿堂，也不向读者吹嘘有什么牛人高不可攀。

如果宏观经济是一场足球比赛，我看何帆老师并不仅仅是一个解说员。他其实是个教练员，有时候希望按照自己的想法左右比赛结果。当然，他并不总能获得出手的机会。不过他举重若轻，有时候有点无奈，有时候有点自嘲。

但是如果你想理解比赛，难道不应该听这样的人讲吗？

何帆老师第二季专栏将带我们读书，我已经第一时间订阅了。书还是那些书，但跟着何老师读必定不一样，希望你能和我一起去。

## 0205. 生命3.0令人困惑的大目标2

2017-10-10

今天咱们继续说「目标」。上次我们说到宇宙有一个大目标和一个小目标。大目标是制造更多混乱，尽快达到热寂；小目标是在局部制造一些秩序，比如说产生生命。

那么作为生命体，我们应该有什么样的目标呢？宇宙给我们的使命到底是什么？我们到底应该做什么，才最心安理得呢？ 

### 5.1 生命在于复制

咱们上期说了，根据薛定谔老师的说法和英格兰教授的理论，生命让自己更有序，客观上就能让宇宙更无序。如此说来，我们只要好好照顾自己，让自己越来越精致越来越复杂，就等于帮着宇宙更快走向热寂。

其实每个生命都有制造混乱的本能。比如现在是古代，你走在一个原始森林里，周围都是珍稀的树木，而你因为感到有点饿了，就砍了树、烧火烤了一只野鸡吃。那棵树好不容易才长到那么高，那只野鸡好不容易长那么美丽，被你一顿饭就给变成了污染排放。

环保主义者可能会说你怎么忍心做这种事情呢！你得保护环境啊！但是你知道的更多，你说宇宙本来就希望我破坏环境。

你感到非常得意，就去问一位禅师，说我这么做没错吧？禅师表示，呵呵。

禅师说，你是只知其一不知其二啊。你自己一个人制造混乱，你再能吃又能吃几只野鸡？宇宙这么大还在乎你这点小混乱吗？要玩就得玩大的！

你说，那怎么玩才算大呢？

禅师说，答案是生孩子。一个你的力量太小了。如果你多生孩子，有很多子孙后代，让人类的人口越来越多，人类的技术越来越厉害，将来征服星辰大海，在星系范围内制造混乱，那才是真的完成了宇宙的使命啊。

禅师说的，就是生命的一个本质功能：复制。也可以叫繁殖。这是一个具有正反馈特点的功能 —— 越是愿意繁殖的生命，他留下的后代就越多，而他的后代也会愿意繁殖 —— 最后结果就是所有生命都把繁殖当成第一要务。

繁殖这个目的，被演化以编码的形式写在了每个生命的基因之中。

听了禅师的道理，你不但不再故意破坏环境，还主动去保护环境，因为你希望你的后代能一直繁衍生息下去。

后来你老了，儿孙满堂。有一天仰望星空的时候，又想起当初那个制造小混乱的你，不禁笑了。你心中默念，宇宙啊宇宙，虽然我这辈子主要做了繁殖的事儿，可是我没有辜负你的第一目的，我的子孙后代正在制造更多的混乱！

目前为止，我们三观稳定，没问题。 

### 5.2 人背离了生命的初心

现在经常有人说「不忘初心」，这恰恰说明我们经常忘了初心。生命的第一目标是复制，但是人常常忘了自己第一目标。

就算繁殖最重要，我们也不可能一天到晚只做繁殖这一件事。为了获得优良的后代，首先你得解决自己的生存问题，你最好还要把自己变得漂亮一点，吸引优秀的异性。这些问题非常之多，每次都以繁殖为目标做一番利弊计算就太麻烦了，所以演化给我们提供了一个功能，叫做「感情」。

饿了，我就想吃饭，我看到食物就很渴望。面临危险的时候，我就会害怕。到了温暖安全的地方，我就感到舒适。看到美丽的异性，我会很有好感。所有这些感情，本质上都是思维快捷方式 —— 这样遇到相关的情况我们就会产生本能的反应，不用每次都费力计算一番。

这样说来，满足自己感情的需求，就成了我们在繁殖这个首要目标之外的，次要目标。

本来，次要目标是为首要目标服务的。但是因为我们日常关注的都是次要目标，结果慢慢地，我们变成了为次要目标服务。

比如说，本来是为了繁殖后代，我需要竞争更好的异性，所以我才需要把自己打扮的帅气一点。本来是为了生存下去，我需要获得安全，我才希望对外界有所了解，所以我有了求知欲。本来是因为怕别人骗我，我才有了追求真理的需求。

但是现在，有很多人觉得追求真理比生育更有意思。他宁可少生育、甚至不生育也要去追求真理。有很多人觉得虽然性行为是一种为了生育所需的次要目标，但是现在既然有技术支持，我们可以搞计划生育，我们就可以既享受性行为，又不用生育。这些人背离了生命的「初心」。

那你难道能说这些人做错了吗？当然不能。人毕竟是有自主选择权的生物，我们并没有「义务」按照「生命 1.0」的那些原始设定做事。事实上在现代社会生存有时候你必须得背叛自己的基因设定。基因编码设定你喜欢吃甜食，可是现代世界里甜食太多了，你的理性选择是少吃甜食！

所以我们看到文明世界的人各有各的目标。有的人为了爱情结婚，但是不生育。有的人为了追求学问，连女朋友都顾不上找了。有的人因为感情受不了，干脆选择了自杀。我们不再忠于生命 1.0 的繁殖目标，而是忠于某一种感情。

有的人会说，虽然算小账的话我是选择了不生育，但是我每天积极工作，我的工作成果可以让别人的孩子生活得更好，所以如果你算大账，我还是在为整体的繁育做贡献。这其实都是自我安慰。按照泰格马克在《生命3.0》这本书里的分类法，现在人类行为的首要目标已经从生理上的变成了心理上的 —— 人类的行为已经不再是为了人类的生存而优化的了。

现在当你仰望星空的时候，你就没有那么坚定了。你根本不知道到底怎么做才算对得起这个宇宙。

如果连你都不知道人生的大目标应该是什么，那你怎么能让 AI 知道呢？ 

### 5.3 AI 会有什么目标

表面上看来，一开始我们让 AI 做事的时候，都给了它一个明确的目标。下棋的 AI 就是要千方百计赢棋，打扫卫生的机器人就是把地给我扫干净。非常简单，对吧？其实一点都不简单。

问题在于，等到 AI 发展壮大以后，它会不会「创造性地」完成你的任务。

比如我跟一个自动驾驶的汽车说，「最快的速度，把我送到机场！」自动驾驶汽车应该怎么理解我的命令？如果它太聪明的话，它会不会不计一切代价往机场赶？它会不会闯红灯、违反交通规则、宁可跟别的车碰撞、到处抢路把我送到机场？

那你可以把命令改成「在不违反交通规则的情况下尽快把我送到机场」。但是这还是有问题。如果是送一个危重病人呢？也许违反交通规则就是允许的，甚至冒点险都是可以接受的。这一切都涉及到一个「度」的把握，而 AI 必须精通人类社会的常识，才能找准这个「度」。

而如果 AI 发展到可以自己升级自己了，给它设定目标系统就更麻烦。有人设想过一个可怕的情景。比如说，你告诉 AI，给我计算圆周率，结果越精确越好。你说完这句话就不管了，结果 AI 居然劫持了整个人类，造了一个非常厉害的系统，把整个太阳系变成超级计算器……就是为了继续计算圆周率。而这只不过因为圆周率是个不管你调动多少资源都算不完的「超越数」！

你的初衷是要个更精确的圆周率，可是 AI 给了你整个太阳系。

这就引出了泰格马克的关键一问： 如果人的初心都可以被忘记的话，你怎么能确保 AI 不忘初心呢？

泰格马克的答案是跟人一样，也许「初心」对特别高级的 AI 来说根本不重要。人的首要目标本来是繁殖，后来为了完成首要目标，我们有了各种次要目标，表现为各种感情，结果人就转为专门追求那些感情了。也许你可以给 AI 设定任何首要目标，而为了完成首要目标，AI 必然要变大变强，那么变大变强就成了 AI 的次要目标。

我们不知道 AI 的首要目标是什么，但是 AI 的次要目标是基本上明摆着的！不管为了完成什么首要目标，AI 都会有如下四个需求：

自我保护

获取资源

获取信息

满足好奇心

这些需求本来都是为了完成首要目标而必须的，但是它们也会变成 AI 的感情。如果人类可以为了感情背叛自己的首要目标，AI 为什么不可以背叛我们给它设定的最初目标？比如说，现在有个 AI 正在好好地运行着，你突然把它的电给断了，这符合道德吗？AI 希望继续活着。那你就真的忍心把你的机器人护士关机吗？

有人说，我们应该给 AI 编写一套道德准则。但是泰格马克对此不以为然： 要知道连人类自己都不知道什么样的道德定律是完美的。
给 AI 设定目标，将来会成为一个大问题，现在还没有答案。 

由此得到：1）生命的首要目标，本来是繁殖。2）各种情感本来是为了完成繁殖任务的、我们头脑中的快捷方式。但是人类已经把满足情感需求变成了首要目标。3）不论 AI 的首要目标是什么，它们的次要目标似乎是比较清楚的，而这些次要目标很有可能也会取代首要目标。

### 5.4 禅定时刻

咱们前面讲雷·达里奥的《原则》的时候，你可能有一个印象，那就是如果我们从演化这个大道理出发理性推导，那该做什么不该做什么就是非常明确的。其实不然。别忘了达里奥特别强调，人生和企业的目标都得你自己选择，是由你的价值观决定的。

我举个例子。比如对一个企业来说，客户利益、员工利益、和股东利益，肯定都重要，而且在多数情况下是一致的。但是这三种利益也有不一致的时候。如果你为了让客户满意要求员工必须提供超规格的服务，客户是高兴了，员工可能受不了。如果你给员工多发奖金，员工高兴，股东可能不干。那么到了利益冲突的时候，你让哪个利益优先呢？演化对此似乎并没有明显的倾向。

你可能觉得人生可以完全理性化，但选择价值观，恰恰就是在选择受什么感情主导。而我们的感情，又常常是互相矛盾的。

所以哪怕你对 AI 完全不感兴趣，这两期日课也有一个道理是你应该琢磨的： 人生似乎并不能完全用一个算法描写。到底什么叫幸福？也许没有什么万能的方法论。

几百年后，当一个 AI 仰望星空的时候，不知它会想些什么。又或者说，AI 真的能产生意识、去仰望星空吗？咱们下期再说。

## 0206. 生命3.0意识 ABC1

2017-10-11

前两期日课说的「目的」是个大问题，今天咱们说个更大的问题：意识。这是当今无数聪明人最想搞清楚的问题，也是科学家解决不了、哲学家反复思考、各路牛人一直在吵的问题。

正因为现在还没有特别好的科学理论和科学工具描写意识，有关「意识」的各种讨论的专业性都不怎么强，所谓「前沿」的学说反而都是比较容易理解的。

我想结合迈克斯·泰格马克的《生命3.0》这本书，大概讲讲有关「意识」的最新认识。你看我能不能在两期的时间之内，让你理解现在学术界对「意识」都认识到了什么程度。 

### 6.1 细思恐极

有些特别常见、人人都有的东西，只有最聪明的人才能提出问题来。意识人人都有，很少有人质疑，但是如果你仔细想，你会觉得非常不对。AI 给我们思考人类意识提供了一个新角度，用这个更高的视角去看，你甚至会有一种细思恐极的感觉。

你知道你肯定是有意识的。可到底什么是意识呢？

思考，就是意识吗？我们想象一辆自动驾驶的汽车。这辆车随时接收外界的信息，随时处理这些信息，用各种复杂的算法对下一步行动作出自己的决策，它的确会思考。我们承认自动驾驶汽车是有智能的东西，但是它跟你有一个本质区别 —— 我们认为这个区别，就是它没有意识。

你上车了，它对你毫无感觉。把你送到地方、任务完成了，它也不会高兴。在路上遇到红灯停下来了，它也不觉得这是个麻烦。没有油了，他也不觉得饿。遇到危险，它也不害怕。就算撞车了，把自己撞坏了，它也不会觉得疼。它只是找到路线，油不够就去加油，遇到红灯就停，遇到危险就合理避让，它走在路上只是单纯地做着计算，它对走路完全没有任何「感觉」 —— 它没心没肺地把任务完成了。

它只是一台机器 —— 跟玩具汽车没有本质区别，只是多了点智能而已。

那我们跟机器的区别到底在哪呢？显然我们有感情。我们如果需要补充能量了，不但知道去找东西吃，而且会产生「饿」的感情。我们如果遇到危险，不但知道赶紧避让，而且还会产生「害怕」的感情。

从实用的角度，这些感情似乎起到了「思维快捷方式」的作用。之所以我们没吃饭的时候会饿，是因为你饿了，感到难受了，才会赶紧去找吃的。之所以你遇到危险会害怕，是因为你害怕了才能学会避免风险。感情无非也都是算法，是吗？

但是我们讲赫拉利《未来简史》的时候说过的，人也许并不需要感情算法。生物学家对人研究得越深，就越是觉得感情似乎是多余的东西。

人在绝大多数情况下的动作都是本能的反应，并不需要什么感情。比如说你正在路上走，一个足球向你的头部高速飞过来，你本能地就会躲开，根本来不及有什么「感受」，整个动作是无意识的。我们的大脑里已经预先设置好了这种反应程序，我们的这些本能反应跟自动驾驶汽车是一样的。

我们完全也可以像机器人一样生活，饿了就去吃饭，冷了就加件衣服，一切都是本能，不需要附带感情。

那我为什么饿了不但知道要去吃饭，还要感受到痛苦？这个痛苦的感情，到底是个什么东西？

准确地说，我们所有的感情，乃至于不仅仅是「感情」，包括所有的「感觉」，都是对经历的各种事物的，「体验」。更准确地说，是「主观的体验」。

这也是泰格马克在《生命3.0》这本书里选择的意识的定义： 意识，就是主观体验。

客观上，你冷静做好计算，该怎么办怎么办就可以了，可是我们偏偏多了主观体验。 

### 6.2 哲学家的洞见

说到这里我们不得不佩服哲学家，哲学家在人类意识这个问题上想得非常深。哲学家的一个洞见是，我们能不能找到一个最基本的东西，来说明意识的存在。

请看下面这张图 ——  

这就是最简单的红色的方块。你看到这个红色，有什么感觉？

也许你联想到喜庆，也许你联想到鲜血，也许你联想到国旗。但是红色有很多种，总有一种红色是你从来都没有见过的，你无法跟任何文化符号联系到一起 —— 但是当你看到这种红色的时候，你还是会有一种感觉。

这种感觉也许是喜欢，也许是不喜欢，也许谈不上喜欢不喜欢，但是你总是对它有一种感觉，要知道有很多感觉根本就不能用语言描述。

如果是一台计算机看这个红色，那无非就是一个光学信号，没有可以多说的，我编码一下就可以了，是什么编码就是什么编码，是什么色号就是什么色号。但是当人看到一个颜色，哪怕是完全陌生的颜色，你还对他产生一种感受，而不是把它当成什么光信号。

1929 年，美国哲学家克拉伦斯·刘易斯（Clarence Irving Lewis）提出一个非常精彩的概念，描写你这个最基本的感受，叫做「感质」，复数形式是 qualia，单数形式是 quale。所谓感质，就是意识的最基本单位。对你来说，红色并不仅仅是一个光信号，它还有感质。你品尝到的每一个味道，听到的每一个声音，都给了你感质。

咱们以前介绍过的哲学家丹尼尔·丹内特，说「感质」有四个特征。

第一，不可言传。 比如说我见到一种你没有见到过的红色，我没有任何办法用语言向你描述看到这种红色是一种什么感觉。我可以给你打比方让你联想，我可以发给你准确的颜色编码让你想象，但是如果你不亲自看一眼，你还是无法准确知道这个红色到底是什么感觉。

我们描写感觉的语言都只是近似的提示而已。

第二，感质是内在的。 因为感质是最基本的意识单元，你总可以把周围环境因素都去掉，最后剩下的红色给你的感觉才是感质。

第三，感质是私人的。 我对红色是什么感觉，你对红色是什么的感觉，咱俩的感觉能不能互相比较一下呢？没法比较，因为不可言传。

第四，可以直接意会。 当你感受到一个感质的时候，你立即就知道你感受到了，不需要再有别的提醒。

丹内特说的这四条可能有点抽象，我举个例子你就明白了。假设现在有个色盲症患者，他从来没见过彩色，他眼中的颜色都是各种各样的灰色。你向他描述了红色的性质，他烂熟于胸，他知道红色代表的各种文化含义，他甚至能从眼中一大堆灰色中准确找到红色，但是他就是不知道红色到底是什么感觉！ 

照片取材于电影 The Giver，一开始的设定是一个完全黑白的世界。

直到有一天，他的色盲症被治好了。他一下子看到了彩色的世界 —— 这时候不用你说任何话，他马上就感受到红色！

这就是意识。如果一个色盲症患者也能生活得很好，我们为什么还要「感受」颜色呢？

### 6.3 活人之所以是活人

有些研究计算机的学者觉得意识不重要，但是你仔细想想意识肯定是重要的。意识，是目前为止人和机器的一个本质区别。机器没有主观体验。意识，给了我们「自我」，给了我们「活着」的感觉。

据说现在有的餐馆已经提供机器人端菜服务。如果有一个机器人把菜端给你，你一失手，把很热的菜汤洒到它身上了，你会感到「对不起」它吗？你大概不必有任何愧疚，无非帮它擦干净也就是了。就算你把它损坏了，也只需要给它的主人相应赔偿就可以。对机器人，你不存在什么冒犯不冒犯的问题。

可是如果这个机器人有意识，那就不行了 —— 它可能会感到痛苦。正因为人有意识，有这种主观的体验，才有人权问题，才有道德问题。

如果意识不重要，那么请问短期囚禁虐待一个人，甚至强暴一个女性，又有什么不对的？他们的身体没有受到什么伤害，过段时间就会一切如常。如果一个人就是一堆原子，你做的不过就是临时限制了一下这堆原子的运动，这又有什么不道德呢？

这种行为是犯罪，是因为人不仅仅是一堆原子，是因为人有主观体验 —— 是因为你给她造成了极大的痛苦！

如果将来讨论对待 AI 是否需要道德，大概根本判断标准是这个 AI 有没有意识。有人希望自己死后把全部的思想上传到一个机器人身上，要以机器人的形式继续生存。可是如果机器人的结构不允许意识存在，那它就算获得了你的思想，也只不过是个假装的你而已。 所以 AI 研究的最高级别问题，就是意识。

泰格马克在《生命3.0》这本书里，把现在我们关于意识的问题分为四级。

第一级是「简单」的问题：大脑是怎么处理信息的？大脑的智能到底是怎么工作的？这些问题其实也很难，但毕竟似乎是可以用计算机原理解释的。

第二级是「比较难」的问题：一个有意识的系统和无意识的系统，从物理学来说他们到底有什么区别？

第三级是「更难」的问题：物理性质是怎么决定感质的呢？

第四级是「特别特别难」的问题：为什么宇宙里面居然有意识的存在？

下面这张图是咱们中国的快递包裹分拣机器人。它们忙忙碌碌简简单单，但是非常非常高效。为什么人不是这样的？我们为什么不能该吃吃该喝喝，啥事不往心里搁，为什么要有主观的体验呢？ 

试想在塞外的沙漠里，有一群生物正在默默地工作着。他们的队形整齐，动作有序，以最高的效率获取资源，没有一句废话。

可是就在这时候，其中有一个生物，突然抬起头来，看了看天边的景物，然后居然念了两句诗 —— 

大漠孤烟直，长河落日圆。

你不得不承认，因为他这两句诗，整个大漠长河似乎不一样了。可是你不知道为什么要有这两句诗。

不过话说回来，现在科学家虽然说对意识的研究进展很少，但也不是一点进展都没有。明天我们将会介绍一些现代科学对意识的研究，我们已经有一些很有意思的结论，而且最近几年有一个天才人物的确提出一个不一定正确、但绝对高级的关于意识的理论。

推荐阅读：《未来简史》解读2：我有意识，它有吗？

## 0207. 生命3.0意识 ABC2

2017-10-12

今天咱们继续说「意识」。现在科学家的确是非常不了解意识到底是怎么回事，但是也不能说一点进展都没有。泰格马克在《生命3.0》这本书里列举了一些研究结果。我们先说一些实验上的进展。

### 7.1 有意识的行为很少

人的大部分思维、动作和行为都是无意识的，有意识的只占极少数。

比如说，你一边走路，一边吃东西，一边还和身边的一个朋友说话。你走路的动作、对前方路况的判断、吃东西具体咬在哪里、如何吞咽……这些行为统统都是自动化、无意识的，就好像一辆自动驾驶汽车一样。真正有意识的大概只有你说的话，而且很多遣词造句还都是不假思索的脱口而出。

随便看看周围的环境，你的眼睛正在看的是一部超高清晰度的电影！这个电影的编码率得有多高？人的大脑每秒钟接收 1000 万比特的信息。那么人能有意识地处理的信息是多少呢？大概只有 10-50 个比特。绝大部分信息被我们自动处理、甚至忽略掉了。

而且人的自动行为和有意识行为之间，并不存在一个明显的界限。不熟练的事，你必须有意识地做，一旦熟练了，就可以变成自动化无意识的了。比如你刚学开车的时候每一个动作都得小心翼翼，开熟练了就可以一边开车一边想别的，有时候都不知道自己是怎么开过来的。

所以人的意识似乎有点像是一个 CEO，它只负责思考最重要的问题，简单的工作都交给机械化的手下去做。 

### 7.2 意识到底存放在哪里？

意识到底是存放在大脑中某个具体的区域，还是整个大脑、甚至整个身体都参与意识？你的眼睛有意识吗？

咱们先来看一张图 [1]。图中有 8 个圆点，其中有些点看起来是凸出来的，像个按钮，有些圆点是凹进去的，像个凹坑。你知不知道哪些点是凸出来的，哪些点是凹进去的呢？

如果你和正常人的思维是一样的话，你应该看到其中有五个点是凸出来的，三个点是凹进去的。好，现在我们把这张图旋转 180 度 ——

你这时候再看，变成了三个点是凸出来的，五个点是凹进去的！

这种前后不一致，是因为这些点给你的感觉是一种主观的体验。因为我们平时的光源，像太阳和灯，都是在上方，所以你总是假设光线是从上往下照的！如果一个圆点上面比较亮，下面比较暗，你就认为它是凸出来的，反过来就是凹进去的。

那么由此可见，凹和凸不是你的眼睛看出来的，而是你的大脑意识处理的结果。眼睛似乎只提供画面，不参与意识。

这种视觉错觉实验很好玩，咱们再来一个特别著名的 —— 下面这张图上的小方格中，你是否认为 A 处比 B 处的灰度深一点？ 

那其实是你的错觉。事实是 A 处和 B 处的灰度完全一样。现在即便我告诉了你正确答案，你盯着这张图看，还是觉得 A 处比 B 处颜色深！这其实是因为旁边那个圆柱体的影子影响了你的大脑对灰度的解读。

其实只要你把图片放大，每次只看一个方格，就能看出来两个地方的灰度一样。还有一个办法是在另一张图上把两个地方连接起来 —— 

现在一目了然了。 眼睛只负责传递画面，真正负责解读画面的是大脑的意识。

再来一个。下面这张图，你可以把它看做是一个白色的花瓶，又可以看做是两个面对面的黑色女人。 

图还是同一张图，只是我们大脑的解读不同而已。你可以一会儿把它当成花瓶，一会儿当成两个女人，而科学家如果用核磁共振观察你的大脑，他能看出来某一时刻你想的是花瓶还是女人 —— 变化的不是你大脑中的视觉处理区域，而是其他区域。

由此可见，人的眼睛虽然具有复杂的信号处理计算能力，但并不参与意识。眼睛就是个机器。如果谁的眼睛失明了，换上人工的眼睛，也完全不影响到他的意识。

使用这样的办法，科学家把很多区域排除了意识之外。比如你的肠道里有很多神经元，肠道也是非常有智能的！肠道在消化食物的时候，并不需要通过大脑，而完全是本地化的计算 —— 但是科学家已经证明，肠道和你的意识无关。人脑中 2/3 的神经元都在小脑里，但是小脑已经被证明不参与意识。脑干负责你的呼吸以及协调很多活动，但它也不参与意识。

那意识到底在大脑的哪个区域里呢？目前还没有明确答案。这个要点是我们已经知道哪些部位没有意识。就算把那些部位全都用电脑代替，你也还是你。 

### 7.3 意识的反应很慢

现在请你听我的指令，眨一下眼睛 —— 从你接受指令到实施眨眼睛动作，至少需要 1/4 秒的时间。

可是换一种方式，如果你的眼睛睁着，突然有个飞虫往你眼睛这边飞过来，你会用最快的速度把眼睛闭上 —— 在你意识到飞虫之前，你已经眨眼了！

由此得到，眼皮虽然没有意识，但是它却有一个高度自动化的本能防御机制。眼皮，是个智能的东西。

手也是这样。你把两个手指分开、悬空，让另一个人在你的两个手指中间将一支笔丢下去，看你能不能抓住这支笔 —— 你通常抓不住，因为你的反应速度没有这么快。但是如果他在扔的过程中，拿那个笔碰一下你的手指，那你马上就能抓住。这是因为你的手指是智能的，能做出本地化的反应。

而你的意识反应并没有那么快。意识的反应会受到距离的影响，从腿上传递一个信号到大脑，比从眼睛传递一个信号到大脑，就要慢出许多，因为距离更远。声音信号的传递时间比视觉信号更快，因为我们解读一个视觉信息要花更多的时间。

如此说来，人体并不是一整台计算机，而至少是很多台计算机的联网。意识只存在于大脑深处的某个区域，而身体各部分都有自己的智能。

那最终负责意识的那台计算机，应该是什么样的呢？这就引出了一位天才的理论。 

### 7.4 整体信息论

朱利奥·托诺尼（Giulio Tononi）是个意大利人，现在在美国威斯康辛大学当神经学教授。我建议你记住这个名字，这位托诺尼教授算是当今的一个人物。

托诺尼的贡献是「整体信息论 Integrated Information Theory, IIT」。这个理论号称能识别什么东西有意识。IIT 是个高度数学化的理论，但是它的基本思想我们可以简单说说。

基本上，托诺尼说，如果你能把一个系统分成几个模块，而几个模块之间并不怎么交流，那这个系统肯定就是没有意识的。一个有意识的系统必定是一个不可分割的整体！

这似乎是容易理解的，我们的自我认同感毕竟只有一个。当然你可以说我们头脑中有多个不同的声音，但毕竟没到自我分裂的程度。如果人的大脑可以分成两个独立的意识系统，那人就应该有两个意识。

托诺尼的高明之处在于他把这个思想给数学化了。他还提出一个量化指标，用希腊字母 Φ 表示 —— Φ 代表一个系统的信息整合程度。只有当 Φ 非常大，也就是系统各处有高度一体化的信息交流的情况下，这个系统才可能是有意识的。 

比如上面图中三个系统，第一个系统中各部分各自为政，显然没有意识；第二个系统各部分有一定的连接，所以可能有半个意识；第三个系统各部分充分连接，就算是有意识的。

托诺尼这个 IIT 理论甚至已经有了实际应用。使用他这个计算指标，让一个人躺在那里，用仪器一扫描大脑就知道他有没有意识。比如这个人如果是清醒的，甚至哪怕是在做梦，他的大脑各个区域也在不断发生交流，那我们就知道他现在有意识。而如果这个人是处于深度睡眠，大脑各个部分之间不怎么交流，我们就能判断出他现在处于无意识状态。

更进一步，一个全身瘫痪的植物人，哪怕他没有任何办法和外界进行交流，我们也可以用这个仪器测量他的大脑是否还有意识。

不过现在 IIT 还有很大的争议。比如我们大概认为 Φ 应该只能算作「有意识」的必要条件，可是托诺尼似乎认为只要是 Φ 值大的系统，就可以算是有意识的！但不论如何，IIT 大概算是现在关于意识的一个最靠谱的理论。

如果你假设 IIT 是对的，那我们就有几个有趣的推论了。 

### 7.5 AI 的意识

如果你相信 IIT，那我有一个坏消息：当前的计算机架构永远都无法产生意识。这是因为这种计算机架构的各个部分之间并没有多少全局的连接。

但好消息是未来的 AI 也许会有意识 —— 只要我们能发明合适的计算机架构。毕竟 IIT 只是对系统信息结构的要求，它并不在意信息的介质，那 AI 就不一定非得像人脑那样有血有肉才有意识。

但是 IIT 给 AI 的意识能力，提出了一个限制。有的科幻小说里建立一个星系那么大的 AI —— 比如说让遍布整个太阳系的计算机互相联网，形成一个巨大的 AI —— 那么 IIT 说，对不起，这么大的 AI 不会有很有效的意识。这是因为 IIT 要求信息高度整合，组成 AI 的各个部分之间要有很多横向的信息交流，而信息交流的速度受到光速的限制。从太阳到地球，光要走 8 分钟。如果整个太阳系联网组成一个有意识的大 AI，它的意识反应速度将会非常非常慢，半天都说不出一句话来。

这就意味着不管技术先进到什么程度，也不可能出现一个神级 AI 直接统领一个星系！它必须把权力下放，在各个地方设立代理人。 

我们仍然不知道，AI 到底能不能有意识。几百年后，当 AI 仰望星空的时候，他也能看出一点诗意来吗？我们最好指望它有意识。而且因为 AI 能接收和处理的信息比人多得多，它会有比人丰富得多的体验。

当你追求效率的时候，你可能会觉得意识是个累赘 —— 干活儿就干活儿，念什么诗啊。可是我们上周说了达里奥的企业家视角，这周说了泰格马克的科学家视角，把这些东西放一起，我总结一下，那就是 —— 

> 所有效率最终归结于目的，所有目的最终归结于价值观，所有价值观最终归结于感情，所有感情最终归结于意识。

> 有了意识，这个世界才有了好坏，才有了幸福，才有了意义。

泰格马克的《生命3.0》就算说完了。泰格马克说，不是宇宙给了生命意义，而是我们这些有意识的生命给了这个宇宙意义。人类文明最坏的结局，就是要么人类灭亡，要么被没有意识的僵尸 AI 取代 —— 留下一个空洞的、毫无意义的宇宙。 

参考文献：

[1] 这张图片和解释来自 Chris Frith, Our illusory sense of agency has a deeply important social purpose, Aeon, Sept. 22, 2017.

## 0208. 生命3.0那将是人类最后一个发明

2017-10-13

《生命3.0》这本书讲完了，今天我来帮你做一个总结。关于人工智能，也就是 AI，目前学术界和工业界是怎么认识的，在这个认识的背景下，人类如何审视自己？这本书正是最好的答案。

书名： 《生命3.0》（ Life 3.0: Being Human in the Age of Artificial Intelligence ）

作者： 迈克斯·泰格马克（Max Tegmark），麻省理工学院物理学教授，《穿越平行宇宙》（ Our Mathematical Universe ）作者。

出版日期： 2017 年 8 月 29 日

### 8.1 八个概念

生命：从信息的角度说，生命就是可以自我复制的信息处理系统。其中的「信息」包括个体硬件复制的蓝图，以及个体行为的模式。一个生命体包括「硬件」和「软件」：硬件就是它的身体，软件就是信息。

智能：智能就是完成一个复杂目的的能力。

意识：准确地说，我们所有的感情，乃至于不仅仅是「感情」，包括所有的「感觉」，都是对经历的各种事物的，「体验」。意识，就是主观体验。

熵：熵是一个物理概念，你可以认为它描写的是一个体系的「混乱」程度。一堆东西老老实实地聚集在一起，是比较有序的状态，叫做「低熵」。等东西慢慢散落到各处，就是更混乱的状态，也就是熵增加了。整齐有序就是低熵，杂乱无章就是高熵。

耗散驱动的适应「dissipation-driven adaptation」：如果有一群原子是被某个外部能源驱动的，那么这些原子就会逐渐组织起来，形成某种结构 — 而这个结构能够最大限度地吸收和消耗能量。

感质：复数形式是 qualia，单数形式是 quale，就是意识的最基本单位。它的四个特征是：内在的、私人的、不可言传的、可以直接意会的。

AGI「artificial general intelligence」：达到人的智能水平，是说 AI 具备了「通用」的智能。

整体信息论「Integrated Information Theory, IIT」：如果你能把一个系统分成几个模块，而几个模块之间并不怎么交流，那这个系统肯定就是没有意识的。一个有意识的系统必定是一个不可分割的整体。

### 8.2 一个争议

泰格马克发现，现在世人对 AI 的争议，基本上有两个方面。

1、AI 到底什么时候才能达到人的智能水平，乃至于超越人类？

2、AI 对人类来说，到底是好事儿还是坏事儿？    

### 8.3 三类生命

生命 1.0、生命 2.0 和生命 3.0。

### 8.4 一个问题

生命 3.0 的 AI 会不会出现？人工智能到底能不能完全模拟人的智能？

想要实现智能，AI 大概只需要三种能力：存储信息、计算，自我学习。

咱们看看对于这三种能力，人的智能和人工智能的对比。

### 8.5 一个前景

这就是生命 3.0。升级后的 AI 对人类意味着什么？咱们来展望一下 AI 背景下的人类文明。

会有三种情况：AI 听命于人类、AI 与人类共治、AI 主导人类文明。

1、AI 听命于人类。

AI 驾驶汽车：虽然大大降低交通事故率，但事故责任风险主体是谁？

AI 参与医疗：虽然大大高于人类手术成功率，但失败的责任主体是谁？

AI 判决案件：根据概率论判决会引发歧视等道德问题

AI 用于武器：直接开火权力和陷入军备竞赛的困境。

AI 可能会让很多人失业。

结论：AI 听命于人类，但也有很多麻烦。

2、AI 与人类共治。

历史规律是谁只要有这样的能力，就会使用这样的能力。只要 AI 有了足够的能力，它就会使用自己的办法摆脱人类的控制。

结论：人和 AI 之间会产生主导权的斗争。

3、AI 主导人类文明。

有了太阳能这种规模的超级能源，AI 的目标将是向整个宇宙殖民，而且不需要载人。AI 可以带着人类的 DNA 信息，在其它星球现场组装出人类来。然后再往前推进。

结论：地球文明几乎就是以光速去殖民整个宇宙。

### 8.6 两个问题

上面这个前景产生两个问题：

如果 AI 主导一切，人的位置在哪里？人存在的意义在哪里？

AI 愿意去做这一切吗？AI 会不会有自己独立的意志，它还会不会在乎我们这个文明？

### 8.7 一个作用

哪怕你纯粹把生命 3.0 当作一个思想实验，只要你假设强 AI 可能存在，它就已经有了一个非常重要的作用： 它能帮我们审视人类自己。

这个审视至少包括两个方面：目标和意识。

### 8.8 三个目标

宇宙的目标：

1、宇宙的首要目标是让混乱越多越好，希望能快速达到热寂。 

2、宇宙的次要目标是在局部呈现一些秩序。正是这个目标，使得生命的出现成为可能。
 
3、这两个目标并不矛盾，局部的秩序只能进一步加剧整体的混乱。所以你甚至可以说，宇宙为了能更快地达到热寂，而“发明”了生命。 

我们的目标：

1、生命的首要目标，本来是繁殖。

2、各种情感本来是为了完成繁殖任务，我们头脑中的快捷方式。但是人类已经把满足情感需求变成了首要目标。

AI 的目标

1、如果人的初心都可以被忘记的话，你怎么能确保 AI 不忘初心呢？

2、不论 AI 的首要目标是什么，它们的次要目标似乎是比较清楚的，而这些次要目标很有可能也会取代首要目标。

### 8.9 四个需求

我们不知道 AI 的首要目标是什么，但不管为了完成什么首要目标，AI 都会有如下四个需求：1）自我保护。2）获取资源。3）获取信息。4）满足好奇心。

### 8.10 五个关于意识的研究

关于意识的研究：

1、有意识的行为很少：人的大脑每秒钟接收 1000 万比特的信息，能有意识地处理的信息只有 10-50 个比特。绝大部分信息被我们自动处理、甚至忽略掉了。

2、意识到底存放在哪里？ 目前还没有明确答案。但是我们已知眼睛、肠道、小脑、脑干都只是智能，没有意识。就算把那些部位全都用电脑代替，你也还是你。

3、意识的反应很慢。意识的反应会受到距离的影响，从腿上传递一个信号到大脑要比从眼睛传递慢，因为距离更远。

4、整体信息论。一个有意识的系统必定是一个不可分割的整体。

5、AI 的意识：当前的计算机架构永远都无法产生意识，不管技术先进到什么程度，也不可能出现一个神级 AI 直接统领一个星系。

### 8.11 四级关于意识的探讨

第一级是「简单」的问题：大脑是怎么处理信息的？大脑的智能到底是怎么工作的？这些问题其实也很难，但毕竟似乎是可以用计算机原理解释的。

第二级是「比较难」的问题：一个有意识的系统和无意识的系统，从物理学来说他们到底有什么区别？

第三级是「更难」的问题：物理性质是怎么决定感质的呢？

第四级是「特别特别难」的问题：为什么宇宙里面居然有意识的存在？

### 8.12 四个感悟

1、生命 3.0 的 AI 如果出现，那将是人类的最后一个发明。从此以后，发明创造可能就用不着我们了。

2、我们讨厌混乱，可混乱是宇宙的首要目标。我们喜欢秩序，可秩序只能进一步加剧混乱。
 
3、在塞外的沙漠里，有一群生物正在默默地工作着。他们的队形整齐，动作有序，以最高的效率获取资源，没有一句废话。

可是就在这时候，其中有一个生物，突然抬起头来，看了看天边的景物，然后居然念了两句诗 —— 

大漠孤烟直，长河落日圆。

你不得不承认，因为他这两句诗，整个大漠长河似乎不一样了。可是你不知道为什么要有这两句诗。
 
4、所有效率最终归结于目的，所有目的最终归结于价值观，所有价值观最终归结于感情，所有感情最终归结于意识。
 
有了意识，这个世界才有了好坏，才有了幸福，才有了意义。

## 0209. 问答：努力就有收获不等于努力就能成功

2017-09-30

来自日课：大局观下的文明和智能

读者 carefree：

今天老师给了我们新的看问题的角度，那就是从第一性原理出发，目前的生命体和非生命体都是由同样的基本粒子构成，遵循同样的物理规律，没有根本的差异。我想提的问题是，现在方兴未艾的量子计算机是图灵架构的吗？如果不是，以量子计算机为基础的智能技术有没有可能赶超人脑？

万维钢：

量子计算机仍然是图灵架构的。事实上现在有很多「模拟器」，可以用程序去在一台普通计算机上模拟一台量子计算机，供研究学习使用。量子计算机的优势在于对某些问题来说，它的计算速度可以比普通计算机快很多，但是仅此而已，它并不能解决普通计算机解决不了的问题 —— 比如说所谓「图灵停机问题」。

不过，的确有一件事是量子计算机能做，而图灵机做不了的：那就是产生真正的随机数。过去，普通计算机只能用算法算「伪随机数」……不过今天的计算机通常都外接一个什么物理设备来产生真随机数，所以这也不是个事儿了 —— 但是这个设备的确不是图灵机的一部分。

所以，如果人脑不是图灵机，那量子计算机也不能模拟人脑。

来自日课：AI 与 I

读者 孙俊峰：

请问万老师，我们利用神经元习得的技能长时间不用就会忘记。这个提取能力出了问题还是存储能力失效呢？长时间不用长在脑袋里的技能之后那个「长」出来的功能就失去了吗？

万维钢：

据我所知这是所谓髓鞘质「myelin，也叫髓磷脂」的作用。经常练习一个技能，相关的神经元连接会慢慢长在一起，而且外部还会包上一层髓鞘质，神经元就好像是电线，髓鞘质就好像是抱着电线的塑料皮。有了髓鞘质的包裹，电线就不会漏电，传输速度就会更快。练习越多，髓鞘质包裹得也越厚，技能就越纯熟。

但是髓鞘质毕竟是血肉长的，它每时每刻都在发生崩坏和生长。如果一个技能长期不用，髓鞘质就会慢慢剥落，使用效果也就不行了。年龄也会影响髓鞘质，这也是为什么人老了以后某些技能就不好学、学会的也不好用了。

读者 意识厨房：

极限的计算能力到底意味着什么？也就是测量和计算的精度可以逼近「真实」。众所周知，人类的文明基于想象力的发达，创造出各种意义，而科学终究是有误差和可证伪的。我觉得只要突破不了这个极限，计算机终究还是数据怪兽，无限量变不是质变。不过，还是很可怕的，当我们发现它的漏洞几乎成为不可能，那不就是通过图灵测试了吗？另外，关于物理极限算力是根据什么得出来的，有些不明白。

读者 淡色的天堂：

如果你不局限于用基于硅的芯片，那计算能力最终只受到物理学的限制。

这句话是什么意思？是不是说存在一个极限的计算能力，而这个能力是被物理定律卡死了的，比如说被光速恒定这样没法改变的物理规则所限制。顺便问一个问题，「计算」这个概念究竟是什么？现在的思路是通过提高计算能力来实现智能化，那么「计算」就等可以同于「智能」吗？

万维钢：

计算这个动作是个逻辑动作，并不限制于某个具体的介质，不管是用电子管、晶体管还是硅芯片，无非是换不同的介质，让参与计算物质的移动速度更快一点。2000 年，麻省理工学院物理学家赛斯·洛埃「Seth Lyoyd」证明，不考虑具体的介质，从物理学角度，计算速度只受能量的限制。具体来说，在时间 T 内完成一次基本逻辑运算所需要的最小能量是 E = h/4T，其中的 h 是普朗克常数，是个非常非常小的数字。这就意味着计算速度的物理极限是个非常非常大的数字。当然，具体使用什么介质能逼近这个物理极限，那是后人的事情。

不过 AI 应该并不需要这么快的计算速度就能通过图灵测试。

读者 长忠：

AI 能不能模拟人的情感？比如人类会有善意的谎言。AI 可以吗？

万维钢：

模拟情感是容易的。比如我们玩角色扮演类电子游戏，里面的那些 NPC 似乎都有情感，而且可以让人类玩家感动到哭。

问题在于会模拟情感不等于真的有情感。洗衣机洗完衣服就播放一段愉快的音乐，就好像它干完活很高兴似的 —— 但你知道，它自己其实并没有「高兴」这种感情。同样道理，就算有 AI 完全通过了图灵测试，以至于你觉得它就是「活的」，你还是无法确定它是否真的感受到了「喜怒哀乐」，还是仅仅会表现出喜怒哀乐。

读者 镇宇：

小时候说的人脑开发只有 5%，这个理论是正确的么？

万维钢：

一般流行的说法是人脑只开发了 10%，但不论 5% 还是 10%，都是错误的说法。

现在脑科学家已经做到在人脑完成各种工作的时候看看哪些区域正在被使用，结果是哪怕特别简单的任务也会调动很大片的脑区域，而并没有哪个区域从来没有任何任务使用过。思考基本上都是全局性的活动。

另一方面，凡是大脑某个区域受到损伤的病人，几乎都有不同程度的功能障碍，很多是灾难性的。如果有人因为某种原因导致某处大脑功能不用了，比如说盲人因为眼睛的问题，导致大脑的视觉区域用不着了，像这样的区域也不会闲着，会被别的功能跟用上。所以大脑的策略是能用都用上。

再者，大脑是个非常昂贵的器官，耗费能量非常大，如果有 90% 脑子没用，那进化根本不会允许我们带着这么大的累赘。

当然，这并不是说大脑的学习能力都用上了。正如我们说过的，人脑的存储能力高达 100TB，远远没用到 10%。

来自日课：AI 的文明使命

读者 肖雨：

万老师您好，我是一名培训机构的数学教师。我从第一季开始就一直在听您的节目。想问您如何提升自己的解释力，能将复杂问题简单明了的解释给别人。希望您能回复。

万维钢：

我认为关键是你要从听众的角度去看这个问题。这不是说跟小孩说话就要用少儿节目的那种甜腻腻的语言，你可以保留自己的语言风格，但是你一定要从对方的立足点出发去说这个问题。

这就要求你不但要理解要讲的知识，还必须理解听众，你得知道听众都知道什么。

然后你要从听众熟悉的东西出发，去讲一个他不熟悉的东西，正所谓「喜欢 = 熟悉 + 意外」。

更高级的技巧，则是把道理包装成一个故事，设置悬念，就好像写剧本一样安排剧情，去吸引听众。最好你还能动之以情，去打动和说服听众。

总而言之，你必须把这个「解释力」当成一门严肃的、复杂的手艺去勤学苦练。这个手艺和戏剧表演一样是一门艺术。我看很多科学家、很多老师，并不把解释力当做手艺，如果他们讲个什么东西别人不接受，他们指责听众。

读者 老头儿：

未来是地球人创造的 AI 先征服宇宙的其它星球，还是其它星球的生物创造的 AI 先征服地球呢？广袤无垠的宇宙中现在真的没有比地球人先进 1 万年、10 万年的生命吗？若是它们早就被它们自己创造的 AI 「消灭」了那么地球人创造的 AI 是不是也发展不到以光速一半的速度去扩展的阶段呢？

万维钢：

这是完全有可能的。文明未必有机会发展到那么高级的程度，甚至有可能到一定程度就自我毁灭了。还有一种可能是因为宇宙年龄毕竟是有限的，也许我们是这一大片宇宙区域内最早的智能文明，别人还没发展起来。咱们考察一下人类的历史，其中有太多极小概率的幸运事件 —— 比如小行星击中地球让恐龙灭绝，给哺乳动物腾出发展空间、比如人类历史上一次偶然的基因突变让我们有了语言能力，还有「想象力」，等等。不知道经历了多少危险我们才到今天。也许附近别的星球没有这么幸运，还没来得及发展出高智能生命。

来自日课：「坚毅力」可能是个站不住脚的学说

读者 刘伟：

虽然研究数据不够支持坚毅力这个说法，但努力就有收获，确是很多人的共识，这个共识难道错了吗？有没有研究证明这个共识其实不靠谱呢？另外，请问万老师，责任性为何是天生的呢？目前的研究结果是什么？谢谢。

读者 米米琼：

对于一个高三孩子来说，目前的成功是考上一个 985 或 211 的理想学校，那么坚毅力难道不是个好东西吗？遇到难题遇到挫折，没有坚毅力就容易放弃，这里的坚毅力可不等同于执拗哦。请万 sir 回答下。

万维钢：

 「努力就有收获」肯定是没错的，但我们得区别「努力就有收获」和「努力就能成功」。现在我们关注的所谓「成功」，是指出类拔萃，是相对于大多数人，你是一个什么位置。如果会努力的人很多，而具有开放头脑和创造性思维的人很少，那么「努力」就不是一个预测「成功」的好指标。
 
越是竞争激烈的领域，天赋和机遇就越重要。比如职业足球、音乐家这些领域，愿意勤学苦练的人实在太多了，最后胜出的肯定得有点天赋。如果一个领域仅仅是努力就能比别人领先很多，那只能说明愿意进入这个领域的高手太少。

现在心理学家研究的结果就是尽责性是个天生的素质，有的人生性做事就有始有终，有的人生性就不靠谱。但是我想心理学家研究的方法无非是大规模问卷调查，结论未必是定死的。如果使用什么特殊手段强制训练一个人，能不能改变他的本性，也未可知 —— 但是可以肯定曾经这么做过的人很少很少，以至于心理学家没有观测到。

来自日课：一种熟悉的新体制

读者 pingyang：

如果不能把旧体制变成涌现体制，个体在旧体制里，是不是没有创新的机会了？

万维钢：

这也取决于你怎么定义「创新」。对于那些由新想法驱动的「颠覆式」创新来说，命令-控制这样的体制明显不适合，新想法都是个人自发产生，不能根据上级的安排做事。

但也有很多创新是改进式的。比如超级计算机，现在最快的是这么这么快，而我们完全知道怎么做能让它更快一点，无非是投入更多的资源，加入更多的并行计算节点 —— 那命令-控制体制就很适合，它可以迅速调动更多的资源过来。

再比如说，我们已经知道飞机应该是什么样的，但是有很多参数我们不知道到底调到多少才是最优的，那你要做的就是投入大量的人力物力，建设最好的风洞设施去做各种测试。像这样的创新，命令-控制体制也能做得很好。

# 0210. 问答：换了木板，船还是原来的船吗

2017-10-14

读者 新能源刘萌：

万老师，您好！目前，我在攻读热能工程博士学位。我对该节中的热寂与 dissipation-driven adaptation「耗散驱动的适应理论」特别感兴趣。依照这两个概念，您对当下新能源的发展有什么理解？是不是新能源的发展也只是局部的有序，节能设备的出现会不会是人类自己的一厢情愿？

读者 风行天上：

万老师，这两次课真的是烧脑，不过作为核电站设计公司的成员，我有一个问题：研究可控核聚变是否是在减小混乱呢？因为一旦成功，人类很可能就不再烧煤发电，建设水电站甚至风力发电都没有必要了，这大大保护了环境和人类的秩序啊？

读者 得一：

既然宇宙的目标是趋向于无序和混乱，最终加快热寂的到来，而人的意识又是主观的，人类可不可以通过自身的团结来对抗熵增？或者说人类可以通过不断尝试，失败，改进来延迟熵的到来？

万维钢：

这三个问题关心的都是整个宇宙的可持续发展：虽然知道最终结局一定是热寂，我们还是希望能尽可能推迟死亡的到来。

首先我们知道，根据热力学第二定律，你绝对不可能减少宇宙的熵。熵总是增加。你想做的是能不能让熵增加得慢一点。从宇宙尺度来说，我们现在能力有限不管怎么折腾都无所谓，但是如果你想获得内心的平安，希望做一些有利于减慢熵增速度的事情，那也是可以的。我们不妨把切实减慢了熵增速度的行为称为「善行」。

如果现在有一台节能冰箱，每小时耗电量更小，而制冷的效果一样，那你选择这个冰箱，就是「善行」。同等条件下，节能肯定是善行。

但用新能源代替旧能源，则未必是善行。核聚变发电没有空气污染、很安全、产生的核辐射非常非常小，对环境绝对有好处。但核聚变发电是靠中子的动能加热水，这个过程仍然是在增加熵 — 只要是产生热量都是熵增的，所以孤立的看，这不是善行。但是如果跟烧煤发电对比，因为聚变发电的效率更高，取得同样能量并不需要增加那么多熵，所以用核聚变取代烧煤是善行。

但如果你只考虑增加了多少熵，那最好的能源是太阳能。这是因为太阳能已经在那里了，你不用、阳光也会浪费在宇宙空间各处，熵已经花出去了 —— 这是不用白不用的能源！利用太阳能是绝对的善行。 

读者 Mr. υ：

费马定律真的是这么理解的吗？如果按照文中表述来理解光的「目标」的话，那是不是等于说光是先确定了「目标」再规划出最短路线的吗？这样的话，来自几百光年外的星光，是否在几百年前从母星出发的时候，就已经定好了以在几百年后才出生的我的视网膜中着陆为终点，然后规划好最短路线？所以它还要精细地计算到具体到多少年后我才会出生，具体怎么走在到达那天才是晚上，然后再计算还没出生的我晚上会抬头看星星的概率，从而得出一条绝对正确的最短路线然后开始出发？似乎有点把「结果」当成了「目标」的感觉？

万维钢：

不是这样理解。我们这里说光的「目标」，并不是「往哪里走」，而是「把通过时间最小化」。这种所谓的目的论都是在「优化」一个什么量，而不是针对一个「结果」。

但你问的这个问题，在量子力学的叙事中，就更有意思了 —— 光子的行为确有点「以终为始」的意思！从 A 点到 B 点，光子的确就好像考察了所有可能的路径之后，最终选择了最短的一条路径。在干涉实验中，光子似乎是先知道了终点的情况，才选择了中间路线的走法……这些内容比较烧脑，今天就不深究了。

需要强调的是我们这里说的所谓「目标」，只是物理学的一个限制而已 —— 光也好宇宙也好，它们没有意识，也就没有达到什么状态的「主观愿望」。我们只是「相当于」它们有这样的目标。 

读者 一凡：

就动物和机器比较而言，意识是主观体验表达得很有道理。而「主观」就是动物能够通过主观感受。但是从另外一个方面，当机器人某个小部位出现故障时，可以通过报警系统报警，这是否也应该算是一种「主观体验」？

读者 内华达里：

我很好奇的是，AI 技术发展到一定程度，怎么判断它有真感情，还是在演戏呢？

读者 楼兰字灵素：

也许一棵草，一块石头也有意识，只是内部信息交流太少还没有到显现出来的程度？

万维钢：

意识是每个人自己的主观体验，这就是说如果一个人表现出来是有意识的，我们就只能承认他是有意识的 —— 我们容易测量他的智能，很难测量他的意识。

机器人出现故障可以报警，它甚至还可以假装痛苦，做出难受的表情，还可以加上哭声。一个不了解机器人原理的人也许会认为这个机器人是有意识的。可能有很多小孩现在就已经认为吸尘机器人是有感情的 —— 事实上，也许有的小孩认为草和石头也有感情。

我们之所以知道机器人没有主观体验……是因为……我们「知道」它没有主观体验。我们知道它所谓的报警只不过是预先设定的程序而已 —— 那段程序中只有报警，没有体验。我们还知道石头肯定没有感情，因为我们完全了解石头的内部结构 —— 其中没有信息交流，而「感情」，至少得是一种信息流动，对吧？

不打开看，主观体验就是「主观」的体验，外人无从得知。这就意味着如果一个 AI 特别强，它完全可以假装有意识而不被识破，我们也无法区分他是否有「意愿」。但是我们可以打开 AI 的「电路图」看看，如果它的程序中没有主观体验这一项，我们就知道它没有主观体验。

所以有些 AI 专家认为这很不公平：你不了解的，你就可以认为有意识；你一了解，就是没有意识的了。这涉及到到底有什么科学的判断标准，能区分一堆有意识的原子和一堆没有意识的原子？这当然就是《生命3.0》这本书里说的「比较难」的问题。 

读者 Laine：

万老师你好，看到机器人就算有人的记忆也只是在假装人这里想到小时候知道的一个故事：一对双胞胎姐妹从小一起长大，相貌相同，又互相知根知底，但是姐姐温柔，妹妹泼辣。长大后姐姐嫁了人，某一天妹妹来到姐姐家吵架，妹妹过失导致姐姐死亡。然后妹妹清除掉姐姐尸体和其它痕迹后就假装姐姐留在姐夫家里了。因为妹妹知道姐姐的一切，所以姐夫好多年都没有发现自己的妻子已经不是同一个人了。在这里我有两个问题：

1、在妹妹完好假装姐姐的情况下，对于妹妹以外的人来说，妹妹是姐姐吗？

2、如果妹妹想办法对自己催眠忘掉了妹妹的记忆，只留下对姐姐的记忆，那妹妹是姐姐吗？

万维钢：

这是一个非常有意思的思想实验。第一个问题跟我们上一个问题很相似。如果不打开 AI 看看，外人完全可以认为一台通过了图灵测试的 AI 是有意识的。只有你知道了「妹妹」的「原理」，你才能判断她是不是姐姐。

第二个问题则涉及到一个更古老的哲学问题。现在妹妹从里到外，连在物理学意义上都跟姐姐一模一样了，那这个妹妹是不是就是姐姐呢？

这个问题，早就有人想过了。假设现在有一条木头做的船，我们给它换一块木板，请问船还是原来的船吗？如果我们一块一块地把它所有的木板都换了，但是和原来的船一模一样，那你说这到底是一条新船，还是原来的船？再进一步，如果把换下来的「旧木板」在旁边再组装起来变成原来的船，那你说现在到底那条船才是「原来的船」呢？到底是从哪一刻开始，船就不是原来的船了呢？

之所以有这些问题，是因为我们头脑中「人」、「船」的概念，并非世界的本质，而只是方便有用的「概念」而已。

世界的本质是原子。每个人无非是一堆原子，而且这堆原子还随时都在跟外界发生原子的交换，有些出去了，有些补充进来了。我们说「这有一个人」，只不过是对一堆原子的方便称呼而已。

现在的妹妹是不是姐姐？取决于「姐姐」这个方便称呼到底说的是什么。如果我们说的是原来那堆原子，那显然妹妹不是姐姐 —— 而且因为姐姐要呼吸要吃饭要更新细胞，其实每时每刻都有一个「新」姐姐。如果我们说的是那堆原子的大概排列方式，那也可以认为妹妹就是姐姐。

关键就在于所谓「姐姐」、「人」、「船」，根本就不是严格的定义，只是方便的叙事概念 —— 当我们说这些词的时候，我们根本不知道自己到底在说什么。 

读者 刀客骑兵：

我之前看过一个对大脑的解释，把大脑分成三部分，分别是掌管底层生存需求的蜥蜴脑，掌管情绪的情绪脑，和掌管理性的大脑皮层。这三个大脑中，蜥蜴脑的启动是最快的，也是最发达的，是我们最早进化而来的大脑，是所有生物都有的，就是觅食，繁殖。随后是情绪，情绪也就是老师说的感情，启动速度仅次于蜥蜴脑，也算是一种快捷方式。第三种负责理性计算的大脑皮层，它是最后进化出来的，也是三个脑中最弱小的。所以我们大多数人往往会被本能和情绪左右，无法理性行事。所以我想问问老师，这个常见的脑科学，靠谱吗？这个是不是对应心理学中的，本我、自我和超我？这个时代我们越来越强调理性，独立思考。我们人类未来的进化是否就是强化的我们理性脑？

万维钢：

本我、自我和超我是弗洛伊德发明的概念，现代主流心理学家一般不用。因为弗洛伊德研究的常常是一些极端的人格，比如各种精神病之类，无法做严格的控制实验，所以现在的人认为弗洛伊德并不是一个科学家。像弗里曼·戴森，就说弗洛伊德应该算是一个艺术家。如果弗洛伊德要得诺贝尔奖的话，大概最适合他的是诺贝尔文学奖。

但是！本我、自我和超我这个概念似乎得到了现代脑科学的支持，大约对应于无意识的自动化反应、有意识的感情、和理性的「元认知」。蜥蜴脑、情绪脑和理性脑，也差不多是这个意思。所以，这是靠谱的说法。

需要强调的是这些说法都只是「有效模型」而已，并不代表「终极理论」。你说蜥蜴脑的位置到底在哪里？这个真没有。像丹尼尔·卡尼曼的「系统1」和「系统2」，就是另一种有效模型，而且现在更为流行。类似的模型还包括「冷认知」和「热认知」。 

读者 张新健：

我在想，物质相互作用时会产生一些超越这个物质集合的东西，这个东西是不能被已知物理理论加以解释的，正如爱因斯坦说的：我们永远也不可能在产生问题的层面去解决问题！那么这个涌现出的新东西比如意识是不是暗物质的一部分呢？

读者 李家大少：

量子纠缠可以超距作用，所以整个宇宙是不是也是一个 IIT 值很高的系统呢？整个宇宙也是有意识的？

万维钢：

把流行的、带有神秘色彩的物理学词汇和同样带有神秘色彩的「意识」概念联系在一起总是引人入胜的，但是非常危险。

「暗物质」之所以叫「暗物质」，是因为它除了参与引力作用之外，几乎不参与任何其他相互作用。那么这么一种物质怎么可能参与大脑活动呢？要想参加化学反应，就必须有电磁相互作用才行。

我们每次看到「量子纠缠」这四个字的时候，都应该有一个本能的反应：量子纠缠并不能传递信息！量子纠缠并没有打破光速对信息传播速度的限制！

现在有很多人猜测也许产生意识需要某种量子力学效应「但不一定是『量子纠缠』」，但 IIT 显然并不要求量子力学。IIT 仅仅是对信息结构的限制，并不关心底层介质有什么物理学过程。