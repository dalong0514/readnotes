# 2019011数据民工来取经R00

## 记忆时间

2020-01-30

## 卡片

### 0101. 反常识卡——如何分析数据

两个核心技能：数据的处理能力和数据的分析能力。

数据分析初阶能力：Excel + 细分/对比的基本思维；数据分析能力进阶：SQL + 业务指标 + 常用分析方法；数据分析能力再进阶：Python + Shell + SQL + 业务指标 + 常用统计指标 + 数据挖掘常用算法；数据分析再再升级：思维的升级。

思维升级包括：场景化思维习惯，数据背后对应的是人与事的场景；观察并思考生活中的营销；入行数据分析后，从数据中发现了更多样更真实的世界。

## 总纲

讲下如何入门数据分析：数据处理能力和数据分析思维。

1『数据分析初阶能力：Excel + 细分/对比的基本思维。』

最初级的分析师，Excel + 细分/对比的基本思维。

第一，数据处理，Excel 只是最基础的能力，当然也是必备的。必备是因为使用频率真的很高，很多同学可能觉得只有 code 才代表能力，千万别有这个不成熟的想法，比如飞机火车出现后，自行车依然是一种极大提升人类出行效率的交通工具。Excel 的熟练程度，也会极大提升数据分析过程中的效率，大量的时间成本就是这样被节省的。

第二，Excel 功能太多，出版的书都好几本新华字典的厚度，我们不能也完全没必要学习所有的功能，则需而取。下面几个关键词（排名不分先后），你如果一看会心一笑那说明就够了，如果懵逼，就说明你还需要学习下它们：透视表 ，刷选，多列排序，折线图，直方图，双坐标图，数据导入分隔符设置，vlookup，count，sum，冻结首行。

2『得到的讲座「伍昊的高效 Excel 指南」以及书籍「2019838你早该这么玩Excel二」，Excel 的学习可以去看官方文档：[Excel 帮助 - Office 支持](https://support.office.com/zh-CN/excel)。』

第三，细分和对比的思维。数据进行分析，基本、必用的方法，是否能用好，跟自己数据敏感度和业务熟练度强相关。如果你觉得这个也很简单，我不认为你错，但是请把它用好。同样，下面我提几个问题，你看看是不是胸里竹子成林：今天，煎饼卖出去 50 张，评价卖的怎么样？今天，知乎 App 活跃 1000 万，评价是否正常？今天，煎饼出摊时间也是 3 小时，为啥收入少了 100 元，为什么？今天，知乎 App 活跃用户跟昨天一样多，知乎盐会员比昨天少买了 100 万，为什么？

以上，问题，第一步，绝对是细分和对比。煎饼摊主，知乎数据分析师，会针对自己业务展开大扫除的分析。

我是煎饼摊老板:

1. 数据敏感度：今天跟昨天比下降比例？今天出摊时间多久，与往常降低多少小时？

2. 业务熟悉度：今天是周末吗？对面多了个卖肉夹馍的？

我是知乎数据分析师:

1. 数据敏感度：下降了多少？昨天是周几？

2. 业务熟悉度：昨天有活动吗？这段时间新增高质量 live 数量怎么样？

1『数据分析能力进阶：SQL + 业务指标 + 常用分析方法。』

SQL 学习起来，比其他编程语言容易入手，不过精通也需要一个过程。入门，看下 W3School-SQL 教程，然后自己练习下，了解基本的语法，剩下的在工作中慢慢提升就中，简单的查询，之前整理的一个特别简单的用 sql 进行统计分析的案例。

2『

[w3school 在线教程](https://www.w3school.com.cn/index.html)

[MySQL 教程 | W3School Sql 教程](https://wizardforcel.gitbooks.io/w3school-sql/content/111.html)

[SQL 教程](https://www.w3school.com.cn/sql/index.asp)，对应的已下载书籍「2020013w3school-sql教程」。

』

业务指标：PV/UV；日活/月活；次日留存（一般分析新用户次日留存）；ARPU；转化率（某动作的转化率，如点击转化率，下单转化率，充值转化率等）。

常用分析方法如下。对比：大法宝，关键要知道怎么对比和谁对比；细分：分地点，分人群，分时间，分产品，分渠道；漏斗：每一步的转化率，清晰有层次；RFM：R 最近消费日期，F 消费频次，M 消费金额，这个可用来粗暴的进行用户分层，已经被广泛用在各个行业；TGI：衡量某类人群某个特征与整体人群该特征平均值进行比较，量化该人群该特征是否强大或弱小；AARRR：Acquisition 用户获取，Activation 活跃，Retention 留存，Revenue收入，Refer 传播。

1『数据分析能力再进阶：Python + Shell + SQL + 业务指标 + 常用统计指标 + 数据挖掘常用算法。』

python 数据分析包学习：pandas+numpy+matplotlib。pandas 等熟悉 python 基本语法后，下一步要学习的。这个要熟悉，花的时间要久一些，因为功能实在太多，但没关系，我们可以用到哪儿学习哪，你后来会发现，常用的就那些；numpy：numpy 中文文档；matplotlib，主要用来绘图，之前有整理 python 绘图的入门文章，都一两行代码画一张图的实例。

Linux 系统的 Terminal，通过 shell 命令大大提升程序员的工作效率，对于数据分析师来说，也是一样。shell 常用命令入手也是特别容易的，但静态 shell 脚本编程就另外需要时间积累。而满足数据分析师 90% 使用场景的 shell 命令，下面列几个：cat；wc；grep；sed；sort；uniq；awk （这个算是一门语言，但很强大，建议入门学习）。

awk 数据统计需要有点 Shell 基础，不过因为我工作中常用，所以也放这里。汇总如下：

常用统计指标：平均值，不解释；中位数，假如小明班级 30 人，成绩排名 15 的成绩分数值就是小明班级成绩分数的中位数；p 值，一句话粗暴解释，用于假设检验，其值反映某一事件发生的可能性大小。假设 A 成立，然后找出支持 A 不成立的概率总和，如果该值小于 0.05（一般是这个阈值，当然可以自己定义），说明小概率事件发生，我们认为 A 成立。

数据挖掘常用算法：线性回归；kmean 聚类；逻辑回归；贝叶斯。以上算法，不同阶段的同学可以采样不同的使用方式：学会如何调用，灌入数据，输出结果，简单解析；了解不同算法的使用场景，优缺点，调用并解释数据；理解其计算方法，并尝试自己写代码失效，并结合业务场景，提取和筛选有效特征，进行模型训练和预测。

1『数据分析再再升级：思维的升级。』

1、场景化思维习惯。数据背后对应的是人与事的场景。用户在什么场景下购买？为什么用户不付费？有些可能数据上看不到，但我们可以按照认知推断。拿自己来说，上班从回龙观到西三期 6 公里，公交和地铁都不太方便，所以会选择骑车，这是使用场景。另外，自己比较注重时间成本，能提升自己效率缩短时间的服务，自己乐于付费，所以不会因为充值小黄车后，就不购买摩拜月卡，相反，连小蓝、哈罗的月卡也都会购买，因为不希望花费时间找车（都是趁运营 MM 搞活动的时候大肆购买，哈哈） 然而，老婆是典型的羊毛党，坚持贯彻将互联网服务免费到底，享受着烧钱大战期间的各种赠送，坚决不买会员，但是当优惠消失，自己又确实需要时，才会临时付费，这就是背后的场景。我和朋友代表的就是两大类用户群体，因为不同的价值观，自然对应不同的用户行为。

2、观察并思考生活中的营销。

1. 为什么我收到电信运营商赠送 15GB 流量？因为我两个手机号，电信号基本没有，运营商要激活我这个沉默已久的用户；

2. 为什么滴滴打车你的价格高？可能你周围叫车用户多而司机少，也可能「其他原因」；

3. 为什么有了淘宝京东，还会再出现拼多多？因为存在生产低端产品的商家群体和不太在乎质量的降级消费群体，但缺少鼓励这样电商平台；

4. 为什么微信改版去掉点赞，增加好看？微信想加深用户粘性，让你看到更多朋友的世界，也让微信文章得到更多曝光；

5. 为什么每个超市都鼓励办会员卡？因为要留住你，增加你选择去他们消费的机会，减少去竞争对手消费的机会；

6. 为什么品牌加盟店费用那么高？因为用户相信背书，用户想降低试错成本，用户有消费习惯，而品牌在一定程度上满足这点，而这就是品牌价值；

7. 为什么地铁里会遇到乞讨者？因为获客成本低，几块钱可以坐一天，遇到几千名乘客，哪有这么便宜的流量！

8. 为什么乞讨会自带音响？为了提高转化率，一天遇到几千名乘客，专业乞讨者早已深谙其道；

3、入行数据分析后，从数据中发现了更多样更真实的世界，很有趣：

1. 人是个性化的，不同价值观的人，进而产生差异的网上行为，数据分析的工作让我从数据上观察到这些差异，也让自己能更客观的看待不同性格和不同价值观的人。

2. 机器学习，分类预测，不同特征输入，得到不同结果，人生也是一样。更认同：你想要什么样的生活，决定于和你关联的因素。这些因素包括：家庭背景，教育背景，周围朋友，居住城市，公司，行业，性格，习惯，价值观，选择。这里面有不可变的客观因素，也有可变因素。不要抱怨客观因素，而要发挥可变因素，因为它才是最重要的因子。

『一些咨询的问题汇总如下。』

入行 4 年，到现在 shell，python，java，hive，spark，scala，竟然也都可以写写了，但并不深入，都是在围绕数据处理和分析使用，只是多了几种数据处理工具而已。像我这样学习这么多语言确实也没必要！纯粹是因为现在的业务数据存储平台，必须用到这些才可以开展，而我知道的大部分公司的数据分析岗位，包括头条，滴滴，快手，美团，bat，也包括我米的其他业务线，数据处理技能上只要熟练 sql，excel，略懂些 shell 和 python 就可以胜任了，真遇到处理不了的数据也有专门的数据攻城狮帮忙。而作为数据分析师的你，剩下的主要工作，是针对业务数据，展开你的脑洞，恢复用户行为的场景，从不同角度，加深数据挖掘，而随着你对业务数据的不断熟悉，你的提升也会很大。

多看知乎前辈的建议，如果不嫌弃，就把我上面的回答再看一遍。先学数据处理的技能，再找公司实习，找实习要比正式员工要求低很多，另外，实习能让你看到真正的业务是怎么运转的，数据是怎么流动的，甚至工作流程是什么样的，邮件是怎么发送的，以后你工作的内容是什么样的，这也会让你更加清楚「数据分析」是不是你想要的。切记，实习中，不要眼高手低，不要嫌活重复没挑战。比如提数和 Excel 处理数据等，我进入第一家大数据公司做数据分析，当时连 sql 也写的很不熟练，也是从提数开始的，而且提数是数据分析第一步，也是对业务熟悉的必须必须经历的，对于数据分析，说夸张点，它就是空气和水，滋养自己数据分析整个生涯，所以不要排斥它。

『资源汇总如下。』

1、《谁说菜鸟不会数据分析》系列，算是大白话了，通俗易懂，并且也实例讲解了数据分析一些常用方法。

2、《数据挖掘与数据化运营实战》卢辉，这本书将了常用的挖掘方法，比如聚类，主成分分析，因子分析，关联规则等，同时还列举了很多阿里实战案例，我转行的时候买的，没有公式，后面入行后才感觉，作者写的真好，都是实践后的干货总结。

2『已下载书籍「2020014谁说菜鸟不会数据分析入门篇」、「2020015谁说菜鸟不会数据分析工具篇」、「2020016谁说菜鸟不会数据分析SPSS篇」和「2019247数据挖掘与数据化运营实战」。』

sql 是一种语言，它用来和数据库进行交互，进行操作数据的增删改查，而数据库是有多种的，比如 mysql，oracle，sql server，hive 等，每种数据库适配的 sql 语言基本相同，所以在学习的时候，选择其中一种数据库进行操作学习即可，mysql 是目前也是互联网采用最广泛的数据库，oracle/sql server 银行等传统企业用的比较多，而 hive 是集成在分布式文件系统 hadoop 之上的数据库，俗称「大数据」，主要用来存储用户访问的行为日志。我们学习 sql 这个语言语法的话，选择 mysql 进行学习即可，其他大同小异。

1、数据分析师，对于 shell 命令的了解，仅限于基本命令的使用和数据的处理，对于 shell 的开发不做特别要求，具体看个人兴趣和时间成本则需投入。

2、鸟哥的 Linux 私房菜，当然也有对应的书，价格比较贵，不过物有所值，书本是对整个 Linux 系统介绍，比较全面，这本书不是专门为数据分析师准备的，很大开发和运维都会读这本书，如果只是数据分析使用，完全没必要全读，主要读 shell 部分就可以了。

2『已下载书籍「2019007鸟哥的Linux私房菜」。』

Python 数据分析第三方：数据分析：pandas，numpy；绘图包：matplotlib，seaborn；机器学习：sklearn，tensorflow 等。

1、《利用Python进行数据分析》，主要介绍如何用 pandas 进行数据分析，也会讲到 numpy，以及 matplotlib 和 pandas 绘图，这本书确实写的很好，但是小白上来阅读可能会一头水雾。

2、《集体智慧编程》，讲了经典的数据挖掘算法，Python 代码，我是刚入门的时候读过，这本书适合有一定 Python 基础的同学阅读，可能刚入门的同学，还是聚焦于 pandas 的熟练使用会比较好，以后入行后有空再读，现在信息大爆炸，即使是好东西，我们也要选择性的获取，珍惜自己的时间。

3、《机器学习》周志华，这本太经典了，我看了 2 遍，虽然并没有进行公式推导，但也收获蛮大，有空会再读。这本书入门同学尤其是偏业务而非技术的分析师可以不用太着急读，开始的精力先聚焦到数据思维，业务，excel，sql，如果有富余精力，再学习 shell，python，一步一步来哈。

2『已下载书籍「2019065利用Python进行数据分析」、「2020017集体智慧编程」和「2020018周志华的机器学习」』

## 01. 大白话 shell 命令系列

1『连接远程服务的方法即为当时搭建 vps 时进服务器的办法：ssh root@192.168.1.1。』

3『

[Linux awk 命令 | 菜鸟教程](https://www.runoob.com/linux/linux-comm-awk.html)

[AWK - 维基百科，自由的百科全书](https://zh.wikipedia.org/wiki/AWK)

[awk 入门教程 - 阮一峰的网络日志](http://www.ruanyifeng.com/blog/2018/11/awk.html)

』

行数命令模板：

    wc -l 文件位置

过滤关键词，命令模板：

    grep '待过滤词' 文件位置
    grep '北京' userprofile.csv

命令模板：

    cut -d '分隔符' -fm,n 文件位置

按某列排序命令模板：

    sort -t'分隔符' -knr 文件位置

某文件行去重后行数。代码样例：

```
# 如下命令解释:
# | 为管道符号，可以简单理解为把上一条命令执行的结果输入到下一条命令
# 这样就把两个不同命令像水管一样连接起来使用
sort -u userprofile.csv | wc -l
```

awk 是一个强大的文本处理语言，用于数据处理和统计。数据分析师应该 get 到它，会严重提高自己的数据处理效率。如果文件超过 Excel 处理能力，因为希望立刻得到基本统计信息，来不及或不想投入一定时间写 python 或其他程序处理，那么用 awk 就太赞了，可轻松对几百万甚至几千万行数据进行处理，秒级别出结果。

2『已下载书籍「2020022The_AWK_Programming_Language」和「2020023Effective_awk_Programming4Ed」。』



