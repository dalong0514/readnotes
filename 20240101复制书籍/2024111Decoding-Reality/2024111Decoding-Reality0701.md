Vlatko Vedral.(2018).2024111Decoding-Reality.Oxford University Press => 0101




0701Social Informatics: Get Connected or Die Tryin'

Everybody knows a Joe. Joe is the kind of guy who was the most popular boy in class, head boy at school, the life and soul of the party, and whenever he needs something, it just seems to happen for him. This is the guy we love to hate! Why is he getting all the breaks when we have to work so damn hard? As we continue to grind out each day at work, we see Joe is the guy with a big house, fast car, and the most beautiful women swooning over him. Most men would give their right arm to have a bit of that magic.

So, how does he do it? Of course, I cannot tell you for sure (if I could my next book would be a bestselling self-help book), but it should come as no surprise that people with more friends and contacts tend to be more successful than people with fewer. Intuitively, we know that these people, by virtue of their wide range of contacts, seem to have more support and opportunity to make the choices they want.

Likewise, again it's no surprise that more interconnected societies tend to be able to cope better with challenging events than ones where people are segregated or isolated. Initially it seems unlikely that this connectedness has anything to do with Shannon's information theory; after all what does sending a message down a telephone line have to do with how societies function or respond to events?

The first substantial clue that information may play some role in sociology came in 1971 from the American economist and Nobel Laureate, Thomas Schelling. Up until his time sociology was a highly qualitative subject (and still predominantly is); however he showed how certain social paradigms could be approached in the same rigorous quantitative manner as other processes where exchange of information is the key driver.

Schelling is an interesting character. He served with the Marshall Plan (the plan to help Europe recover after World War II), the White House, and the Executive Office of the President from 1948 to 1953, as well as holding a string of positions at illustrious academic institutions, including Yale and Harvard. Schelling is most famous for his work on conflicts between nation-states, particularly those with nuclear weapons. Here the central idea is that of ‘pre-commitment'. One party in a conflict can strengthen its strategic position by cutting off some of its options to make its threats more credible. For example, an army that burns its bridges, making retreat impossible, is a classic military example – here the opposition now knows you can no longer retreat and therefore its strategy is more limited. They know you are fighting until the end – a classic case of brinkmanship.

But Schelling went further. He realized that studying conflict can result in an understanding stretching far beyond military conflict. He applied a similar analysis to individuals' internal struggles. The problem, he suggested, is that pretty much everybody suffers from a split personality on various issues. For example, one side of you may desperately want to lose weight or quit smoking or run two miles a day or get up early to work. On the other hand, the other side may want an extra dessert or a cigarette, hate exercise, or love sleep. Both selves are equally valid, and equally rational about pursuing their desires. But they do not exist at the same time and which side wins depends on the strategies that the two personalities use. In Schelling's view, we could improve the chances of one side winning by showing a huge commitment which the other side would find difficult to match. So whilst the second side says I want to stay in bed a bit longer, the first side can retaliate with ‘but I am paying $70 a week for morning personal training sessions'. Gym memberships, not keeping cigarettes in the house, not having a car and walking to work instead, are all examples of what Shelling referred to as ‘burning your bridges'.

Studying conflict thus turned out to be important not only for the military, but also for individuals and, as we will see shortly, for understanding segregation in a society. And underlying it will, of course, be the concept of information.

The idea of using information theory in social studies is certainly not something new and we can trace its roots back way before Schelling. In fact, it is the use of statistical methods in social sciences that prompted Boltzmann to apply them within physics in order to come up with his entropy formula. Of course, a direct application of the statistical methods used in information theory is much more challenging given the complex nature of any human society (yes, human society is far more complex than any physical system), but it has the same underlying premise. When compared to a simple gas of atoms, which is a typical model in physics, every human being has added variability in that he or she can formulate an independent complex strategy in order to satisfy their own ends.

Information itself appears in many different guises in the social context: connections between individuals, actions, and states of individuals, capacity of societies to process data, and so on. All of these types of information play a role in the functioning of a society.

An important idea that we have alluded to in the previous chapters, but whose more precise introduction we have been delaying, is that of ‘mutual information'. This concept is very important in understanding a diverse number of phenomena in Nature and will be the key when we explain the origin of structure in any society.

Mutual information is the formal word used to describe the situation when two (or more) events share information about one another. Having mutual information between events means that they are no longer independent; one event has something to tell you about the other. For example, when someone asks if you'd like a drink in a bar, how many times have you replied ‘I'll have one if you have one'? This statement means that you are immediately correlating your actions with the actions of the person offering you a drink. If they have a drink, so will you; if they don't, neither will you. Your choice to drink-or-not-to-drink is completely tied to theirs and hence, in information theory parlance, you both have maximum mutual information.

A little more formally, the whole presence of mutual information can be phrased as an inference indicator. Two things have mutual information if by looking at just one of them you can infer something about one of the properties of the other one. So, in the above example, if I see that you have a drink in front of you that means logically that the person offering you a drink also has a glass in front of them (given that you only drink when the person next to you drinks).

Of course mutual information between events is not always perfect, it could also be imperfect, in that you ‘usually' but not always will have a drink if your friend has a drink. In this case any inference between the two of you will be weaker.

Whenever we discuss mutual information we are really asking how much information an object/person/idea has about another object/person/idea. In the telephone communication example, Alice and Bob share mutual information. After she has communicated to Bob, the two now share this same message. When Bob tells you what the message is, assuming maximum mutual information between Alice and Bob, you will then know what message Alice sent without having to ask Alice. In cases of non-maximal mutual information (e.g. Bob may have forgotten parts of it) we can only infer the message with partial success.

When it comes to DNA, its molecules share information about the protein they encode. Different strands of DNA share information about each other as well (we know that A only binds to G and C only binds to T). Furthermore the DNA molecules of different people also share information about one another (a father and a son, for example, share half of their DNA genetic material) and the DNA is itself sharing information with the environment – in that the environment determines through natural selection how the DNA evolves.

In thermodynamics, mutual information is established between the demon's memory and the movement of the particles. How much work the demon can extract is dependent on how much information the demon has on the actual speed of the particles. In financial strategies, the profit derived is inevitably linked to how much information you share with the market (random betting aside). If you want to know how the price of the stock will move, then you need to have complete information about the market (often virtually impossible given the complexity and volume of information). Given that everything interacts to some degree with everything else, mutual information is simply everywhere!

One of the phenomena we will try to understand here, using mutual information, is what we call ‘globalization', or the increasing interconnectedness of disparate societies. Another social phenomenon we will address is the division of every society into different classes and the related negative effects of segregation.

Before we delve further into social phenomena, I need to explain an important concept in physics called a phase transition. Stated somewhat loosely, phase transitions occur in a system when the information shared between the individual constituents become large (so for a gas in a box, for an iron rod in a magnetic field, and for a copper wire connected into an electric circuit, all their constituents share some degree of mutual information).

A high degree of mutual information often leads to a fundamentally different behaviour, although the individual constituents are still the same. To elaborate this point, the individual constituents are not affected on an individual basis, but as a group they exhibit entirely different behaviour. The key is how the individual constituents relate to one another and create a group dynamic. This is captured by the phrase ‘more is different', by the physicist Philip Anderson, who contributed a great deal to the subject, culminating in his Nobel Prize in 1977.

A common example of a group dynamic is the effect we observe when boiling or freezing water (i.e. conversion of a liquid to a gas or conversion of a liquid to a solid). These extreme and visible changes of structures and behaviour are known as phase transitions. When water freezes, the phase transition occurs as the water molecules becomes more tightly correlated and these correlations manifest themselves in stronger molecular bonds and a more solid structure.

The formation of societies and significant changes in every society – such as a revolution or a civil war or the attainment of democracy – can, in fact, be better understood using the language of phase transitions.

I now present one particular example that will explain phase transitions in more detail. This example will then act as our model to explain various social phenomena that we will tackle later in the chapter. Let us imagine a simple solid, made up of a myriad of atoms (billions and billions of them). Atoms usually interact with each other, although these interactions hardly ever stretch beyond their nearest neighbours. So, atoms next to each other will feel each other's presence only, while the ones that are further apart from each other will typically never directly exchange any information.

It would now be expected that as a result of the ‘nearest neighbour' interaction, only the atoms next to each other share information while this is not possible where there is no interaction. Though this may sound logical, it is in fact entirely incorrect. Think of a whip: you shake one end and this directly influences the speed and range at which the other end moves. You are transferring movement using the interconnectedness of atoms in the whip. Information can be shared between distant atoms because one atom interacts with its neighbours, but the neighbours also interact with their neighbours, and so on. This concept can be explained more elegantly through the concept of ‘six degrees of separation'.

You often see it claimed that each person on this planet is at most six people away from any other person. This sounds shocking at first but actually makes complete sense if you look at it in detail. I am, for example, just three degrees of separation (three people) away from Bill Clinton. How's this? Well, I know a guy quite well who works in the City of London. His boss knows the boss of the American branch of the bank and the American boss knows Bill Clinton. So there we go! So if you count the number of people separating Bill Clinton and me you will see that there are only three. Though I may be particularly indifferent to the fact that I am separated from former President Clinton only by three degrees (he surely is), it is nevertheless interesting that this is so. It is also interesting that this is how connections work. It doesn't matter whether you know a person doing X, all that matters is that you are connected into society, because, through this, you have access to almost everybody on the planet (and somebody somewhere should know something about X).

It is very easy to see why any one person is connected to any other with at most six degrees of separation. Say that I know roughly 100 people (probably more, but it is said that 200 is the capacity for the human brain to differentiate and memorize different names and faces – this is our evolutionary inheritance for the early days of human evolution, where time was spent in small tribes). Each of the 100 people I know knows 100 more people, and so on. After five steps this number reaches ten billion (100 times 100 times 100 times 100 times 100, five times). The number of people in the world is six billion. So, even five steps of connections and acquaintances are enough in this model to connect everyone to everyone else on this planet. But, of course, maybe not everyone knows 100 people, and so on, which leads to perhaps needing six degrees to make a network that covers everyone in the world. Perhaps this is why in society we gravitate to more connected people, to optimize our interconnectedness.

Why is this networking between people important? You might argue that decisions made by society are to a high degree controlled by individuals – who ultimately think for themselves. It is clear, however, that this thinking is based on the common information shared between individuals. It is this interaction between individuals that is responsible for the different structures within society as well as society itself.

Societies can, in addition, have a certain number of other features, such as a degree of centralization in their decision making. One extreme form of centralization is dictatorship, and it is not very interesting to analyse as individuals have less of a role in any decision making (by definition). The other extreme is much more interesting, and this means that there is no centralization and where individuals line up of their own accord. Here we would like the consensus to emerge just by individuals interacting with one another – no external stimulus is allowed. In this case, the information shared between individuals becomes much more important. So how do all people agree to make a decision, if they only interact locally, i.e. with a very limited number of neighbours?

In order to understand how local correlations can lead to the establishment of structures within society, let us return to the example of a solid. Solids are regular arrays of atoms. This time, however, rather than talking about how water becomes ice, let's consider how a solid becomes a magnet. Every atom in a solid can be thought of as a little magnet on its own. Initially these magnets are completely independent of one another and there is no common north/south alignment – meaning that they are all pointing in random directions. The whole solid – the whole collection of atoms – would then be a random collection of magnets and would not be magnetized as a whole (this is known as a paramagnet). All the random little atomic magnets would simply cancel each other out in effect and there would be no net magnetic field.

However, if the atoms interact, then they can affect each other's state, i.e. they can cause their neighbours to line up with them. Now through the same principle as six degrees of separation, each atom affects the other atoms it is connected to, and in turn these affect their own neighbours, eventually correlating all the atoms in the solid. If the interaction is stronger than the noise due to the external temperature, then all magnets will eventually align in the same direction and the solid as a whole generates a net magnetic field and hence becomes magnetic! All atoms now behave coherently in tune, just like one big magnet. The point at which all atoms ‘spontaneously' align is known as the point of phase transition, i.e. the point at which a solid becomes a magnet.

Can this simple idea be applied to something as complicated as human society? Initially, this seems like it may be very difficult. We would like to think of humans as little magnets (let's say that they can ‘politically' point in the left or right direction) and we now investigate under what circumstances whole societies can swing to the left or to the right and how this requires very little external influence. This would be the social analogue of the magnetic phase transition.

You may object that atoms are simple systems compared to humans. After all humans can think, feel, get angry, while atoms are not alive and their range of behaviour is far simpler. But this is not the point! The point is that we are only focusing on one relevant property of humans (or atoms) here. Atoms are not all that simple either, but we are choosing to make them so by looking only at their magnetic properties. Humans are much more complicated still, but now we only want to know about their political preference, and these can be quite simple in practice.

Let us discuss this aspect a bit more. Surely there is a crucial difference between atoms and humans. Namely, humans have free will. They are autonomous and make their own decisions, create their own destinies. Atoms are incapable of this. While this discussion of free will is a very intricate one, and we will debate it later, there is something that could already be said on it here.

Suppose for that matter that you observe satellite pictures of people walking up and down a busy street, such as Oxford Street in London. You will not be able to make out who the individuals are – that is if you use the google.com satellite pictures (I am sure that CIA or MOSSAD can easily accomplish a better resolution). People will appear as dots moving between two straight lines – the edges of the pavement of Oxford Street. There will be some larger dots in the middle representing the traffic, which we will ignore for the time being.

You now observe how the dots move. They will broadly move up and down the street, but there will be a certain movement to the left and to the right too, as the dots avoid each other. Imagine now that someone shows you this picture of dots moving in this fashion, but does not tell you that they represent people. Would you be able to tell, just from the motion of the dots, whether they represent something living (even intelligent?) from something non-living (such as atoms, or billiard balls hitting each other and bouncing off in different directions)?

Most likely you wouldn't be able to tell the difference, as the motion of people or atoms would be roughly the same (in their own ways they both avoid collisions, either via seeing and moving or via electrostatic repulsion). Both would be known as a diffusion process – a general overall flow in one direction (up and down), but with some random irregularities every once in a while. And this is precisely my point, that living and non-living things appear to behave in a very similar manner.

We now return to the issue of phase transitions and human societies. Suppose that we have a chain of systems where each system only interacts with its two neighbours. Such a system was first considered in physics by Ernest Ising, who studied it during his PhD in the 1920s. Unfortunately, he was able to prove very conclusively that there is no phase transition in such a model. So, if you think of atoms in such a chain as being little magnets, then they can never ever spontaneously align with each other no matter what happens outside. This was apparently such a disappointing conclusion to Ising, who was hoping to explain phase transitions microscopically, that he quit physics after his PhD!

Too bad for Ising, because some 20 years later Lars Onsager showed in a very beautiful paper that if instead of a chain you look at a two-dimensional array of atoms, then there is a phase transition at low enough temperatures. And for this, Onsager was awarded a Nobel Prize for chemistry. The whole area of phase transitions then started to thrive, resulting in a number of fundamental discoveries and Nobel Prizes (Anderson's included).

Among one of the most striking results in phase transitions that I am aware of is a very general ‘no-go' theorem. No-go theorems are broad results that rule out some specific kind of behaviour. Ising's result is a special kind of no-go theorem that says that there are no phase transitions in one dimension (chains). Interestingly, it can be shown that there are no general phase transitions in two dimensions (planes) either. The only exception to this no-go in the two-dimensional case is the model that Onsager analysed (so he was very lucky after all!). The very fact that we see ice turn into water and water into vapour already implies that the Universe has to be at least three-dimensional.

Anyway, what has all this to do with human societies? You can think of atoms in the above systems, not as little magnets, but as human beings! Yes, as commented above, we are more complicated than atoms, but some of our features are very simple. Think of a human being and his political predispositions. Suppose that we have two choices in a society, to be conservative or to be liberal. These two states would be the human analogue of a magnet with two states: pointing to the right, or pointing to the left (I am fully aware that some cynics might say that ‘in power' or ‘out of power' are more important directions in politics).

Now, in general, a society will be in a state such that some members are conservative and some liberal. But suppose that we ask under what conditions would all members become, say, liberal? Our discussion of Ising's result would suggest that if we have a very simple society where every member discusses politics only with their two nearest neighbours (and no one else), then there is no way that we can have a fully liberal society. We can never have a spontaneous liberalization and we are always forced to live with some conservatives!

A one-dimensional society is therefore very easy to describe and there are no surprising changes here. One such society is the mafia depicted in the movie Goodfellas (this is indeed far from being liberal). The main boss of the mafia, the capo di tutti capi, is a guy called Pauly, who would only communicate his orders to his two closest men – he would rarely talk to anyone else. They would then in turn communicate to their closest allies, and so on. This is not only secure so far as it prevents the FBI from finding the key people in the mafia, but it also leads to an increased stability within the mafia itself. It is therefore very unlikely that the mafia as a whole will suddenly undergo a phase transition and change its behaviour significantly, for example, electing a new leader or breaking down due to a few rogue informants.

Interestingly, if we allow everyone to interact with everyone else, then even in one dimension phase transitions are possible. Now, the real world is somewhere between these two extremes. None of us really speaks only to our neighbours, and no-one certainly communicates to everyone in the world. As I said above, our circle of family, friends, and acquaintances to which we are sufficiently connected usually extends to roughly 200 people.

In fact, the number of connections we have with other humans follows what is known as a power law distribution. The number of people who know lots of other people is smaller than the number of people who know few. And the ratio of the two numbers follows a strict law, similar to the Zipf law of letter frequencies mentioned earlier in the book. More precisely, there are a million times fewer people with 1000 contacts than with 10 contacts. People with lots of connections are just statistically improbable in the same way that longer words are less likely to be heard in English.

This unevenness in the number of contacts leads to a very important model where there is a great deal of interaction with people close by and then, every once in a while, there is a long-distance interaction with someone far away. This is called a ‘small world network' and is an excellent model for how and why disease propagates rapidly in our world. When we get ill, disease usually spreads quickly to our closest neighbours. Then it is enough that only one of the neighbours takes a long-distance flight and this can then make the virus spread in distant places. And this is why we are very worried about swine flu and all sorts of other potential viruses that can kill humans.

Let us now consider why some people believe – rightly or wrongly – that the information revolution has and will transform our society more than any other revolution in the past – such as the industrial revolution discussed in earlier chapters. Some sociologists, such as Manuel Castells, believe that the Internet will inflict much more profound transformations in our society than ever previously seen in history. His logic is based on the above idea of phase transitions, though, being a sociologist, he may not be interpreting them in quite the same way as a physicist does mathematically.

To explain, we can think of early societies as very ‘local' in nature. One tribe exists here, another over there, but with very little communication between them. Even towards the end of the nineteenth century, transfer of ideas and communication in general were still very slow. So for a long time humans have lived in societies where communication was very short range. And, in physics, this would mean that abrupt changes are impossible. Societies have other complexities, so I would say that ‘fundamental change is unlikely' rather than ‘impossible'. Very recently, through the increasing availability of technology we can travel far and wide, and through the Internet we can learn from and communicate with virtually anyone in the world.

Early societies were like the Ising model, while later ones are more like the small world networks. Increasingly, however, we are approaching the stage where everyone can and does interact with everyone else. And this is exactly when phase transitions become increasingly more likely. Money (and even labour) can travel from one end of the globe to another in a matter of seconds or even faster. This, of course, has an effect on all elements of our society.

Analysing social structures in terms of information theory can frequently reveal very counterintuitive features. This is why it is important to be familiar with a language of information theory, because without a formalized framework, some of the most startling and beautiful effects are much harder to understand in terms of root causes. Take segregation in a modern society, for example. Modern-day Los Angeles has distinct areas with clearly defined boundaries for white, Hispanic and black Americans. It is clear that this segregation is not legally imposed from above (each person is legally free to buy a property in any area they wish to) so is the inescapable conclusion that they are all a bunch of racists? The surprising answer, according to Schelling, is no, and that even the most liberal minded communities could end up transitioning into a segregated state. Segregation in this sense occurs very much like the phase transition we discussed earlier.

To simulate segregation, Schelling used a very simple model analogous to the phase transition model of a magnet described before. Imagine a two-dimensional grid, on which you can lay black and white pieces randomly. If we take this as synonymous with communities, this corresponds to a very liberal and mixed community (in the magnet example, this corresponds to a completely disordered state, where all the little magnets are aligned in all different directions).

Now we have to study the dynamics and see how segregation emerges. Schelling looked at the following rule: each and every piece looks around at its neighbours and if it sees a certain number of neighbours of different colour, it makes a decision to move somewhere else. It's clear that an extreme racist attitude is going to lead to segregation (e.g. if every piece moved just because one of its neighbours were of a different colour). However, and this is the surprise Schelling presented, it appears that even if you take a very liberal view, and move only when all your neighbours are of a different colour, this still leads us naturally to a segregated society. What this means in the Ising model is that even the weakest interaction is enough to make it undergo a phase transition. In such a model, interactions would force two spins to align themselves in the same way that in Schelling's model neighbours become racially homogeneous (to remind the reader, a city is analogous to a two-dimensional structure and in two dimensions, unlike in one dimension, the Ising model exhibits phase transitions).

The most natural way of thinking about this is in terms of mutual information. In the initial state, which was completely disordered, there was very little mutual information – because by looking at one piece, it is difficult to infer the colour of the neighbours (as by definition, the pieces are laid out in a disordered manner). However the mutual information is maximal in a maximally segregated society, as you can look at one piece and you can then infer the colour of all the pieces surrounding it. As with other phase transitions we have talked about, here mutual information is also a signature of a segregated society (a segregated society would represent an ordered state of magnets, when they all behave collectively).

If you properly understand Schelling's simple model, then you will quickly see that this doesn't have to apply to just racial segregation. It could also apply to any other grouping in a society. Political, financial, social, intellectual separations can all be studied and understood using the same logic.

We have been grossly simplifying societies here, but our analysis certainly contains some elements of truth. To see how much truth, let us test our predictive power on a very simple question. What is the distribution of wealth in a typical society? This question combines the gambling elements we discussed in the previous chapter with social elements we are discussing now.

If the basis of every society is information, as I have been arguing, does optimizing information tell us about the wealth distribution within a society? The answer is both yes and no. Let me explain the no first.

When we optimize the Shannon information we typically obtain a distribution of probabilities that is called Gaussian or bell curve. This distribution is named after the German mathematician Karl Friedrich Gauss, who first noticed the ubiquity of Gaussian distributions in Nature. For example, atoms in a gas distribute their speeds according to a Gaussian distribution. Most atoms move at some middle-range speed (say 500 metres per second). Then equally smaller numbers move at around 400 and 600 meters per second. The number of atoms that we record as we move away from 500 metres per second diminishes very quickly. And this is the main feature of Gaussians, which have a typical bell-shaped profile.

The distribution of wealth in most societies is not Gaussian. It is in fact a power law. This means that the number of very wealthy individuals is very small, whereas the number of poor is huge. If wealth followed a Gaussian distribution, then most people would be somewhere in the middle with small deviations to the richer and poorer side of the spectrum. This, alas, is never ever the case in any society we are aware of (not even in totalitarian communist regimes of the past such as the Soviet Union).

Where does the power law distribution come from? Why is the probability of having one million dollars in your bank account 1000 times smaller than having $1000? This is exactly what the power law says. If there are 100 millionaires in a country, then there are 100,000 people with only $1000.

Let us try to see why this is so. The complete answer is not known, but we can make some guesses (if I knew the answer I would probably immediately book myself a plane ticket to Stockholm to pick up a Noble Prize in economics). The favoured explanation seems to be a principle that can be called ‘the-rich-get-richer'. In simple terms, wealth doesn't just add to wealth, it multiplies. Those that have more will get proportionally more and so the gap between the haves and have-nots increases to conform to the power law. Even if everyone starts equally well off, the small random differences in people's fortunes (some will win on the random stock market, others will lose) will sooner or later grow to become large.

Does this mean that information has nothing to do with wealth distribution? No. People acquire wealth not only by themselves, but through a set of networks that they create using all sorts of social mechanisms. Social interactions are complicated and go on in parallel in all corners of any given society. The social dynamic is very intricate and changes on very short time-scales.

This means that we expect information not to have the additive property, namely that the joint information contained in two independent events must be equal to the sum of the information content of each individual event (this was used in Chapter 3 to derive Shannon's entropy). If additivity fails, the correct measure of information is no longer Shannon's. One person who studied these non-additive measures extensively is a Brazilian physicist, Constantino Tsallis. Why is wealth not additive? As we have seen, having some wealth and gaining more does not just result in the sum of the two. Wealth does not just simply add, it super-adds! This is another view of the principle of increasing returns in economics (which we met in Chapter 6). There is no contradiction here, since wealth is not a conserved quantity. It can be created out of nothing (by nothing I mean ‘no initial wealth'; I do not mean without any physical resources).

If we use a different formula to Shannon's, but still an inverse function of probability, we can explain the power law distribution. Therefore, even one of the key aspects of social dynamics and stability – its wealth distribution – is an outcome of simple information theory. If not Shannon's in actual form, this surely is Shannon in spirit.

Some sociologists are optimistic that the information age will lead to a fairer society that will improve everyone's living conditions, as well as narrowing the gap between the haves and have-nots. Others are rather pessimistic, claiming that the new age will bring an abrupt end, a kind of phase transition, to present society (through all sorts of mechanisms such as increased crime due to the breakdown of families, global terrorism, global warming, and so on).

It is unlikely that information theory will tell us what the future has in store for us. One thing is for sure, though. With greater interconnectedness of the world, we had better improve the speed of our thinking and decision making. In a more interconnected society we are more susceptible to sudden changes. Mutual information simply increases very rapidly and if we want to make good decisions we need to ensure that our own information processing keeps pace. The future, it seems, will not only favour the brave but also the fastest.

Having seen how information underpins various social, biological, and physical phenomena, we are now ready to take the discussion to the next level. We travel back to the questions of where this information comes from, how much of it there is in the Universe and what is the fastest that it can be processed. The answers to these questions underpin all the chapters we have seen so far. In order to understand the ultimate origins of information we need to take an exciting voyage of discovery. And this will take us into the realms of quantum mechanics, the true nature of randomness, whether teleportation is possible, and the question of free will and determinism. It's going to be a rocky boat, so hold on tight!

Key points

Correlated systems are those that share some common information.

Individuals in a society become correlated in many ways thorough various interactions, by communication for example.

Societies are networks of correlated individuals. The degree of correlation and networking determines what kind of society we have.

Most societies exist between the two extremes: completely connected and completely disconnected individuals. Such societies are an example of small world networks and explain many social phenomena, from the spread of disease to the winner-takes-all and fit-get-rich principles.