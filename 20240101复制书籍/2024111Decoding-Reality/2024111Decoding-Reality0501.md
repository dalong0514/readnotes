Vlatko Vedral.(2018).2024111Decoding-Reality.Oxford University Press => 0101

## 0501Murphy's Law: I Knew this Would Happen to Me

Life now seems so robust that it becomes difficult to imagine how it could ever end. Are we now masters of our own destiny? With the robustness of biological information, combined with deliberate genetic engineering, are we capable of adapting to any environment Nature throws at us? Aside from some exceptional force majeure (in which case no payout is guaranteed) is there any condition under which life may end?

One of the most topical and interesting discussions is whether life could run out of energy to function. But how could life ever run out of energy; and what does this actually mean? Are we just talking about the Sun dying or natural resources being depleted? The argument is that however life evolves in the future, it is difficult to imagine how it could run without the basic fuel. So if the Sun does die, we may find ourselves in a bit of pickle. However, in my view this hypothesis is entirely incorrect. At the end of the day, regardless of what happens in the Universe, the total energy is always conserved and it is merely our ability to process this energy that remains in question. Regardless of the Sun dying or natural resources being depleted, the same energy still exists within the Universe, and the challenge would then be to find different ways of harnessing it.

My argument in this chapter is that life paradoxically ends not when it underdoses on fuel, but, more fundamentally, when it overdoses on ‘information' (i.e. when it reaches a saturation point and can no longer process any further information). We have all experienced instances where we feel we cannot absorb any more information. The question is: is this fatal?

What would you like the epitaph on your tombstone to read when you die? Usually people do not have a strong desire to inscribe anything grand or meaningful themselves, but their close ones, the family, friends, and relatives, choose to write something down to commemorate their loss. Epitaphs, more frequently than not, contain a very brief description of the person, when they lived, and a statement amounting to the fact that that they will be greatly missed. Cemeteries are ultimately for the living, not the dead.

Perhaps you think similarly and you feel that you should lighten up the mood and atmosphere for the living who come and pay you a tribute. If they bring flowers to your grave, the least you could do is surprise them with an original epitaph. You may therefore be tempted to write something witty and funny that would be entertaining to the crowd gathering around your final resting place. George Bernard Shaw, an Irish playwright, subscribed to this view, which is why his epitaph reads: ‘I knew this would happen to me'.

In physics, the certainty with which Shaw knew of his inevitable death is retold through the Second Law of thermodynamics. Admittedly the Second Law is not as funny as Shaw but it does present this notion in a far more fundamental and widely applicable way.

The Second Law of thermodynamics tells us that in physical terms, a system reaches its death when it reaches its maximum disorder (i.e. it contains as much information as it can handle). This is sometimes (cheerfully) referred to as thermal death, which could really more appropriately be called information overload. This state of maximum disorder is when life effectively becomes a part of the rest of the lifeless Universe. Life no longer has any capacity to evolve and remains entirely at the mercy of the environment.

The Second Law of thermodynamics tells us not only that a system dies when it reaches its maximum disorder, it tells us, startlingly, that every physical system must inevitably tend towards its maximum disorder. But life is just another complex physical system, so what is the Second Law telling us about life? It is telling us that even life, one the most robust processes in the Universe, must eventually end – that its death is ultimately inevitable!

The question then is how certain are we about the Second Law. Life is telling us that it can propagate forever, whereas the Second Law is telling us that every physical system must eventually reach its thermal death. So who is right, as these two views seem to stand in direct opposition to each other?

To answer this question it's only right that we now give a little more colour to the Second Law of thermodynamics, one of the most fundamental laws in science. Scientists in fact trust the foundations of the Second Law so much that this is what the great English philosopher Bertrand Russell had to say about it:

That Man is the product of causes which had no prevision of the end they were achieving; that his origin, his growth, his hopes and fears, his loves and his beliefs, are but the outcome of accidental collocations of atoms; that no fire, no heroism, no intensity of thought and feeling, can preserve an individual life beyond the grave; that all the labours of all the ages, all the devotion, all the inspiration, all the noonday brightness of human genius, are destined to extinction in the vast death of the solar system, and that the whole temple of Man's achievement must inevitably be buried beneath the debris of a universe in ruins – all these things, if not quite beyond dispute, are yet so nearly certain, that no philosophy which rejects them can hope to stand. Only within the scaffolding of these truths, only on the firm foundation of unyielding despair, can the soul's habitation henceforth be safely built.

What Russell is saying (all in one breath – in a paragraph that contains an eleven-line sentence) is that increase in disorder is so certain that we had better get used to it as fast as possible. No serious philosopher can ignore it. Any belief that we hold, that contradicts the Second Law, does not have much chance of being correct – we really are only deluding ourselves if we think that we can escape its firm clutches.

Incidentally, if you think that Russell's statement sounds a bit depressing, you should read the German philosopher Friedrich Nietzsche. He, in fact, based the whole of his philosophy on the premise that physics implies that life is ultimately pointless, as eventually it must become extinct. The idea of absolute progress (the idea of progress to the point of perfection) must therefore ultimately be an illusion, in direct contrast to the ideas underpinning the evolution of life. Nietzsche thought that this conclusion is so difficult to live with that he needed to introduce the concept of a ‘superhuman' – an improved version of the human, able to come to terms with the fact that life cannot achieve absolute progress. Nietzsche, sadly, did not himself have the key attributes of his superhuman – he spent the last 11 years of his life in a lunatic asylum unable to deal with life, disillusioned and alone. A very depressing end to one of history's greatest thinkers.

Scientists, however, are pedantic beings. While Russell's and Nietzsche's arguments hold weight and seem logical from a philosophical perspective, a quantified proof of the Second Law is what scientists require. Only when we are able to quantify something mathematically can we test it reliably to verify or falsify it.

So how could the Second Law be described mathematically? Physics presents one mathematical formulation of the Second Law, based on a quantity known as ‘entropy'. This is the quantity von Neumann was referring to when he suggested to Shannon for him to name his information function similarly (Chapter 3). Entropy is a quantity that measures the disorder of a system and can be applied to any situation in which there are multiple possibilities. Physics presents a mathematical formulation of entropy by looking at all the possible states that the system can occupy. Each one of these states will occur with a certain probability that can be inferred from experiments or from some other principles. The logarithm of these probabilities is then taken and the total entropy of the system is then a direct function of this and tells us its degree of disorder:

S = k log W.

Using the concept of entropy physicists recast the Second Law into the principle that the entropy of a closed system always increases. This principle is one of the most fundamental laws in science and has deeply profound and wide-ranging significance for practically everything in the Universe. In fact, you can even think of the Universe itself as a closed system, in which case the Second Law tells us that its entropy is always increasing, i.e. that it is always becoming more and more disordered.

Amazingly, this entropy derived by physicists has the same form as the information-theoretic entropy derived by Shannon. Shannon derived his entropy to convey the amount of information that any communication channel can carry. So in the same sense, maybe we can look at the physicists' concept of entropy as quantifying the information content of a closed system. The Second Law then simply says that the system evolves to the state of maximal information, where no new information can be contained. For those of us using the Internet this will be a very familiar concept. When we are close to the bandwidth of our Internet link, our browser slows down, sometimes dramatically. This really is the information overload that we discussed earlier in this chapter.

When asked in a survey by a popular science magazine Spiked, for my opinion on the greatest discovery in physics, I immediately replied that it was Boltzmann's: ‘S = k log W'. This formula, from one of the founders of modern physics, Ludwig Boltzmann, provides the link between our microscopic and macroscopic understandings of the world. S is the entropy of a system and it signifies how disordered the system is. This is its macroscopic feature. W tells us about the number of its different microscopic states, and k is just a constant Boltzmann derived associating the two. It is Boltzmann's formula that shows us that it is, at least in principle, possible to reduce all our macroscopic knowledge to some basic microscopic physical laws; an attitude and philosophy that is frequently labelled as ‘reductionistic'.

Clearly Boltzmann's family thought the same, as this very simple formula for entropy was the epitaph written on his gravestone. Boltzmann discovered the formula in 1870, when he was about 30 years old. He argued that entropy will always grow with time – until it reaches its maximum, and this is exactly another way of stating the Second Law of thermodynamics. At the time this was considered very controversial and Boltzmann met stiff opposition on this and on several other ideas from his closest and most respected colleagues.

Boltzmann, like other great thinkers of our time, suffered a more complicated end than is usual. The pressure of the prevailing scientific establishment clearly was a factor in driving him to suicide. Interestingly, and possibly not accidentally, Nietzsche and Boltzmann are not the only people who suffered a tragic fate after thinking about the consequences of the Second Law. There is also Paul Ehrenfest, who committed suicide, and Robert Mayer, who became insane. Therefore, a disclaimer is possibly appropriate here: should the reader wish to continue reading about the Second Law, they do so at their own risk and I am accepting no liability.

Boltzmann's epitaph is actually not all that different to Shaw's. Only, rather than saying ‘I knew this would happen to me', Boltzmann's says ‘I knew my entropy had to reach its maximum sooner or later'. (Admittedly physicists are not as witty as playwrights, but, on the other hand, they probably have a deeper insight into the behaviour of the Universe.)

A very important point is that the Second Law of thermodynamics should not be confused with the energy conservation principle, which is in fact known as the First Law of thermodynamics. The First Law says that energy cannot be created out of nothing. It can only be transformed from one form to another, e.g. from electrical energy to the picture and sound in your TV. It is the First Law that is relevant when we discuss various environmental issues. Our planet has finite stored energy resources, such as coal, oil, and natural gas, which we use to extract useful work, e.g. making plastics, driving our cars, or making our food. The popular concern is that these resources are finite and will eventually be depleted – perhaps forcing us to move to a new planet with fresh resources. But wait a minute! Why should we be moving if energy is conserved? Surely it is just transformed from one form to another, so all we have to do is transform it back into useful energy, so that the cycle can continue.

To answer this, the Second Law enters, and the news is not good! The Second Law tells us that when we convert one form of energy into another we cannot do this with perfect efficiency (i.e. the entropy, the degree of disorder in the process, has to increase). For example, whenever we burn gas to run a car, not all of its energy is converted neatly into the motion of the car; some is lost to less useful effects such as heat and noise. Likewise, we can never draw back together all the energy (the exhaust fumes, motion of car, noise created, etc.) and turn it back into gas in an efficient manner. Some energy just simply has to be lost in this conversion process. This is exactly what the Second Law says: disorder must increase overall and energy must be randomly dissipated to the environment. As a consequence, the environment (e.g. our planet) absorbs this dissipated energy, which manifests itself as a rise in temperature. And so whenever any kind of energy is used we have global warming as a necessary consequence of the Second Law.

In fact, the Second Law is telling us that the only sure-fire way to prevent global warming is simply never to use any energy. Here I am not just talking about avoiding luxuries such as driving cars, using aerosols, or even taking any overseas holidays. Even when you do something as necessary as eating food, you convert it into work, but at the same time, according to the Second Law, this is an inefficient process and you inevitably make things hotter around yourself. Though don't think you can substitute for your home heating system by simply eating more. The increase in temperature is tiny, but the point is that it is still there. One person generates per second as much heat as a typical light bulb (calculating this is one of my favourite exam questions in the first year undergraduate physics that I teach); but when you add up the total contribution from six billion people things do heat up more substantially. To prevent this there is only one way – you must not do anything (though try telling that to your boss). Quit living and there won't be any global warming – at least none as far as man-made causes are involved (now there's a tall order for extreme environmentalists).

The concern for life on this planet is therefore not to run out of energy per se, but rather to run out of ways of processing this energy as efficiently as possible. It is interesting that though this is still widely misunderstood at present, Boltzmann, even in 1886, was able to clearly illustrate this point: ‘The general struggle for existence of living beings is therefore not a fight for energy, which is plentiful in the form of heat, unfortunately untransformably, in every body. Rather, it is a struggle for entropy that becomes available through the flow of energy from the hot Sun to the cold Earth. To make the fullest use of this energy, the plants spread out the immeasurable areas of their leaves and harness the Sun's energy by a process as yet unexplored, before it sinks down to the temperature level of our Earth, to drive chemical syntheses of which one has no inkling as yet in our laboratories.'

So what do we actually mean when we talk about a higher entropy environment? Recall that entropy quantifies the randomness of a system. Any physical system is made up of atoms, and more randomness just means that there is more motion for these atoms and more positions for them to occupy within the system. This inevitably induces collisions and a higher temperature within the system. When you feel hot in the room, this is because you are being hit by faster moving atoms transferring their energy to you as they hit you. In a cooler room the converse is true, fewer atoms are moving around at high speed and there is overall less transfer of energy, so you feel cooler. In physics this principle is very important when studying the property of atoms, since it is very hard to see what's going on at high temperatures because the atoms are moving around and rapidly bouncing off one another. So we need to cool the system down in order to slow the atoms and distinguish their behaviour more easily. Of course when we are talking about cooling a system for such studies, it's not just cooling by a few degrees; it's basically to cool it as much as is physically possible (currently to a few billionths of a degree above absolute zero).

We cannot prevent warming up of the Earth according to physics, but what we can and should control is our influence on this warming up process. Our actions will inevitably, though not entirely (contrary to popular belief), affect the rate at which this temperature increases. Ideally we must control this rate, so that by the time the temperature becomes unbearable for us, we have a strategy in place to ensure our survival. This strategy could take the form of evacuating Earth and perhaps colonizing some other part of the Universe. This inevitability of evacuation is not as implausible as one might think. Consider that even a five-degree increase in the overall temperature of the planet would result in a melting of both the polar ice caps, a subsequent increase in sea level, and a significant decrease in land mass not to mention the dramatic changes in weather patterns accompanying this.

The whole point of environmentalism is to make sure that if anything kills us – as a species – it is the First Law, not the Second Law (i.e. that we run out of natural resources before we reach a boiling point). To a physicist, however, the Second Law is far more inevitable and there is no contradiction to it, whereas at least with the First Law we have a fighting chance of finding ways of using different forms of energy. The Second Law can really be a very fast killer (working currently on time-scales of hundreds of years), while with the First Law we could possibly keep going for a little while longer (millions of years). Any hope of surviving indefinitely on this planet is therefore a hope misplaced. We will as a species eventually have to leave; it's purely a case of whether this is sooner or later.

Of course, our planet is a hugely complex system and overall the average temperature has gone both up and down throughout its history. This is because of various ‘local' effects. For example, the Earth has been unusually hot in the last 10,000 years, which is apparently one of the main reasons why the human species has been able to develop so effectively, much more than at any other time.

In fact, it will not come as a big surprise that a more developed society consumes more energy. If we take GDP (Gross Domestic Product) per capita as a proxy of how developed a society is, then a recent study (2006) shows a very strong correlation between the degree of development and society's energy consumption. At the top of the list we have the USA closely followed by Japan, Australia, UK, France, Germany, and Canada. All these nations are way above the world average. On the other hand, at the bottom, below the world average are Argentina, Brazil, China, South Africa, and many more developing nations. According to the Second Law, more energy consumption typically also implies a greater entropy increase so therefore this information can be used as a another (better?) indication of one's relative contribution to global warming than just looking at CO2 emissions. The shining light in this analysis was clearly Japan, being nearly twice as efficient as the US (in terms of having the same degree of development, but only half the energy consumption). So what do we think about a global tax in line with our energy (or entropy) efficiency? Perhaps we are calling for a global market in entropy trading? Well, it might sound crazy but maybe it's not such a bad idea. Anyway you heard it here first folks!

Genetically speaking, humans have existed with pretty much the same makeup for the last 150,000 years. Using genetic information, our origins can be traced to somewhere in Africa, but most of the time before the last 10,000 years, the climate was very harsh, temperatures much lower, and humans were forced to move around quite a lot in order to survive. When you move around in such conditions it is difficult to communicate within peer groups and establish the basic tools to propagate knowledge and culture. In such scenarios it is clear that primitive survival instincts dominate.

In spite of all these fluctuations, according to the Second Law the overall trend is for the planet to tend towards a point of thermal death. The thermal death would happen when the Sun cools down until both the Earth and the other planets all reach the same temperature, though in practice astrophysics tells us that before this happens, the Sun will first blow up into a red giant and destroy the other planets. And after this, it is very difficult to imagine how any kind of life would be possible.

The astute reader may be now reaching a point of profound confusion. It seems that the tendency of entropy in physics is from order (low entropy) to chaos (high entropy). In biology, on the other hand, life generates order and the tendency of living beings is to become less and less chaotic and more ordered (complex). Aren't these two tendencies contradicting one another? Is life trying to violate the Second Law of thermodynamics? Ever since the discovery of the Second Law, this has been a hot topic of discussion.

On the other hand, we could argue that the Second Law and life go hand in hand. We have argued previously that the genetic code has become more complex with evolution and therefore, according to Shannon, requires more bits of information and so has a higher entropy. Thus while entropy in physics increases according to the Second Law, at the same time so does the entropy of the genetic code according to Shannon. So is this increase in entropy in the genetic code related to the Second Law? Does this in fact mean that, far from violating it, life is just a simple consequence of the Second Law of thermodynamics?

Schrödinger was the first to argue convincingly that life maintains itself on low entropy through increasing the entropy of its environment. Of course, this is not in opposition to the fact that the genome may be getting more complex with time. In fact, it may be that you need a more complex genome in order to better utilize the environment and bring yourself to a lower entropy state. Schrödinger expounded his views on life maintaining itself on low entropy in a very beautiful little book entitled What is Life? He actually suggested in the very same book that in addition to the energy content of food (for example, the number of calories in a Mars bar) its entropy content should also be displayed. Imagine buying a Mars bar from Tesco with a label telling you that eating this bar will contribute five units of entropy. What does this actually mean? This means that as far as energy is concerned you can survive on Mars bars for a long time but practically you are missing crucial information required to keep your body in a highly ordered (low entropy) state. It is fair to say that the less crucial the information contained in the food, the higher its entropy content.

Of course, high-entropy foods can be formulated with other foods to reduce the overall entropy contribution to your body. This is, of course, the concept of a balanced diet. Again, it is the Second Law that dominates here in that allowing the body to degenerate into a highly disordered state will make you dysfunctional at best and more likely sooner or later will kill you! Morgan Spurlock would agree wholeheartedly with this, after a month of consuming just McDonalds' meals (although, according to the Second Law, he would have achieved the same effect by eating the same energy equivalent of cauliflower, which would still lead to a similarly unbalanced nutritional profile, continuing to increase his entropy. To illustrate that it's not energy but entropy that matters, maybe my first movie should be Super-Cauliflower Me?).

All this would lead to the conclusion that the best foods are those for which a certain energy value gives the lowest entropy increase in the body. Now I am going to stick my neck out a little and conjecture that the entropy value of a food is correlated to its completeness, not only in terms of the range of nutrients available but also the bioavailability of the nutrients. So, the Second Law indicates that the kind of food that minimizes your overall entropy production for the same energy cost should clearly be the best way forward. This is another hot and extremely pertinent area of research, and if I find the exact answer, you can read about it in Professor Vedral's Diet Revolution.

Interestingly, there is one argument against the Second Law that survived for over a hundred years, before being recently refuted. The argument was presented by James Clerk Maxwell in 1867. He postulated a hypothetical creature, whom we now call Maxwell's demon, which purports to be so clever as to violate the Second Law. Maxwell thought that, while inanimate objects, such as houses, chairs, and mountains, must invariably conform to the Second Law and deteriorate with time, perhaps intelligence can avoid it altogether. The demon manages to convert heat into work without any loss of efficiency. This is in direct opposition to the Second Law. This demon greatly worried scientists at the time, and was threatening to shake the foundations of physics. On the other hand, this would have been great news for humanity, as it was suggesting that work could be extracted from an energy source at zero cost.

Here is Maxwell's ingenious idea. It is so simple, and yet so fundamental, that we will encounter its application in every subsequent chapter. An example of a non-living physical system that is maximally disordered is the atoms comprising the air in your living room. They whiz about, bouncing back and forth between the walls of your room at the staggering speed of 500 metres per second. If your room is five metres long (probably the average size), then every atom in it goes 100 times back and forth between the walls of your room in only one second. Now this, you must admit, is pretty fast.

Atoms move around in a completely disorganized fashion, some up and some down, some left and some right, and so on. If you computed their entropy you would find it to be at its maximum, i.e. the motion of these atoms, given certain energy, could not possibly be more disorganized.

What Maxwell imagined is a little creature, of molecular size – so little that we wouldn't be able to see it with the naked eye. But, unlike molecules, this creature was able to observe the speeds and directions of the travelling atoms. Even more than simply observing, it would use its intelligence in a very capricious way. The demon would stand in the middle of the room and every time an atom approached it, the demon would act like a traffic policeman and do the following; if the demon, using its speedometer, observed that the atom was moving quickly then it would direct it to one side of the room. However, if the atom was moving slowly, it would direct it to the other side of the room. Any redirection would be done without affecting the speed of the atoms.

This process would separate slow moving molecules to one side and fast moving molecules to the other side of the room. In other words, it would be able to introduce some order into what was initially a very disordered system – without costing any energy. Maxwell showed that all the demon really needs to do is measure and think, whilst all the demon's other actions could happen without dissipating any energy.

Creating order out of disorder is precisely what the Second Law tells us it isn't possible to do! Disorder simply must always increase and persist. For you, the demon's ordering of the atoms in the room would effectively manifest itself in the room being of unequal temperature. The side with slower atoms would be cooler than the one with faster atoms, and when we have a temperature difference then we also have a capacity to do work, which effectively implies a free lunch (energy for no cost).

Maxwell was therefore very worried. While lifeless physical objects surely conform to the Second Law, it seemed to him that life, intelligent life in particular, could easily violate it.

The Second Law is only valid for isolated systems, those that do not interact with other systems. However, no living being is an island. We exchange energy and matter with our environment, and this was precisely where Schrödinger's point comes in. Living systems stay alive by sucking out energy and low entropy (information) from their environments. So, a living system can and does reduce its disorder, but this is always at the expense of increasing the disorder elsewhere in its environment (hence our discussion on global warming).

Even the Earth itself is not an isolated system – it receives energy from the Sun in the form of sunlight. Evolution of life may on its own decrease disorder, but the Earth is getting hotter as a consequence, and the Sun will eventually cool down. Once the Earth and the Sun reach the same temperature, i.e. thermal death, life will no longer be possible, even in principle, let alone in practice. And this now shows us why life needs to be very creative to survive. Only von Neumann's ‘robots', that are capable of reproducing, exploiting, and ultimately fleeing their environments, will endure in this Universe.

Let's come back to Maxwell now. What about his demon – what do we make of it? Can such a being exist given all the above discussion? Can anything reduce the total entropy? Not just its own disorder, but the disorder of the total Universe including itself?

The Hungarian physicist Leo Szilard – one of the people who helped create the atomic bomb during World War II – realized that the key insight into why the demon does not violate the Second Law lies in using the concept of information. What he realized in very simple terms is that all the demon had to do was to process some very simple form of information. Maxwell's demon can, in other words, be demoted from a ‘supernatural' being to an ordinary computer. The important point in Szilard's observation is that a demon could be made into a physical system – there just isn't anything important about intelligence, and the demon could simply and blindly be following a computer program code (note that Szilard was discussing these concepts 10 years before computers were even invented). The key implication of the demon being a physical system is that, as a result of the Second Law, it has to heat up for one reason or another. Heating up is simply a manifestation of its increase in entropy resulting from the demon gaining the information. Szilard thought that it was the measuring of atoms' speed that required the demon to do the work and therefore heat up. And so, concluded Szilard, the demon cannot exist, even in principle.

Many people have subsequently reached the same conclusion. The most interesting step was taken in the 1960s by an American physicist, Rolf Landauer of IBM. Following closely in the footsteps of Szilard, he concluded that not just demons, but in fact any computer has to heat up as it functions. Like Maxwell's demon, a computer processes information as it runs and any information processing – so Landauer argued – must lead to wasting of heat. So the heating of computers is as certain as the Second Law of thermodynamics.

We already know this directly from experience. If you keep your PC or laptop on for a long time, you notice that it becomes hotter. This heating effect is ultimately a necessary consequence of the way that computers process information. We can even do a small calculation to estimate how hot things can get when computers calculate. A computer can perform say a billion calculations in a second. Current computers generate of the order of one million basic units of heat per calculation. Therefore if we assume some reasonable properties of your room (and multiply this by the product of Boltzmann's constant and the temperature), all this amounts to a few degrees increase of temperature in a day. So computers are very effective heat radiators (some perhaps more effective at radiating heat than computing).

But is this temperature increase absolutely necessary in any kind of information processing? Can we not have smooth, frictionless information processors that just run without dissipation, and in the most environmentally friendly way? The answer to this question is very interesting.

If memory is properly configured it can keep track of all the information processing without any increase in heat and disorder. However, when the memory is full, then in order to continue to operate – rather than suffering an information overload – it needs to reset itself or delete some of the information. You may think ‘so what's the problem, just press the delete key', but the fact that we cannot just press a delete key and forget about the information that we have just deleted is ultimately what proves that ‘information is indeed physical'.

When we ‘delete' information all we actually do is displace this unwanted information to the environment, i.e. we create disorder in the environment. The dumping of this information into the environment, by definition, results in an increase in the entropy of the environment and therefore an increase in its temperature. It is for this reason that computers are fitted with little fans in order to remove the heat generated by the components as information is continually erased.

This logic was used by Charles Bennett, an IBM colleague of Landauer, to finally exorcise Maxwell's demon. So even if the demon processes information for measuring speeds, it must have a finite memory and hence must eventually delete this information to continue. It is this deletion of information from the demon's memory that increases the information in the environment by at least the amount of work that has been done by the demon. The demon, even in a perfect setup, therefore cannot violate the Second Law.

The main message from Landauer and Bennett's work is that information, rather than being an abstract notion, is entirely a physical quantity. In this sense it is at least on an equal footing with work and energy. So now we have brought information up to the important level of energy and matter. But, as I promised, I will show that information is even more fundamental than this. I first caught a glimpse of this realization whilst I was an undergraduate in London. The three words ‘information is physical' stimulated a new perspective and would profoundly affect how my own research would evolve.

Take the human brain as an example of an information processing device. The information inside our heads and the speed at which it is processed still exceeds the capacity of any computer (note that this won't be true in a few years time if the current trend continues!). We have some ten billion neurons in the brain. They are responsible for moving electrical impulses around our head and our body. Whenever someone touches you, neurons generate a signal at the point where the touch happened and this signal then travels along a network of nerves up to your brain (and sometimes other parts of your body).

Let us assume that every nerve cell or neuron can hold one bit of information, namely a zero or a one. This bit is encoded as the presence or absence of an electrical signal in neurons, i.e. when there is an electrical signal the brain detects a one, and when there is no electrical signal the brain detects a zero. This is probably an oversimplification but let's keep the story simple. So, our brain can hold ten billion bits of information. Once we have used up all the bits of memory in our head, in order to be able to record anything further you would first have to delete some information i.e. you would have to forget. This will make your environment hotter, since you have to dump some memories elsewhere. So it is the forgetting (not the forgiving) that requires energy.

The reader may be wondering how much order we could create by using up all the memory our brain allows. The result is very surprising; we would generate a million times less order than would be required to cool down a normal bottle of water by one degree. This is something your fridge at home could do in a matter of seconds.

So why does a home PC generate so much heat in the environment when it only has a fraction of our brain's computational power? This is because our brain is far more efficient as an information processor and only dumps to the environment when absolutely needed. While a computer uses one million units of energy per calculation our brain uses only one hundred. To be fair to computers they have only existed as such for the last 60 years, whereas life has been working at this game for the last three and a half billion years.

In Chapter 4 we argued that at the core of life is the information processing embedded in DNA replication. The central calculation that the DNA performs is matching base pairs and each of these matches costs approximately a hundred units of energy. To re-create a whole new strand of DNA then requires around one billion units of energy. This information processing increases the temperature of the environment.

Each of these units of energy we are talking about directly depends on the temperature. What if information processing were altogether done at the absolute zero of temperature? (This is approximately –273 degrees Celsius.) Would computers still heat up? Interestingly, thermodynamics tells us that, if we could process information at absolute zero, then there would actually be no heat dissipation during computation. But, guess what? Physics prohibits any object from reaching this mystical temperature. This is known as the Third Law of thermodynamics. So, there is no way to win when one plays with Nature – there just isn't any free lunch. Thanks to information, common sense wisdom has been scientifically vindicated after all: ‘no pain, no gain!'

墨菲定律：我早已预料到会如此

当今的生命形态呈现出前所未有的顽强，让我们难以想象它将如何走向终点。我们是否真的已经掌控了自己的命运？凭借着生物信息的坚韧性，以及人类主动进行的基因工程（genetic engineering），我们是否已经具备了适应任何自然环境的能力？除了一些特殊的不可抗力因素（这种情况下没有什么是可以保证的）之外，还存在其他可能导致生命终结的条件吗？

当前最引人关注的讨论话题之一是关于生命是否会因能量耗尽而无法维续。但是，生命真的会耗尽能量吗？这句话究竟意味着什么？这是否仅仅指太阳最终熄灭或自然资源枯竭的问题？有观点认为，不管生命将来如何演化，如果没有基本的能量供给，就很难想象它如何继续运作下去。因此，如果太阳真的熄灭了，我们可能就会陷入真正的困境。然而，我认为这种假设完全是错误的。实际上，无论宇宙中发生什么变化，能量总量都是守恒的，真正的问题在于我们能否找到方法去利用这些能量。即便太阳熄灭或自然资源耗尽，这些能量依然存在于宇宙中，我们面临的挑战是要找到新的方法来获取和利用这些能量。

本章我想说明一个看似矛盾的观点：生命的终结往往不是因为能量的耗尽，而是更本质地源于「信息」（information）的超载 —— 当我们达到了信息处理的极限，无法再接收任何新的信息时。我们每个人都曾有过这样的体验：感觉自己已经无法接收更多信息了。那么问题来了：这种状态会致命吗？

你是否想过自己的墓碑上会刻着怎样的墓志铭？一般来说，人们很少会想要为自己刻下什么豪言壮语，通常是至亲好友们会选择一些文字来寄托哀思。大多数墓志铭都很简单，包含逝者的简短介绍、在世时间，以及表达深切怀念之情的话语。说到底，墓地更多是为了安慰在世的人们，而非逝者本身。

也许你也这么想，觉得应该为来祭奠你的人们营造一个轻松一点的氛围。如果他们带着鲜花来到你的墓前，你至少可以用一个独特的墓志铭给他们一个惊喜。于是，你可能会想写些俏皮有趣的话，让聚集在你墓前的人们会心一笑。爱尔兰剧作家 George Bernard Shaw 就是这么想的，这就是为什么他的墓志铭写着："我就知道我会这样。"

在物理学领域，Shaw 对死亡必然性的认知，在热力学第二定律中找到了呼应。虽然热力学第二定律可能不如 Shaw 的墓志铭那么幽默，但它用一种更基础、更具普遍性的方式阐述了这个生命必将终结的道理。

热力学第二定律从物理角度告诉我们，当一个系统达到最大混乱度（也称为熵值）时，即当它包含了所能处理的最大信息量时，就会达到死亡状态。这种状态有个颇具讽刺意味的称谓 ——"热寂」，但从本质上看，它其实是一种信息过载状态。在这种最大混乱度的状态下，生命实际上就与周围无生命的宇宙融为一体了。此时的生命失去了所有进化的能力，完全受制于环境的影响。

热力学第二定律不仅揭示了系统在达到最大混乱度时会走向死亡，更令人深思的是，它表明每个物理系统都必然会朝着最大混乱度发展。而生命本质上也是一个复杂的物理系统，那么这个定律对生命意味着什么？它向我们揭示了一个深刻的事实：即使是生命这个宇宙中最为神奇的现象之一，最终也必将走向终结 —— 这是一个无法避免的自然规律。

那么问题来了：我们对热力学第二定律到底能有多确定？从生命现象来看，它似乎可以永远延续下去；但从热力学第二定律来看，每个物理系统最终都必须走向热寂（thermal death，即能量完全均匀分布的状态）。那么，这两种似乎完全对立的观点，到底哪个是对的呢？

要回答这个问题，我们不妨先深入了解一下热力学第二定律 —— 这个被誉为科学界最基本定律之一的物理法则。科学家们对这个定律的可靠性抱有极大的信心，正如英国著名哲学家 Bertrand Russell 曾经说过：

人类的诞生源于一系列毫无目的的因果；我们的起源、成长、希望与恐惧、爱与信仰，不过是原子随机结合的产物；无论多么热忱、多么英勇、多么深刻的思想与情感，都无法让个体的生命超越死亡的界限；人类历代的心血、无私的奉献、闪耀的灵感、最为辉煌的智慧成果，终将随着太阳系的消亡而归于虚无，人类所有的文明成就也必将淹没在宇宙的废墟之中 —— 这些论断，即便不是绝对无可争议，也已接近真理，任何试图否认这些的哲学思想都难以立足。唯有接受这些真相，唯有立足于这看似绝望却坚实的基础之上，我们才能为心灵构建真正安稳的归宿。

Russell 在一段话中（用一个长达十一行的长句）指出，熵增（即热力学第二定律，Second Law of Thermodynamics）是如此确定的规律，我们最好尽快接受这个现实。没有任何一位严肃的哲学家能够忽视这一点。任何与热力学第二定律相悖的信念，都不太可能是正确的 - 如果我们认为能够摆脱这个基本规律的约束，那无疑是在自欺欺人。

说到这里，如果你觉得 Russell 的观点听起来有些悲观，那么你更应该了解一下德国哲学家 Friedrich Nietzsche。他的整个哲学思想体系都建立在一个源自物理学的前提之上：由于宇宙终将毁灭，生命最终也必将消亡，因此生命从根本上来说是没有意义的。这就意味着，追求绝对进步（即通向完美的进步）终究只是一种幻想，这与生命进化的基本原理形成了鲜明的对比。Nietzsche 认为这个结论令人难以承受，因此他提出了「超人」（Übermensch）的概念 —— 一个能够接受生命无法达到绝对完美这一事实的进化版人类。然而讽刺的是，Nietzsche 自己却没能达到他所构想的超人境界 —— 在他生命的最后 11 年里，他在精神病院中孤独地度过，内心充满幻灭，无法面对现实。这位历史上最伟大的思想家之一就这样迎来了令人扼腕叹息的悲惨结局。

然而，科学家们是非常严谨的群体。虽然从哲学角度来看，Russell 和 Nietzsche 的论点既有分量又合乎逻辑，但科学家们需要对第二定律进行定量证明。我们只有通过数学方法对现象进行量化，才能可靠地验证或证伪它。

那么如何用数学来描述第二定律呢？物理学提供了一种基于「熵（entropy)」这个物理量的数学表述。正是这个概念促使 John von Neumann 建议 Claude Shannon 用类似的方式来命名他的信息函数（第三章）。熵是用来度量系统混乱程度的物理量，它可以应用于任何存在多种可能性的情况。物理学通过考察系统所有可能的状态，建立了熵的数学表述。每个状态都有其发生的概率，这些概率可以通过实验或其他原理推导获得。将这些概率取对数后，就能得到系统的总熵，这个值直接反映了系统的无序程度：

S = k log W。

物理学家借助熵（entropy）这个概念，将热力学第二定律表述为：在一个封闭系统中，熵永远是增加的。这个原理是科学界最基本的定律之一，它对宇宙中几乎所有事物都有着深远的影响。实际上，如果我们把整个宇宙看作一个封闭系统，那么根据热力学第二定律，宇宙的熵会不断增加，换句话说，整个宇宙正在逐渐变得更加混乱无序。

有趣的是，物理学家发现的熵与 Shannon 在信息理论中提出的熵（Information-theoretic Entropy）竟然具有相同的数学形式。Shannon 提出这个熵的概念是为了描述通信信道所能传输的信息量。从这个角度来看，我们或许可以将物理学中的熵理解为一个封闭系统所包含的信息量。这样一来，热力学第二定律（Second Law of Thermodynamics）就可以简单理解为：系统会逐渐发展到一个信息达到最大值的状态，在这个状态下就无法再容纳任何新的信息了。这个概念对于经常上网的我们来说其实很容易理解：当我们的网络带宽接近极限时，浏览器就会变得特别慢。这正是我们在本章前面提到的信息过载（Information Overload）现象。

当科普杂志 Spiked 做调查问我「物理学史上最伟大的发现是什么」时，我毫不犹豫地回答是玻尔兹曼的公式："S = k log W」。这个公式出自现代物理学的开创者之一 Ludwig Boltzmann，它巧妙地连接起了我们对世界的微观和宏观认识。公式中的 S 代表系统的熵，用来描述一个系统混乱的程度 —— 这是从宏观角度的描述。W 则告诉我们系统在微观层面上可能存在的不同状态数量，k 是玻尔兹曼发现的一个用来沟通这两个概念的常数。正是这个公式让我们明白，原则上我们可以用基本的微观物理规律来解释所有的宏观现象，这种思维方式在科学界被称为「还原论」（reductionism）。

玻尔兹曼家人显然也认识到这个公式的重要性，因此将这个简洁的熵公式刻在了他的墓碑上。玻尔兹曼于 1870 年推导出这个公式，当时他年仅 30 岁。他提出熵会随时间持续增加，直至达到最大值的观点，这实际上就是热力学第二定律的另一种表述。然而在当时，这个理论极具争议性，玻尔兹曼不仅在这个观点上，还在其他几个理论上都遭到了其最信任的同事们的强烈质疑。

玻尔兹曼与其他卓越的科学先驱一样，最终迎来了一个悲剧性的结局。当时科学界主流观点的巨大压力无疑是导致他选择自杀的重要因素之一。值得关注的是，在研究热力学第二定律及其深远影响后遭遇不幸的，不仅仅只有尼采和玻尔兹曼。Paul Ehrenfest 最终也选择了自杀，而 Robert Mayer 则陷入了疯狂。因此，在此不得不做出提醒：继续深入了解热力学第二定律的读者们，请充分意识到潜在风险，本文作者对此不承担任何责任。

Boltzmann 的墓志铭与 Shaw 的相比，其实并没有太大的差别。Shaw 说的是「我知道这会发生在我身上」，而 Boltzmann 则写道「我知道我的熵（entropy）迟早会达到最大值」。（物理学家或许不如剧作家那般风趣，不过他们对宇宙运行的规律倒是有着更深刻的理解。）

这里需要特别强调的是，热力学第二定律不应与能量守恒原理（即热力学第一定律）混为一谈。热力学第一定律指出能量不能凭空产生，它只能从一种形式转换为另一种形式，比如电视机将电能转换为图像和声音就是一个很好的例子。在讨论环境问题时，热力学第一定律起着关键作用。我们地球上储存的能源，如煤炭、石油和天然气都是有限的，这些能源被我们用来完成各种工作，例如生产塑料、驱动汽车或者生产食物。人们普遍担心这些资源终将耗尽，甚至可能迫使人类不得不迁移到其他拥有充足资源的星球。不过这里值得思考：既然能量是守恒的，为什么我们还需要迁移呢？按理说，能量只是在不同形式之间转换，那么我们只需要将其重新转换为可利用的能量，就能维持能量循环了，不是吗？

这时我们需要借助热力学第二定律来解答这个问题，但结果并不乐观！热力学第二定律告诉我们，在能量形式转换的过程中，我们无法达到完美的效率（即系统的熵（entropy），也就是系统无序程度，必然会增加）。举个例子，当我们使用汽油驱动汽车时，汽油的能量并不能完全转化为汽车的动能；部分能量会以热量和噪声等其他形式释放出去。同样地，我们也无法将所有已转换的能量（包括尾气、汽车运动、产生的噪音等）有效地重新组合并转化为汽油。在能量转换过程中，部分能量必然会损失。这正是热力学第二定律所阐述的：系统的无序度必须整体增加，能量必须向环境中随机扩散。因此，环境（比如我们的地球）会吸收这些扩散的能量，导致温度上升。这就意味着，任何形式的能量使用都会因为热力学第二定律而不可避免地导致全球变暖。

实际上，热力学第二定律（Second Law）告诉我们，预防全球变暖的唯一百分百有效的方法就是完全不使用任何能量。这里我说的不仅仅是要放弃开车、使用气雾剂这样的享受，甚至包括放弃一切海外旅行。即使是进行像吃饭这样维持生命必需的活动时，你的身体将食物转化为能量，但根据热力学第二定律，这个转化过程总是不可能完全有效，必然会向周围环境释放一些热量。当然，别想着通过多吃东西来取代家里的暖气系统。虽然温度的升高很微小，但重要的是这种升温确实存在。一个人每秒钟产生的热量大约相当于一个普通灯泡（计算这个数值是我最喜欢给大一物理学生出的考试题之一）；但当我们把全球 60 亿人的热量加在一起时，温度上升就变得相当可观了。要避免这种情况，只有一个办法 —— 保持绝对静止（这个理由恐怕很难向你的老板解释）。如果人类停止一切活动，确实就不会有全球变暖问题了 —— 至少就人为因素而言是这样（这对那些极端环保主义者来说倒是个终极解决方案）。

对于地球上的生命来说，我们真正需要担心的不是能源的匮乏，而是如何找到更多高效利用能源的方法。有趣的是，虽然这个观点在今天仍常被人误解，但 Boltzmann 在 1886 年就已经清楚地阐述了这一点："生物为生存而进行的普遍竞争，并非是在争夺能量，因为能量以热能的形式普遍存在于万物之中，只可惜这些热能难以转化利用。相反，这是一场对熵的争夺，这种熵产生于能量从炽热的太阳向寒冷的地球流动的过程中。为了最大限度地利用这种能量，植物将它们的叶片展开成巨大的面积，通过一个我们现在还没有完全理解的过程来捕获太阳能。在这些能量降至地球温度之前，植物利用它们进行着一系列化学合成，这些过程即便在现代实验室中我们也还没有完全掌握。"

什么是高熵环境呢？让我们先来了解一下：熵是一个用来衡量系统随机性的物理量。所有的物理系统都是由原子组成的，系统的随机性越大，意味着其中的原子运动就越剧烈，它们在系统中可以占据的位置也就越多。这种情况必然会导致原子之间的碰撞增加，使得系统的温度升高。当你在房间里感觉热时，实际上是因为快速运动的原子不断碰撞到你的身体，将能量传递给你。相反，在温度较低的房间里，高速运动的原子较少，传递的能量也就更少，所以你会感觉凉爽。这个原理在物理学研究原子特性时特别重要：因为在高温状态下，原子运动剧烈且不断相互碰撞，很难观察它们的具体行为。因此，我们需要将系统降温，减缓原子运动，这样才能更好地研究它们的性质。当然，这里说的降温并不是降低几度那么简单，而是要将温度降到物理学上能达到的最低温度（目前能达到的最低温度是接近绝对零度的几十亿分之一度）。

从物理学角度来看，我们无法阻止地球升温，但我们能够也应该控制人类活动对这一升温过程的影响。与普遍观点不同，虽然我们的行为不是决定性因素，但必然会影响全球温度上升的速度。理想情况下，我们必须对这个速度进行调控，这样当温度达到人类难以适应的程度时，我们已经准备好了确保物种存续的应对方案。这个方案可能包括撤离地球，在宇宙的其他适宜区域建立人类聚居地。这种最终需要撤离地球的前景并非天方夜谭。要知道，即使全球平均温度仅上升五度，就足以导致南北极冰盖融化，引发海平面上升，导致陆地面积显著减少，更不用说还会引起气候规律的剧烈改变。

环境保护主义的核心在于确保人类文明若要面临终结，应该是因为耗尽了自然资源（热力学第一定律），而不是被地球变得过热所毁灭（热力学第二定律）。不过，在物理学家看来，热力学第二定律带来的结局是完全无法避免的，而面对热力学第一定律，我们至少还有机会开发和利用各种新的能源形式。热力学第二定律可能会成为一个快速的终结者（按目前的发展趋势可能在几百年内显现），而在热力学第一定律的约束下，我们或许还能继续在地球上生存相当长的时间（可能长达数百万年）。因此，期望永久地在这颗星球上生存是不切实际的。作为一个物种，人类终将需要离开地球；这不是要不要走的问题，而是早走还是晚走的问题。

当然，纵观地球历史，我们的这颗星球是一个极为复杂的系统，其整体平均温度一直在起起落落。造成这种变化的原因是各种区域性的影响因素。比如说，在过去的 1 万年里，地球的温度明显高于往常，这也被认为是人类能够空前发展的主要原因之一，这种发展速度是地球历史上其他任何时期都未曾见过的。

事实上，一个社会越发达，其能源消耗就越大，这是很容易理解的现象。如果我们将人均 GDP（Gross Domestic Product）作为衡量社会发达程度的指标，那么 2006 年的一项研究显示了社会发展程度与能源消耗之间存在很强的相关性。在统计数据顶端是美国，紧随其后的是日本、澳大利亚、英国、法国、德国和加拿大。这些国家的能源消耗都远高于世界平均水平。而在统计数据底端，能源消耗低于世界平均水平的国家包括阿根廷、巴西、中国、南非等众多发展中国家。根据热力学第二定律（物质和能量总是趋向于由有序向无序转化），更多的能源消耗通常也意味着更大的熵增加（entropy increase），因此这一指标可能比单纯考察二氧化碳排放更能反映一个国家对全球变暖的相对贡献。在这项分析中，日本无疑是一个突出的典范，它在实现相同发展水平的同时，能源消耗仅为美国的一半，显示出了显著的能源使用效率。那么，我们是否应该考虑根据国家的能源（或熵）效率来制定全球性税收政策？甚至可以设想建立一个全球性的熵交易市场？这些想法虽然听起来可能有些大胆，但未必不值得认真考虑。这确实是一个值得深入探讨的创新性观点。

从遗传学的角度来看，人类在过去 15 万年里的基因特征基本保持不变。通过基因信息研究，科学家们发现我们的祖先起源于非洲。但在近 1 万年之前的漫长岁月里，地球气候异常严酷，气温远低于现在，人类不得不为了生存而不断迁移。在这样艰难的环境下，人们很难与他人保持稳定的交流，也难以建立起传承知识和文化的基本工具。在这种生存环境下，人类的原始生存本能自然成为主导。

虽然环境在不断变化，但根据热力学第二定律（Second Law of Thermodynamics），整个地球的发展趋势终将走向热寂（Heat Death）。当太阳逐渐冷却，直到地球和其他行星的温度趋于一致时，热寂就会发生。不过天体物理学告诉我们，在这种情况发生之前，太阳会先膨胀成为红巨星（Red Giant）并摧毁周围的行星。在那之后，任何形式的生命都很难继续存在。

读者朋友们现在可能产生了深深的困惑。在物理学中，熵的变化趋势是从有序（低熵）走向混乱（高熵）。而在生物学中，生命却能够产生秩序，生命体的发展趋势是逐渐减少混乱、增加有序度（复杂性）。这两种趋势难道不是相互矛盾的吗？生命是否在试图违反热力学第二定律？自从热力学第二定律被发现以来，这个问题一直是科学界热议的话题。

然而，我们也可以从另一个角度来看待热力学第二定律与生命的关系。我们之前已经论证过，基因密码（genetic code）在进化过程中变得越来越复杂。根据 Claude Shannon 的信息论，这意味着需要更多的比特信息来描述，因此具有更高的熵。这样看来，当物理学中的熵按照第二定律增加的同时，基因密码的熵也在按照 Shannon 理论增加。那么，基因密码中的熵增加是否与热力学第二定律存在某种联系呢？这是否意味着，生命不仅没有违反热力学第二定律，反而是这一定律的必然结果？

Schrödinger 最早提出了一个引人深思的观点：生命是通过增加周围环境的混乱度来维持自身的有序状态的。生命体内的基因组（genome）可能会随着时间变得更复杂，但这与上述观点并不矛盾。实际上，要想更好地利用环境资源并保持自身的有序状态，生命可能需要一个更复杂的基因组。

Schrödinger 在他那本优美的小书《生命是什么？》中详细阐述了这个关于生命维持有序状态的观点。他在书中提出了一个有趣的建议：食品包装上除了标注能量含量（比如英国 Mars 品牌巧克力棒的卡路里数）外，还应该标注其混乱度。想象一下，你在英国连锁超市 Tesco 买到的 Mars 巧克力棒上贴着这样的标签："食用本产品将增加五个单位的混乱度」。这是什么意思呢？这表明虽然从能量角度来说，你可以靠吃巧克力棒维持很长时间，但实际上你的身体缺少了维持有序状态所需的重要营养物质。一个简单的道理是：食物中包含的营养信息越少，其混乱度就越高。

当然，高熵食物可以通过与其他食物的合理搭配来降低对身体的总体影响。这其实就是我们常说的平衡饮食理念。在这里，热力学第二定律（Second Law of Thermodynamics）起着决定性作用，因为一旦让身体陷入高度混乱的状态，轻则会影响身体机能，重则可能危及生命！纪录片导演 Morgan Spurlock 在进行了一个月只吃麦当劳的实验后，一定深有体会（不过，按照热力学第二定律，如果他吃入相同热量的花椰菜，结果也不会好到哪里去，同样会造成营养严重失衡，让身体的熵持续升高。为了证明真正要关注的不是能量而是熵，也许我该拍摄一部新片，叫《花椰菜狂食 30 天》？）。

基于以上分析，我们可以得出这样的结论：最佳的食物应该是那些在提供相同能量的情况下，让身体产生最少混乱度的食物。在这里，我想大胆地提出一个推测：食物的熵值与其完整性密切相关，这种完整性不仅体现在营养种类的丰富程度上，还包括营养的生物可利用性（bioavailability）。因此，根据热力学第二定律（Second Law of Thermodynamics）的指导，在相同能量摄入的情况下，能够最大程度减少身体熵值产生的食物，应该就是我们的最佳选择。这个领域目前正处于研究的热点阶段，而且与我们的生活息息相关。如果我最终找到了确切的答案，各位读者可以在我的新书《Vedral 教授的饮食革命》中找到答案。

有趣的是，有一个质疑热力学第二定律的论点存在了超过一百年之久，直到最近才被彻底驳斥。这个论点是由 James Clerk Maxwell 在 1867 年提出的。他设想了一个假想的生物，现在我们称之为「麦克斯韦妖」，这个假想生物据说具有超常的能力，可以违背热力学第二定律。Maxwell 认为，虽然像房屋、椅子和山脉这样的无生命物体必须遵守热力学第二定律并随时间不可避免地衰败，但具有智能的生物可能可以完全规避这一定律。这个麦克斯韦妖能够毫无损耗地将热能转化为有用功，这完全违背了热力学第二定律。在当时，这个设想让科学家们深感困扰，因为它似乎动摇了物理学的基本原理。不过从另一个角度来看，如果这个设想是正确的，对人类来说倒是个天大的好消息，因为这意味着我们可以不消耗任何成本就从能源中获取有用功。

这就是 Maxwell 提出的精妙构想。它看似简单，却蕴含着深刻的基本原理，在接下来的每一章中我们都会看到它的应用。让我们来看一个最大混乱状态的非生命物理系统例子：你客厅里的空气分子。这些分子以惊人的每秒 500 米的速度，在房间内不停地穿梭碰撞。假设你的房间长度是 5 米（这大概是一般房间的长度），那么每个空气分子在短短一秒内就能在房间两端往返大约 100 次。这个速度确实令人咋舌。

这些原子的运动完全随机，有的往上，有的往下，有的往左，有的往右，呈现出完全杂乱的状态。如果计算它们的熵（entropy），你会发现它已经达到了最大值。换句话说，在特定能量条件下，这些原子的运动状态已经达到了最大的混乱程度。

Maxwell 设想了一个微观世界中的神奇生物，它小到只有一个分子那么大，我们的肉眼根本无法看到。这个假想中的小生物与普通分子不同，它能够观察到原子运动的速度和方向。不仅如此，它还能够灵活运用自己的智慧来分拣这些原子。这个被称为「麦克斯韦妖」的小生物会站在房间中央，就像一个交通警察一样指挥来往的原子：当它观察到一个快速运动的原子接近时，就把它引导到房间的一边；当看到慢速运动的原子时，则将其引导到房间的另一边。在这个过程中，它不会改变原子的运动速度。

通过这样的分类，这个小生物就能够将运动快的分子和慢的分子分别集中到房间的不同区域。也就是说，它能够在原本完全混乱的系统中创造出秩序，而神奇的是，这个过程不需要消耗任何能量。Maxwell 指出，这个假想中的小生物只需要进行观测和思考，它所做的其他动作都不会消耗能量。

将混乱变成有序，这恰恰违背了热力学第二定律（Second Law of Thermodynamics）告诉我们的原理！根据这个定律，系统的无序度只能增加，不能减少。设想一下，如果麦克斯韦妖（Maxwell's demon）真的能对房间里的原子进行分类排序，就会导致房间内的温度分布不均匀。原子运动较慢的一侧温度较低，而原子运动较快的一侧温度较高。这种温度差异就能够产生有用的功，这就相当于我们找到了一个永动机，可以不消耗任何代价就获得能量。

正因如此，Maxwell 感到十分困扰。虽然没有生命的物体必然会遵循热力学第二定律，但在他看来，生命体，尤其是具有智慧的生命，似乎能够轻易地打破这个定律。

热力学第二定律仅适用于孤立系统，也就是那些不与外界发生任何相互作用的系统。但在现实中，所有的生命体都无法独立存在。我们始终在与周围环境进行能量和物质的交换，这正是 Schrödinger 的核心论点。生命系统之所以能够维持存活，正是通过不断从环境中获取能量和低熵（即有序的信息）。因此，虽然生命系统能够降低自身的混乱程度，但代价就是增加了环境其他部分的无序度（这也是为什么我们会讨论全球变暖问题）。

即便是地球本身也不是一个孤立系统 —— 它持续从太阳获取阳光形式的能量。尽管生命的进化过程可能会减少局部的无序度，但这个过程导致地球温度上升，而太阳终将逐渐冷却。当地球和太阳最终达到相同温度时，也就是达到所谓的热死亡状态，生命将在理论上和现实中都无法继续存在。这也让我们明白了为什么生命需要如此富有创造力才能生存下去。在这个宇宙中，只有像 von Neumann 设想的那种能够自我复制、利用环境资源并最终能够摆脱当前环境限制的「机器人」，才可能真正持续生存下去。

让我们重新回到 Maxwell 的话题。关于他提出的麦克斯韦妖（Maxwell's demon），我们应该如何看待这个概念？基于前面的讨论，这样一个假想的存在真的可能实现吗？有什么东西能够真正降低总熵值吗？这里说的不仅是降低它自身的熵，而是要降低包括它自己在内的整个宇宙的总熵。

匈牙利物理学家 Leo Szilard —— 二战期间参与原子弹研制的科学家之一 —— 发现了理解麦克斯韦妖（Maxwell's demon）为何不违反热力学第二定律的关键：这一切都与信息有关。他简明地指出，这个假想的妖精实际上只是在进行简单的信息处理。因此，麦克斯韦妖不再是一个「超自然」的存在，而可以被视为一台普通的计算机。

Szilard 的重要发现在于，这个妖精可以被简化为一个物理系统 —— 其中智能并非关键因素，它只需要机械地执行一串计算机程序指令即可（值得注意的是，Szilard 在计算机发明之前 10 年就提出了这些观点）。将妖精视为物理系统带来的关键推论是：根据热力学第二定律，这个系统在运作过程中必然会产生热量。这种升温现象其实就是系统在获取信息过程中熵增加的直接体现。Szilard 认为，正是在测量原子速度的过程中，这个系统需要做功，因此产生热量。据此，他最终得出结论：这样的妖精即使在理论上也不可能存在。

随后有许多研究者也得出了相同的结论。其中最具突破性的进展出现在 20 世纪 60 年代，来自 IBM 公司的美国物理学家 Rolf Landauer。他在 Szilard 研究的基础上进一步研究，发现不仅是麦克斯韦妖（Maxwell's demon），事实上任何计算机在运行过程中都必然会产生热量。就像麦克斯韦妖一样，计算机在运行时会进行信息处理，而根据 Landauer 的论证，任何信息处理过程都必然会产生热耗散。这使得计算机产生热量成为了一个如同热力学第二定律一样不可避免的基本规律。

这一点我们从日常经验就能直接体会到。如果你的台式电脑或笔记本电脑开机运行很久，你会发现它会变得越来越热。这种发热现象实际上是计算机进行信息处理的必然结果。我们甚至可以通过一个简单的计算来估算计算机在运算时会产生多少热量。一台计算机每秒可以进行约十亿次运算，而现代计算机在每次运算时会产生大约一百万个基本热量单位。因此，如果我们考虑房间的一些基本物理参数（再结合玻尔兹曼常数（Boltzmann's constant）和温度的乘积），这些热量足以在一天之内使房间温度上升好几度。由此可见，计算机确实是相当高效的散热设备（有些计算机似乎在产生热量方面比进行计算更在行）。

那么，这种温度上升是否是所有信息处理过程中都无法避免的呢？我们能否制造出一种理想的信息处理器，让它在运行时不产生任何能量损耗，实现真正的环保运算？这个问题的答案相当有趣。

如果内存配置合理，它可以在不产生额外热量和不增加无序度的情况下处理所有信息。但是，当内存被占满时，为了避免信息处理系统超负荷，系统就需要进行重置或删除一些信息。你可能会想："这有什么问题呢？按一下删除键不就行了？」然而，事实恰恰相反 —— 我们无法通过简单地按下删除键就让信息彻底消失，这正好证明了「信息是具有物理性质的」这一观点。

当我们「删除」信息时，实际上只是将这些不需要的信息转移到了环境中，这个过程会增加环境中的混乱程度。这种信息向环境的转移过程，按照物理学定义，必然会导致环境熵值的上升，从而使环境温度升高。这就解释了为什么计算机都需要安装散热风扇 —— 它们的作用是带走在持续删除信息过程中电子元件产生的热量。

这个逻辑被 Charles Bennett（Landauer 在 IBM 的同事）用来最终解决了麦克斯韦妖（Maxwell's demon）的悖论。即使麦克斯韦妖在处理测量速度的信息（information）时，它也必须受限于有限的内存，因此必须不断删除旧信息才能继续工作。当麦克斯韦妖从内存中删除信息时，环境中的信息量会增加，这个增加量至少等于妖魔所做的功（work）。因此，即使在理想情况下，麦克斯韦妖也无法违反热力学第二定律（Second Law of Thermodynamics）。

Landauer 和 Bennett 研究工作的核心启示是：信息并非抽象概念，而是完完全全的物理量。从这个角度来看，信息至少与功和能量具有同等地位。因此，我们现在已经将信息提升到了与能量和物质同等重要的层面。但是，正如我之前承诺的，我将向大家展示信息其实比这更加基础和根本。我第一次对这一认识有所领悟是在我还是伦敦的本科生时期。"information is physical（信息是物理的)」这句话为我打开了一个全新的视角，并深刻影响了我后来研究工作的发展方向。

让我们来看看人脑这个神奇的信息处理设备。目前为止，我们大脑中储存的信息量和处理信息的速度仍然超过任何计算机的处理能力（不过要注意，按照目前科技发展的趋势，这个说法可能在几年后就不再成立了！）。人类大脑中约有一百亿个神经元。这些神经元的主要工作是在我们的大脑和身体各个部位之间传递神经信号。比如当有人碰触你的时候，被触碰部位的神经元就会产生信号，这个信号随后会通过神经系统传输到大脑（有时也会传到身体的其他部位）。

让我们假设每个神经细胞或神经元能存储一个比特（bit）的信息，即 0 或 1。这个比特是通过神经元中电信号的有无来编码的：当存在电信号时，大脑识别为 1；当没有电信号时，大脑识别为 0。这可能是过度简化了，但让我们先保持这个简单的模型。这样计算的话，我们的大脑可以存储 100 亿个比特的信息。当我们用完了大脑中所有的存储空间后，要继续记录新的信息，就必须先删除一些旧信息，也就是必须遗忘。这个遗忘过程会使环境温度升高，因为这些被删除的记忆信息必须以热能的形式释放到环境中。所以说，遗忘（而不是宽恕）才是需要消耗能量的过程。

读者可能会好奇，如果我们用尽大脑所有的存储空间，能创造多少有序性。结果令人十分意外：我们所能产生的有序性，竟然比把一瓶普通的水降温 1 度所需的还要小一百万倍。而这点温度变化，普通家用冰箱只需要几秒钟就能做到。

为什么家用电脑虽然只有人脑计算能力的一小部分，却会产生如此多的热量呢？这是因为我们的大脑在信息处理方面效率要高得多，只有在必需时才会向环境释放热量。比较而言，计算机每进行一次运算需要消耗一百万个能量单位，而我们的大脑只需要一百个。当然，这也情有可原，因为计算机的发展历史仅有 60 年，而生命演化却已经持续了三十五亿年。

在第 4 章中，我们讨论过生命的核心在于 DNA 复制过程中的信息处理。DNA 中最基本的运算是碱基配对，每次配对过程大约消耗一百个能量单位。要完成一整条新 DNA 链的构建，总共需要消耗约十亿个能量单位。这个信息处理过程会导致环境温度的升高。

我们讨论的每个能量单位都与温度直接相关。那么，如果在绝对零度（约为 -273.15 摄氏度）下进行信息处理会怎样呢？在这种情况下计算机还会发热吗？有趣的是，热力学理论告诉我们，如果能在绝对零度下处理信息，计算过程中就不会产生热量损耗。然而，物理学法则告诉我们，任何物体都不可能达到这个极限温度，这就是热力学第三定律。因此，在与自然规律的博弈中，我们永远不可能占上风 —— 这世上没有免费的午餐。通过信息理论的研究，这个朴素的认知现在获得了科学的证实：付出才会有回报！

### Key points

Physical entropy, which describes how disordered a system is, tends to increase with time. This is known as the Second Law of thermodynamics.

Physical entropy is closely related to Shannon's entropy, and is in fact an instance of it.

The increasing complexity of life is driven by the overall increase in disorder in the Universe.

Systems which exploit disorder are called Maxwell's demons. All living systems are Maxwell's demons, but so are some non-living things, e.g. computers. Computers perform well in specific calculation tasks and use energy, in the form of electricity, to do work and produce heat. All demons work this way.

As a result the environment which demons populate increases in temperature. All life and therefore, all cars, and computers contribute to global warming, which is necessary according to the Second Law.

Information, far from being an abstract concept, has been shown to have a very real physical representation.

关键要点：

描述系统无序程度的物理熵（Physical entropy）会随时间增加，这就是热力学第二定律。

物理熵与香农熵（Shannon entropy）密切相关，实际上前者是后者的一个具体体现。

生命复杂性的提升是由宇宙整体无序度增加所驱动的。

利用混乱度的系统被称为麦克斯韦妖（Maxwell's demon）。所有的生命系统都是麦克斯韦妖，一些非生命体比如计算机也是如此。计算机在特定的计算任务中表现出色，它们通过消耗电能来完成工作并产生热量。所有的麦克斯韦妖都遵循这个原理。

正因如此，麦克斯韦妖存在的环境温度会上升。所有的生命形式，以及由此衍生的汽车和计算机等，都会促进全球变暖。这种现象符合热力学第二定律（Second Law of Thermodynamics）的要求。

信息并非只是一个抽象的概念，研究已经证明它在物理世界中有着具体的表现形式。