Leopold Aschenbrenner.(2024).2024109Situational-Awareness-The-Decade-Ahead.Dwarkesh podcast => IIId. The Free World Must Prevail

## IIId. The Free World Must Prevail

[IIId. The Free World Must Prevail - SITUATIONAL AWARENESS](https://situational-awareness.ai/the-free-world-must-prevail/)

Superintelligence will give a decisive economic and military advantage. China isn't at all out of the game yet. In the race to AGI, the free world's very survival will be at stake. Can we maintain our preeminence over the authoritarian powers? And will we manage to avoid self-destruction along the way?

In this piece:

Whoever leads on superintelligence will have a decisive military advantage

The Gulf War, or: What a few-decades-worth of technological lead implies for military power

The military advantage would be decisive even against nuclear deterrents

China can be competitive

1. Compute

2. Algorithms

The authoritarian peril

Maintaining a healthy lead will be decisive for safety

Superintelligence is a matter of national security

The story of the human race is War. Except for brief and precarious interludes, there has never been peace in the world; and before history began, murderous strife was universal and unending.

…

Might not a bomb no bigger than an orange be found to possess a secret power to destroy a whole block of buildings — nay, to concentrate the force of a thousand tons of cordite and blast a township at a stroke?

Winston Churchill, "Shall We All Commit Suicide?"

Superintelligence will be the most powerful technology—and most powerful weapon—mankind has ever developed. It will give a decisive military advantage, perhaps comparable only with nuclear weapons. Authoritarians could use superintelligence for world conquest, and to enforce total control internally. Rogue states could use it to threaten annihilation. And though many count them out, once the CCP wakes up to AGI it has a clear path to being competitive (at least until and unless we drastically improve US AI lab security).

Every month of lead will matter for safety too. We face the greatest risks if we are locked in a tight race, democratic allies and authoritarian competitors each racing through the already-precarious intelligence explosion at breakneck pace—forced to throw any caution by the wayside, fearing the other getting superintelligence first. Only if we preserve a healthy lead of democratic allies will we have the margin of error for navigating the extraordinarily volatile and dangerous period around the emergence of superintelligence. And only American leadership is a realistic path to developing a nonproliferation regime to avert the risks of self-destruction superintelligence will unfold.

Our generation too easily takes for granted that we live in peace and freedom. And those who herald the age of AGI in SF too often ignore the elephant in the room: superintelligence is a matter of national security, and the United States must win.

自由世界势在必行

超级智能（Superintelligence）将带来决定性的经济和军事优势。中国在这场竞争中仍然是强有力的竞争者。在通用人工智能（AGI）的竞赛中，自由世界的存亡正处于危急关头。我们能否继续保持对专制政权的优势？我们能否在这个过程中避免自我毁灭？

本文内容：

超级智能领域的领先者将获得决定性军事优势

海湾战争启示：技术代差对军事实力的深远影响

即使在核威慑下，军事优势依然具有决定性作用

中国的竞争实力

1. 计算能力
2. 算法

专制政权的威胁

保持充分的领先优势对安全至关重要

超级智能关乎国家安全

人类的历史就是战争史。除了短暂而脆弱的和平时期，世界从未真正享有和平；在有历史记载之前，致命的冲突就无处不在，绵延不绝。

...

一颗仅有橘子大小的炸弹，会不会就藏有摧毁整片建筑群的神秘力量呢？甚至能够凝聚千吨炸药的威力，一击就将整座城镇夷为平地？

—— Winston Churchill，《我们都要自杀吗？》

超级智能将成为人类有史以来最强大的技术 —— 同时也是最强大的武器。它将带来决定性的军事优势，其重要性可能仅次于核武器。独裁者可能利用超级智能谋求世界统治，并加强国内控制。无法无天的国家可能用它来威胁毁灭人类。尽管许多人认为中国已经出局，但一旦中共意识到通用人工智能的重要性，它确实有能力参与竞争（至少在我们显著提升美国人工智能实验室安全之前）。

每一个月的技术领先都至关重要。如果我们陷入势均力敌的竞争，风险将达到顶峰 —— 民主盟友和专制对手都在已经危险的智能爆发阶段竞相冒进 —— 被迫抛开一切谨慎，生怕对方先获得超级智能。只有当民主盟友保持足够的领先优势，我们才能有足够的安全空间来应对超级智能出现前后极其动荡和危险的时期。而只有在美国的领导下，才有可能建立起防止超级智能带来自我毁灭风险的防扩散机制。

我们这一代人过于习以为常地享受着和平与自由。那些在科幻小说中预言通用人工智能时代来临的人，往往忽视了一个显而易见的事实：超级智能是国家安全问题，美国必须在这场竞赛中胜出。

### Whoever leads on superintelligence will have a decisive military advantage

Superintelligence is not just any other technology—hypersonic missiles, stealth, and so on—where US and liberal democracies' leadership is highly desirable, but not strictly necessary. The military balance of power can be kept if the US falls behind on one or a couple such technologies; these technologies matter a great deal, but can be outweighed by advantages in other areas.

The advent of superintelligence will put us in a situation unseen since the advent of the atomic era: those who have it will wield complete dominance over those who don't.

I've previously discussed the vast power of superintelligence. It'll mean having billions of automated scientists and engineers and technicians, each much smarter than the smartest human scientists, furiously inventing new technologies, day and night. The acceleration in scientific and technological development will be extraordinary. As superintelligence is applied to R&D in military technology, we could quickly go through decades of military technological progress.

The Gulf War, or: What a few-decades-worth of technological lead implies for military power

The Gulf War provides a helpful illustration of how a 20-30 year lead in military technology can be decisive. At the time, Iraq commanded the fourth-largest army in the world. In terms of numbers (troops, tanks, artillery), the US-led coalition barely matched (or was outmatched) by the Iraqis, all while the Iraqis had had ample time to entrench their defenses (a situation that would normally require a 3:1, or 5:1, advantage in military manpower to dislocate).

But the US-led coalition obliterated the Iraqi army in a merely 100-hour ground war. Coalition dead numbered a mere 292, compared to 20k-50k Iraqi dead and hundreds of thousands of others wounded or captured. The Coalition lost a mere 31 tanks, compared to the destruction of over 3,000 Iraqi tanks.

The difference in technology wasn't godlike or unfathomable, but it was utterly and completely decisive: guided and smart munitions, early versions of stealth, better sensors, better tank scopes (to see farther in the night and in dust storms), better fighter jets, an advantage in reconnaissance, and so on.

(For a more recent example, recall Iran launching a massive attack of 300 missiles at Israel, "99%" of which were intercepted by superior Israel, US, and allied missile defense.)

A lead of a year or two or three on superintelligence could mean as utterly decisive a military advantage as the US coalition had against Iraq in the Gulf War. A complete reshaping of the military balance of power will be on the line.

Imagine if we had gone through the military technological developments of the 20th century in less than a decade. We'd have gone from horses and rifles and trenches, to modern tank armies, in a couple years; to armadas of supersonic fighter planes and nuclear weapons and ICBMs a couple years after that; to stealth and precision that can knock out an enemy before they even know you're there another couple years after that.

That is the situation we will face with the advent of superintelligence: the military technological advances of a century compressed to less than a decade. We'll see superhuman hacking that can cripple much of an adversary's military force, roboarmies and autonomous drone swarms, but more importantly completely new paradigms we can't yet begin to imagine, and the inventions of new WMDs with thousandfold increases in destructive power (and new WMD defenses too, like impenetrable missile defense, that rapidly and repeatedly upend deterrence equilibria).

And it wouldn't just be technological progress. As we solve robotics, labor will become fully automated, enabling a broader industrial and economic explosion, too. It is plausible growth rates could go into the 10s of percent a year; within at most a decade, the GDP of those with the lead would trounce those behind. Rapidly multiplying robot factories would mean not only a drastic technological edge, but also production capacity to dominate in pure materiel. Think millions of missile interceptors; billions of drones; and so on.

Of course, we don't know the limits of science and the many frictions that could slow things down. But no godlike advances are necessary for a decisive military advantage. And a billion superintelligent scientists will be able to do a lot. It seems clear that within a matter of years, pre-superintelligence militaries would become hopelessly outclassed.

The military advantage would be decisive even against nuclear deterrents

To be even clearer: it seems likely the advantage conferred by superintelligence would be decisive enough even to preemptively take out an adversary's nuclear deterrent. Improved sensor networks and analysis could locate even the quietest current nuclear submarines (similarly for mobile missile launchers). Millions or billions of mouse-sized autonomous drones, with advances in stealth, could infiltrate behind enemy lines and then surreptitiously locate, sabotage, and decapitate the adversary's nuclear forces. Improved sensors, targeting, and so on could dramatically improve missile defense (similar to, say, the Iran vs. Israel example above); moreover, if there is an industrial explosion, robot factories could churn out thousands of interceptors for each opposing missile. And all of this is without even considering completely new scientific and technological paradigms (e.g., remotely deactivating all the nukes).

It would simply be no contest. And not just no contest in the nuclear sense of "we could mutually destroy each other," but no contest in terms of being able to obliterate the military power of a rival without taking significant casualties. A couple years of lead on superintelligence would mean complete dominance.

If there is a rapid intelligence explosion, it's plausible a lead of mere months could be decisive: months could mean the difference between roughly human-level AI systems and substantially superhuman AI systems. Perhaps possessing those initial superintelligences alone, even before being broadly deployed, would be enough for a decisive advantage, e.g. via superhuman hacking abilities that could shut down pre-superintelligence militaries, more limited drone swarms that threaten instant death for every opposing leader, official, and their families, and advanced bioweapons developed with AlphaFold-style simulation that could target specific ethnic groups, e.g. anybody but Han Chinese (or simply withhold the cure from the adversary).

### China can be competitive

Many seem complacent about China and AGI. The chip export controls have neutered them, and the leading AI labs are in the US and the UK—so we don't have much to worry about, right? Chinese LLMs are fine—they are definitely capable of training large models!—but they are at best comparable to the second tier of US labs. And even Chinese models are often mere ripoffs of American open source releases (for example, the Yi-34B architecture seems to have essentially the Llama2 architecture, with merely a few lines of code changed). Chinese deep learning used to be more important than it is today (for example Baidu published one of the first modern scaling law papers), and while China publishes more papers in AI than the US, they don't seem to have driven any of the key breakthroughs in recent years.

That's all merely a prelude, however. If and when the CCP wakes up to AGI, we should expect extraordinary efforts on the part of the CCP to compete. And I think there's a pretty clear path for China to be in the game: outbuild the US and steal the algorithms.

1. Compute

1a. Chips: China now seems to have demonstrated the ability to manufacture 7nm chips. While going beyond 7nm will be difficult (requiring EUV), 7nm is enough! For reference, 7nm is what Nvidia A100s used. The indigenous Huawei Ascend 910B, based on the SMIC 7nm platform, seems to only be ~2-3x worse on performance/$ than an equivalent Nvidia chip would be.

The yield of SMIC's 7nm production and the general maturity of Chinese abilities here is debated, and a critical open question is in what quantities they could produce these 7nm chips. Still, it seems like there's at least a very reasonable chance they'll be able to do this at large scale in a few years.

Most of the gains in AI chips have come from improved chip design adapting them for AI use cases (and China likely already steals Nvidia chip designs from the Taiwan supply chain). 7nm vs. 3nm or 2nm, and their general fab immaturity, probably makes things more expensive for China. But that seems by no means fatal; you can make very good AI chips on top of a 7nm process. I wouldn't have high confidence by this point, for example, that they couldn't just spend a bit more and get ample compute for the $100B+ and trillion-dollar training clusters in a few years.

1b. Outbuilding the US: The binding constraint on the largest training clusters won't be chips, but industrial mobilization—perhaps most of all the 100GW of power for the trillion-dollar cluster. But if there's one thing China can do better than the US it's building stuff.

In the last decade, China has roughly built as much new electricity capacity as the entire US capacity (while US capacity has remained basically flat). In the US, these things get stuck in environmental review, permitting, and regulation for a decade first. It thus seems quite plausible that China will be able to simply outbuild the US on the largest training clusters.

The AI power buildout for 2030 seems much more doable for China than the US. Based on earlier estimates from Racing to the Trillion-Dollar Cluster.

2. Algorithms

As discussed extensively in Counting the OOMs, scaling compute is only part of the story: algorithmic advances probably contribute at least half of AI progress. We're developing the key algorithmic breakthroughs for AGI right now (essentially the EUV of algorithms because of the data wall).

By default, I expect Western labs to be well ahead; they have much of the key talent, and in recent years have developed all of the key breakthroughs. The size of the advantage may well be equivalent to a 10x (or even 100x) bigger cluster in a few years; this would provide the United States with a reasonably comfortable lead.

And yet, on the current course, we will completely surrender this advantage: as discussed extensively in the security section, the current state of security essentially makes it trivial for China to infiltrate American labs. And so, unless we lock down the labs very soon, I expect China to be able to simply steal the key algorithmic ingredients for AGI, and match US capabilities.

(Even worse, if we don't improve security, there's an even more salient path for China to compete. They won't even need to train their own AGI: they'll just be able to steal the AGI weights directly. Once they've stolen a copy of the automated AI researcher, they'll be off to the races, and can launch their own intelligence explosion. If they're willing to apply less caution—both good caution, and unreasonable regulation and delay—than the US, they could race through the intelligence explosion more quickly, outrunning us to superintelligence.)

To date, US tech companies have made a much bigger bet on AI and scaling than any Chinese efforts; consequently, we are well ahead. But counting out China now is a bit like counting out Google in the AI race when ChatGPT came out in late 2022. Google hadn't yet focused their efforts in an intense AI bet, and it looked as though OpenAI was far ahead—but once Google woke up, a year and half later, they are putting up a very serious fight. China, too, has a clear path to putting up a very serious fight. If and when the CCP mobilizes in the race to AGI, the picture could start looking very different.

Perhaps the Chinese government will be incompetent; perhaps they decide AI threatens the CCP and impose stifling regulation. But I wouldn't count on it.

I, for one, think we need to operate under the assumption that we will face a full-throated Chinese AGI effort. As every year we get dramatic leaps in AI capability, as we start seeing early automation of software engineers, as AI revenue explodes and we start seeing $10T valuations and trillion-dollar cluster buildouts, as a broader consensus starts to form that we are on the cusp of AGI—the CCP will take note. Much as I expect these leaps to wake up the USG to AGI, I would expect it to wake up the CCP to AGI—and to wake up to what being behind on AGI would mean for their national power.

They will be a formidable adversary.

中国可能具有更强的竞争潜力

在通用人工智能（AGI）领域，许多人对中国持轻视态度。芯片出口管制似乎已经限制了中国的发展，而顶尖 AI 实验室主要集中在美国和英国 —— 因此看起来没有太多可担心的。中国的大语言模型（LLM）表现尚可 —— 它们确实具备训练大规模模型的能力！—— 但总体水平可能仅相当于美国的二流实验室。甚至许多中国模型看起来只是美国开源模型的轻微改动（如 Yi-34B 架构基本上就是 Llama2 架构，仅略作调整）。

尽管中国曾在深度学习领域占据重要地位（例如百度发表了最早的现代扩展定律论文之一），并且在 AI 领域的论文数量超过美国，但近年来似乎未能推动关键性技术突破。

然而，这仅仅是开端。一旦中国共产党充分认识到通用人工智能的重要性，我们应该预期将会看到极其罕见的竞争努力。事实上，中国参与全球 AI 竞争很可能存在一条相对清晰的路径：通过大规模投资计算资源和战略性技术获取，逐步缩小与国际先进水平的差距。

1、计算资源。

芯片：中国目前已经展示出制造 7 纳米芯片的能力。尽管进一步缩小到低于 7 纳米的制程将极其困难（需要使用极紫外光刻技术），但 7 纳米制程已经可以满足许多高性能计算需求。作为参考，Nvidia A100 等主流 GPU 就采用了 7 纳米制程。基于国内 SMIC 7 纳米工艺平台的华为麒麟 910B 芯片，在性能成本比方面，大约比同等规格的 Nvidia 芯片低 2-3 倍。

关于 SMIC 7 纳米生产线的芯片良率（即合格芯片数量与总生产芯片数量的比例）和中国芯片制造能力的成熟度，业界仍存在不同看法。目前一个关键的未解问题是，中国能否批量生产这些 7 纳米芯片。尽管存在不确定性，但业内普遍认为，中国在未来几年实现大规模 7 纳米芯片生产的可能性相当高。

人工智能芯片的技术进步主要源于针对 AI 应用场景的芯片设计优化（中国很可能已经通过台湾供应链获取了英伟达的芯片设计）。7nm 到 3nm 或 2nm 工艺的制造工艺不成熟，可能会增加中国的生产成本。但这绝非不可逾越的障碍；在 7nm 工艺基础上同样可以研发出性能优秀的人工智能芯片。就目前情况而言，我不会轻易否定中国有能力通过适当投入，在未来几年内为价值数千亿美元的训练集群获得充足的计算资源。

在超越美国的竞争中：限制大规模训练集群发展的关键不在于芯片技术，而是工业动员能力 —— 尤其是万亿美元集群所需的 100GW 电力。但如果说有一项中国明显强于美国的领域，那就是大规模基础设施建设。

在过去的十年里，中国新建的电力装机容量大约相当于整个美国的电力容量（同时美国的电力装机容量基本保持不变）。在美国，这类基础设施项目动辄会在环境评估、许可审批和法规监管中耗费十年时间。因此，中国很可能能够在建设大规模 AI 训练集群方面轻松超越美国。

这一估计基于早期著作《竞逐万亿美元集群》中的预测，对于 2030 年的 AI 基础设施建设，中国似乎比美国更具可行性。

2、算法。

正如在《计算计算单位》中广泛讨论的，扩大计算规模仅是 AI 发展的一部分：算法进步可能贡献了 AI 进步的至少一半。我们目前正在开发通用人工智能（AGI）的关键算法突破 —— 这些突破堪比算法领域的极紫外光技术，因为我们正面临数据获取的瓶颈。

从传统观点来看，我预期西方实验室将继续保持领先地位；他们拥有大部分顶尖人才，并且在近年来开发了所有关键技术突破。这种优势的规模在几年内可能相当于拥有一个大 10 倍（甚至 100 倍）的计算集群；这将为美国提供相当舒适的领先优势。

然而，按照目前的发展路径，我们将彻底丧失技术优势：正如安全章节中详细讨论的，当前的安全状况本质上让中国能够轻而易举地渗透美国研究实验室。除非我们尽快加强实验室安全，否则我预计中国将能够直接窃取通用人工智能（AGI）的关键算法，并迅速追赶美国的技术能力。

（更为严峻的是，如果我们不改善安全措施，中国将找到一条更直接的竞争路径。他们甚至不需要从头训练 AGI：只需直接窃取 AI 模型权重。一旦窃取了自动化 AI 研究系统的副本，他们就可能迅速推进，并启动自身的智能爆炸进程。如果他们愿意比美国承担更少的审慎态度 —— 不论是出于合理谨慎还是过度监管和拖延 —— 他们可能更快地推进智能爆炸，抢先抵达超级智能。）

迄今为止，美国科技公司在人工智能和规模化发展上的投入远超中国，因此我们目前处于明显领先地位。不过，现在就轻易判定中国不具竞争力，就像曾经在 ChatGPT 于 2022 年末推出时低估 Google 在 AI 领域的潜力一样。当时 Google 尚未全面聚焦 AI 发展，看似被 OpenAI 甩开很大距离 —— 但一旦 Google 重新发力，仅仅一年半后就展现出极具竞争力的态势。中国同样也具备在通用人工智能（AGI）竞赛中迅速崛起的潜力。如果和当中国共产党全面动员，整个竞争格局可能会发生根本性变化。

或许中国政府的行动会不够得力；或许他们会认为 AI 构成政治威胁而实施严格管控。但我不会低估他们的能力。

就我个人而言，我们必须做好准备：中国很可能会全力以赴地推进通用人工智能（AGI）的研发。随着人工智能能力每年都在取得戏剧性突破，软件工程领域开始出现早期自动化迹象，人工智能产业收入呈爆发式增长，市值接近 10 万亿美元，大规模计算集群投资达到万亿美元级别，而且越来越多的专家开始认为我们正逼近通用人工智能的拐点 —— 中国共产党必然会密切关注这一趋势。正如这些技术进步势必会引起美国政府（USG）的高度重视，我同样预计它将激发中国共产党对通用人工智能的战略危机感，促使他们深刻认识到在 AGI 领域落后可能带来的国力消长。

### The authoritarian peril

A dictator who wields the power of superintelligence would command concentrated power unlike any we've ever seen. In addition to being able to impose their will on other countries, they could enshrine their rule internally. Millions of AI-controlled robotic law enforcement agents could police their populace; mass surveillance would be hypercharged; dictator-loyal AIs could individually assess every citizen for dissent, with advanced near-perfect lie detection rooting out any disloyalty.

Most importantly, the robotic military and police force could be wholly controlled by a single political leader, and programmed to be perfectly obedient—no more risk of coups or popular rebellions.

Whereas past dictatorships were never permanent, superintelligence could eliminate basically all historical threats to a dictator's rule and lock in their power (cf value lock-in). If the CCP gets this power, they could enforce the Party's conception of "truth" totally and completely.

To be clear, I don't just worry about dictators getting superintelligence because "our values are better." I believe in freedom and democracy, strongly, because I don't know what the right values are. In the long arc of history, "time has upset many fighting faiths." I believe we should place our faith in mechanisms of error correction, experimentation, competition, and adaption.

Superintelligence will give those who wield it the power to crush opposition, dissent, and lock in their grand plan for humanity. It will be difficult for anyone to resist the terrible temptation to use this power. I hope, dearly, that we can instead rely on the wisdom of the Framers—letting radically different values flourish, and preserving the raucous plurality that has defined the American experiment.

At stake in the AGI race will not just be the advantage in some far-flung proxy war, but whether freedom and democracy can survive for the next century and beyond. The course of human history is as brutal as it is clear. Twice in the 20th century tyranny threatened the globe; we must be under no delusion that this threat is banished forever. For many of my young friends, freedom and democracy feel like a given—but they are not. By far the most common political system in history is authoritarianism.

I genuinely do not know the intentions of the CCP and their authoritarian allies. But, as a reminder: the CCP is a regime founded on the continued worship of perhaps the greatest totalitarian mass-murderer in human history ("with estimates ranging from 40 to 80 million victims due to starvation, persecution, prison labor, and mass executions"); a regime that recently put a million Uyghurs in concentration camps and crushed a free Hong Kong; a regime that systematically practices mass surveillance for social control, both of the new-fangled (tracking phones, DNA databases, facial recognition, and so on) and the old-fangled (recruiting an army of citizens to report on their neighbors) kind; a regime that ensures all text messages passes through a censor, and that goes so far to repress dissent as to pull families into police stations when their child overseas attends a protest; a regime that has cemented Xi Jinping as dictator-for-life; a regime that touts its aims to militarily crush and "reeducate" a free neighboring nation; a regime that explicitly seeks a China-centric world order.

The free world must prevail over the authoritarian powers in this race. We owe our peace and freedom to American economic and military preeminence. Perhaps even empowered with superintelligence, the CCP will behave responsibly on the international stage, leaving each to their own. But the history of dictators of their ilk is not pretty. If America and her allies fail to win this race, we risk it all.

威权主义的危险

一位掌握超级智能（superintelligence）权力的独裁者，将拥有历史上前所未有的极端集中的权力。除了能够对其他国家强加意志外，他们还可以在内部彻底巩固统治。数百万由人工智能控制的机器人执法人员将对民众进行严密监控；大规模监控系统将被极大地强化；效忠独裁者的人工智能可以对每个公民进行个性化的异议评估，通过近乎完美的谎言识别技术根除任何潜在的不忠迹象。

更为关键的是，机器人军队和警察部队可以完全由单一政治领导人控制，并被精确编程为绝对服从 —— 这将彻底消除政变和民众起义的可能性。

与历史上曾经昙花一现的独裁政权不同，超级智能可以基本消除威胁独裁者统治的所有历史性因素，实现权力的永久「价值锁定」（value lock-in）。如果某个极权政权获得这种技术，他们将能够以前所未有的方式完全且彻底地强制推行自身的「真相」。

诚然，我担心独裁者获得超级智能，并非简单地认为「我们的价值观更优」。我坚定地相信自由和民主，恰恰是因为我清楚地知道，没有人能真正定义绝对正确的价值观。正如历史所证明的，曾经笃信的信念常常会随时间推移而被颠覆。我坚信，我们应该信赖那些能够不断纠错、实验、竞争和适应的机制。

超级智能将赋予掌控者一种强大的力量：压制异议、消除不同声音，并将自己的宏大愿景强加于人类。面对如此诱人的权力，几乎没有人能够完全抵制其诱惑。我由衷地希望，我们能够遵循开国元勋的智慧 —— 让多元的价值观自由生长，保持美国精神中那种充满活力的开放性和包容性。

在通用人工智能（AGI）的竞赛中，真正的赌注不仅仅是某个遥远战场上的战略优势，更是关乎自由和民主能否在未来百年乃至更长时间里继续存续。人类历史的发展路径既残酷又清晰：20 世纪，暴政曾两度威胁整个世界。我们绝不能天真地认为这种威胁已经永远消散。对于许多年轻人而言，自由和民主看似理所当然，实则岌岌可危。纵观历史，专制主义才是最为普遍的政治制度。

我真诚地不了解中国共产党及其专制盟友的意图。但是，请记住：中共是一个建立在持续崇拜人类历史上可能是最伟大的极权主义屠杀者之上的政权。据估计，毛泽东时期造成的死亡人数在 4000 万至 8000 万之间，死因包括饥饿、政治迫害、劳动营和大规模处决。这是一个 recently 将 100 万维吾尔人关进拘禁营并压制香港自由的政权；一个系统性地为社会控制进行大规模监控的政权，手段包括现代科技（追踪手机、DNA 数据库、面部识别等）和传统方式（招募公民互相监视）；一个确保所有通讯都经过审查的政权，甚至不惜将家庭拉到警察局，只因他们在海外的孩子参加了抗议；一个将习近平巩固为终身独裁者的政权；一个公开吹嘘要军事上压制并「再教育」自由邻国的政权；一个明确追求以中国为中心的世界秩序的政权。

在与专制势力的科技竞争中，自由世界必须占据上风。我们享有的和平与自由，源于美国在经济和军事领域的领先地位。即便中国共产党获得超级智能，也许仍会在国际舞台上保持克制，遵循国际规则。然而，历史证明这类专制政权往往难以自我约束。如果美国及其盟友在这场竞赛中落后，将可能面临严重的战略风险。

### Maintaining a healthy lead will be decisive for safety

It is the cursed history of science and technology that as they have unfolded their wonders, they have also expanded the means of destruction: from sticks and stones, to swords and spears, rifles and cannons, machine guns and tanks, bombers and missiles, nuclear weapons. The "destruction/$" curve has consistently gone down as technology has advanced. We should expect the rapid technological progress post-superintelligence to follow this trend.

Perhaps dramatic advances in biology will yield extraordinary new bioweapons, ones that spread silently, swiftly, before killing with perfect lethality on command (and that can be made extraordinarily cheaply, affordable even for terrorist groups). Perhaps new kinds of nuclear weapons enable the size of nuclear arsenals to increase by orders of magnitude, with new delivery mechanisms that are undetectable. Perhaps mosquito-sized drones, each carrying a deadly poison, could be targeted to kill every member of an opposing nation. It's hard to know what a century's worth of technological progress would yield—but I am confident it would unfold appalling possibilities.

Humanity barely evaded self-destruction during the Cold War. On the historical view, the greatest existential risk posed by AGI is that it will enable us to develop extraordinary new means of mass death. This time, these means could even proliferate to become accessible to rogue actors or terrorists (especially if, as on the current course, the superintelligence weights aren't sufficiently protected, and can be directly stolen by North Korea, Iran, and co.).

North Korea already has a concerted bioweapons program: the US assesses that "North Korea has a dedicated, national level offensive program" to develop and produce bioweapons. It seems plausible that their primary constraint is how far their small circle of top scientists has been able to push the limits of (synthetic) biology. What happens when that constraint is removed, when they can use millions of superintelligences to accelerate their bioweapons R&D? For example, the US assesses that North Korea currently has "limited ability" to genetically engineer biological products—what happens when that becomes unlimited? With what unholy new concoctions will they hold us hostage?

Moreover, as discussed in the superalignment section, there will be extreme safety risks around and during the intelligence explosion—we will be faced with novel technical challenges to ensure we can reliably trust and control superhuman AI systems. This very well may require us to slow down at some critical moments, say, delaying by 6 months in the middle of the intelligence explosion to get additional assurances on safety, or using a large fraction of compute on alignment research rather than capabilities progress.

Some hope for some sort of international treaty on safety. This seems fanciful to me. The world where both the CCP and USG are AGI-pilled enough to take safety risk seriously is also the world in which both realize that international economic and military predominance is at stake, that being months behind on AGI could mean being permanently left behind. If the race is tight, any arms control equilibrium, at least in the early phase around superintelligence, seems extremely unstable. In short, "breakout" is too easy: the incentive (and the fear that others will act on this incentive) to race ahead with an intelligence explosion, to reach superintelligence and the decisive advantage, too great. At the very least, the odds we get something good-enough here seem slim. (How have those climate treaties gone? That seems like a dramatically easier problem compared to this.)

The main—perhaps the only—hope we have is that an alliance of democracies has a healthy lead over adversarial powers. The United States must lead, and use that lead to enforce safety norms on the rest of the world. That's the path we took with nukes, offering assistance on the peaceful uses of nuclear technology in exchange for an international nonproliferation regime (ultimately underwritten by American military power)—and it's the only path that's been shown to work.

Perhaps most importantly, a healthy lead gives us room to maneuver: the ability to "cash in" parts of the lead, if necessary, to get safety right, for example by devoting extra work to alignment during the intelligence explosion.

The safety challenges of superintelligence would become extremely difficult to manage if you are in a neck-and-neck arms race. A 2 year vs. a 2 month lead could easily make all the difference. If we have only a 2 month lead, we have no margin at all for safety. In fear of the CCP's intelligence explosion, we'd almost certainly race, no holds barred, through our own intelligence explosion—barreling towards AI systems vastly smarter than humans in months, without any ability to slow down to get key decisions right, with all the risks of superintelligence going awry that implies. We'd face an extremely volatile situation, as we and the CCP rapidly developed extraordinary new military technology that repeatedly destabilized deterrence. If our secrets and weights aren't locked down, it might even mean a range of other rogue states are close as well, each of them using superintelligence to furnish their own new arsenal of super-WMDs. Even if we barely managed to inch out ahead, it would likely be a pyrrhic victory; the existential struggle would have brought the world to the brink of total self-destruction.

Superintelligence looks very different if the democratic allies have a healthy lead, say 2 years. That buys us the time necessary to navigate the unprecedented series of challenges we'll face around and after superintelligence, and to stabilize the situation.

If and when it becomes clear that the US will decisively win, that's when we offer a deal to China and other adversaries. They'll know they won't win, and so they'll know their only option is to come to the table; and we'd rather avoid a feverish standoff or last-ditch military attempts on their part to sabotage Western efforts. In exchange for guaranteeing noninterference in their affairs, and sharing the peaceful benefits of superintelligence, a regime of nonproliferation, safety norms, and a semblance of stability post-superintelligence can be born.

In any case, as we go deeper into this struggle, we must not forget the threat of self-destruction. That we made it through the Cold War in one piece involved too much luck—and the destruction could be a thousandfold more potent than what we faced then. A healthy lead by an American-led coalition of democracies—and a solemn exercise of this leadership to stabilize whatever volatile situation we find ourselves in—is probably the safest path to navigating past this precipice. But in the heat of the AGI race, we better not screw it up.

保持技术领先对维护全球安全至关重要

科技发展的历史一直是一把双刃剑：每一次技术进步不仅展现人类智慧的光芒，也不可避免地拓展了毁灭的可能性。从原始的棍棒和石块，到后来的剑和矛，再到步枪、大炮，乃至机枪、坦克、轰炸机、导弹，最终发展到核武器，技术进步似乎总是伴随着更强大的毁灭能力。随着科技的发展，单位成本上的破坏能力曲线持续下降。我们有理由相信，超级智能时代的技术进步也将遵循这一规律。

生物学可能会带来惊人的突破，催生出前所未有的生物武器 —— 这些武器能悄无声息地传播，迅速蔓延，并能精确地在指令下实施致命打击（而且制造成本极低，甚至恐怖组织也能负担）。新型核武器或许能使核武库成倍扩增，并配备难以察觉的投送系统。想象一下，蚊子大小的无人机携带致命毒剂，精准地针对性消灭敌国的每一个成员。虽然很难预测一个世纪的技术进步会带来什么，但我确信，这将开启令人毛骨悚然的可能性。

在冷战期间，人类曾险些走向自我毁灭的边缘。从历史角度看，通用人工智能（AGI）最大的存在性风险，就是它可能为人类提供前所未有的大规模杀伤性武器。这一次，这些武器可能会扩散到恐怖分子和极端势力的手中（尤其是在当前技术路径下，如果超级智能系统的关键参数防护不足，很可能被朝鲜、伊朗等国家直接窃取）。

朝鲜已经拥有一个协调一致的生物武器计划：美国情报评估指出，朝鲜存在「专门的国家级进攻性生物武器发展计划」。可以合理推测，目前他们的主要瓶颈在于顶级科学家团队能够将（合成）生物学推进到何种程度。然而，当这一限制被人工智能（AI）突破，数百万个高度智能的系统能够加速生物武器研发时，局面将发生巨大改变。举例来说，美国目前认为朝鲜在基因工程生物产品方面仅具「有限能力"—— 如果这种能力变得无限制，他们可能会用何种令人恐惧的生物武器威胁世界？

正如超对齐（Superalignment）部分所讨论的，在人工智能可能快速自我改进并突破人类控制能力的关键阶段（即「智能爆炸"），我们将面临极其严峻的安全风险。在这个过程中，确保可靠地控制和信任超越人类智能的 AI 系统，将是一项前所未有的技术挑战。这可能意味着我们需要在某些关键时刻审慎行事，例如在智能迅速发展的中间阶段暂停 6 个月，以获得额外的安全保障；或者将大部分计算资源投入到 AI 系统与人类价值观对齐的研究中，而非单纯追求 AI 能力的提升。

一些人对制定某种国际安全条约抱有希望。然而，这种想法在我看来显得相当天真。在中国共产党和美国政府都充分意识到通用人工智能（AGI）安全风险的世界里，他们同样会认识到国际经济和军事主导权正处于危险之中。落后于 AGI 发展仅仅几个月，就可能意味着永远被甩在后面。

如果这场技术竞赛如此紧张，那么在超级智能早期阶段的任何军备控制平衡都显得极其脆弱。说白了，技术「突破」实在太容易：推动智能迅速进化以获得超级智能和决定性优势的动机（以及对对手可能采取同样行动的恐惧）实在太过强烈。至少，我们能获得一个「聊胜于无」结果的可能性看起来微乎其微。(且看那些气候条约的进展吧 —— 相比通用人工智能的挑战，气候问题简直是小菜一碟。)

我们维护全球安全的最后希望，可能就在于民主国家组成的联盟能够保持领先优势。美国必须在这一进程中发挥引领作用，并运用这一优势在全球推广安全准则。这正如我们处理核技术扩散时采取的策略：通过提供和平利用核技术的援助，换取国际核不扩散机制（最终由美国的军事实力作为保障）—— 这是迄今为止被证明最有效的路径。

更为关键的是，保持技术领先为我们提供了战略回旋的余地：如果必要，我们可以「兑现」部分领先优势，确保技术安全。例如，在人工智能快速发展（智能爆炸）的关键阶段，投入更多精力确保技术对齐与可控性。

在一场势均力敌的技术竞争中，超级智能（Superintelligence）的安全挑战将变得极其棘手。仅仅 2 年与 2 个月的领先优势就可能彻底改变局面。如果我们的技术领先仅有 2 个月，那么安全方面将毫无缓冲空间。出于对中国共产党可能引发的智能爆炸（Intelligence Explosion）的恐惧，我们很可能会不惜一切代价迅速推进自身的智能发展 —— 在几个月内不计后果地推进远远超越人类智能的 AI 系统，没有丝毫减缓节奏以审慎做出关键决策的余地，这无疑将带来超级智能失控的巨大风险。

我们将面临极其危险的局面：我们和中国共产党将迅速开发出不断颠覆战略平衡的尖端军事技术。如果我们的技术机密和模型权重得不到有效保护，这甚至可能意味着其他一些不稳定国家也即将紧随其后，每个国家都会利用超级智能为自己建造新一代超级大规模杀伤性武器。即便我们勉强领先，这也很可能是一场代价惨重的胜利 —— 这场关乎存亡的竞争将把世界推向自我毁灭的深渊。

如果民主阵营能在人工智能（Superintelligence）发展中保持约 2 年的领先优势，局势将会大不相同。这段宝贵的时间窗口将帮助我们应对围绕超级智能出现的前所未有的复杂挑战，并逐步稳定局势。

当美国明确处于决定性优势时，我们将向中国和其他潜在对手提出战略协议。对方将清楚地意识到继续对抗毫无胜算，唯一的选择就是进行谈判。我们希望避免可能出现的紧张对峙和因绝望而发起的军事冒险。通过保证不干涉对方内政，并共享超级智能带来的和平红利，我们可以共同建立一个关于技术控制、安全准则和全球稳定的新型国际框架。

无论如何，随着我们愈发深入这场关乎生存的博弈，我们绝不能忘记自我毁灭的巨大风险。我们在冷战中侥幸存活，而当前可能面临的毁灭性威胁将远远超过那个年代。由美国主导的民主国家联盟给予明智的指引 —— 并以严肃而谨慎的态度应对我们所面临的任何不稳定局势 —— 或许是绕过这个生死关头的最安全路径。但在通用人工智能（AGI）竞赛的白热化阶段，我们千万不能出任何差错。

### Superintelligence is a matter of national security

It is clear: AGI is an existential challenge for the national security of the United States. It's time to start treating it as such.

Slowly, the USG is starting to move. The export controls on American chips are a huge deal, and were an incredibly prescient move at the time. But we have to get serious across the board.

The US has a lead. We just have to keep it. And we're screwing that up right now. Most of all, we must rapidly and radically lock down the AI labs, before we leak key AGI breakthroughs in the next 12-24 months (or the AGI weights themselves). We must build the compute clusters in the US, not in dictatorships that offer easy money. And yes, American AI labs have a duty to work with the intelligence community and the military. America's lead on AGI won't secure peace and freedom by just building the best AI girlfriend apps. It's not pretty—but we must build AI for American defense.

We are already on course for the most combustive international situation in decades. Putin is on the march in Eastern Europe. The Middle East is on fire. The CCP views taking Taiwan as its destiny. Now add in the race to AGI. Add in a century's worth of technological breakthroughs compressed into years post-superintelligence. It will be the one of most unstable international situations ever seen—and at least initially, the incentives for first-strikes will be tremendous.

There's already an eerie convergence of AGI timelines (~2027?) and Taiwan watchers' Taiwan invasion timelines (China ready to invade Taiwan by 2027?)—a convergence that will surely only heighten as the world wakes up to AGI. (Imagine if in 1960, the vast majority of the world's uranium deposits were somehow concentrated in Berlin!) It seems to me that there is a real chance that the AGI endgame plays out with the backdrop of world war. Then all bets are off.

通用人工智能：国家安全的生命线

毫无疑问：通用人工智能是美国国家安全面临的存亡之战。是时候以前所未有的严肃态度来应对这一挑战了。

美国政府（USG）已经开始缓慢但坚定地行动。对美国高端芯片的出口管控是一记关键一招，在当时看来极其先见卓识。但我们必须在全方位范围内认真对待这场较量。

美国目前在通用人工智能领域占据领先地位。我们的任务是维持这一优势，但眼下我们正面临严峻挑战。最关键的是，我们必须迅速且彻底地控制人工智能研究实验室，防止在未来 12 至 24 个月内泄露关键的通用人工智能突破成果（包括 AGI 模型权重）。我们应在美国建立计算集群，而非在提供廉价资金的专制国家。美国的 AI 实验室确实有责任与情报机构和军方密切合作。单靠开发娱乐性 AI 应用，美国在通用人工智能领域的领先优势无法保障全球和平与自由。尽管这看起来并不那么理想，但我们必须为美国国防发展人工智能。

目前，我们已经处于几十年来最具潜在爆发性的国际局势之中。普京正在东欧地区扩张势力。中东局势硝烟四起。中国共产党视统一台湾为其战略必然。现在，再叠加通用人工智能的激烈竞争，以及后超级智能时代可能在极短时间内集中释放的百年技术突破，这将成为历史上最不稳定的国际形势之一。在这一进程的初期，各方进行先发制人攻击的诱惑将极其强烈。

一种令人毛骨悚然的时间线诡异地重叠了 —— 通用人工智能（AGI）可能出现的时间线（约 2027 年？）与台湾观察家预测中国将入侵台湾的时间线（2027 年？）惊人地一致。随着世界逐渐觉醒，这种重叠只会变得更加明显。（就好比 1960 年，世界上绝大多数铀矿床莫名其妙地集中在柏林！）我认为，通用人工智能的命运可能很可能在一场世界大战的背景下演绎。到那时，一切都将变得不可预测。

Next post in series:

IV. The Project

### Reference

For example, Yi-Large seems to be a GPT-4-class model on LMSys, but that's over a year after OpenAI released GPT-4.↩

Similarly, Qwen hugging face code cites Mistral a lot, and it seems that Chinese LLM dependence on American open-source is an explicit worry that has made its way to the Chinese Premier.↩

The Huawei Ascend 910B seems to cost around 120,000 yuan per card, or about $17k. This is produced on the SMIC 7nm node, while performing similarly to an A100. H100s are maybe ~3x better than A100s, while costing somewhat more ($20-25k ASP), suggesting only a ~2-3x cost increase for equivalent AI GPU performance for China right now.↩

For example, they're still using Western HBM memory (which for some reason is not export controlled?), though CXMT is said to be sampling HBM next year.↩

Though, since they can still import other types of chips from the West, they could simply direct the entirety of their 7nm node to AI chips, making up for lower overall production.↩

Notably, even cybercriminals were able to hack Nvidia and get key GPU design secrets. Moreover, TPUv6 designs were apparently among what was stolen by the recently-indicted Chinese national at Google.↩

For example, maybe these are 2x worse on perf/$ or perf/Watt. In turn, that also means to achieve the same overall datacenter performance, you need more power, and need more chips networked together, which also makes things more of a hassle.↩

Note that even 3x more on chips would be much less than that in terms of increase in datacenter costs. Actual logic fab costs are <5% of Nvidia GPU cost, and even considering memory and CoWoS it's less than 20% of the Nvidia pricetag due to their margin. And even GPUs themselves tend to be only 50-60% of the cost of a datacenter. So 3x more expensive on the chip fab end might translate into much, much less than a 3x increase in overall cost. Even for 10x more expensive chips, it seems like China could stomach that without hugely increasing datacenter costs.↩

Some argue that even if China stole these secrets, they wouldn't be able to compete because it requires tacit knowledge. I disagree. I think of this as having two layers. The bottom layer is the engineering prowess for large-scale training runs; these training runs can be hacky and delicate and requires tacit knowledge. But as I'll discuss later, Chinese AI efforts have shown themselves perfectly capable of training large-scale models, and I think they will have this tacit knowledge indigenously. The top layer is the algorithmic recipe—things like model architecture, the right scaling laws, etc.—that could be conveyed in a one-hour call. These compute multipliers are usually discrete changes, meaning the underlying tacit knowledge for large-scale training runs should transfer. I don't think "tacit knowledge" will be a decisive barrier for Chinese AGI efforts.↩

(Primarily monarchy.)↩

Consider the following comparison of unstable vs. stable arms control equilibria. 1980s arms control during the Cold War reduced nuclear weapons substantially, but targeted a stable equilibrium. The US and the Soviet Union still had 1000s of nuclear weapons. MAD was assured, even if one of the actors tried a crash program to build more nukes; and a rogue nation could try to build some nukes of their own, but not fundamentally threaten the US or Soviet Union with overmatch.

However, when disarmament is to very low levels of weapons or occurs amidst rapid technological change, the equilibrium is unstable. A rogue actor or treaty-breaker can easily start a crash program and threaten to totally overmatch the other players. Zero nukes wouldn't be a stable equilibrium; similarly, this paper has interesting historical case studies (such as post-WWI arms limitations and the Washington Naval Treaty) where disarmament in similarly dynamic situations destabilized, rather than stabilized.

If mere months of lead on AGI would give an utterly decisive advantage, this makes stable disarmament on AI similarly difficult. A rogue upstart or a treaty-breaker could gain a huge edge by secretly starting a crash program; the temptation would be too great for any sort of arrangement to be stable.↩

It's worth appreciating just how a big a deal 2 years is in terms of difference in AI capabilities. Given the already-rapid pace of AI progress today, and the even-more-rapid pace we should expect in an intelligence explosion, and the broader technological explosion post-superintelligence, a "even" a 2-year-lead would mean vast differences in capability.↩

Daniel Ellsberg recounts this rivetingly, as one of the nuclear war planners at RAND and in the national security apparatus at the time.

Everyone will be racing to their own superintelligences, and there will be a limited window before someone ahead will have irreversibly pulled away. There will be a big incentive to try to disable the enemy superintelligence clusters before they've gained a sufficient physical advantage (e.g., using superintelligence to develop impenetrable missile defense or drone swarms) that leaves everyone else permanently in the dust.