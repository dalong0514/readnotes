Leopold Aschenbrenner.(2024).2024109Situational-Awareness-The-Decade-Ahead.Dwarkesh podcast => Introduction

SITUATIONAL AWARENESS

The Decade Ahead

Introduction

I. From GPT-4 to AGI: Counting the OOMs

II. From AGI to Superintelligence: the Intelligence Explosion

IIIa. Racing to the Trillion-Dollar Cluster

IIIb. Lock Down the Labs: Security for AGI

IIIc. Superalignment

IIId. The Free World Must Prevail

IV. The Project

V. Parting Thoughts

Full series as PDF

About

Dwarkesh podcast

局势洞察

未来十年

引言

I. 从 GPT-4 到通用人工智能（AGI)：计算数量级（OOMs）分析

II. 从通用人工智能到超级智能（Superintelligence)：智能爆炸

IIIa. 迈向万亿规模算力集群

IIIb. 实验室管控：AGI 安全保障

IIIc. 超级对齐

IIId. 自由世界必胜

IV. The Project

V. 结语

完整系列 PDF 版

关于

Dwarkesh 播客

## SITUATIONAL AWARENESS: The Decade Ahead

Leopold Aschenbrenner, June 2024

You can see the future first in San Francisco.

Over the past year, the talk of the town has shifted from $10 billion compute clusters to $100 billion clusters to trillion-dollar clusters. Every six months another zero is added to the boardroom plans. Behind the scenes, there's a fierce scramble to secure every power contract still available for the rest of the decade, every voltage transformer that can possibly be procured. American big business is gearing up to pour trillions of dollars into a long-unseen mobilization of American industrial might. By the end of the decade, American electricity production will have grown tens of percent; from the shale fields of Pennsylvania to the solar farms of Nevada, hundreds of millions of GPUs will hum.

The AGI race has begun. We are building machines that can think and reason. By 2025/26, these machines will outpace many college graduates. By the end of the decade, they will be smarter than you or I; we will have superintelligence, in the true sense of the word. Along the way, national security forces not seen in half a century will be unleashed, and before long, The Project will be on. If we're lucky, we'll be in an all-out race with the CCP; if we're unlucky, an all-out war.

Everyone is now talking about AI, but few have the faintest glimmer of what is about to hit them. Nvidia analysts still think 2024 might be close to the peak. Mainstream pundits are stuck on the willful blindness of "it's just predicting the next word". They see only hype and business-as-usual; at most they entertain another internet-scale technological change.

Before long, the world will wake up. But right now, there are perhaps a few hundred people, most of them in San Francisco and the AI labs, that have situational awareness. Through whatever peculiar forces of fate, I have found myself amongst them. A few years ago, these people were derided as crazy—but they trusted the trendlines, which allowed them to correctly predict the AI advances of the past few years. Whether these people are also right about the next few years remains to be seen. But these are very smart people—the smartest people I have ever met—and they are the ones building this technology. Perhaps they will be an odd footnote in history, or perhaps they will go down in history like Szilard and Oppenheimer and Teller. If they are seeing the future even close to correctly, we are in for a wild ride.

Let me tell you what we see.

Table of Contents

Each essay is meant to stand on its own, though I'd strongly encourage reading the series as a whole. For a pdf version of the full essay series, click here.

Introduction [this page]

History is live in San Francisco.

I. From GPT-4 to AGI: Counting the OOMs

AGI by 2027 is strikingly plausible. GPT-2 to GPT-4 took us from ~preschooler to ~smart high-schooler abilities in 4 years. Tracing trendlines in compute (~0.5 orders of magnitude or OOMs/year), algorithmic efficiencies (~0.5 OOMs/year), and "unhobbling" gains (from chatbot to agent), we should expect another preschooler-to-high-schooler-sized qualitative jump by 2027.

II. From AGI to Superintelligence: the Intelligence Explosion

AI progress won't stop at human-level. Hundreds of millions of AGIs could automate AI research, compressing a decade of algorithmic progress (5+ OOMs) into ≤1 year. We would rapidly go from human-level to vastly superhuman AI systems. The power—and the peril—of superintelligence would be dramatic.

III. The Challenges

IIIa. Racing to the Trillion-Dollar Cluster

The most extraordinary techno-capital acceleration has been set in motion. As AI revenue grows rapidly, many trillions of dollars will go into GPU, datacenter, and power buildout before the end of the decade. The industrial mobilization, including growing US electricity production by 10s of percent, will be intense.

IIIb. Lock Down the Labs: Security for AGI

The nation's leading AI labs treat security as an afterthought. Currently, they're basically handing the key secrets for AGI to the CCP on a silver platter. Securing the AGI secrets and weights against the state-actor threat will be an immense effort, and we're not on track.

IIIc. Superalignment

Reliably controlling AI systems much smarter than we are is an unsolved technical problem. And while it is a solvable problem, things could easily go off the rails during a rapid intelligence explosion. Managing this will be extremely tense; failure could easily be catastrophic.

IIId. The Free World Must Prevail

Superintelligence will give a decisive economic and military advantage. China isn't at all out of the game yet. In the race to AGI, the free world's very survival will be at stake. Can we maintain our preeminence over the authoritarian powers? And will we manage to avoid self-destruction along the way?

IV. The Project

As the race to AGI intensifies, the national security state will get involved. The USG will wake from its slumber, and by 27/28 we'll get some form of government AGI project. No startup can handle superintelligence. Somewhere in a SCIF, the endgame will be on.

V. Parting Thoughts

What if we're right?

Next post in series:

I. From GPT-4 to AGI: Counting the OOMs

While I used to work at OpenAI, all of this is based on publicly-available information, my own ideas, general field-knowledge, or SF-gossip.

Thank you to Collin Burns, Avital Balwit, Carl Shulman, Jan Leike, Ilya Sutskever, Holden Karnofsky, Sholto Douglas, James Bradbury, Dwarkesh Patel, and many others for formative discussions. Thank you to many friends for feedback on earlier drafts. Thank you to Joe Ronan for help with graphics, and Nick Whitaker for publishing help.

Dedicated to Ilya Sutskever.

局势洞察：未来十年

Leopold Aschenbrenner，2024 年 6 月

未来的雏形，始现旧金山。

过去一年里，这座城市的热门话题从百亿美元计算集群，迅速升级到千亿美元，再到万亿美元规模。董事会的规划每半年就要在预算后面添加一个零。在这场大幕之后，各方正在激烈争夺这十年内所有可能获得的电力供应协议和变压设备。美国企业巨头正准备投入数万亿美元，掀起一场史无前例的工业动员。到 2030 年前，美国的电力产能将提升数十个百分点。从宾夕法尼亚的页岩气田到内华达的太阳能基地，数亿计算芯片将日夜不停地运转。

通用人工智能的竞赛已然打响。我们正在创造能够思考和推理的机器。到 2025/26 年，这些机器的能力将超越众多大学毕业生。到这个十年结束时，它们的智能将远超你我。我们将迎来真正意义上的超级智能。在这个过程中，半个世纪未见的国家安全力量将被调动，而 The Project 也将随之启动。如果幸运，我们将与 CCP 展开一场全面竞赛；如果不幸，那将是一场全面战争。

如今，人工智能已成为热门话题，但几乎没有人能真正理解即将来临的巨变。全球最大芯片公司 Nvidia 的分析师仍认为 2024 年可能是市场顶点。主流观察家们仍固守着「不过是预测下一个词」的片面认知。他们只看到表面的热度和商业机会，顶多认为这是另一次互联网规模的技术革新。

世界即将觉醒，但此时此刻，真正具备局势洞察力的或许只有几百人，他们大多集中在旧金山和各大 AI 实验室。机缘巧合下，我有幸成为他们中的一员。几年前，这些人还被视为异类 —— 但他们坚信技术发展趋势，这让他们成功预见了过去几年 AI 的突破性进展。他们对未来几年的预测是否同样准确，仍有待时间验证。但这些人都极其聪明 —— 是我遇到过最聪明的一群人 —— 而且正是他们在开发这项技术。也许他们会成为历史的一个特殊注脚，又或许会像原子弹之父 Oppenheimer、氢弹之父 Teller 以及核物理学家 Szilard 那样，在人类历史上留下浓墨重彩的一笔。如果他们对未来的预见哪怕只有一半是对的，我们都将经历一场前所未有的变革之旅。

让我来分享我们的观察。

目录

虽然每篇文章都可以独立阅读，但我强烈建议您完整阅读整个系列。如需查看完整论文系列的 PDF 版本，请点击此处。

引言 [本页]

历史的转折正在旧金山展开。

I. 从 GPT-4 到通用人工智能：计算数量级（OOMs）分析

2027 年实现通用人工智能（AGI）的可能性令人震惊。从 GPT-2 到 GPT-4 的 4 年进化中，AI 能力从「相当于学龄前儿童」跃升至「堪比优秀高中生」。通过分析计算能力（每年提升约 0.5 个数量级)、算法效率（每年提升约 0.5 个数量级），以及从简单对话机器人到 AI 智能体（agent）的能力解放（unhobbling），我们有理由相信到 2027 年会出现另一次类似的质的飞跃。

II. 从通用人工智能到超级智能：智能爆炸

AI 的进步不会止步于人类水平。数亿个 AGI 系统将能够自动进行 AI 研究，把原本需要十年才能实现的算法进步（超过 5 个数量级）压缩到不到一年时间内完成。我们将迅速从人类级别的 AI 跨越到远超人类的系统。超级智能带来的力量将是空前的，但其潜在危险也同样巨大。

III. 挑战

IIIa. 迈向万亿美元算力集群

我们正在见证史上最惊人的技术资本协同加速。随着 AI 产业收入的爆发性增长，在这个十年结束之前，数万亿美元将涌入图形处理器（GPU)、数据中心和电力基础设施建设。这场工业革新浪潮将推动美国电力产能提升数十个百分点，其规模之大前所未有。

IIIb. 实验室管控：AGI 安全保障

目前，美国顶尖的 AI 实验室仍将安全置于次要地位。他们实际上是在不经意间将 AGI 的核心机密和模型权重（weights）暴露给了 CCP。要在国家级威胁面前保护 AGI 的核心机密将需要付出巨大努力，而我们现在的准备远远不够。

IIIc. 超级对齐（Superalignment)

如何可靠地控制比人类更智能的 AI 系统，这个技术难题至今未解。尽管这个问题理论上可以解决，但在快速的智能爆发过程中，情况很容易失控。管控这一过程将极其考验人类的能力；一旦失败，可能导致文明毁灭级的灾难。

IIId. 自由世界必胜

超级智能将带来决定性的经济和军事优势。中国在这场竞赛中仍然是强劲对手。在迈向 AGI 的竞赛中，自由世界的存续正面临考验。我们能否保持对威权国家的领先优势？我们能否避免在这个过程中自我毁灭？

IV. The Project

随着 AGI 竞赛的白热化，国家安全机构将全面介入。美国政府将从沉睡中苏醒，在 2027/2028 年，我们将看到某种形式的政府 AGI 项目启动。没有任何一家初创公司能够独自应对超级智能。在某个机密情报设施（Sensitive Compartmented Information Facility，SCIF）中，人类文明最关键的一战将展开。

V. 思考与展望

如果这一切预测都成真，人类将何去何从？

系列文章下篇:

I. 从 GPT-4 到通用人工智能：计算数量级分析

尽管我曾在人工智能研究公司 OpenAI 工作，但本文所有内容均来自公开信息、个人见解、行业通用知识以及旧金山科技圈的讨论。

特别感谢 Collin Burns、Avital Balwit、Carl Shulman、Jan Leike、Ilya Sutskever、Holden Karnofsky、Sholto Douglas、James Bradbury、Dwarkesh Patel 等诸多同仁的真知灼见。感谢众多朋友对初稿提供的宝贵意见。同时感谢 Joe Ronan 在数据可视化方面的协助，以及 Nick Whitaker 在编辑出版环节的支持。

谨以此文献给 Ilya Sutskever。