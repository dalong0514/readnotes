Nate Silver.(2012).2018173The-Signal-and-the-Noise.Penguin Group => 0101





## 1001THE POKER BUBBLE

The year 2003 was the start of the "poker boom," a sort of bubble economy in which the number of new and inexperienced players was growing exponentially and even a modicum of poker skill could be parlayed into large profits. The phenomenon had two immediate and related causes. One was the 2003 World Series of Poker in Las Vegas, which was won by a twenty-seven-year-old amateur, a Nashville accountant with the auspicious name of Chris Moneymaker. Moneymaker was the literal embodiment of the poker everyman: a slightly pudgy office drone who, through a never-ending series of daring bluffs and lucky draws, had turned the $39 he'd paid to enter an online qualifying tournament into a $2.5 million purse.

ESPN turned Moneymaker's achievement into a six-part miniseries, played on nearly continuous repeat on weekday evenings until baseball season finally came along to fill the void. It was terrific advertising for the "sport" of poker, which until that time had a reputation for being seedy, archaic, and intimidating. Suddenly, every balding, five-foot-eight accountant who had long ago given up on his dream of being the next Michael Jordan or Derek Jeter could see in Moneymaker someone who looked just like him, who had a job just like his, and who in a matter of weeks had gone from rank amateur to the winner of the biggest poker tournament in the world.

But the ESPN broadcasts presented a highly sanitized version of what reality actually looks like at the poker table. For one thing, out of the necessity of compressing more than forty hours of play involving more than eight hundred players into six hours of broadcasts, they showed only a small fraction of the hands as they were actually played. What's more, because of the ingenious invention of the "hole cam"—pinhole-size cameras installed around the edge of the table beside each player—the cards of not just Moneymaker but those of each of his opponents were revealed to the home audience as the hand was being played out, giving the audience the feeling of being clairvoyant. Poker is a pretty easy game if you know what cards your opponent holds.

Moneymaker was cast as the protagonist who could do no wrong. Hands that a sober analysis might have concluded he'd played poorly were invariably praised by the announcers—rash bluffs became gutsy ones, premature folds became perceptive ones. Moneymaker was not some slightly-above-average schmoe getting the cards of his life*1 but a poker savant who was cunning enough to have developed into a world-class player almost overnight.

The viewer was led to believe that poker is easy to learn, easy to profit from, and incredibly action-packed—none of which is true. But that didn't stop many of them from concluding that only a ticket to Las Vegas separated them from life as the next Chris Moneymaker. The number of participants in the World Series of Poker's $10,000 main event exploded, from 839 the year that Moneymaker won it to 8,773 just three years later.

I was one of those people.2 I lived the poker dream for a while, and then it died. I learned that poker sits at the muddy confluence of the signal and the noise. My years in the game taught me a great deal about the role that chance plays in our lives and the delusions it can produce when we seek to understand the world and predict its course.

FIGURE 10-1: WORLD SERIES OF POKER MAIN EVENT PARTICIPANTS, 1970–2006

The Start of a Poker Dream

The other catalyst of the poker boom was the Internet. Internet poker had existed in some form since 1998, but it began to go mainstream in 2003 as companies like Party Poker and PokerStars became more aggressive about marketing their way through the legal quagmire of Internet gambling. Players from all around the world flocked to the online games, overcoming their reservations about the security and legality of the virtual cardrooms. They offered a whole host of conveniences: 24/7 access to every form of poker at stakes ranging from pennies a hand to hundreds of dollars; a faster-paced experience (a computer chip can shuffle much faster than a human dealer can—and there's no need to tip it); the comfort of playing from home rather than at a smoky, decrepit casino.

I had a job not unlike Moneymaker's, as I described earlier, working as an economic consultant for the accounting firm KPMG. One of my buddies at work suggested that we start a regular game, gambling just enough to make ourselves nervous. I had a smidgen of poker experience, having made a few four-in-the-morning sojourns to the Soaring Eagle Indian Casino in Mount Pleasant, Michigan. But I was rusty and needed practice and began to look online. A clunky, buggy site named Pacific Poker was making players an offer that was hard to refuse: $25 in real-money poker chips, with almost no strings attached.3

I lost the initial $25 fairly quickly, but the players in the Pacific Poker games did not seem much more sophisticated than the mix of ex-convicts and septuagenarians who populated the games at the Soaring Eagle. So I deposited $100 of my own. Almost all professional poker players begin their careers on winning streaks—the ones that lose at first are usually sensible enough to quit—and I was no exception. My bankroll began to grow, by $50 or $100 a night at first and them sometimes by $500 or $1,000. After about three months, my winnings hit $5,000; I began staying up all night to play, taking a cab to work at the crack of dawn and faking my way through the workday. After six months and $15,000 in winnings, I quit my job, leaving the exciting world of international tax consulting behind to split my time between playing cards and working for Baseball Prospectus. It was liberating; I felt as though I'd hacked the system somehow.

I have no idea whether I was really a good player at the very outset. But the bar set by the competition was low, and my statistical background gave me an advantage. Poker is sometimes perceived to be a highly psychological game, a battle of wills in which opponents seek to make perfect reads on one another by staring into one another's souls, looking for "tells" that reliably betray the contents of the other hands. There is a little bit of this in poker, especially at the higher limits, but not nearly as much as you'd think. (The psychological factors in poker come mostly in the form of self-discipline.) Instead, poker is an incredibly mathematical game that depends on making probabilistic judgments amid uncertainty, the same skills that are important in any type of prediction.

How Poker Players Predict Hands

Good poker players are not distinguished by their ability to predict which cards will come next, as though they had ESP. Only the most superstitious or paranoid players believe that the order of the shuffle is anything other than random. Only the very worst ones will have failed to commit the most basic odds calculations to memory: that a flush has about a 1-in-3 chance of coming in with two cards to come, or that a pair of aces will beat a pair of kings about 80 percent of the time. The core analytic skill, rather, is what players call "hand reading": in figuring which cards your opponent might hold, and how they might affect her decisions throughout the rest of the hand.

This is an extremely challenging problem, especially in Texas hold 'em, the most commonly played variant of the game. In hold 'em, the cards are kept facedown and nothing is certain about an opponent's hand until all the bets are in and the pot is pushed someone's way. Each player begins the hand with one of 1,326 possible hand combinations. Everything from a majestic pair of aces to the lowly seven-deuce are among them, and nothing but the player's love of money prevents her from playing the one hand as though it is the other one.

However, players can use their hand-reading skills to develop what amounts to a forecast of their opponent's likely range of hands. Poker players often talk about "putting opponents on a hand," and sometimes they proceed as though they know exactly what two cards the opponent holds. But the best players always entertain numerous hypotheses, which they weigh and balance against the opponent's actions. A good poker forecast is probabilistic. It should become more precise as the hand is played out, but it is usually not possible to predict exactly which of the 1,326 possible hands your opponent holds until the cards are revealed, particularly if your opponent is skilled and is deliberately behaving unpredictably.4

Indeed, information is so hard to come by in Texas hold 'em that players begin to make estimates about their opponents' range of hands even before any of the cards are dealt. In online games, this is often done through data mining: you'll have statistics on how loose or tight, how passive or aggressive, each opponent's play has been in previous games. In brick-and-mortar casinos, it is done through players' past histories with one another—or, failing that, through what amounts to ethnic profiling. Players from Sweden, Lebanon, and China, for instance, have a reputation for being more aggressive than those from France, England, or India. Younger players are presumed to be looser and more aggressive than older ones. Men are assumed to be more likely to bluff than women. These stereotypes, like any others, are not always true: at the hold 'em games I used to play in at the Bellagio in Las Vegas, the best players were very often women, and they were good in part because they were much more aggressive than their opponents assumed. But poker players don't have the time for political correctness. Even if the stereotype that women play more conservatively than men is false 45 percent of the time, the fact that it might be true 55 percent of the time gives them something to work with.

Once the game begins, these crude assumptions are supplanted by more reliable information: how the player has played previous hands at the table that day and how she is playing this one. The process is fundamentally and profoundly Bayesian, with each player updating their probabilistic assessments after each bet, check, and call. If you doubt the practical uses of Bayes's theorem, you have probably never witnessed a poker game.

* * *

A QUICK PRIMER ON TEXAS HOLD 'EM

It is easy to access the rules of Texas hold 'em online or in other books, but I'll point out a few basics for the uninitiated, to introduce you to the terminology used in the next few pages. These rules are simple compared with those of other card games. But much as is the case in chess, the relatively simple rules create a game with exceptional tactical and strategic depth.

The game begins when two personal cards (called down cards or hole cards) are dealt facedown to each player. A round of betting ensues at this stage. These personal cards then start to be combined with a series of community cards (also called the board) that are dealt faceup and shared between all players at the table. Each player seeks to formulate his best five-card poker hand between his down cards and the community cards. The community cards are revealed sequentially, with a round of betting separating each stage. The first three cards are revealed simultaneously and are called the flop (one of the many pieces of colorful vocabulary that poker players use). The fourth community card, called the turn, is revealed next. Finally the last card, the river, is exposed, and a final round of betting takes place. More often than not, all players but one will have folded by this point. If not, the players' down cards are finally flipped faceup and the best hand at the showdown wins the pot.

The ranking of poker hands goes thusly:

A straight flush (K Q J T 9)

Four-of-a-kind (7 7 7 7 2)

A full house (Q Q Q 5 5)

A flush (A J 9 4 2)

A straight (8 7 6 5 4)

Three-of-a-kind or a set (9 9 9 A 2)

Two pair (A A 3 3 7)

One pair (K K 9 8 6)

An unpaired high card (A Q 8 5 3).

Otherwise-tied hands are awarded to the player with the highest-ranking cards: for instance, an ace-high flush beats a 9-high flush. When pairs are of the same rank, the tie is broken by the third-highest card (or kicker). For example, the hand (8 8 K 7 5) beats the hand (8 8 Q 7 6) since the kicker is a king rather than a queen.

* * *

A Not So Simple Poker Hand

Say that you're playing in a $5/$10 no-limit hold 'em game at the Bellagio.* The first few players fold and you find yourself looking at some decent cards, a pair of eights (8 8). So you raise to $25 and are called by just one player, a sixtysomething man whom we will call the Lawyer.

The Lawyer is a nice guy—a little chatty in between hands, but quiet enough once the cards are dealt. We have learned that he has done fairly well for himself as a partner at an intellectual property law firm on the East Coast. You might imagine him wearing a polo shirt and periodically texting his friend to check on tee times. He had one beer when the cocktail waitress first came around before switching to coffee. He is not likely to be intimidated by these medium-size stakes and isn't acting like it.

When the Lawyer first sat down at the table with us, we had been torn between two hypotheses about him: first, that he might be playing to show off a little, and therefore might make a few wild moves and bluffs, and second that he might take a more legalistic and by-the-book approach. Our subsequent observation has confirmed that the latter profile is more likely to be correct: he seems to be a mediocre player, avoiding catastrophic errors but without applying much finesse. The Lawyer is by no means the worst player at the table, but he's probably not a long-term winner. Still, we haven't played against him for all that long and aren't completely sure about any of this.

So what do we know about the Lawyer's hand so far? The only thing we know absolutely without doubt is that he cannot hold any hands that contain the 8 or the 8, since those cards are in our hand. Unfortunately, that reduces the number of starting hand combinations only to 1,225 from 1,326, each of which was equally likely to be dealt when the hand began.

However, the Lawyer has given us some other information: he has chosen to call our bet. That means his hand is likely to be at least decent: most players, including the Lawyer, fold a clear majority of their hands against a raise before the flop. It also means he is unlikely to have an extremely strong hand like a pair of aces, since he called not just in lieu of folding but also in lieu of reraising, although this possibility cannot be discounted completely.*

We can start to form a probabilistic, Bayesian assessment of what hands the Lawyer might hold. From past experience with players like this, we know that his range of hands is likely to include pairs like 9 9. It might include some hands with aces, especially if both cards are of the same suit (like the hand A 5), meaning that it can more easily make flushes. Likewise, it might include what are called "suited connectors"—hands like 6 5 that have consecutive cards of the same suit and which can make both flushes and straights. Finally, he might call with hands that contain two face cards like the king of clubs and the jack of diamonds (K J).

If we had enough time, we could enumerate the Lawyer's hand range completely, with all 1,326 possibilities assigned a probability from 0 percent to 100 percent given his action so far, as in figure 10-2a. This is how a computer, which can sort through the possibilities very quickly, might think about his play.

FIGURE 10-2A: PROBABALISTIC REPRESENTATION OF OPPONENT'S HAND RANGE

A matrix like this is far too complicated to keep track of under real-world conditions, however, so what players seek to do instead is break their opponent's range into groups of hands that might function in about the same ways as one another (figure 10-2b). In this case, the group of hands that would most concern us is if the Lawyer began the hand with a pair higher than our eights.

Fortunately, the probability of this is low: a player is blessed with a pair only rarely in hold 'em. Indeed, when the cards are first dealt in hold 'em, the chance of starting out with a pair of nines or better is only about 3 percent. However, we need to update our estimate of this probability because of his call: the Lawyer is throwing out many of his worthless hands, increasing the chance that he has a strong one. According to our estimate, the chance he holds a pair higher than our eights has already risen to about 6 percent given how he has played the hand thus far.

The other 94 percent of the time, the Lawyer starts out with a worse hand than ours. The problem is that there are five cards still left to come, and while it is relatively hard for them to improve our pair (we would need to catch one of the two remaining eights in the deck), he could more easily make a higher pair, straight, or flush.

The Lawyer takes a swig of coffee as the dealer arranges the flop cards on the center of the table. They consist of two clubs—a king and a three—along with the nine of hearts.

K 9 3

These cards have not improved our hand. Our hope is that they have not improved the Lawyer's either, in which case our pair of eights will still be best. So we make a relatively modest bet of $35 into the $65 pot. The Lawyer pauses for a moment and calls.

This call is not great news for us, as we can see by further refining our estimate of his hand range. The key, following Bayes's theorem, is to think in terms of conditional probabilities. For instance, if the Lawyer started with a hand like K J, now giving him a pair of kings, how likely is it that he'd call us again? (He'd almost certainly at least call having made top pair, but might he have raised instead?) What about if he began the hand with a smaller pair than ours, like 7 7—how likely is it that he'd call rather than fold? If we had the luxury of time, we could go through all 1,326 hand combinations individually and revise our estimates accordingly (figure 10-3).

Our actual estimates at the table will not be quite as precise as this. Still, we can come to some broad probabilistic characterizations of his hand range given his call. About 30 percent of the time, the Lawyer's hand connected strongly with the flop and he has a pair of kings or better—a good hand that is unlikely to fold without a lot of pressure. There is also about a 20 percent chance that he has a pair worse than kings but better than our eights. These hands beat ours as well, but the Lawyer might be more likely to fold them later if we keep betting aggressively.

Meanwhile, there is about a 25 percent chance that the Lawyer has a draw to a straight or a flush, which is behind us for now but has many ways to improve. Finally, there is a 25 percent chance that he has a worse pair than ours or has almost nothing and is continuing in the hand solely in the hope of bluffing us later; these are the most favorable cases.

You can see how complicated poker decisions become. Some of these possibilities imply that we should continue to bet our hand as aggressively as possible. Others imply we should take a more cautious approach, while still others would mean we should be preparing to fold.

Just as we are contemplating this thorny decision, the dealer puts out the ideal card and makes our life easy. It is one of the two remaining eights in the deck, the 8, giving us three of a kind. The only way we are beaten is if the Lawyer started out with a pair of nines or a pair of kings and made a higher set on the flop, and has played them passively in order to trap us. (Poker players term this "slowplaying.") Still, we should not be thinking so defensively. In sorting through his possible hands, we should have the better one perhaps 98 percent of the time. So this time we make a relatively large bet: $100 into the $135 pot.

The Lawyer calls us once more. Because he is likely to have folded out his weaker pairs and weaker draws, we can now narrow his hand range even further. In fact, of the 1,326 hands that he might have started out with, not more than about seventy-five are all that likely at this stage. Often, he will have a pair of kings, a hand that we were previously worried about but now beat. To the extent we are concerned, it's mostly about another club coming, which could still give him a flush.

Instead, the final card is the harmless-looking five of spades, which does not complete the flush:

K 9 3 8 5

We bet $250 into the $335 pot, hoping that the Lawyer will call us with a worse hand. Suddenly, however, he springs to life. "I'm all-in," he says to the dealer in a voice just barely louder than a whisper. He neatly pushes his remaining chips—about $1,200—into the pot.

What the hell just happened? We now need to put our Bayesian thinking skills to the test. If our forecast of his hand range is off, we could easily make a $1,200 mistake.

We look at the board and realize there is one exact hand, one from among the 1,326 random combinations, that seems most consistent with his play. The specific hand is a seven and a six of clubs (7 6). It is a suited connector, so we think he would have called with it before the flop. On the flop, this hand made a flush draw with four clubs, and we didn't bet enough to push him off it. On the turn, the hand missed its flush but nevertheless became stronger: the 8 that made our hand three-of a-kind gave the Lawyer the possibility of making a straight with any ten or five. If that was indeed his hand, the 5 on the river made his straight, which beats our three-of-a-kind and would explain why he is now betting so boldly.

So should we fold? Even if you have never played poker, it is worth pausing for a moment to consider what you'd do.

The answer is that you should very probably not fold. In fact, against many players, you should be pleased that more money is going into the pot.

The solution comes from Bayes's theorem. It's true that the all-in bet is an extremely powerful move—it conveys much more information than his calls before. But before the Lawyer went all-in, we would have assigned a very low probability—perhaps 1 percent—to his holding exactly the seven and six of clubs, just one possible hand out of the myriad combinations. Unless we are extremely confident that the 7 6 is about the only hand that he'd make this play with, folding could be a huge mistake. Our hand only needs to be good about 35 percent of the time to make the call correct mathematically.

In fact, there are some alternate possibilities for his hand. The Lawyer could have a set of threes or possibly a set of fives, which still lose to our set of eights. He could plausibly have made two-pair with a hand like K 5. Some players would play a pair of aces in this way. In his Bayesian model of our hand range, the Lawyer might reasonably figure that hands like this are better than ours even though they are not—good enough to go all-in—and he might be willing to get a lot of money in with them.

There are also a couple of hands apart from the straight which would beat us. If the Lawyer was slowplaying a set of nines the whole way, or a set of kings, he'll now get our money. This is counterbalanced by the possibility of a complete bluff. If the Lawyer had a flush draw that missed, the only way he can win the pot is by bluffing at it.

As Arthur Conan Doyle once said, "Once you eliminate the impossible, whatever remains, no matter how improbable, must be the truth." This is sound logic, but we have a lot of trouble distinguishing the impossible from the highly improbable and sometimes get in trouble when we try to make too fine a distinction. All of the opponent's hands are in some way highly improbable at this stage; this has been an unusual hand. It is a matter of weighing improbabilities against other improbabilities, and the calculation weighs against the hypothesis that he has 7 6 exactly. If we ran the possibilities through a computer, it might think there's something like a two-thirds probability that we still have the best hand (figure 10-5).

In practice, poker players might differ a lot in how they assess the probabilities for his hand. Skilled poker players are probably better than 99.9 percent of the population at making reasonably good probabilistic judgments under uncertainty. In fact, I don't know of a single game or intellectual exercise that better refines these skills. However, when I posted this hand on Two Plus Two, an online forum for professional poker players, assessments ranged from that we were nearly certain to have the best hand to that we were nearly certain to be beat.6 My view is that both these assessments are overconfident. We should not proceed as though we don't know anything about the opponent's hand, but in general our predictive errors come in thinking that there is more certainty in the world than there really is. In this case, seeking to put the opponent on an exact hand would imply a fold, while a fuller assessment of the probabilities—coupled with the favorable adds from the pot—means that we should call instead.

Schrödinger's Poker Hand

If this hand came up in a televised tournament on ESPN that showed us each player's hole cards, the analysis from the commentators might be different. They might assert that the fold was obvious if they knew that the opponent held 7 6. In a parallel universe where the hand played out exactly the same way but the opponent had 3 3 instead, they'd tell us how thrilled we should be to get more money into the pot.

In a televised game in 2009, two world-class players, Tom Dwan and Phil Ivey, played a hand in which the pot size eventually reached more than a million dollars.7 In the hand, Ivey caught a miracle card on the turn to make him a 5-high straight. Unfortunately, the same card also gave Dwan a 7-high straight,* the only possible better hand. "If anybody can get away from this, it's Phil Ivey," one of the announcers said, implying that it would be a sign of superior poker talent if he folded. In fact, throwing away the hand would have been a terrible play. Given what Ivey knew at the time, and how aggressively he and Dwan play, he should have expected to have the best hand at least 90 percent of the time. If Ivey hadn't lost all his chips on the hand, he would have been playing badly.

While television coverage has been a great boon to poker, it leaves many casual players with misleading impressions about the right way to play it, focusing too much on the results and not enough on the correct decision-making process.

"It's not very common that you can narrow someone's holdings down to one hand," Dwan told me. "Definitely much less common than most pros and TV shows would have you believe."

Making Ourselves Unpredictable

Dwan was once better known by his online screen name "durrrr," which he selected because he figured it would put the other players on tilt if they lost to him. Dwan deposited $50 at the online site Full Tilt Poker at age seventeen, later dropping out of Boston College to play poker full-time.8 He rose through the ranks to become the apex predator in the online-poker food chain.9 Millions of dollars flowed through him each month; sometimes he lost it but more often he won.10

By the time I spoke with him in 2012, Dwan was widely considered among the best no-limit hold 'em players in the world.11 He has a reputation for being creative, aggressive, and most of all, fearless. In 2009, he challenged any player in the world, except for his close friend Phil Galfond, to play him head-to-head at very favorable odds. Three strong players eventually took him on and Dwan won two of these matches.

Yet for all his apparent bravado—Dwan is fairly low-key in person—12 his approach to thinking about poker and the world in general is highly probabilistic. He profits because his opponents are too sure of themselves. "It's important in most areas of life to come up with a probability instead of a yes or no," he told me. "It's a huge flaw that people make in a lot of areas that they analyze, whether they're trying to form a fiscal union, pay for groceries, or hoping that they don't get fired."

Dwan seeks to exploit these tendencies by deliberately obfuscating his play. If the most important technical skill in poker is learning how to forecast your opponent's hand range, the next-most-important one is making your own play unpredictable. "The better people are, the less certain you're going to be about what they have or what they're doing or what their range is," Dwan says. "And they'll be more apt to manipulate that to take advantage of your judgments."

While I'll never be the player that Dwan is, I took advantage of this in my own way during my days as a poker professional. In the soft online games of the mid-2000s, I could make money by playing conservative, tight poker, but I soon discovered that a more aggressive style could make me even more. The idea was to find the blind spots that my opponents might have in estimating my hand range.

When you raise before the flop, for instance, the opponent will typically put you on big cards like those containing aces, kings, and queens. You will have those hands sometimes, of course. But I would also raise with hands like the ones we were worried about the Lawyer having, hands with small cards like 7 6. What I found is that when big cards came on the board, like an ace or king, the opponent would often give me credit for catching those cards and fold. If smaller cards came instead, meanwhile, I'd often have made a pair or some kind of good draw. Sometimes, I'd even make an unlikely-seeming hand like a straight with these cards, which could send my opponents into tilt. One interesting thing about poker is that the very best players and the very worst ones both play quite randomly, although for different reasons.* Thus, you can sometimes fool opponents into thinking you are a weak player even if you are likely to take their money.

Eventually, some of my opponents caught on to my more aggressive style, but this wasn't all bad. It meant that they were more likely to call down when I did have a "predictable" hand like a pair of kings, making these hands more profitable for me.

In fact, bluffing and aggressive play is not just a luxury in poker but a necessity—otherwise your play is just too predictable. Poker games have become extremely aggressive since I stopped playing regularly five years ago, and game theory13 as well as computer simulations14 strongly suggest this is the optimal approach. Blitzing your opponent with a deluge of possibilities is the best way to complicate his probability calculations.

Sometimes you may also be able to identify situations where your opponents' intuitive estimates of the probabilities are too crude. Whenever a poker player thinks that his opponent might never play a certain hand in a certain way—never bluff in a certain situation, for instance—that's when you have the opportunity to exploit him by confusing his sense of the improbable and the impossible.

"There were a bunch of things I did that I knew were extremely suboptimal but made me a really large amount of money for a long portion of time," Dwan told me. "It's only in the last few years people finally started realizing and getting better."

Dwan's main game, no-limit hold 'em, is especially fertile for such a strategy because you potentially control, through the size of your bets, the amount of money at stake on each decision. Some choices that Dwan makes involve no more than $100, while others might be for stakes of $10,000, $100,000 or even more. Make a few extra decisions right in million-dollar pots, and the collective sum of what you do for $100 at a time hardly matters at all.

I mostly played limit hold 'em instead, where the betting increment is fixed on each round. (Until very recently, this was the most popular game outside of tournaments; ten years ago, there were often no more than two or three no-limit games running anywhere in the United States.15) Limit poker offers fewer opportunities for creativity. Still, until practice caught up with theory, I had a couple of very successful years by exploiting an aggressive approach. In both 2004 and 2005, I made an income from poker in the six figures, with my cumulative profits from the game peaking at about $400,000 overall.

The Prediction Learning Curve

The difference between Dwan and me is that, while he is willing to take on almost literally any other player for any stakes at any time, I was merely in the upper middle class of poker players and needed to be in a game with some bad ones to be a favorite to make money. Fortunately, there were plenty of these bad players—what poker players call fish—during the poker boom years.

There is a learning curve that applies to poker and to most other tasks that involve some type of prediction. The key thing about a learning curve is that it really is a curve: the progress we make at performing the task is not linear. Instead, it usually looks something like this (figure 10-6)—what I call the Pareto Principle of Prediction.

FIGURE 10-6: THE PARETO PRINCIPLE OF PREDICTION

What you see is a graph that consists of effort on one axis and accuracy on the other. You could label the axes differently—for instance, experience on the one hand and skill on the other. But the same general idea holds. By effort or experience I mean the amount of money, time, or critical thinking that you are willing to devote toward a predictive problem. By accuracy or skill I mean how reliable the predictions will prove to be in the real world.

The name for the curve comes from the well-known business maxim called the Pareto principle or 80-20 rule (as in: 80 percent of your profits come from 20 percent of your customers16). As I apply it here, it posits that getting a few basic things right can go a long way. In poker, for instance, simply learning to fold your worst hands, bet your best ones, and make some effort to consider what your opponent holds will substantially mitigate your losses. If you are willing to do this, then perhaps 80 percent of the time you will be making the same decision as one of the best poker players like Dwan—even if you have spent only 20 percent as much time studying the game.

This relationship also holds in many other disciplines in which prediction is vital. The first 20 percent often begins with having the right data, the right technology, and the right incentives. You need to have some information—more of it rather than less, ideally—and you need to make sure that it is quality-controlled. You need to have some familiarity with the tools of your trade—having top-shelf technology is nice, but it's more important that you know how to use what you have. You need to care about accuracy—about getting at the objective truth—rather than about making the most pleasing or convenient prediction, or the one that might get you on television.

Then you might progress to a few intermediate steps, developing some rules of thumb (heuristics) that are grounded in experience and common sense and some systematic process to make a forecast rather than doing so on an ad hoc basis.

These things aren't exactly easy—many people get them wrong. But they aren't hard either, and by doing them you may be able to make predictions 80 percent as reliable as those of the world's foremost expert.

Sometimes, however, it is not so much how good your predictions are in an absolute sense that matters but how good they are relative to the competition. In poker, you can make 95 percent of your decisions correctly and still lose your shirt at a table full of players who are making the right move 99 percent of the time. Likewise, beating the stock market requires outpredicting teams of investors in fancy suits with MBAs from Ivy League schools who are paid seven-figure salaries and who have state-of-the-art computer systems at their disposal.

In cases like these, it can require a lot of extra effort to beat the competition. You will find that you soon encounter diminishing returns. The extra experience that you gain, the further wrinkles that you add to your strategy, and the additional variables that you put into your forecasting model—these will only make a marginal difference. Meanwhile, the helpful rules of thumb that you developed—now you will need to learn the exceptions to them.

However, when a field is highly competitive, it is only through this painstaking effort around the margin that you can make any money. There is a "water level" established by the competition and your profit will be like the tip of an iceberg: a small sliver of competitive advantage floating just above the surface, but concealing a vast bulwark of effort that went in to support it.

I've tried to avoid these sorts of areas. Instead, I've been fortunate enough to take advantage of fields where the water level was set pretty low, and getting the basics right counted for a lot. Baseball, in the pre-Moneyball era, used to be one of these. Billy Beane got an awful lot of mileage by recognizing a few simple things, like the fact that on-base percentage is a better measure of a player's offensive performance than his batting average. Nowadays pretty much everyone realizes that. In politics, I'd expect that I'd have a small edge at best if there were a dozen clones of FiveThirtyEight. But often I'm effectively "competing" against political pundits, like those on The McLaughlin Group, who aren't really even trying to make accurate predictions. Poker was also this way in the mid-2000s. The steady influx of new and inexperienced players who thought they had learned how to play the game by watching TV kept the water level low.

FIGURE 10-7: THE PARETO PRINCIPLE OF PREDICTION IN COMPETITIVE ENVIRONMENTS

If you have strong analytical skills that might be applicable in a number of disciplines, it is very much worth considering the strength of the competition. It is often possible to make a profit by being pretty good at prediction in fields where the competition succumbs to poor incentives, bad habits, or blind adherence to tradition—or because you have better data or technology than they do. It is much harder to be very good in fields where everyone else is getting the basics right—and you may be fooling yourself if you think you have much of an edge.

In general, society does need to make the extra effort at prediction, even though it may entail a lot of hard work with little immediate reward—or we need to be more aware that the approximations we make come with trade-offs. But if you're approaching prediction as more of a business proposition, you're usually better off finding someplace where you can be the big fish in a small pond.

The Economics of the Poker Bubble

The Pareto Principle of Prediction implies that the worst forecasters—those who aren't getting even the first 20 percent right—are much worse than the best forecasters are good. Put another way, average forecasters are closer to the top than to the bottom of the pool. I'm sure that I'd lose a ton of money if I played poker against Dwan. But I'd gladly play him if, as part of the deal, I were also guaranteed a match for the same stakes against some random person I picked off the street, against whom I'd expect to make back my losses and then some.

We can test this hypothesis empirically by examining the statistical records of poker players. I evaluated the data from an online poker site, which consisted of a random sampling of no-limit hold 'em players over a period in 2008 and 2009. These statistics told me how much money the players won or lost per hand, relative to the stakes they were playing.17

Because near-term wins and losses are very much subject to luck, I applied a statistical procedure18 to estimate what the players' true long-term profitability was. I then ordered the players by their skill level and broke them down into ten equal-size quadrants. The top quadrant—consisting of the top 10 percent of the player pool*—corresponds to the best player at a typical ten-person table.19 The bottom 10 percent, meanwhile, are the biggest fish.

Figure 10-8a represents my estimate of how skilled the players in each quadrant really are, measured as money won or lost per one hundred hands in a no-limit hold 'em game with $5/$10 blinds. The figures include both money won and lost to the other players and that lost to the casino, which either takes a small percentage of each pot (known as the rake) or charges an hourly fee for dealing the game.20

FIGURE 10-8A: ESTIMATED MONEY WON OR LOST PER 100 HANDS IN A $5/$10 NO-LIMIT HOLD 'EM GAME

I estimate that the very best player at the table in one of these games is averaging a profit of about $110 per one hundred hands played over the long run. That's a nice wage in an online casino, where hands are dealt very quickly and you could get almost that many hands during an hour or two.* It's less attractive in a traditional casino, where it might take four hours to play the same number of hands, and translates to wage of $25 or $30 per hour.

The key insight, however, is that the worst players at the table are losing money much faster than even the best ones are making it. For instance, I estimate that the worst player in the game—the biggest fish—was losing at a rate of more than $400 per one hundred hands. This player is so poor that he would literally be better off folding every hand, which would cost him only $150 per one hundred hands instead.

Here you see the statistical echo of the 80/20 rule: there's a much larger difference between the very worst players and the average ones than between the average ones and the best. The better players are doing just a few things differently from one another, while those at the lower end of the curve are getting even the basics wrong, diverging wildly from optimal strategy.

In the classic poker movie Rounders,21 Matt Damon's character advises us that if you can't spot the sucker in your first half hour at the table, then you must be the sucker. I don't think this is quite true: it may be that the game doesn't have any suckers. It is emphatically the case, however, that if you can't spot one or two bad players in the game, you probably shouldn't be playing in it. In poker, the line between success and failure is very thin and the presence of a single fish can make the difference.

In the game I just described, the one fish was feeding a lot of hungry mouths. His presence was worth about $40 per 100 hands to the other players. That subsidy was enough that about half of them were making money, even after the house's cut. Poker abides by a "trickle up" theory of wealth: the bottom 10 percent of players are losing money quickly enough to support a relatively large middle class of break-even players.

But what happens when the fish—the sucker—busts out, as someone losing money at this rate is bound to do? Several of the marginally winning players turn into marginally losing ones (figure 10-8b). In fact, we now estimate that only the very best player at the table is still making money over the long run, and then less than he did before.

FIGURE 10-8B: ESTIMATED MONEY WON OR LOST PER 100 HANDS IN A $5/$10 NO-LIMIT HOLD 'EM GAME AFTER FISH BUSTS OUT

What's more, the subtraction of the fish from the table can have a cascading effect on the other players. The one who was formerly the next-to-worst player is now the sucker, and will be losing money at an even faster rate than before. So he may bust out too, in turn making the remaining players' task yet more challenging. The entire equilibrium of the poker ecosystem can be thrown out of balance.

How, in fact, do poker games sustain themselves if the worst players are a constant threat to go broke? Sometimes there are fishy players with bottomless pockets: PokerKingBlog.com has alleged that Guy Laliberté, the CEO of Cirque du Soleil, lost as much as $17 million in online poker games in 2008,22 where he sought to compete in the toughest high-stakes games against opponents like Dwan. Whatever the number, Laliberté is a billionaire who was playing the game for the intellectual challenge and to him this was almost nothing, the equivalent of the average American losing a few hundred bucks at blackjack.

Much more commonly, the answer is that there is not just one fishy player who loses money in perpetuity but a steady stream of them who take their turn in the barrel, losing a few hundred or a few thousand dollars and then quitting. At a brick-and-mortar casino like the Bellagio, these players might wander in from the craps table, or from one of its nightclubs, or after going on a winning streak in a tournament or a smaller-stakes game.

In the online poker environment of my experience, the fish population was more irregular and depended on the regulatory environment in different countries, the amount of advertising that the poker sites were doing, and perhaps even the time of year.23 During the poker boom years, however, the player pool was expanding so rapidly that there was always a wealth of fishes.

That was about to change.

The Poker Bubble Bursts

In October 2006 the outgoing Republican Congress, hoping to make headway with "values voters" before the midterm elections24 but stymied on more pressing issues, passed a somewhat ambiguous law known as the Unlawful Internet Gambling Enforcement Act (UIGEA). The UIGEA, strictly speaking, didn't make online poker illegal. What it did, rather, was to target the third-party companies that facilitated the movement of money into and out of the poker sites. Sure, you could play poker, the law said, in effect—but you couldn't have any chips. Meanwhile, the Department of Justice began targeting companies that were offering online gambling to Americans. David Carruthers, the CEO of an offshore site known as BetOnSports PLC, was arrested on a layover in Dallas while changing planes on a trip from the United Kingdom to Costa Rica. Other prosecutions soon followed.

All this scared the hell out of many online poker players—as well as many of the proprietors of the games. Party Poker, then the largest online poker site, locked Americans out of the games two weeks after the UIGEA passed; its stock crashed by 65 percent in twenty-four hours.25 Other companies stayed in business, developing workarounds to the new law, but it had become harder to get your money in and riskier to take it back out.

I had made most of my money from Party Poker, which advertised aggressively and was known for having the fishiest players. During the two-week grace period after Party Poker made its announcement but kept the games open to Americans, the games there were fishier than ever, sometimes taking on a Lord of the Flies mentality. I had some of my winningest poker days during this period.

Once Party Poker shut Americans out, however, and I shifted my play to tougher sites like PokerStars, I found that I wasn't winning anymore. In fact, I was losing—a lot: about $75,000 during the last few months of 2006, most of it in one horrible evening. I played through the first several months of 2007 and continued to lose—another $60,000 or so. At that point, no longer confident that I could beat the games, I cashed out the rest of my money and quit.

My conclusion at the time was that the composition of the player pool had changed dramatically. Many of the professional players, reliant on the game for income, had soldiered on and kept playing, but most of the amateurs withdrew their funds or went broke. The fragile ecology of the poker economy was turned upside down—without those weak players to prop the game up, the water level had risen, and some of the sharks turned into suckers.26

Meanwhile, even before the new law passed, my play had begun to deteriorate, or at least cease to improve. I had hit a wall, playing uncreative and uninspired poker. When I did play, I combined the most dangerous trait of the professional player—the sense that I was entitled to win money—with the bad habits of the amateur, playing late into the evening, sometimes after having been out with friends.

In retrospect, things worked out pretty fortunately for me. The extra time I had on my hands—and my increased interest in the political process following the passage of the UIGEA—eventually led to the development of FiveThirtyEight. And while it wasn't fun to lose a third of my winnings, it was better than losing all of them. Some players who continued in the game were not so lucky. In 2011, the "Black Friday" indictments filed by the Department of Justice shut down many of the online poker sites for good,27 some of which proved to be insolvent and did not let players cash out their bankrolls.

I've sometimes wondered what would have happened if I'd played on. Poker is so volatile that it's possible for a theoretically winning player to have a losing streak that persists for months, or even for a full year. The flip side of this is that it's possible for a losing player to go on a long winning streak before he realizes that he isn't much good.

Luck Versus Skill in Poker

Luck and skill are often portrayed as polar opposites. But the relationship is a little more complicated than that.

Few of us would doubt, for instance, that major-league baseball players are highly skilled professionals. It just isn't easy to hit a baseball thrown at ninety-eight miles per hour with a piece of ash, and some human beings are a wee bit more refined in their talent for this than others. But there is also a lot of luck in baseball—you can hit the ball as hard as hell and still line out to the second baseman. It takes a lot of time for these skill differences to become obvious; even a couple of months' worth of data is not really enough. In figure 10-9, I've plotted the batting averages achieved by American League players in April 2011 on one axis, and the batting averages for the same players in May 2011 on the other one.28 There seems to be no correlation between the two. (A player named Brendan Ryan, for instance, hit .184 in April but .384 in May.) And yet, we know from looking at statistics over the longer term—what baseball players do over whole seasons or over the course of their careers—that hitting ability differs substantially from player to player.29

FIGURE 10-9: BATTING AVERAGE FOR AMERICAN LEAGUE PLAYERS, APRIL AND MAY 2011

Poker is very much like baseball in this respect. It involves tremendous luck and tremendous skill. The opposite of poker would be something like tic-tac-toe (figure 10-10). There is no element of luck in the game, but there isn't much skill either. A precocious second grader could do just as well as Bill Gates at it.

FIGURE 10-10: SKILL VERSUS LUCK MATRIX

Low luck

High luck

Low skill

Tic-Tac-Toe

Roulette

High skill

Chess

Poker

Still, it can take a long time for poker players to figure out how good they really are. The luck component is especially strong in limit hold 'em, the game that I specialized in. Correct strategy in this game implies that you will scrap and fight for many pots, and staying in so many hands to the end means that a lot depends on the luck of the deal. A very good limit hold 'em player, in a game where the betting increments are $100 and $200, might make $200 for every one hundred hands played. However, the volatility in his results—as measured by a statistic called standard deviation—is likely to be about sixteen times that, or about $3,200 for every one hundred hands.30

What this means is that even after literally tens of thousands of hands are played, a good player might wind up behind or a bad one might wind up ahead. In figure 10-11, I've modeled the potential profits and losses for a player with the statistics I just described. The bands in the chart show the plausible range of wins and losses for the player, enough to cover 95 percent of all possible cases. After he plays 60,000 hands—about as many as he'd get in if he played forty hours a week in a casino every week for a full year—the player could plausibly have made $275,000 or have lost $35,000. In essence, this player could go to work every day for a year and still lose money. This is why it is sometimes said that poker is a hard way to make an easy living.

Of course, if this player really did have some way to know that he was a long-term winner, he'd have reason to persevere through his losses. In reality, there's no sure way for him to know that. The proper way for the player to estimate his odds of being a winner, instead, is to apply Bayesian statistics,31 where he revises his belief about how good he really is, on the basis of both his results and his prior expectations.

If the player is being honest with himself, he should take quite a skeptical attitude toward his own success, even if he is winning at first. The player's prior belief should be informed by the fact that the average poker player by definition loses money, since the house takes some money out of the game in the form of the rake while the rest is passed around between the players.32 The Bayesian method described in the book The Mathematics of Poker, for instance, would suggest that a player who had made $30,000 in his first 10,000 hands at a $100/$200 limit hold 'em game was nevertheless more likely than not to be a long-term loser.

FIGURE 10-11: PLAUSIBLE WIN RATES FOR SKILLED LIMIT HOLD 'EM PLAYER, $100/$200 GAME

Our Poker Delusions

Most players, as you might gather, are not quite this honest with themselves. I certainly wasn't when I was living in the poker bubble. Instead, they start out with the assumption that they are winning players—until they have the truth beaten into them.

"Poker is all about people who think they're favorites when they're not," Dwan told me. "People can have some pretty deluded views on poker."

Another player, Darse Billings, who developed a computer program that competed successfully33 against some of the world's best limit hold 'em players,* put it even more bluntly.

"There is no other game that I know of where humans are so smug, and think that they just play like wizards, and then play so badly," he told me. "Basically it's because they don't know anything, and they think they must be God-like, and the truth is that they aren't. If computer programs feed on human hubris, then in poker they will eat like kings."

This quality, of course, is not unique to poker. As we will see in chapter 11, much of the same critique can be applied to traders on Wall Street, who often think they can beat market benchmarks like the S&P 500 when they usually cannot. More broadly, overconfidence is a huge problem in any field in which prediction is involved.

Poker is not a game like roulette, where results are determined purely by luck and nobody would make money if they took an infinite number of spins on the wheel. Nor are poker players very much like roulette players; they are probably much more like investors, in fact. According to one study of online poker players, 52 percent have at least a bachelor's degree34—about twice the rate in the U.S. population as a whole, and four times the rate among those who purchase lottery tickets.35 Most poker players are smart enough to know that some players really do make money over the long term—and this is what can get them in trouble.

Why We Tilt

Tommy Angelo pursued a poker dream before it was cool. In 1990, at the age of thirty-two, he quit his job as a drummer and pianist for a country rock band to play poker full-time.36

"I was hooked on it," Angelo told me when I spoke with him in 2012. "I loved the idea of being a professional poker player when I first heard the words. The whole idea was so glorious, of not having a job. It's like you're beating society, making all your money on your wits alone. I couldn't imagine anything more appealing."

But Angelo, like most poker players, had his ups and downs—not just in his results but also in the quality of his play. When he was playing his best, he was very good. But he wasn't always playing his best—very often, he was on tilt.

"I was a great tilter," Angelo reflected in his book, Elements of Poker, referring to a state of overaggressive play brought on by a loss of perspective.37 "I knew all the different kinds. I could do steaming tilt, simmering tilt, too loose tilt, too tight tilt, too aggressive tilt, too passive tilt, playing too high tilt, playing too long tilt, playing too tired tilt, entitlement tilt, annoyed tilt, injustice tilt, frustration tilt, sloppy tilt, revenge tilt, underfunded tilt, overfunded tilt, shame tilt, distracted tilt, scared tilt, envy tilt, this-is-the-worst-pizza-I've-ever-had tilt, I-just-got-showed-a-bluff tilt, and of course, the classics: I-gotta-get-even tilt, and I-only-have-so-much-time-to-lose-this-money tilt, also known as demolition tilt."

What Angelo eventually came to realize is that, for all his skill, his periodic bouts of tilt prevented him from doing much more than scrape by. As we have seen, it is considerably easier to lose money at poker when you play badly than to make money when you are playing well. Meanwhile, the edge even for a long-term winning player is quite small. It is quite plausible for someone who plays at a world-class level 90 percent of the time to lose money from the game overall if he tilts the other 10 percent of the time.

Angelo realized the full extent of his tilt problems once he was in his forties, after he had started writing about the game and coaching other players. He is naturally a perceptive person, and what started out as strategy sessions often turned into therapy sessions.

"I was coaching so many different types of people with so many different types of problems related to poker," he told me. "The problems were very easy to see in another person. I'd say here's a guy that's just as smart as me. And I know for a fact he's delusional about his skill. And I know that if everyone else is delusional, I have to be too."

Every poker player tilts at least to some degree, Angelo thinks. "If someone came up to me and said ‘I don't tilt,' my mind registers, ‘There's another delusional statement from a delusional human.' It happens all the time."

I had my own types of tilt when I played poker actively. I wasn't one of those throw-stuff-around-the-room type of guys. Nor would I turn into a crazy maniac when I tilted, trying to play every hand (although my "A-game" was wild enough). Sometimes I'd even tighten up my game a bit. However, I'd play mechanically, unthinkingly, for long stretches of time and often late into the night—I'd just call a lot and hope that the pot got pushed my way. I had given up, deep down, on really trying to beat the game.

I realize now (I'm not sure that I did when I was playing) what my tilt triggers were. The biggest one was a sense of entitlement. I didn't mind so much when I wasn't getting many cards and had to fold for long stretches of time—that, I realized, was part of the statistical variance in the game. But when I thought I had played particularly well—let's say I correctly detected an opponent's bluff, for instance—but then he caught a miracle card on the river and beat my hand anyway, that's what could really tilt me. I thought I had earned the pot, but he made the money.

By tilting, I could bring things back into a perverse equilibrium: I'd start playing badly enough that I deserved to lose. The fundamental reason that poker players tilt is that this balance is so often out of whack: over the short term, and often over the medium term, a player's results aren't very highly correlated with his skill. It certainly doesn't help matters when players have an unrealistic notion about their skill level, as they very often will. "We tend to latch onto data that supports our theory," Angelo told me. "And the theory is usually ‘I'm better than they are.'"

Beyond Results-Oriented Thinking

In the United States, we live in a very results-oriented society. If someone is rich or famous or beautiful, we tend to think they deserve to be those things. Often, in fact, these factors are self-reinforcing: making money begets more opportunities to make money; being famous provides someone with more ways to leverage their celebrity; standards of beauty may change with the look of a Hollywood starlet.

This is not intended as a political statement, an argument for (or against) greater redistribution of wealth or anything like that. As an empirical matter, however, success is determined by some combination of hard work, natural talent, and a person's opportunities and environment—in other words, some combination of noise and signal. In the U.S., we tend to emphasize the signal component most of the time—except perhaps when it comes to our own shortcomings, which we tend to attribute to bad luck. We can account for our neighbors' success by the size of their home, but we don't know as much about the hurdles they had to overcome to get there.

When it comes to prediction, we're really results-oriented. The investor who calls the stock market bottom is heralded as a genius, even if he had some buggy statistical model that just happened to get it right. The general manager who builds a team that wins the World Series is assumed to be better than his peers, even if, when you examine his track record, the team succeeded despite the moves he made rather than because of them. And this is certainly the case when it comes to poker. Chris Moneymaker wouldn't have been much of a story if the marketing pitch were "Here's some slob gambler who caught a bunch of lucky cards."

Sometimes we take consideration of luck too far in the other direction, when we excuse predictions that really were bad by claiming they were unlucky. The credit-rating agencies used a version of this excuse when their incompetence helped to usher in the financial collapse. But as a default, just as we perceive more signal than there really is when we make predictions, we also tend to attribute more skill than is warranted to successful predictions when we assess them later.

Part of the solution is to apply more rigor in how we evaluate predictions. The question of how skillful a forecast is can often be addressed through empirical methods; the long run is achieved more quickly in some fields than in others. But another part of the solution—and sometimes the only solution when the data is very noisy—is to focus more on process than on results. If the sample of predictions is too noisy to determine whether a forecaster is much good, we can instead ask whether he is applying the attitudes and aptitudes that we know are correlated with forecasting success over the long run. (In a sense, we'll be predicting how good his predictions will be.)

Poker players tend to understand this more than most other people, if only because they tend to experience the ups and downs in such a visceral way. A high-stakes player like Dwan might experience as much volatility in a single session of poker as a stock market investor would in his lifetime. Play well and win; play well and lose; play badly and lose; play badly and win: every poker player has experienced each of these conditions so many times over that they know there is a difference between process and results.

If you talk with the very best players, they don't take any of their success for granted; they focus as much as they can on self-improvement. "Anyone who thinks they've gotten good enough, good enough that they've solved poker, they're getting ready for a big downswing," Dwan told me.

Angelo tries to speed the process along with his clients. "We're walking around in this cloud of noise all the time," he said. "Very often we don't see what's going on accurately." Angelo's methods for achieving this are varied and sometimes unconventional: he is an advocate of meditation, for instance. Not all his clients meditate, but the broader idea is to increase their level of self-awareness, encouraging them to develop a better sense for which things are and are not within their control.*

When we play poker, we control our decision-making process but not how the cards come down. If you correctly detect an opponent's bluff, but he gets a lucky card and wins the hand anyway, you should be pleased rather than angry, because you played the hand as well as you could. The irony is that by being less focused on your results, you may achieve better ones.

Still, we are imperfect creatures living in an uncertain world. If we make a prediction and it goes badly, we can never really be certain whether it was our fault or not, whether our model was flawed or we just got unlucky. The closest approximation to a solution is to achieve a state of equanimity with the noise and the signal, recognizing that both are an irreducible part of our universe, and devote ourselves to appreciating each for what it is.