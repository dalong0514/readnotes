Nate Silver.(2012).2018173The-Signal-and-the-Noise.Penguin Group => Conclusion

## Introduction

This is a book about information, technology, and scientific progress. This is a book about competition, free markets, and the evolution of ideas. This is a book about the things that make us smarter than any computer, and a book about human error. This is a book about how we learn, one step at a time, to come to knowledge of the objective world, and why we sometimes take a step back.

This is a book about prediction, which sits at the intersection of all these things. It is a study of why some predictions succeed and why some fail. My hope is that we might gain a little more insight into planning our futures and become a little less likely to repeat our mistakes.

这是一本关于信息、技术与科学进步的著作，同时也是一部探讨竞争、自由市场和思想演进的智慧之书。它追溯了人类智慧的独特之处 - 那些使我们超越计算机的本质，也诚实地审视了人类认知的局限性。这是一个关于学习的故事：我们如何一步步地接近客观世界的真相，又为何时常会陷入原地踏步的困境。

预测，恰恰是这一切的交汇点。本书深入研究了预测的奥秘：为什么有些预测能够精准命中，而有些则偏离目标。我们的终极期望是，通过对过去的反思，能够稍稍提升我们规划未来的洞察力，并减少重蹈覆辙的可能性。

### More Information, More Problems

The original revolution in information technology came not with the microchip, but with the printing press. Johannes Gutenberg's invention in 1440 made information available to the masses, and the explosion of ideas it produced had unintended consequences and unpredictable effects. It was a spark for the Industrial Revolution in 1775,1 a tipping point in which civilization suddenly went from having made almost no scientific or economic progress for most of its existence to the exponential rates of growth and change that are familiar to us today. It set in motion the events that would produce the European Enlightenment and the founding of the American Republic.

But the printing press would first produce something else: hundreds of years of holy war. As mankind came to believe it could predict its fate and choose its destiny, the bloodiest epoch in human history followed.2

Books had existed prior to Gutenberg, but they were not widely written and they were not widely read. Instead, they were luxury items for the nobility, produced one copy at a time by scribes.3 The going rate for reproducing a single manuscript was about one florin (a gold coin worth about $200 in today's dollars) per five pages,4 so a book like the one you're reading now would cost around $20,000. It would probably also come with a litany of transcription errors, since it would be a copy of a copy of a copy, the mistakes having multiplied and mutated through each generation.

This made the accumulation of knowledge extremely difficult. It required heroic effort to prevent the volume of recorded knowledge from actually decreasing, since the books might decay faster than they could be reproduced. Various editions of the Bible survived, along with a small number of canonical texts, like from Plato and Aristotle. But an untold amount of wisdom was lost to the ages,5 and there was little incentive to record more of it to the page.

The pursuit of knowledge seemed inherently futile, if not altogether vain. If today we feel a sense of impermanence because things are changing so rapidly, impermanence was a far more literal concern for the generations before us. There was "nothing new under the sun," as the beautiful Bible verses in Ecclesiastes put it—not so much because everything had been discovered but because everything would be forgotten.6

The printing press changed that, and did so permanently and profoundly. Almost overnight, the cost of producing a book decreased by about three hundred times,7 so a book that might have cost $20,000 in today's dollars instead cost $70. Printing presses spread very rapidly throughout Europe; from Gutenberg's Germany to Rome, Seville, Paris, and Basel by 1470, and then to almost all other major European cities within another ten years.8 The number of books being produced grew exponentially, increasing by about thirty times in the first century after the printing press was invented.9 The store of human knowledge had begun to accumulate, and rapidly.

FIGURE I-1: EUROPEAN BOOK PRODUCTION

As was the case during the early days of the World Wide Web, however, the quality of the information was highly varied. While the printing press paid almost immediate dividends in the production of higher quality maps,10 the bestseller list soon came to be dominated by heretical religious texts and pseudoscientific ones.11 Errors could now be mass-produced, like in the so-called Wicked Bible, which committed the most unfortunate typo in history to the page: thou shalt commit adultery.12 Meanwhile, exposure to so many new ideas was producing mass confusion. The amount of information was increasing much more rapidly than our understanding of what to do with it, or our ability to differentiate the useful information from the mistruths.13 Paradoxically, the result of having so much more shared knowledge was increasing isolation along national and religious lines. The instinctual shortcut that we take when we have "too much information" is to engage with it selectively, picking out the parts we like and ignoring the remainder, making allies with those who have made the same choices and enemies of the rest.

The most enthusiastic early customers of the printing press were those who used it to evangelize. Martin Luther's Ninety-five Theses were not that radical; similar sentiments had been debated many times over. What was revolutionary, as Elizabeth Eisenstein writes, is that Luther's theses "did not stay tacked to the church door."14 Instead, they were reproduced at least three hundred thousand times by Gutenberg's printing press15—a runaway hit even by modern standards.

The schism that Luther's Protestant Reformation produced soon plunged Europe into war. From 1524 to 1648, there was the German Peasants' War, the Schmalkaldic War, the Eighty Years' War, the Thirty Years' War, the French Wars of Religion, the Irish Confederate Wars, the Scottish Civil War, and the English Civil War—many of them raging simultaneously. This is not to neglect the Spanish Inquisition, which began in 1480, or the War of the Holy League from 1508 to 1516, although those had less to do with the spread of Protestantism. The Thirty Years' War alone killed one-third of Germany's population,16 and the seventeenth century was possibly the bloodiest ever, with the early twentieth staking the main rival claim.17

But somehow in the midst of this, the printing press was starting to produce scientific and literary progress. Galileo was sharing his (censored) ideas, and Shakespeare was producing his plays.

Shakespeare's plays often turn on the idea of fate, as much drama does. What makes them so tragic is the gap between what his characters might like to accomplish and what fate provides to them. The idea of controlling one's fate seemed to have become part of the human consciousness by Shakespeare's time—but not yet the competencies to achieve that end. Instead, those who tested fate usually wound up dead.18

These themes are explored most vividly in The Tragedy of Julius Caesar. Throughout the first half of the play Caesar receives all sorts of apparent warning signs—what he calls predictions19 ("beware the ides of March")—that his coronation could turn into a slaughter. Caesar of course ignores these signs, quite proudly insisting that they point to someone else's death—or otherwise reading the evidence selectively. Then Caesar is assassinated.

"[But] men may construe things after their fashion / Clean from the purpose of the things themselves," Shakespeare warns us through the voice of Cicero—good advice for anyone seeking to pluck through their newfound wealth of information. It was hard to tell the signal from the noise. The story the data tells us is often the one we'd like to hear, and we usually make sure that it has a happy ending.

And yet if The Tragedy of Julius Caesar turned on an ancient idea of prediction—associating it with fatalism, fortune-telling, and superstition—it also introduced a more modern and altogether more radical idea: that we might interpret these signs so as to gain an advantage from them. "Men at some time are masters of their fates," says Cassius, hoping to persuade Brutus to partake in the conspiracy against Caesar.

The idea of man as master of his fate was gaining currency. The words predict and forecast are largely used interchangeably today, but in Shakespeare's time, they meant different things. A prediction was what the soothsayer told you; a forecast was something more like Cassius's idea.

The term forecast came from English's Germanic roots,20 unlike predict, which is from Latin.21 Forecasting reflected the new Protestant worldliness rather than the otherworldliness of the Holy Roman Empire. Making a forecast typically implied planning under conditions of uncertainty. It suggested having prudence, wisdom, and industriousness, more like the way we now use the word foresight. 22

The theological implications of this idea are complicated.23 But they were less so for those hoping to make a gainful existence in the terrestrial world. These qualities were strongly associated with the Protestant work ethic, which Max Weber saw as bringing about capitalism and the Industrial Revolution.24 This notion of forecasting was very much tied in to the notion of progress. All that information in all those books ought to have helped us to plan our lives and profitably predict the world's course.

• • •

The Protestants who ushered in centuries of holy war were learning how to use their accumulated knowledge to change society. The Industrial Revolution largely began in Protestant countries and largely in those with a free press, where both religious and scientific ideas could flow without fear of censorship.25

The importance of the Industrial Revolution is hard to overstate. Throughout essentially all of human history, economic growth had proceeded at a rate of perhaps 0.1 percent per year, enough to allow for a very gradual increase in population, but not any growth in per capita living standards.26 And then, suddenly, there was progress when there had been none. Economic growth began to zoom upward much faster than the growth rate of the population, as it has continued to do through to the present day, the occasional global financial meltdown notwithstanding.27

FIGURE I-2: GLOBAL PER CAPITA GDP, 1000–2010

The explosion of information produced by the printing press had done us a world of good, it turned out. It had just taken 330 years—and millions dead in battlefields around Europe—for those advantages to take hold.

信息汇聚，问题丛生

信息技术的第一次革命，并非人们通常认为的微芯片时代，而是要追溯到古腾堡 1440 年发明的印刷机。这项伟大的发明让信息成为大众的共享资源，并引发了思想的空前激荡，带来了一系列意料之外的深远影响。它成为 1775 年工业革命的关键引擎，标志着人类文明从漫长的停滞期跃升到今天我们所熟知的高速发展阶段。这一技术革新推动了欧洲启蒙运动的兴起，并为美国共和国的诞生铺平了道路。

然而，印刷机最初带来的，却是令人震惊的宗教战争。随着人类开始相信自己可以掌控命运，一个血腥而残酷的历史时代随之而来。

在古腾堡印刷术出现之前，书籍确实已经存在，但它们并不常见，也很少被广泛阅读。这些书籍更像是贵族的奢侈品，由抄写员一本一本地手工誊抄。当时，复制一份手稿的成本极高，大约每五页需要一枚金弗罗林（相当于今天约 200 美元的金币），这意味着一本普通的书籍可能会花费高达 2 万美元。更糟糕的是，这些手抄本往往充满了誊抄错误，因为它们是一份又一份地复制，每一次复制都会不可避免地引入新的错误。

在这样的背景下，知识的积累变得极其困难。学者们不得不付出巨大的努力，只为防止已有的知识被遗忘和损失。书籍可能会比它们被复制的速度更快地腐烂。在那个时代，只有少数经典著作得以保存，如《圣经》的不同版本，以及柏拉图和亚里士多德的一些作品。然而，大量的智慧和知识已经永远地消失在历史的长河中，而记录新知识的动力也极其微弱。

在那个时代，追求知识似乎是徒劳的，甚至令人绝望。与我们这个瞬息万变的时代不同，对于早期的几代人来说，知识的短暂和易逝是一种切身的忧虑。人们深信「天下没有新鲜事」，这并非因为一切都已被探索，而是因为一切终将被遗忘。

印刷机的出现彻底改变了这一现状。这项革命性的技术使得制作一本书的成本骤然下降 —— 从原来的动辄数万美元，降至仅需 70 美元。印刷机如同一场知识的迅猛暴风，迅速席卷欧洲：从德国的古腾堡开始，很快蔓延到罗马、塞维利亚、巴黎和巴塞尔，仅十年间就传遍了几乎所有欧洲主要城市。在印刷机发明的第一个世纪里，书籍产量呈几何级数增长，足足扩大了三十倍。人类知识首次有了持久的载体，开始真正意义上的积累和传播。

图 I-1：欧洲图书生产

就像万维网早期一样，信息质量呈现出极大的不均衡性。印刷术几乎立即为高质量地图的制作带来了革命性进步 [10]，但畅销书单很快就被异端宗教著作和伪科学作品所主导 [11]。这一时期，错误可以像批量生产的商品一样被复制，最著名的例子是《错误圣经》，它在历史上犯下了最荒谬的印刷错误：将「不可通奸」错印成「应当通奸」[12]。与此同时，接触如此多的新思想正在引发大规模的认知混乱。信息数量以远超我们理解和处理能力的速度激增，我们越来越难以准确区分有价值的信息和无稽之谈 [13]。矛盾的是，本应增进理解的海量共享知识，反而加深了人们在国家和宗教认同上的隔阂。面对信息洪流，人们往往会本能地进行选择性接收：只关注符合自身立场的信息，忽略其他内容，并与志同道合者结盟，将不同观点视为敌对。

印刷机最热衷的早期用户是那些致力于传播宗教思想的人。马丁·路德的《九十五条论纲》本身并不特别激进，类似的观点此前已多次被讨论。正如历史学家伊丽莎白·艾森斯坦所指出的，真正革命性的是路德的论纲「并未仅仅贴在教堂大门上」。相反，它们通过古腾堡印刷机被复制了至少三十万份 —— 即使放在今天也是一个令人瞩目的传播规模。

宗教改革引发的宗教分裂很快使欧洲陷入长期的战争。从 1524 年到 1648 年，欧洲经历了一系列持续不断的宗教战争，包括德国农民战争、施马尔卡尔登战争、八十年战争、三十年战争、法国宗教战争、爱尔兰联合战争、苏格兰内战和英国内战 —— 其中许多战争甚至是同时进行的。这一时期还包括始于 1480 年的西班牙宗教裁判所，以及 1508 年至 1516 年的神圣联盟战争，尽管这些事件与新教传播的关系相对较少。仅三十年战争就造成了德国三分之一人口的死亡，使得 17 世纪成为历史上最为血腥的世纪之一，可能仅次于 20 世纪初期。

在这个动荡的时代，印刷技术却悄然推动了科学与文学的蓬勃发展。伽利略冒着风险分享着被审查的思想，莎士比亚则用戏剧描绘人性的深刻洞见。

莎士比亚的戏剧常常将命运编织成悲剧的主线，令人扼腕叹息。作品的悲剧性正源于角色们理想与现实的巨大张力：他们渴望掌控自身命运，却被无形的力量推向悲惨结局。在那个时代，人类已经开始意识到命运可以被质疑，但尚未掌握改变命运的能力。挑战命运的人往往付出生命的代价。

在《凯撒大帝》中，这一主题得到了最为戏剧性的呈现。凯撒不断收到预示灾难的预兆 ——「提防三月月中」这样的警告在剧中反复回响。然而，这位骄傲的统治者却傲慢地忽视了所有征兆，执意将警告解读为针对他人的预言。悲剧性的是，他选择性地曲解证据，最终在背叛与暴力中迎来了自己的末日。

莎士比亚借西塞罗的口吻发出警告：「人们常常会按照自己的想象来诠释事物，完全偏离事物的本来面目」—— 这对于任何希望在信息汪洋中寻找真相的人来说，都是极其珍贵的忠告。在海量信息中，真相往往被淹没在噪音中。数据讲述的故事，常常是我们主观想听的故事，而我们总是倾向于为其编织一个圆满的结局。

然而，《凯撒大帝之死》不仅延续了关于预测的古老观念 —— 将其与宿命论、命理占卜紧密联系 —— 更重要的是，它引入了一个更加现代且富有革命性的思想：人类可以主动解读这些迹象，并从中获得战略性优势。正如卡西乌斯激励布鲁特斯时所说：「人在某些时刻，终将成为自身命运的主人。」

在那个时代，「人定胜天」的理念正在逐渐获得认可。有趣的是，「预测」和「预报」这两个词如今几乎可以互换使用，但在莎士比亚的年代，它们承载着截然不同的含义。「预测」更多指巫师和占卜师的神秘预言，而「预报」则更接近卡西乌斯所代表的、基于理性和主观能动性的前瞻性判断。

「预测」一词源自英语中的日耳曼语言，20 而「预言」则源于拉丁语。21 预测更多体现了新教徒对现实世界的关注，而非罗马天主教帝国那种对来世的迷恋。做出预测通常意味着在不确定的条件下进行理性规划。这种做法体现了审慎、智慧和勤奋，与我们今天理解的「远见卓识」颇为相似。22

这一概念背后的神学内涵相当复杂。23 但对于那些希望在现实世界中谋生的人而言，这些内涵就简单得多了。这些品质与马克斯·韦伯所描述的推动资本主义和工业革命的新教职业伦理紧密相连。24 预测的概念本质上与进步密不可分。人们相信，书籍中的知识积累将帮助我们更好地规划生活，并理性地预测世界的发展方向。

试图重塑社会的新教徒开始学会利用积累的知识推动社会变革。工业革命主要在新教国家兴起，尤其是那些拥有言论自由的国家，宗教和科学思想可以不受压制地自由交流 [25]。

工业革命的历史意义难以估量。在人类历史的绝大部分时期，经济增长微乎其微，每年仅约 0.1%，勉强维持缓慢的人口增长，但人们的生活水平却长期停滞 [26]。突然间，一切都发生了变化。经济增长开始以前所未有的速度上升，远远超过人口增长率，这一势头一直延续至今，尽管中间偶尔经历全球金融危机 [27]。

图 I-2：全球人均 GDP，1000-2010 年印刷术带来的信息革命为人类文明带来了深远的变革。这一进程用了 330 年的时间，付出了欧洲战场上无数生命的代价。

### The Productivity Paradox

We face danger whenever information growth outpaces our understanding of how to process it. The last forty years of human history imply that it can still take a long time to translate information into useful knowledge, and that if we are not careful, we may take a step back in the meantime.

The term "information age" is not particularly new. It started to come into more widespread use in the late 1970s. The related term "computer age" was used earlier still, starting in about 1970.28 It was at around this time that computers began to be used more commonly in laboratories and academic settings, even if they had not yet become common as home appliances. This time it did not take three hundred years before the growth in information technology began to produce tangible benefits to human society. But it did take fifteen to twenty.

The 1970s were the high point for "vast amounts of theory applied to extremely small amounts of data," as Paul Krugman put it to me. We had begun to use computers to produce models of the world, but it took us some time to recognize how crude and assumption laden they were, and that the precision that computers were capable of was no substitute for predictive accuracy. In fields ranging from economics to epidemiology, this was an era in which bold predictions were made, and equally often failed. In 1971, for instance, it was claimed that we would be able to predict earthquakes within a decade,29 a problem that we are no closer to solving forty years later.

Instead, the computer boom of the 1970s and 1980s produced a temporary decline in economic and scientific productivity. Economists termed this the productivity paradox. "You can see the computer age everywhere but in the productivity statistics," wrote the economist Robert Solow in 1987.30 The United States experienced four distinct recessions between 1969 and 1982.31 The late 1980s were a stronger period for our economy, but less so for countries elsewhere in the world.

Scientific progress is harder to measure than economic progress.32 But one mark of it is the number of patents produced, especially relative to the investment in research and development. If it has become cheaper to produce a new invention, this suggests that we are using our information wisely and are forging it into knowledge. If it is becoming more expensive, this suggests that we are seeing signals in the noise and wasting our time on false leads.

In the 1960s the United States spent about $1.5 million (adjusted for inflation33) per patent application34 by an American inventor. That figure rose rather than fell at the dawn of the information age, however, doubling to a peak of about $3 million in 1986.35

FIGURE I-3: RESEARCH AND DEVELOPMENT EXPENDITURES PER PATENT APPLICATION

As we came to more realistic views of what that new technology could accomplish for us, our research productivity began to improve again in the 1990s. We wandered up fewer blind alleys; computers began to improve our everyday lives and help our economy. Stories of prediction are often those of long-term progress but short-term regress. Many things that seem predictable over the long run foil our best-laid plans in the meanwhile.

生产力悖论

当信息增长速度超过我们理解和处理的能力时，我们就可能陷入信息的迷茫与困境。过去四十年的人类历史告诉我们，将海量信息转化为有价值的知识是一个漫长的过程，如果不谨慎应对，我们很可能在这个过程中遇到挫折。

「信息时代」这个概念并非突然出现。它在 1970 年代后期逐渐流行起来。稍早一些的相关概念是「计算机时代」[28]，大约始于 1970 年。那是计算机开始逐步进入实验室和学术领域，尽管尚未成为普通家庭的日常设备。与过去相比，这一次信息技术的发展周期大大缩短，从技术萌芽到对社会产生实质性影响，仅仅用了十五到二十年。

1970 年代是「用大量理论解释极少数据」的巅峰时期，正如经济学家 Paul Krugman 所描述的。当时，我们开始使用计算机模拟世界，但逐渐意识到这些模型是多么粗糙、充满假设，计算机的精确计算并不等同于准确的预测。从经济学到流行病学，这是一个充满大胆预测也常常失败的年代。比如 1971 年，有人声称十年内就能预测地震 [29]，但四十年过去了，我们仍然无法实现这一目标。

矛盾的是，1970 和 1980 年代的计算机热潮反而导致了经济和科学生产力的短暂下降，经济学家将此称为「生产力悖论」。正如经济学家 Robert Solow 在 1987 年著名的论断：「计算机时代无处不在，却未见于生产力统计」[30]。在这期间，美国经历了从 1969 年到 1982 年的四次经济衰退 [31]。尽管晚 1980 年代对美国经济相对有利，但对世界其他地区的国家却并不理想。

科学进步比经济进步更难量化。32 衡量科学发展的一个重要指标是专利的数量，尤其是与研发投资相关联。如果产生一项新发明的成本降低了，这意味着我们正在有效地转化信息，将其升华为有价值的知识。反之，如果成本不断攀升，则可能意味着我们正在徒劳地在复杂信息中寻找有意义的线索，实际上是在浪费资源。

在 20 世纪 60 年代，美国每一项美国发明家的专利申请平均投入约 150 万美元（根据通货膨胀调整 33）。然而，在信息技术革命的初始阶段，这一投入并未减少，反而持续上升，到 1986 年时几乎翻了一番，达到了约 300 万美元的峰值。35

图 1-3：每个专利申请的研究与开发支出

随着我们对新技术的能力有了更加务实的认识，1990 年代我们的研究生产力开始重新提升。研究过程中的弯路减少了；计算机逐渐改善了我们的日常生活，并为经济发展提供了助力。预测的历史往往是长期进步与短期波折交织的故事。许多看似可以长期预测的事情，却常常会在瞬息万变中打乱我们精心制定的计划。

### The Promise and Pitfalls of "Big Data"

The fashionable term now is "Big Data." IBM estimates that we are generating 2.5 quintillion bytes of data each day, more than 90 percent of which was created in the last two years.36

This exponential growth in information is sometimes seen as a cure-all, as computers were in the 1970s. Chris Anderson, the editor of Wired magazine, wrote in 2008 that the sheer volume of data would obviate the need for theory, and even the scientific method.37

This is an emphatically pro-science and pro-technology book, and I think of it as a very optimistic one. But it argues that these views are badly mistaken. The numbers have no way of speaking for themselves. We speak for them. We imbue them with meaning. Like Caesar, we may construe them in self-serving ways that are detached from their objective reality.

Data-driven predictions can succeed—and they can fail. It is when we deny our role in the process that the odds of failure rise. Before we demand more of our data, we need to demand more of ourselves.

This attitude might seem surprising if you know my background. I have a reputation for working with data and statistics and using them to make successful predictions. In 2003, bored at a consulting job, I designed a system called PECOTA, which sought to predict the statistics of Major League Baseball players. It contained a number of innovations—its forecasts were probabilistic, for instance, outlining a range of possible outcomes for each player—and we found that it outperformed competing systems when we compared their results. In 2008, I founded the Web site FiveThirtyEight, which sought to forecast the upcoming election. The FiveThirtyEight forecasts correctly predicted the winner of the presidential contest in forty-nine of fifty states as well as the winner of all thirty-five U.S. Senate races.

After the election, I was approached by a number of publishers who wanted to capitalize on the success of books such as Moneyball and Freakonomics that told the story of nerds conquering the world. This book was conceived of along those lines—as an investigation of data-driven predictions in fields ranging from baseball to finance to national security.

But in speaking with well more than one hundred experts in more than a dozen fields over the course of four years, reading hundreds of journal articles and books, and traveling everywhere from Las Vegas to Copenhagen in pursuit of my investigation, I came to realize that prediction in the era of Big Data was not going very well. I had been lucky on a few levels: first, in having achieved success despite having made many of the mistakes that I will describe, and second, in having chosen my battles well.

Baseball, for instance, is an exceptional case. It happens to be an especially rich and revealing exception, and the book considers why this is so—why a decade after Moneyball, stat geeks and scouts are now working in harmony.

The book offers some other hopeful examples. Weather forecasting, which also involves a melding of human judgment and computer power, is one of them. Meteorologists have a bad reputation, but they have made remarkable progress, being able to forecast the landfall position of a hurricane three times more accurately than they were a quarter century ago. Meanwhile, I met poker players and sports bettors who really were beating Las Vegas, and the computer programmers who built IBM's Deep Blue and took down a world chess champion.

But these cases of progress in forecasting must be weighed against a series of failures.

If there is one thing that defines Americans—one thing that makes us exceptional—it is our belief in Cassius's idea that we are in control of our own fates. Our country was founded at the dawn of the Industrial Revolution by religious rebels who had seen that the free flow of ideas had helped to spread not just their religious beliefs, but also those of science and commerce. Most of our strengths and weaknesses as a nation—our ingenuity and our industriousness, our arrogance and our impatience—stem from our unshakable belief in the idea that we choose our own course.

But the new millennium got off to a terrible start for Americans. We had not seen the September 11 attacks coming. The problem was not want of information. As had been the case in the Pearl Harbor attacks six decades earlier, all the signals were there. But we had not put them together. Lacking a proper theory for how terrorists might behave, we were blind to the data and the attacks were an "unknown unknown" to us.

There also were the widespread failures of prediction that accompanied the recent global financial crisis. Our naïve trust in models, and our failure to realize how fragile they were to our choice of assumptions, yielded disastrous results. On a more routine basis, meanwhile, I discovered that we are unable to predict recessions more than a few months in advance, and not for lack of trying. While there has been considerable progress made in controlling inflation, our economic policy makers are otherwise flying blind.

The forecasting models published by political scientists in advance of the 2000 presidential election predicted a landslide 11-point victory for Al Gore.38 George W. Bush won instead. Rather than being an anomalous result, failures like these have been fairly common in political prediction. A long-term study by Philip E. Tetlock of the University of Pennsylvania found that when political scientists claimed that a political outcome had absolutely no chance of occurring, it nevertheless happened about 15 percent of the time. (The political scientists are probably better than television pundits, however.)

There has recently been, as in the 1970s, a revival of attempts to predict earthquakes, most of them using highly mathematical and data-driven techniques. But these predictions envisaged earthquakes that never happened and failed to prepare us for those that did. The Fukushima nuclear reactor had been designed to handle a magnitude 8.6 earthquake, in part because some seismologists concluded that anything larger was impossible. Then came Japan's horrible magnitude 9.1 earthquake in March 2011.

There are entire disciplines in which predictions have been failing, often at great cost to society. Consider something like biomedical research. In 2005, an Athens-raised medical researcher named John P. Ioannidis published a controversial paper titled "Why Most Published Research Findings Are False."39 The paper studied positive findings documented in peer-reviewed journals: descriptions of successful predictions of medical hypotheses carried out in laboratory experiments. It concluded that most of these findings were likely to fail when applied in the real world. Bayer Laboratories recently confirmed Ioannidis's hypothesis. They could not replicate about two-thirds of the positive findings claimed in medical journals when they attempted the experiments themselves.40

Big Data will produce progress—eventually. How quickly it does, and whether we regress in the meantime, will depend on us.

大数据（Big Data)」的承诺与陷阱

大数据已成为当下最热门的技术术语。IBM 的数据显示，我们每天生成 2.5 百万亿（quintillion）字节的数据，而且令人惊讶的是，这些数据中超过 90% 是在过去短短两年内产生的。

这种信息的指数级增长，有时被视为技术发展的万能钥匙，犹如上世纪 70 年代人们对计算机的狂热。著名科技杂志《连线（Wired)》主编 Chris Anderson 在 2008 年甚至断言，海量数据的积累本身将使传统的理论研究和科学方法变得多余。

这是一本极力拥护科学和技术的著作，看起来充满乐观色彩。然而，作者认为这种观点存在严重的误区。数据本身是无声的，是我们赋予其意义。正如凯撒曾经那样，我们可能会以一种自我服务的方式阐释数据，使其脱离客观现实。

基于数据的预测或许会成功，也可能以失败告终。当我们否认自身在这一过程中的主动角色时，失败的可能性就会急剧增加。在对数据提出更高要求之前，我们首先需要对自己的认知和态度提出更高的要求。

也许你听到我的背景会感到诧异。作为一个以数据和统计分析著称、善于做精准预测的专业人士，我有着有趣的职业经历。2003 年，在一份令人乏味的咨询工作中，我开发了 PECOTA 预测系统，专门用于预测大联盟棒球运动员的表现。这个系统的独特之处在于采用概率预测模型，为每个球员给出了多种可能的结果范围，最终证明比同类系统更为准确。

2008 年，我创立了 FiveThirtyEight 网站，致力于选举结果预测。这个网站的预测令人印象深刻：在五十个州中，成功预测了四十九个州的总统大选结果，并准确预测了所有三十五个美国参议院选举的获胜者。

这些成功引起了出版界的广泛关注。当时，像《Moneyball》和《Freakonomics》这样揭示数据分析如何改变传统领域的书籍非常流行。受此启发，我决定写一本探索数据驱动预测在棒球、金融和国家安全等多个领域应用的著作。

在四年的调查旅程中，我与来自十多个领域的百余位专家深入交流，阅读了数百篇学术论文和专著，并游历了从拉斯维加斯到哥本哈根的诸多地方。通过这个过程，我逐渐意识到：在大数据时代，预测的效果并不理想。我感到幸运的是，尽管犯了诸多错误，但仍取得了成功，而且我善于选择和把控研究方向。

以棒球为例，这是一个极具代表性的特例。它不仅是一个丰富而富有启示的例外，更是本书探讨的重点 —— 为什么在《金钱球》（一部关于棒球统计分析的著名作品）问世十年后，数据分析师和传统球探能够实现前所未有的默契与合作。

这本书还列举了一些令人鼓舞的进步案例。天气预报就是其中之一，它融合了人类专业判断和计算机技术。尽管气象学家常常被诟病，但他们已经取得了显著成就，能够比 25 年前准确三倍地预测飓风登陆位置。在此同时，我还遇到了一些在赌博领域战胜对手的职业玩家，以及像 IBM Deep Blue 团队这样成功挑战世界象棋冠军的计算机专家。

然而，这些预测领域的进步必须与同期的诸多失败案例相对照。

如果说有一种精神最能定义美国人，那就是我们坚信能够掌控自身命运的信念。这种信念源自古罗马政治家卡西厄斯（主动掌控命运）的哲学思想。我们的国家诞生于工业革命的黎明，由一群宗教改革者开创，他们深知思想的自由流通不仅能传播宗教理念，还能推动科学和商业的发展。作为一个国家，我们的优点和缺点 —— 如创新精神和勤奋态度，以及傲慢与急躁 —— 都植根于这种对个人选择的坚定信念。

新千年对美国人来说是一个令人沮丧的开端。9 月 11 日恐怖袭击悄然来袭，令人措手不及。这并非因为缺乏信息，恰恰相反，就像六十年前珍珠港事件一样，所有预警信号都已经存在。然而，我们未能将这些零散的信息拼接成完整的图景。由于缺乏对恐怖分子行为模式的正确理解，我们对眼前的数据视而不见，最终导致这场袭击成为一个我们完全无法预料的「未知领域」。

与此同时，最近的全球金融危机也暴露了我们在预测方面的严重缺陷。我们天真地相信各种经济模型，却没有意识到这些模型对基础假设有多么脆弱，最终酿成大祸。更为常态的是，我发现我们连经济衰退这样的重大趋势都难以提前几个月预测，尽管已经付出了极大的努力。尽管在通货膨胀控制方面取得了进展，但经济政策制定者们依然像瞎子一样摸索前进，缺乏清晰的前瞻性视野。

政治科学家在 2000 年总统选举前发布的预测模型预测阿尔·戈尔将以 11 个百分点的压倒性优势获胜。38 然而，乔治·W·布什最终赢得了大选。这种预测失误并非个案，在政治预测领域中类似的失败屡见不鲜。宾夕法尼亚大学的菲利普·E·特洛克进行的长期研究发现，即便政治科学家断言某个政治结果绝对不可能发生，这种结果仍然会在约 15% 的情况下意外出现。（尽管如此，这些政治科学家的预测准确性可能还是要比电视评论员稍好一些。）

与 1970 年代类似，近期再次掀起了一波预测地震的热潮，这些尝试大多采用高度数学化和数据驱动的技术。然而，这些预测往往描绘了从未发生的地震场景，却未能帮助我们为真实发生的地震做好准备。福岛核反应堆原本被设计为能够承受 8.6 级地震，这在很大程度上源于部分地震学家认为更大级别的地震根本不可能发生。而现实却是，2011 年 3 月，日本遭遇了可怕的 9.1 级大地震。

在某些学科中，预测往往会失败，并给社会带来巨大的代价。生物医学研究就是一个典型的例子。2005 年，John P. Ioannidis（一位在雅典成长的医学研究者）发表了一篇具有里程碑意义的论文，题为「为什么大多数已发表的研究发现是错误的」[39]。

这篇论文深入研究了同行评审期刊中的研究结果，特别关注那些在实验室中看似成功验证的医学假说。令人惊讶的是，论文得出结论：这些看似可靠的科学发现，在实际应用中很可能会失效。拜耳实验室后来的研究证实了 Ioannidis 的担忧。当他们尝试重现这些实验时，惊讶地发现约三分之二的「成功」研究结果在实际操作中无法复制 [40]。

大数据终将推动进步，但进步的速度和方向，取决于我们如何应对和引导。

### Why the Future Shocks Us

Biologically, we are not very different from our ancestors. But some stone-age strengths have become information-age weaknesses.

Human beings do not have very many natural defenses. We are not all that fast, and we are not all that strong. We do not have claws or fangs or body armor. We cannot spit venom. We cannot camouflage ourselves. And we cannot fly. Instead, we survive by means of our wits. Our minds are quick. We are wired to detect patterns and respond to opportunities and threats without much hesitation.

"This need of finding patterns, humans have this more than other animals," I was told by Tomaso Poggio, an MIT neuroscientist who studies how our brains process information. "Recognizing objects in difficult situations means generalizing. A newborn baby can recognize the basic pattern of a face. It has been learned by evolution, not by the individual."

The problem, Poggio says, is that these evolutionary instincts sometimes lead us to see patterns when there are none there. "People have been doing that all the time," Poggio said. "Finding patterns in random noise."

The human brain is quite remarkable; it can store perhaps three terabytes of information.41 And yet that is only about one one-millionth of the information that IBM says is now produced in the world each day. So we have to be terribly selective about the information we choose to remember.

Alvin Toffler, writing in the book Future Shock in 1970, predicted some of the consequences of what he called "information overload." He thought our defense mechanism would be to simplify the world in ways that confirmed our biases, even as the world itself was growing more diverse and more complex.42

Our biological instincts are not always very well adapted to the information-rich modern world. Unless we work actively to become aware of the biases we introduce, the returns to additional information may be minimal—or diminishing.

The information overload after the birth of the printing press produced greater sectarianism. Now those different religious ideas could be testified to with more information, more conviction, more "proof"—and less tolerance for dissenting opinion. The same phenomenon seems to be occurring today. Political partisanship began to increase very rapidly in the United States beginning at about the time that Tofller wrote Future Shock and it may be accelerating even faster with the advent of the Internet.43

These partisan beliefs can upset the equation in which more information will bring us closer to the truth. A recent study in Nature found that the more informed that strong political partisans were about global warming, the less they agreed with one another.44

Meanwhile, if the quantity of information is increasing by 2.5 quintillion bytes per day, the amount of useful information almost certainly isn't. Most of it is just noise, and the noise is increasing faster than the signal. There are so many hypotheses to test, so many data sets to mine—but a relatively constant amount of objective truth.

The printing press changed the way in which we made mistakes. Routine errors of transcription became less common. But when there was a mistake, it would be reproduced many times over, as in the case of the Wicked Bible.

Complex systems like the World Wide Web have this property. They may not fail as often as simpler ones, but when they fail they fail badly. Capitalism and the Internet, both of which are incredibly efficient at propagating information, create the potential for bad ideas as well as good ones to spread. The bad ideas may produce disproportionate effects. In advance of the financial crisis, the system was so highly levered that a single lax assumption in the credit ratings agencies' models played a huge role in bringing down the whole global financial system.

Regulation is one approach to solving these problems. But I am suspicious that it is an excuse to avoid looking within ourselves for answers. We need to stop, and admit it: we have a prediction problem. We love to predict things—and we aren't very good at it.

为什么未来会如此令人震惊

从生物学角度看，人类与数千年前的祖先并没有本质区别。然而，我们在漫长进化中形成的一些生存本能和思维模式，在快速变化的信息时代可能会成为阻碍。曾经帮助我们生存的思维方式，如今可能会限制我们适应日新月异的技术世界。

人类并没有很多天然防御手段。我们不够快速，也不够强壮。没有锋利的爪子、尖锐的牙齿，也没有天生的身体护甲。我们不能喷毒、变色或飞行。与其他动物不同，人类凭借的是智慧生存。我们的大脑敏捷，能够快速识别模式，并迅速对机遇和威胁做出反应。

「人类寻找模式的能力比其他动物更强，」麻省理工学院神经科学家 Tomaso Poggio 告诉我。「在复杂环境中识别物体，本质上是一种概括能力。比如，一个新生婴儿就能识别面孔的基本特征，这是进化而来的本能，而非后天学习。」

然而，Poggio 指出，这种进化本能有时会产生副作用 —— 人们会在毫无规律的地方看到虚幻的模式。「人们总是喜欢在随机噪声中寻找意义，」他说。

人类大脑相当非凡；它可以存储约三太字节（TB）的信息。41 然而，这仅仅是 IBM 所称的目前世界每天产生的信息量的百万分之一。因此，我们必须非常谨慎地选择要记忆的信息。

阿尔文·托夫勒在 1970 年出版的《未来震撼》一书中，预见了「信息过载」的一些潜在影响。他认为，人们会倾向于用符合自身偏见的方式来理解和简化复杂的世界，尽管这个世界正变得越来越多元和复杂。42

我们的生物本能并不总是能很好地适应信息丰富的现代社会。除非我们主动识别和克服自身的认知偏见，否则获取更多信息可能并不会带来显著的认知收益，甚至会出现收益递减的情况。

印刷机的出现带来了信息泛滥，这反而加剧了宗教分歧。借助更多的信息和「证据」，不同的宗教观点可以被更有力地论证，但这同时也降低了人们对异议的包容度。如今，我们似乎正在经历着类似的社会现象。政治极化从 Toffler 撰写《未来震撼》的年代开始在美国迅速蔓延，随着互联网的兴起，这一趋势正以更快的速度加剧。

这种党派偏见（partisan beliefs）打破了「信息越多越接近真相」的朴素假设。《自然》杂志的一项研究发现，政治立场强硬的人，即便对全球变暖的了解越深入，他们之间的分歧反而越大。

在每天产生 2.5 quintillion（百亿亿，即 10^18）字节的海量信息中，真正有价值的信息其实非常有限。大多数信息不过是「噪音」（noise），而这些噪音的增长速度远远超过了有效「信号」（signal）。尽管有无数假设等待验证，海量数据等待挖掘，但客观真相的总量却几乎保持不变。

印刷机彻底改变了我们犯错的方式。手工抄写时常见的笔误变得越来越少。然而，当错误确实发生时，它们往往会被成倍地复制 —— 就像著名的「罪恶圣经」事件（一个因印刷错误导致圣经文本出现严重失误的历史案例）。

复杂系统，如万维网，都有这种独特的特征。它们可能不会像简单系统那样频繁出错，但一旦出错，后果往往是毁灭性的。资本主义和互联网这两个在传播信息方面极其高效的系统，同时也为好想法和坏想法的传播创造了土壤。值得警惕的是，这些负面想法可能会产生极其不成比例的影响。以金融危机为例，当时的金融体系杠杆率已经高到惊人的程度，信用评级机构模型中的一个轻微不当假设，就足以引发全球金融系统的大规模崩溃。

监管或许是解决这类问题的一种途径。但我怀疑，这更可能是我们回避自我反思的借口。我们需要诚实地面对现实：我们有一个根本的预测问题。我们热衷于预测未来，但现实是，我们的预测能力相当有限。

### The Prediction Solution

If prediction is the central problem of this book, it is also its solution.

Prediction is indispensable to our lives. Every time we choose a route to work, decide whether to go on a second date, or set money aside for a rainy day, we are making a forecast about how the future will proceed—and how our plans will affect the odds for a favorable outcome.

Not all of these day-to-day problems require strenuous thought; we can budget only so much time to each decision. Nevertheless, you are making predictions many times every day, whether or not you realize it.

For this reason, this book views prediction as a shared enterprise rather than as a function that a select group of experts or practitioners perform. It is amusing to poke fun at the experts when their predictions fail. However, we should be careful with our Schadenfreude. To say our predictions are no worse than the experts' is to damn ourselves with some awfully faint praise.

Prediction does play a particularly important role in science, however. Some of you may be uncomfortable with a premise that I have been hinting at and will now state explicitly: we can never make perfectly objective predictions. They will always be tainted by our subjective point of view.

But this book is emphatically against the nihilistic viewpoint that there is no objective truth. It asserts, rather, that a belief in the objective truth—and a commitment to pursuing it—is the first prerequisite of making better predictions. The forecaster's next commitment is to realize that she perceives it imperfectly.

Prediction is important because it connects subjective and objective reality. Karl Popper, the philosopher of science, recognized this view.45 For Popper, a hypothesis was not scientific unless it was falsifiable—meaning that it could be tested in the real world by means of a prediction.

What should give us pause is that the few ideas we have tested aren't doing so well, and many of our ideas have not or cannot be tested at all. In economics, it is much easier to test an unemployment rate forecast than a claim about the effectiveness of stimulus spending. In political science, we can test models that are used to predict the outcome of elections, but a theory about how changes to political institutions might affect policy outcomes could take decades to verify.

I do not go as far as Popper in asserting that such theories are therefore unscientific or that they lack any value. However, the fact that the few theories we can test have produced quite poor results suggests that many of the ideas we haven't tested are very wrong as well. We are undoubtedly living with many delusions that we do not even realize.

• • •

But there is a way forward. It is not a solution that relies on half-baked policy ideas—particularly given that I have come to view our political system as a big part of the problem. Rather, the solution requires an attitudinal change.

This attitude is embodied by something called Bayes's theorem, which I introduce in chapter 8. Bayes's theorem is nominally a mathematical formula. But it is really much more than that. It implies that we must think differently about our ideas—and how to test them. We must become more comfortable with probability and uncertainty. We must think more carefully about the assumptions and beliefs that we bring to a problem.

The book divides roughly into halves. The first seven chapters diagnose the prediction problem while the final six explore and apply Bayes's solution.

Each chapter is oriented around a particular subject and describes it in some depth. There is no denying that this is a detailed book—in part because that is often where the devil lies, and in part because my view is that a certain amount of immersion in a topic will provide disproportionately more insight than an executive summary.

The subjects I have chosen are usually those in which there is some publicly shared information. There are fewer examples of forecasters making predictions based on private information (for instance, how a company uses its customer records to forecast demand for a new product). My preference is for topics where you can check out the results for yourself rather than having to take my word for it.

预测：问题与解决方案

如果说预测是这本书要探讨的核心问题，那么它本身也将指向解决之道。

预测早已融入我们生活的方方面面。想想看，当你选择上班路线、考虑是否继续一段约会，或是精心计划未来的存款，其实都是在对未来做出预测 —— 你的每一个选择都在悄悄影响最终的结果。

在日常生活中，并非每个决定都需要我们深思熟虑；毕竟，我们对每个选择能投入的时间是有限的。有趣的是，即便你没有察觉，预测已经成为你日常生活中的常态，你每天都在不知不觉中进行着无数次预测。

这就是为什么本书将预测视为一种人人都能参与的活动，而非少数专家的专属领域。很多人喜欢在专家预测失误时幸灾乐祸，但我们要明白：说自己的预测「不比专家差」，恐怕算不上什么值得骄傲的事。

在科学领域，预测的角色更是举足轻重。这里我想坦诚地告诉你一个看似有争议，但实际上极其重要的观点：没有绝对客观的预测。我们的每一个预测，都难免会带上个人的主观色彩。

这本书坚决反对那种「不存在客观真理」的虚无主义观点。相反，它强调，对客观真理的信念及其追求，是做出更准确预测的基础。对于预测者来说，首要任务是承认自身认知的局限性。

预测之所以重要，是因为它架起了主观认知与客观现实之间的桥梁。科学哲学家卡尔·波普尔（Karl Popper）曾深刻阐述了这一观点 [45]。在他看来，一个科学假说必须是可证伪的，即可以通过预测在现实世界中接受检验。

令人担忧的是，我们已经测试的少数几个理论成效并不理想，而更多的理论甚至无法被验证。举例来说，在经济学领域，预测失业率比验证经济刺激政策的有效性要容易得多；在政治科学中，我们可以检验预测选举结果的模型，但评估政治制度变革对政策影响的理论可能需要数十年时间才能得到验证。

我不像波普尔那样极端地认为这些理论因此是非科学的或毫无价值。然而，我们已经测试的少数理论已经得出了相当糟糕的结果，这一事实暗示着未经验证的许多观点可能同样存在严重的错误。我们无疑生活在诸多未被察觉的迷思之中。

···

但是，我们仍然有前进的道路。这不是依赖未成熟政策理念的解决方案 —— 尤其是当我已经认识到我们的政治体系本身就是问题的重要根源。相反，真正的解决之道在于改变我们的思维态度。

这种态度体现在贝叶斯定理（Bayes's theorem）中，我将在第 8 章详细阐述。贝叶斯定理看似只是一个数学公式，但实际上意义深远。它启示我们必须以全新的方式审视自己的想法，并学会如何正确地检验它们。我们需要学会接纳概率的不确定性，更审慎地审视自己面对问题时潜意识中的假设和信念。

全书大致可分为两个部分：前七章诊断预测问题的本质，而最后六章则着眼于探索和应用贝叶斯的解决方案。

每一章都聚焦于一个特定主题，并对其进行深入探讨。无可否认，这是一本细节丰富的书 —— 一方面是因为真相常常藏在细节之中，另一方面是因为我相信，对某个主题的深入了解能够带来远超简单概括的洞察。

我选择的主题通常都是公开可获取信息的领域。相比之下，预测者基于私密信息（比如公司利用客户记录预测新产品需求）做出预测的例子就少得多。我更喜欢那些读者可以自行验证结果的主题，而不是盲目相信作者的观点。

### A Short Road Map to the Book

The book weaves between examples from the natural sciences, the social sciences, and from sports and games. It builds from relatively straightforward cases, where the successes and failures of prediction are more easily demarcated, into others that require slightly more finesse.

Chapters 1 through 3 consider the failures of prediction surrounding the recent financial crisis, the successes in baseball, and the realm of political prediction—where some approaches have worked well and others haven't. They should get you thinking about some of the most fundamental questions that underlie the prediction problem. How can we apply our judgment to the data—without succumbing to our biases? When does market competition make forecasts better—and how can it make them worse? How do we reconcile the need to use the past as a guide with our recognition that the future may be different?

Chapters 4 through 7 focus on dynamic systems: the behavior of the earth's atmosphere, which brings about the weather; the movement of its tectonic plates, which can cause earthquakes; the complex human interactions that account for the behavior of the American economy; and the spread of infectious diseases. These systems are being studied by some of our best scientists. But dynamic systems make forecasting more difficult, and predictions in these fields have not always gone very well.

Chapters 8 through 10 turn toward solutions—first by introducing you to a sports bettor who applies Bayes's theorem more expertly than many economists or scientists do, and then by considering two other games, chess and poker. Sports and games, because they follow well-defined rules, represent good laboratories for testing our predictive skills. They help us to a better understanding of randomness and uncertainty and provide insight about how we might forge information into knowledge.

Bayes's theorem, however, can also be applied to more existential types of problems. Chapters 11 through 13 consider three of these cases: global warming, terrorism, and bubbles in financial markets. These are hard problems for forecasters and for society. But if we are up to the challenge, we can make our country, our economy, and our planet a little safer.

The world has come a long way since the days of the printing press. Information is no longer a scarce commodity; we have more of it than we know what to do with. But relatively little of it is useful. We perceive it selectively, subjectively, and without much self-regard for the distortions that this causes. We think we want information when we really want knowledge.

The signal is the truth. The noise is what distracts us from the truth. This is a book about the signal and the noise.

本书的阅读指南

本书穿梭于自然科学、社会科学、体育和游戏等多个领域的案例之间。从相对简单直接的案例入手，在这些案例中预测的成败更容易辨别，逐步过渡到需要更复杂方法的复杂案例。

第 1 至 3 章深入探讨了近期金融危机预测中的失败案例、棒球领域的成功实践，以及政治预测领域的不同方法 —— 有些方法卓有成效，而有些则未能奏效。这些章节将引导读者思考预测问题的根本性挑战：我们如何在不被个人偏见干扰的情况下，合理运用数据和判断？市场竞争在何种条件下能提升预测准确性，又可能在哪些情况下降低预测质量？我们如何在尊重历史经验的同时，又充分认识到未来可能呈现的变化？

第 4 至 7 章聚焦于复杂的动态系统（dynamic systems）—— 这些系统具有高度不确定性和非线性特征。包括地球大气层运行机制（影响天气变化）、地质板块运动（可能导致地震）、驱动美国经济运行的复杂人类互动，以及传染性疾病的传播模式。尽管这些系统正由顶尖科学家进行深入研究，但动态系统的固有复杂性使得预测变得尤为困难，在这些领域的预测往往并不尽如人意。

第 8 章至第 10 章聚焦解决方案 —— 首先介绍一位运用贝叶斯定理异常精准的体育博彩专家，其专业水平远超多数经济学家和科学家，随后探讨国际象棋和扑克这两类游戏。由于运动和游戏遵循明确的规则，它们堪称测试预测能力的绝佳实验场。这些案例帮助我们深入理解随机性和不确定性，并为我们如何将信息转化为知识提供独特的洞察。

贝叶斯定理同样适用于更深层次的复杂问题。第 11 章至第 13 章聚焦三个典型案例：全球气候变化、恐怖主义和金融市场泡沫。这些都是预测者和社会共同面临的棘手难题。但只要我们勇于迎接挑战，就能为国家、经济乃至整个地球的安全增添一份保障。

自从印刷机问世以来，我们的信息世界已经发生了翻天覆地的变化。如今，信息唾手可得，多到让人应接不暇。然而，真正有价值的信息其实寥寥无几。我们往往带着主观偏见和选择性视角来接收信息，却很少反思这种接收方式本身可能带来的认知扭曲。表面上我们渴求信息，实际上我们真正需要的是深度理解和洞察。

信号代表真相，而噪音则是蒙蔽真相的迷障。这本书，就是要帮助我们辨别信号与噪音。

## Conclusion

A Major League shortstop has some plays he can always make, some plays he can never make, and some he'll have to dive for. The diving plays are the most spectacular and will catch our attention. But they can lead to a myopic view of the shortstop's abilities.

The legendary shortstop Derek Jeter was a frequent subject of debate during the Moneyball era. Broadcasters and scouts noticed that Jeter seemed to make an especially large number of diving plays and concluded that he was an exceptional shortstop for that reason. Stat geeks crunched the numbers and detected a flaw in this thinking.1 Although Jeter was a terrific athlete, he often got a slow jump on the ball and dove because he was making up for lost time. In fact, the numbers suggested that Jeter was a fairly poor defensive shortstop, despite having won five Gold Glove awards. The plays that Jeter had to dive for, a truly great defensive shortstop like Ozzie Smith might have made easily—perhaps receiving less credit for them because he made them look routine.

FIGURE C-1: SHORTSTOP DIVING RANGES

Whatever range of abilities we have acquired, there will always be tasks sitting right at the edge of them. If we judge ourselves by what is hardest for us, we may take for granted those things that we do easily and routinely.

One of the most spectacularly correct predictions in history was that of the English astronomer Edmund Halley, who in 1705 predicted that a great comet would return to the earth in 1758. Halley had many doubters, but the comet returned just in the nick of time.2 Comets, which in antiquity were regarded as being wholly unpredictable omens from the gods,3 are now seen as uncannily regular and predictable things.

Astronomers predict that Halley's Comet will next make its closest approach to the earth on July 28, 2061. By that time, many problems in the natural world that now vex our predictive abilities will have come within the range of our knowledge.

Nature's laws do not change very much. So long as the store of human knowledge continues to expand, as it has since Gutenberg's printing press, we will slowly come to a better understanding of nature's signals, if never all its secrets.

And yet if science and technology are the heroes of this book, there is the risk in the age of Big Data about becoming too starry-eyed about what they might accomplish.

There is no reason to conclude that the affairs of men are becoming more predictable. The opposite may well be true. The same sciences that uncover the laws of nature are making the organization of society more complex. Technology is completely changing the way we relate to one another. Because of the Internet, "the whole context, all the equations, all the dynamics of the propagation of information change," I was told by Tim Berners-Lee, who invented the World Wide Web in 1990.4

The volume of information is increasing exponentially. But relatively little of this information is useful—the signal-to-noise ratio may be waning. We need better ways of distinguishing the two.

This book is less about what we know than about the difference between what we know and what we think we know. It recommends a strategy so that we might close that gap. The strategy requires one giant leap and then some small steps forward. The leap is into the Bayesian way of thinking about prediction and probability.

在棒球运动中，短击手（守备位置最接近二垒和三垒之间的内野手）面对不同难度的接球时，会有三种情况：有些球他总能接住，有些球永远无法接到，还有一些需要通过高难度的横身跳跃来接球。这些惊险的跳跃接球最为吸引观众的眼球，但也可能导致人们对短击手实际防守能力的片面理解。

在「数据棒球」（一种基于统计分析评估球员价值的方法）时代，传奇短击手德里克·杰特成为热议对象。电视解说和专业球探注意到杰特频繁做出惊人的跳跃接球，因此认为他是一位出色的防守球员。然而，专业统计分析师仔细研究后发现了这种看法中的关键问题 [1]。尽管杰特是位优秀的运动员，但他对来球的反应常常较慢，不得不通过跳跃来弥补初始位置的不利。实际数据表明，杰特其实是一位防守能力相当一般的短击手，尽管他曾获得过五次金手套奖（棒球最佳防守奖）。

对于那些杰特不得不拼命跳跃才能接到的球，像奥齐·史密斯这样真正顶级的防守短击手可能会轻而易举地接住，甚至因为动作看起来如此自然而没有获得太多关注。

图 C-1：短击手跳跃接球范围

无论我们已经掌握了多么广泛的能力，总会有一些任务恰好触及我们能力的极限。如果我们总是以最难完成的任务来衡量自己，就可能忽视那些我们轻松应对的日常事务。

历史上最令人惊叹的预测之一，要数英国天文学家爱德蒙·哈雷在 1705 年对一颗大彗星的预测。他预言这颗彗星将在 1758 年重返地球，尽管当时许多人持怀疑态度，但这颗彗星最终准确无误地按照预测出现。[2] 在古代，彗星被视为来自诸神的不可预测的神谕，[3] 而如今，它们已经被视为异常精确和可预测的天体现象。

天文学家预测，哈雷彗星下次将于 2061 年 7 月 28 日最接近地球。到那时，现在困扰我们预测能力的自然界谜题，很可能已经被我们的知识所揭开。

自然法则变化极其缓慢。只要人类知识的宝库如同古腾堡印刷术问世以来那样不断扩大，我们就能逐步更好地解读自然的信号，尽管永远无法穷尽其全部奥秘。

尽管科学和技术在这本书中堪称主角，但在大数据时代，我们仍需警惕对其能力的盲目崇拜。

我们不能轻易地认为人类社会正变得越来越可预测。事实恰恰相反。揭示自然规律的科学，反而正在让社会运转变得更加错综复杂。技术正彻底改变我们彼此交往的方式。正如发明万维网的 Tim Berners-Lee 所说，因为互联网，「信息传播的整个背景、方程和动态都在发生根本性的变化」。

信息量正以指数级速度膨胀。然而，真正有价值的信息却少之又少 —— 信噪比（即有效信号与无用噪声的比例）正在持续下降。我们迫切需要找到更好的方法来甄别有用信息。

这本书的重点不在于我们已经了解的知识，而是关注我们所知道的和我们以为知道的之间的巨大差距。它提供了一种策略，帮助我们缩小这道鸿沟。这个策略需要一次勇敢的跨越，随后是一系列谨慎的步伐。这次跨越，就是进入贝叶斯概率思维的崭新世界。

### Think Probabilistically

Bayes's theorem begins and ends with a probabilistic expression of the likelihood of a real-world event. It does not require you to believe that the world is intrinsically uncertain. It was invented in the days when the regularity of Newton's laws formed the dominant paradigm in science. It does require you to accept, however, that your subjective perceptions of the world are approximations of the truth.

This probabilistic element of the Bayesian way may seem uncomfortable at first. Unless we grew up playing cards or other games of chance, we were probably not encouraged to think in this way. Mathematics classrooms spend more time on abstract subjects like geometry and calculus than they do on probability and statistics. In many walks of life, expressions of uncertainty are mistaken for admissions of weakness.

When you first start to make these probability estimates, they may be quite poor. But there are two pieces of favorable news. First, these estimates are just a starting point: Bayes's theorem will have you revise and improve them as you encounter new information. Second, there is evidence that this is something we can learn to improve. The military, for instance, has sometimes trained soldiers in these techniques,5 with reasonably good results.6 There is also evidence that doctors think about medical diagnoses in a Bayesian manner.7

It is probably better to follow the lead of our doctors and our soldiers than our television pundits.

• • •

Our brains process information by means of approximation.8 This is less an existential fact than a biological necessity: we perceive far more inputs than we can consciously consider, and we handle this problem by breaking them down into regularities and patterns.

Under high stress, the regularities of life will be stripped away. Studies of people who survived disasters like the September 11 attacks found that they could recall some minute details about their experiences and yet often felt almost wholly disconnected from their larger environments.9 Under these circumstances, our first instincts and first approximations may be rather poor, often failing to recognize the gravity of the threat. Those who had been forced to make decisions under extreme stress before, like on the battlefield, were more likely to emerge as heroes, leading others to safety.10

Our brains simplify and approximate just as much in everyday life. With experience, the simplifications and approximations will be a useful guide and will constitute our working knowledge.11 But they are not perfect, and we often do not realize how rough they are.

Consider the following set of seven statements, which are related to the idea of the efficient-market hypothesis and whether an individual investor can beat the stock market. Each statement is an approximation, but each builds on the last one to become slightly more accurate.

No investor can beat the stock market.

No investor can beat the stock market over the long run.

No investor can beat the stock market over the long run relative to his level of risk.

No investor can beat the stock market over the long run relative to his level of risk and accounting for his transaction costs.

No investor can beat the stock market over the long run relative to his level of risk and accounting for his transaction costs, unless he has inside information.

Few investors beat the stock market over the long run relative to their level of risk and accounting for their transaction costs, unless they have inside information.

It is hard to tell how many investors beat the stock market over the long run, because the data is very noisy, but we know that most cannot relative to their level of risk, since trading produces no net excess return but entails transaction costs, so unless you have inside information, you are probably better off investing in an index fund.

The first approximation—the unqualified statement that no investor can beat the stock market—seems to be extremely powerful. By the time we get to the last one, which is full of expressions of uncertainty, we have nothing that would fit on a bumper sticker. But it is also a more complete description of the objective world.

There is nothing wrong with an approximation here and there. If you encountered a stranger who knew nothing about the stock market, informing him that it is hard to beat, even in the crude terms of the first statement, would be a lot better than nothing.

The problem comes when we mistake the approximation for the reality. Ideologues like Phil Tetlock's hedgehogs behave in this way. The simpler statements seem more universal, more in testament to a greater truth or grander theory. Tetlock found, however, that his hedgehogs were very poor at making predictions. They leave out all the messy bits that make life real and predictions more accurate.

We have big brains, but we live in an incomprehensibly large universe. The virtue in thinking probabilistically is that you will force yourself to stop and smell the data—slow down, and consider the imperfections in your thinking. Over time, you should find that this makes your decision making better.

概率思考

贝叶斯定理（Bayes's theorem）从始至终都是通过概率的方式来表达现实世界事件发生的可能性。它并不要求你相信世界本质上是不确定的，事实上，它诞生于牛顿定律主导科学研究的年代。然而，贝叶斯定理确实需要你接受一个观点：我们对世界的主观认知，本质上是对真相的近似和推测。

对于许多人来说，这种基于概率的思考方式最初可能会让人感到不适。除非从小就接触纸牌或概率游戏，大多数人并不习惯用这种方式思考问题。传统的数学教育更倾向于教授几何和微积分等抽象学科，而很少关注概率与统计。更令人遗憾的是，在现实生活中，人们常常将表达不确定性误解为示弱，这实际上阻碍了我们更理性地看待世界。

当你第一次尝试进行概率估计时，结果可能会相当不准确。但这里有两个令人欣慰的好消息。首先，这些初步估计只是起点：通过贝叶斯定理（Bayes's theorem），你可以随着新信息的出现不断修正和完善你的判断。其次，有证据表明这种能力是可以通过学习来提升的。例如，军队有时会专门训练士兵掌握这些思维技巧，并取得了相当不错的效果。同样，医生在进行医疗诊断时也常常运用类似的概率推理方法。

相比那些夸夸其谈的电视评论员，我们或许更应该向医生和士兵学习。

···

人类的大脑天生就擅长用「快速概括」的方式处理海量信息。这不仅仅是一种思维特征，更是大脑应对复杂世界的生存策略。我们每时每刻接收的信息远远超出大脑能够逐一细致分析的范围，所以大脑会本能地提取关键特征、寻找共同模式，以便快速理解和应对周围的环境。

在极度压力下，生活的常规模式会被瞬间打破。对于 9·11 恐怖袭击等重大灾难的幸存者的研究发现，他们能清晰记住事发时的细微细节，但同时又感到与周围环境极度隔绝。9 在这种情况下，我们最初的直觉和判断往往相当不准确，常常未能意识到威胁的严重程度。那些曾在战场等极端环境中做出决策的人，更可能表现出英雄主义，成功引导他人走向安全。10

我们的大脑在日常生活中同样倾向于简化和概括信息。随着经验的积累，这些简化和概括会逐渐成为有用的认知工具，构成我们的实用知识。11 但它们并不完美，我们常常没有意识到自己认知中存在的粗糙近似。

以下是关于有效市场假说（Efficient Market Hypothesis）的一组陈述，探讨个人投资者是否能够战胜股市。每个陈述都是一个逐步精细化的近似，试图更准确地解释复杂的市场现象。

1 没有投资者能击败股市。

2 在投资领域，长期战胜股市市场几乎是不可能的。

3 即使考虑到个人风险承受能力，普通投资者很难持续超越整体市场表现。

4 当我们将交易成本纳入考虑范围时，战胜股市变得更加困难。

5 只有拥有内部信息的投资者，才可能在长期中获得超额收益。

6 绝大多数投资者难以在考虑风险和交易成本后持续跑赢大盘，除非他们掌握特殊信息渠道。

7 分析投资者长期战胜股市的比例是极其困难的，因为市场数据波动很大。但研究表明，由于交易本身不会产生净额外收益，反而会增加交易成本，大部分投资者最终都难以战胜市场。对于普通投资者来说，通过购买指数基金（追踪大盘整体走势的投资工具）分散风险，是更明智的投资策略。

第一个粗略的近似估计 —— 断言没有投资者能战胜股市 —— 看似极其有力。但当我们推进到最后一个充满不确定性表达的版本时，所得结论已经无法用简单的口号概括。尽管如此，这反而是对客观世界更为全面的描述。

偶尔使用近似估计并非坏事。假如你遇到一个对股市一无所知的陌生人，用简单直白的方式告诉他战胜股市非常困难，这已经比完全不了解要有意义得多。

问题出在将近似估计等同于现实的时候。在 Phil Tetlock 研究中，那些喜欢用单一视角看待问题的「刺猬型思考者」（hedgehogs，指倾向于用单一、简单的理论解释复杂事物的人）就常常犯这种错误。他们认为越简单的陈述越能体现普遍真理，越能印证某种宏大理论。然而，Tetlock 发现这些刺猬型思考者在做预测时恰恰相当糟糕。他们往往忽视了那些使生活真实且预测更精准的复杂细节。

我们拥有大脑，但生活在一个难以理解的浩瀚宇宙中。以概率思维思考的妙处在于，它能帮助我们暂停思考，仔细审视数据，放慢脚步，审视自身思维中的盲点和不足。长此以往，你会发现这种思考方式能显著提升决策质量。

### Know Where You're Coming From

Bayes's theorem requires us to state—explicitly—how likely we believe an event is to occur before we begin to weigh the evidence. It calls this estimate a prior belief.

Where should our prior beliefs come from? Ideally, we would like to build on our past experience or even better the collective experience of society. This is one of the helpful roles that markets can play. Markets are certainly not perfect, but the vast majority of the time, collective judgment will be better than ours alone. Markets form a good starting point to weigh new evidence against, particularly if you have not invested much time in studying a problem.

Of course, markets are not available in every case. It will often be necessary to pick something else as a default. Even common sense can serve as a Bayesian prior, a check against taking the output of a statistical model too credulously. (These models are approximations and often rather crude ones, even if they seem to promise mathematical precision.) Information becomes knowledge only when it's placed in context. Without it, we have no way to differentiate the signal from the noise, and our search for the truth might be swamped by false positives.

What isn't acceptable under Bayes's theorem is to pretend that you don't have any prior beliefs. You should work to reduce your biases, but to say you have none is a sign that you have many. To state your beliefs up front—to say "Here's where I'm coming from"12—is a way to operate in good faith and to recognize that you perceive reality through a subjective filter.

了解你的认知起点

贝叶斯定理（Bayes's theorem）要求我们在开始权衡证据之前，明确阐明对某个事件发生概率的最初判断。这种最初的估计被称为「先验信念」。

那么，先验信念从何而来？理想情况下，我们希望它建立在个人过去经验的基础上，更好的是建立在整个社会的集体经验之上。市场在这一过程中可以发挥重要作用。市场虽然并非完美，但在绝大多数情况下，集体判断往往比个人判断更为准确。对于没有深入研究某个问题的人来说，市场可以提供一个很好的初始参考点，帮助我们权衡新的证据。

在现实世界中，并非所有决策都能通过市场机制来优化。这时，我们常常需要选择其他默认方案。即便是朴素的常识，也可以作为贝叶斯推理（Bayesian inference）的先验知识，帮助我们谨慎看待统计模型的输出结果。(这些模型本质上是近似的，即便看似精确，其实往往相当粗糙。）只有将信息置于特定语境中，它才能转化为真正的知识。缺乏语境，我们就难以区分有效信号和无意义噪声，搜寻真相的过程很可能会被误报所迷惑。

在贝叶斯思维中，最不可取的是装作自己没有任何预设立场。我们应该努力减少个人偏见，但声称自己完全没有偏见，恰恰说明偏见已经根深蒂固。坦诚地阐明自己的立场 —— 解释「我的出发点是什么」—— 不仅是诚实的表现，也是承认每个人对现实的认知都带有主观色彩。

### Try, and Err

This is perhaps the easiest Bayesian principle to apply: make a lot of forecasts. You may not want to stake your company or your livelihood on them, especially at first.* But it's the only way to get better.

Bayes's theorem says we should update our forecasts any time we are presented with new information. A less literal version of this idea is simply trial and error. Companies that really "get" Big Data, like Google, aren't spending a lot of time in model land.* They're running thousands of experiments every year and testing their ideas on real customers.

Bayes's theorem encourages us to be disciplined about how we weigh new information. If our ideas are worthwhile, we ought to be willing to test them by establishing falsifiable hypotheses and subjecting them to a prediction. Most of the time, we do not appreciate how noisy the data is, and so our bias is to place too much weight on the newest data point. Political reporters often forget that there is a margin of error when polls are reported, and financial reporters don't always do a good job of conveying how imprecise most economic statistics are. It's often the outliers that make the news.

But we can have the opposite bias when we become too personally or professionally invested in a problem, failing to change our minds when the facts do. If an expert is one of Tetlock's hedgehogs, he may be too proud to change his forecast when the data is incongruous with his theory of the world. Partisans who expect every idea to fit on a bumper sticker will proceed through the various stages of grief before accepting that they have oversimplified reality.

The more often you are willing to test your ideas, the sooner you can begin to avoid these problems and learn from your mistakes. Staring at the ocean and waiting for a flash of insight is how ideas are generated in the movies. In the real world, they rarely come when you are standing in place.13 Nor do the "big" ideas necessarily start out that way. It's more often with small, incremental, and sometimes even accidental steps that we make progress.

勇于尝试，宽容错误

这或许是最容易落实的贝叶斯原则：大胆做出预测。尤其在初期，你可能不愿意拿公司前途或个人生计冒险。但唯有不断尝试，才能逐步提高洞察力和判断能力。

贝叶斯定理教导我们：每当获得新信息时，就应该及时更新我们的预测。这一理念的实践可以简单理解为不断试错。像谷歌这样真正精通大数据的公司，并不会过多地沉迷于理论模型。他们每年都会进行数千次实验，直接在真实用户中检验自己的想法。

贝叶斯定理鼓励我们以严谨的态度看待新信息。如果我们的观点真的有价值，就应该勇于建立可证伪的假设，并通过预测来验证它们。然而，我们常常低估了数据中的噪音，容易对最新的数据点赋予过高的权重。比如，政治记者在报道民调结果时常常忽视误差范围，金融记者也往往未能充分传达经济统计数据固有的不确定性。在新闻报道中，往往是那些异常值更容易吸引眼球。

当我们对某个问题投入过深时，往往会陷入思维的误区，即使事实已经证明我们的观点有误，也会固执己见。以特洛克描述的「刺猬型专家」为例，他们可能会因为过于自负，在数据与自身世界观相悖时仍死守己见。那些喜欢将复杂问题简单化、追求「口号式」理解的人，往往需要经历一个痛苦的认知过程，才能承认自己对现实的理解过于单一。

越是频繁地质疑和检验自己的想法，就越能及早避免这些认知陷阱，并从中学习。与电影中凭空等待灵感不同，现实世界中的创新很少在原地孕育。真正的突破性想法往往并非一蹴而就，而是通过微小的、渐进的，有时甚至是意外的尝试逐步发展而来。

### Our Perceptions of Predictability

Prediction is difficult for us for the same reason that it is so important: it is where objective and subjective reality intersect. Distinguishing the signal from the noise requires both scientific knowledge and self-knowledge: the serenity to accept the things we cannot predict, the courage to predict the things we can, and the wisdom to know the difference.14

Our views on how predictable the world is have waxed and waned over the years. One simple measure of it is the number of times the words "predictable" and "unpredictable" are used in academic journals.15 At the dawn of the twentieth century, the two words were used almost exactly as often as one another. The Great Depression and the Second World War catapulted "unpredictable" into the dominant position. As the world healed from these crises, "predictable" came back into fashion, its usage peaking in the 1970s. "Unpredictable" has been on the rise again in recent years.

FIGURE C-2: THE PERCEPTION OF PREDICTABILITY, 1900–2012

These perceptions about predictability are more affected by the fashions of the sciences16 and the shortness of our memories—has anything really bad happened recently?—than by any real change in our forecasting skills. How good we think we are at prediction and how good we really are may even be inversely correlated. The 1950s, when the world was still shaken by the war and was seen as fairly unpredictable, was a time of more economic17 and scientific18 productivity than the 1970s, the decade when we thought we could predict everything, but couldn't.

These shifting attitudes have reverberated far beyond academic journals. If you drew the same chart based on the use of the words "predictable" and "unpredictable" in English-language fiction, it would look almost exactly the same as in figure C-2.19 An unpredicted disaster, even if it has no direct effect on us, shakes our confidence that we are in control of our fate.

But our bias is to think we are better at prediction than we really are. The first twelve years of the new millennium have been rough, with one unpredicted disaster after another. May we arise from the ashes of these beaten but not bowed, a little more modest about our forecasting abilities, and a little less likely to repeat our mistakes.

我们对可预测性的感知

预测之所以对我们来说如此困难，正是因为它极其重要：它是客观现实与主观认知交汇的关键点。要在纷繁复杂的信息中（即「噪音」）提取有价值的信息（即「信号」），需要兼具科学的专业洞察力和对自身的深刻认知。这意味着既要有接受无法预测事件的平静心态，又要有预测可掌控事件的勇气，更要有辨别两者区别的智慧。14

人类对世界的可预测性的看法随着时代变迁而不断演变。学术界对「可预测」和「不可预测」这两个词的使用频率，某种程度上反映了这种认知变化。15 在 20 世纪初，这两个词的使用频率几乎相当。但大萧条和第二次世界大战的剧烈动荡，让「不可预测」迅速成为主流表达。随着世界从这些创伤中逐渐恢复，「可预测」重新获得关注，并在 1970 年代达到使用高峰。而近年来，面对全球化、技术革命等复杂挑战，「不可预测」再次开始上升。

图 C-2：1900–2012 年间可预测性的认知变迁

关于可预测性的这些看法，更多地受到科学研究的流行趋势和我们短暂记忆的影响 —— 最近是否真的发生了什么令人不安的事？—— 而非我们预测能力的实际变化。有趣的是，我们对预测能力的自我评估可能与实际水平呈负相关。1950 年代，尽管世界仍被战争阴霾笼罩，被视为极不确定的时期，但其经济发展和科学创新的活力却超过了 1970 年代 —— 那个我们自诩能够预测一切，实际上却能力有限的年代。

这种不断变化的认知态度，已经远远超出了学术界的讨论范围。如果我们追踪英语文学作品中「可预测」和「不可预测」这些词汇的使用频率，绘制出的图表几乎与图 C-2 如出一辙 19。即便是一个出乎意料的灾难，即使它并未直接影响我们，也足以撼动我们对掌控命运的自信心。

我们总是忍不住高估自己的预测能力。新千年的前十二年困难重重，接连不断地发生了一连串意料之外的灾难。但愿我们能从这些磨难中吸取教训，变得更加谦卑，对自身预测能力保持清醒，同时减少重蹈覆辙的可能性。

## ACKNOWLEDGMENTS

As the author Joseph Epstein has noted, it is a lot better to have written a book than to actually be writing one. Writing a book requires a tremendous amount of patience, organization, and discipline, qualities that I lack and that writing a blog do not very much encourage.

I was therefore highly dependent on many others who had those qualities in greater measure, and whose wisdom helped to shape the book in many large and small ways.

Thank you to my parents, Brian David Silver and Sally Thrun Silver, to whom this book is dedicated, and to my sister, Rebecca Silver.

Thank you to Virginia Smith for being a terrific editor in all respects. She, as Laura Stickney, Ann Godoff, and Scott Moyers, believed in the vision of the book. They made few compromises in producing a book that fulfilled that vision and yet tolerated many excuses when I needed more time to get it there.

Thank you to my literary agent, Sydelle Kramer, for helping me to conceive of and sell the project. Her advice was invariably the right kind: gentle enough, but never too gentle, on the many occasions when the book seemed at risk of running off the rails.

Thank you to my research assistant, Arikia Millikan, who provided boundless enthusiasm for the book, and whose influence is reflected in its keen interest in science and technology. Thank you to Julia Kamin, whose organizational skills helped point the way forward when the book was at a critical stage. Thank you to Jane Cavolina and Ellen Cavolina Porter, who produced high-quality transcriptions on a demanding schedule.

Thank you to Emily Votruba, Veronica Windholz, Kaitlyn Flynn, Amanda Dewey, and John Sharp for turning the book around against an extremely tight production schedule, and for their understanding that "today" usually meant "tonight" and that "tonight" usually meant "5 in the morning."

Thank you to Robert Gauldin for his love and support. Thank you to Shashank Patel, Kim Balin, Bryan Joiner, Katie Halper, Jason MacLean, Maryam Saleh, and Jessica Klein for tolerating my rambling on about the book for hours at a time on the one hand or going into hiding for weeks at a time on the other.

Thank you to Micah Cohen at the New York Times, who assisted with this book in more ways than I can count.

Thank you to my bosses and colleagues at the New York Times, especially Megan Liberman, Jim Roberts, David Leonhardt, Lisa Tozzi, Gerry Mullany, Rick Berke, Dick Stevenson, Derek Willis, Matt Ericson, Greg Veis, and Hugo Lindgren, who trusted me to manage the demands of the book production cycle along with those of the news cycle. Thank you to Bill Keller, Gerry Marzorati, and Jill Abramson for bringing me into the New York Times family.

Thank you to John Sides, Andrew Gelman, Tom Schaller, Ed Kilgore, Renard Sexton, Brian McCabe, Hale Stewart, and Sean Quinn for their contributions to the FiveThirtyEight blog.

Thank you to Richard Thaler and Anil Kashyap, of the University of Chicago, for reviewing the chapters related to economics and finance. Thank you to David Carr, Kathy Gauldin, and Page Ashley for reminding me of the importance of finishing the book, and to Will Repko for helping to instill that work ethic that might get it there.

Thank you to Gary Huckabay, Brandon Adams, Rafe Furst, Kevin Goldstein, Keith Urbahn, Matthew Vogel, Rachel Hauser, Jennifer Bloch, Thom Shanker, Kyu-Young Lee, and Mark Goldstein for serving as connectors and facilitators at key points along the way.

Many people were polled on the title of this book. Thank you to Jonah Peretti, Andrea Harner, Kyle Roth, Jessi Pervola, Ruth Welte, Brent Silver, Richard Silver, Amanda Silver, Roie Lindegren, Len Lindegren, Zuben Jelveh, Douglas Jester, Justin Wolfers, J. Stephen Steppard, Robert Erikson, Katie Donalek, Helen Lee, Katha Pollitt, Jeffrey Toobin, David Roberts, Felix Salmon, Hillary Bok, Heather Hurlburt, Art Goldhammer, David Karol, Sara Robinson, Max Sawicky, Michael O'Hare, Marc Tracy, Daniel Davies, E. J. Graff, Paul Starr, Russ Wellen, Jeffrey Hauser, Dana Goldstein, Suzy Khimm, Jonathan Zasloff, Avi Zenilman, James Galbraith, Greg Anrig, Paul Waldman, and Bob Kuttner for providing their advice.

This book is fairly scrupulous about citing the origin of its ideas, but some people I interviewed were more influential in determining its direction than might be inferred by the number of times that they appear in the text. This list includes Daniel Kahneman, Vasik Rajlich, Dr. Alexander "Sandy" McDonald, Roger Pielke Jr., John Rundle, Thomas Jordan, Irene Eckstrand, Phil Gordon, Chris Volinsky, Robert Bell, Tim Berners-Lee, Lisa Randall, Jay Rosen, Simon Jackman, Diane Lauderdale, Jeffrey Sachs, Howard Lederer, Rodney Brooks, Henry Abbott, and Bruce Bueno de Mesquita among others.

I hope to return all these favors someday. I will start by buying the first beer for anybody on this list, and the first three for anybody who should have been, but isn't.

— Nate Silver

Brooklyn, NY