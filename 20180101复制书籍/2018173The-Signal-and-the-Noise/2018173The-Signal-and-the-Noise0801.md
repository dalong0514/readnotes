Nate Silver.(2012).2018173The-Signal-and-the-Noise.Penguin Group => Less and Less and Less Wrong

## 0801Less and Less and Less Wrong

The sports bettor Haralabos "Bob" Voulgaris lives in a gleaming, modernist house in the Hollywood Hills of Los Angeles—all metal and glass, with a pool in the back, like something out of a David Hockney painting. He spends every night from November through June watching the NBA, five games at a time, on five Samsung flat screens (the DirecTV guys had never seen anything like it). He escapes to his condo at Palms Place in Las Vegas whenever he needs a short break, and safaris in Africa when he needs a longer one. In a bad year, Voulgaris makes a million dollars, give or take. In a good year, he might make three or four times that.

So Bob enjoys some trappings of the high life. But he doesn't fit the stereotype of the cigar-chomping gambler in a leisure suit. He does not depend on insider tips, crooked referees, or other sorts of hustles to make his bets. Nor does he have a "system" of any kind. He uses computer simulations, but does not rely upon them exclusively.

What makes him successful is the way that he analyzes information. He is not just hunting for patterns. Instead, Bob combines his knowledge of statistics with his knowledge of basketball in order to identify meaningful relationships in the data.

This requires a lot of hard work—and sometimes a lot of guts. It required a big, calculated gamble to get him to where he is today.

• • •

Voulgaris grew up in Winnipeg, Manitoba, a hardworking but frostbitten city located ninety miles north of the Minnesota border. His father had once been quite wealthy—worth about $3 million dollars at his peak—but he blew it all gambling. By the time Voulgaris was twelve, his dad was broke. By the time he was sixteen, he realized that if he was going to get the hell out of Winnipeg, he needed a good education and would have to pay for it himself. So while attending the University of Manitoba, he looked for income wherever he could find it. In the summers, he'd go to the far northern reaches of British Columbia to work as a tree climber; the going rate was seven cents per tree. During the school year, he worked as an airport skycap, shuttling luggage back and forth for Winnipeggers bound for Toronto or Minneapolis or beyond.

Voulgaris eventually saved up to buy out a stake in the skycap company that he worked for and, before long, owned much of the business. By the time he was a college senior, in 1999, he had saved up about $80,000.

But $80,000 still wasn't a lot of money, Voulgaris thought—he'd seen his dad win and lose several times that amount many times over. And the job prospects for a philosophy major from the University of Manitoba weren't all that promising. He was looking for a way to accelerate his life when he came across a bet that he couldn't resist.

That year, the Los Angeles Lakers had hired the iconoclastic coach Phil Jackson, who had won six championships with the Chicago Bulls. The Lakers had plenty of talent: their superstar center, the seven-foot-one behemoth Shaquille O'Neal, was at the peak of his abilities, and their twenty-one-year-old guard Kobe Bryant, just four years out of high school, was turning into a superstar in his own right. Two great players—a big man like O'Neal and a scorer like Bryant—has long been a formula for success in the NBA, especially when they are paired with a great coach like Jackson who could manage their outsize egos.

And yet conventional wisdom was skeptical about the Lakers. They had never gotten into a rhythm the previous year, the strike-shortened season of 1998–99, when they churned through three coaches and finished 31-19, eliminated in four straight games by the San Antonio Spurs in the second round of the playoffs. Bryant and O'Neal were in a perpetual feud, with O'Neal apparently jealous that Bryant—still not old enough to drink legally—was on the verge of eclipsing him in popularity, his jersey outselling O'Neal's in Los Angeles sporting goods stores.1 The Western Conference was strong back then, with cohesive and experienced teams like San Antonio and Portland, and the rap was that the Lakers were too immature to handle them.

When the Lakers were blown out by Portland in the third game of the regular season, with O'Neal losing his cool and getting ejected midway through the game, it seemed to confirm all the worst fears of the pundits and the shock jocks. Even the hometown Los Angeles Times rated the Lakers as just the seventh-best team in the NBA2 and scolded Vegas handicappers for having given them relatively optimistic odds, 4-to-1 against, of winning the NBA title before the season had begun.

Just a couple of weeks into the 1999–2000 regular season, the Vegas bookmakers had begun to buy into the skepticism and had lengthened the Lakers' odds to 6½ to 1, making for a much better payout for anyone who dared to buck the conventional wisdom. Voulgaris was never a big believer in conventional wisdom—it's in large part its shortcomings that make his lifestyle possible—and he thought this was patently insane. The newspaper columnists and the bookies were placing too much emphasis on a small sample of data, ignoring the bigger picture and the context that surrounded it.

The Lakers weren't even playing that badly, Voulgaris thought. They had won five of their first seven games despite playing a tough schedule, adjusting to a new coach, and working around an injury to Bryant, who had hurt his wrist in the preseason and hadn't played yet. The media was focused on their patchy 1998–99 season, which had been interrupted by the strike and the coaching changes, while largely ignoring their 61-21 record under more normal circumstances in 1997–98. Voulgaris had watched a lot of Lakers games: he liked what Jackson was doing with the club. So he placed $80,000—his entire life savings less a little he'd left over for food and tuition—on the Lakers to win the NBA championship. If he won his bet, he'd make half a million dollars. If he lost it, it would be back to working double shifts at the airport.

Initially, Voulgaris's instincts were looking very good. From that point in the season onward, the Lakers won 62 of their remaining 71 contests, including three separate winning streaks of 19, 16, and 11 games. They finished at 67-15, one of the best regular-season records in NBA history. But the playoffs were another matter: the Western Conference was brutally tough in those years, and even with home-court advantage throughout the playoffs—their reward for their outstanding regular season—winning four series in a row would be difficult for the Lakers.

Los Angeles survived a scare against a plucky Sacramento Kings team in the first round of the playoffs, the series going to a decisive fifth game, and then waltzed past Phoenix in the Western Conference Semifinals. But in the next round they drew the Portland Trail Blazers, who had a well-rounded and mature roster led by Michael Jordan's former sidekick—and Jackson's former pupil—Scottie Pippen. Portland would be a rough matchup for the Lakers: although they lacked the Lakers' talent, their plodding, physical style of play often knocked teams out of their rhythm.3

The Lakers won the first game of the best-of-seven series fairly easily, but then the roller-coaster ride began. They played inexplicably poorly in the second game in Los Angeles, conceding twenty consecutive points to Portland in the third quarter4 and losing 106-77, their most lopsided defeat of the season.5

The next two games were played at the Rose Garden in Portland, but in Game 3, the Lakers gathered themselves after falling down by as many as thirteen points in the first half, with Bryant swatting away a shot in the final seconds to preserve a two-point victory.6 They defied gravity again in Game 4, overcoming an eleven-point deficit as O'Neal, a notoriously poor free-throw shooter, made all nine of his attempts.7 Trailing three games to one in the series, the Trail Blazers were "on death's door," as Jackson somewhat injudiciously put it.8

But in the fifth game, at the Staples Center in Los Angeles, the Lakers couldn't shoot the ball straight, making just thirty of their seventy-nine shots in a 96-88 defeat. And in the sixth, back in Portland, they fell out of rhythm early and never caught the tune, as the Blazers marched to a 103-93 win. Suddenly the series was even again, with the deciding Game 7 to be played in Los Angeles.

The prudent thing for a gambler would have been to hedge his bet. For instance, Voulgaris could have put $200,000 on Portland, who were 3-to-2 underdogs, to win Game 7. That would have locked in a profit. If the Blazers won, he would make more than enough from his hedge to cover the loss of his original $80,000 bet, still earning a net profit of $220,000.9 If the Lakers won instead, his original bet would still pay out—he'd lose his hedge, but net $320,000 from both bets combined.* That would be no half-million-dollar score, but still pretty good.

But there was a slight problem: Voulgaris didn't have $200,000. Nor did he know anybody else who did, at least not anybody he could trust. He was a twenty-three-year-old airport skycap living in his brother's basement in Winnipeg. It was literally Los Angeles or bust.

Early on in the game his chances didn't look good. The Blazers went after O'Neal at every opportunity, figuring they'd either force him to the free-throw line, where every shot was an adventure, or get him into foul trouble instead as he retaliated. Halfway through the second quarter, the strategy was working to a tee, as O'Neal had picked up three fouls and hadn't yet scored from the field. Then Portland went on a ferocious run midway through the third quarter, capped off by a Pippen three-pointer that gave them a sixteen-point lead as boos echoed throughout the Staples Center.10

Voulgaris's odds at that point were very long. Rarely did a team11 that found itself in the Lakers' predicament—down sixteen points with two minutes left to play in the third quarter—come back to win the game; it can be calculated that the odds were about 15-to-1 against their doing so.12 His bet—his ticket out of Winnipeg—looked all but lost.13

But early in the fourth quarter, the downside to Portland's brutally physical style of play suddenly became clear. Their players were beaten-up and fatigued, running on fumes and adrenaline. The Lakers were playing before their home crowd, which physiologists have shown provides athletes with an extra burst of testosterone when they need it most.14 And the Lakers were the younger team, with a more resilient supply of energy.

Portland, suddenly, couldn't hit a shot, going more than six minutes without scoring early in the fourth quarter, right as the Lakers were quickening their pace. L.A. brought their deficit down to single digits, then five points, then three, until Brian Shaw hit a three-pointer to even the score with four minutes left, and Bryant knotted two free-throws a couple of possessions later to give them the lead. Although Portland's shooting improved in the last few minutes, it was too late, as the Lakers made clear with a thunderous alley-oop between their two superstars, Bryant and O'Neal, to clinch the game.

Two weeks later, the Lakers disposed of the Indiana Pacers in efficient fashion to win their first NBA title since the Magic Johnson era. And Bob the skycap was halfway to becoming a millionaire.

运动博彩高手哈拉拉博斯「鲍勃」沃尔加里斯的家位于洛杉矶好莱坞山，是一栋典型的现代主义住宅 —— 通体由金属和玻璃打造，后院还有一个泳池，俨然一幅大卫·霍克尼的画作。从每年 11 月到次年 6 月，他都会同时观看五场 NBA 比赛，用五台三星大屏幕（这阵势连 DirecTV 的技术人员都大开眼界）。偶尔需要短暂休息时，他会躲进拉斯维加斯的棕榈广场公寓；想彻底放松就会跑到非洲探险。

在不太顺利的年份，鲍勃能轻松赚到百来万美元；运气好的时候，收入甚至能翻上三四倍。

看起来，鲍勃已经拥有了令人羡慕的奢华生活。但他绝不是传统印象中那种嚼着雪茄、穿着花哨休闲服的赌徒。他既不依赖内部消息，也不指望黑哨作假，更没有所谓的「固定套路」。虽然会使用电脑模拟辅助决策，但从不盲目迷信这些技术。

他的成功源于独特的信息分析方法。Bob 不只是机械地寻找数据模式，而是巧妙地将统计学和篮球专业知识相结合，从数据中发现深层次的、有价值的洞察。

这条路注定不平坦 —— 需要持续不断的努力和过人的勇气。只有通过一次又一次精心策划的大胆尝试，他才最终建立起自己的独特优势。

在加拿大寒冷的温尼伯，Voulgaris 经历了一段艰难的成长岁月。这座位于明尼苏达州边境北方 90 英里的城市，见证了他不屈不挠的奋斗历程。他的父亲曾经是一个百万富翁，资产高达 300 万美元，但由于沉迷赌博，最终输掉了所有家产。

面对家庭的经济困境，年仅 16 岁的 Voulgaris 意识到只有靠自己才能改变命运。在马尼托巴大学求学期间，他拼命地寻找各种赚钱机会。夏天，他会不畏艰险地前往不列颠哥伦比亚省最北端，以每棵树仅 7 美分的微薄报酬从事树木砍伐工作。学期间，他在机场担任行李员，为往返于多伦多、明尼阿波利斯等城市的旅客搬运行李。

凭借顽强的毅力和勤奋，Voulgaris 逐渐积累资本，最终购买了行李员公司的股份，并迅速发展成为公司的主要所有者。到 1999 年大学毕业时，他已经成功积累了 8 万美元的资金，为未来的发展奠定了基础。

8 万美元对于 Voulgaris 来说还算不上什么大钱 —— 他早已见惯了父亲输赢几倍于此的赌局。作为一个曼尼托巴大学的哲学专业毕业生，他面临着并不宽阔的职业前景。就在此时，他遇到了一个令人无法抵挡的赌注，或许能为他的人生按下「快进」键。

那一年，洛杉矶湖人队请来了极具个人风格的教练 Phil Jackson，这位曾在芝加哥公牛队率队夺得六次冠军的传奇教头。湖人队可谓是群星璀璨：七英尺一的超级中锋 Shaquille O'Neal 正处于职业生涯的巅峰期，而年仅 21 岁的后卫 Kobe Bryant，自高中毕业仅四年，已然绽放出超级巨星的光芒。在 NBA 的历史上，像 O'Neal 这样的内线大佬和 Bryant 这样的得分机器的黄金搭档，再加上能妥善处理球星们强大个性的杰出教练 Jackson，向来是制胜的经典配方。

那时，外界对湖人队的前景持谨慎态度。在 1998-99 赛季这个被罢工缩短的赛季中，球队接连更换了三位主教练，全季 29 场比赛仅获得 31 胜 19 负，最终在季后赛第二轮被圣安东尼奥马刺队横扫出局。布莱恩特和奥尼尔之间的矛盾由来已久，奥尼尔显然嫉妒这位年轻得连酒都不能合法饮用的队友正迅速超越自己的人气，在洛杉矶的体育用品店里，布莱恩特的球衣销量已经超过了奥尼尔。当时，西部联盟群雄并起，圣安东尼奥和波特兰等经验丰富、战术默契的球队层出不穷，外界普遍质疑湖人队缺乏成熟度，是否能够在这样的竞争环境中立足。

当湖人队在常规赛第三场比赛中被波特兰队大比分击败，奥尼尔在比赛中途情绪失控被罚出场时，这似乎印证了媒体评论员和极端言论主持人最悲观的预测。就连洛杉矶本地的时报也仅将湖人队评为 NBA 第七强球队，并对拉斯维加斯博彩公司在赛季开始前给出的 4 比 1 夺冠赔率持批评态度。

赛季初的几周里，拉斯维加斯的博彩公司开始接受这种悲观情绪，将湖人队的夺冠赔率延长到 6½ 比 1，这对于那些敢于挑战传统观点的人来说，意味着更高的潜在回报。Voulgaris 从未盲目相信传统观点 —— 恰恰是这些观点的局限性，造就了他独特的生存之道。他认为这种看法简直荒谬至极。报纸专栏作家和博彩公司过分看重了有限的数据样本，忽视了更宏观的全局和背后的复杂脉络。

湖人队的表现并不像外界批评的那么糟，Voulgaris 心中很清楚。尽管面临艰难的赛程，正在适应新教练，还要应对 Bryant 因赛前手腕受伤尚未登场的困难，球队依然在前七场比赛中取得了五场胜利。媒体过分聚焦于他们 1998-99 赛季被罢工和教练变动中断的零碎战绩，却忽视了球队在 1997-98 赛季更为正常环境下稳定的 61 胜 21 负成绩。Voulgaris 对 Lakers 的比赛了如指掌，他很欣赏 Jackson 的执教风格。于是，他毅然决定将自己全部的生命积蓄 80,000 美元（仅留少许维持生活和学费）押注球队夺取 NBA 总冠军。如果赌注成功，他将赚得 50 万美元；如果失败，他就只能重返机场，继续从事繁重的轮班工作。

最初，Voulgaris 的预测看起来非常精准。从那个赛季的这个时期开始，湖人队在接下来的 71 场比赛中赢得了 62 场，其中包括三次令人印象深刻的连胜：19 场、16 场和 11 场。他们最终以 67 胜 15 负的战绩结束常规赛，这是 NBA 历史上最出色的战绩之一。

然而，季后赛的情况却截然不同。那些年的 NBA 西部联盟竞争极其激烈，即便湖人队凭借出色的常规赛成绩获得了全程主场优势，连续赢得四个系列赛仍然是一项艰巨的挑战。

在季后赛第一轮，洛杉矶湖人队险险战胜了顽强的萨克拉门托国王队，这个系列赛一直鏖战到决胜的第五场。随后，他们在西部联盟半决赛中轻松击败了菲尼克斯太阳队。但在接下来的比赛中，他们遇到了实力更强的波特兰开拓者队。这支球队拥有一个全面且成熟的阵容，由迈克尔·乔丹的前队友、菲尔·杰克逊的前学生斯科特·皮蓬领导。

波特兰开拓者对湖人队构成了一个棘手的对手。尽管他们的整体实力不及湖人，但他们缓慢而充满对抗性的打法常常能够破坏对手的节奏和战术部署，使对手感到极大的压力。

湖人队在七场四胜制系列赛的第一场比赛中轻松获胜，但随后比赛就进入了惊心动魄的过山车模式 [4]。他们在洛杉矶的第二场比赛中表现反常，在第三节让波特兰队连续攻入 20 分，最终以 106-77 惨败，这是本赛季最为狼狈的一场比赛 [5]。

接下来的两场比赛在波特兰的玫瑰花园球馆进行。在第三场比赛中，湖人队在上半场落后多达 13 分后奋起反击，布莱恩特在比赛最后几秒钟果断封盖了对方的投篮，以微弱的两分优势险胜 [6]。在第四场比赛中，他们再次上演绝地反击，克服了 11 分的落后局面，向所有人证明了不可能。当时，以罚球投篮糟糕而闻名的奥尼尔却罕见地命中了全部 9 次罚球 [7]。随着比赛战况发展，开拓者队已经处于「穷途末路」，正如主教练杰克逊略显不恰当地形容的那样 [8]。

但在洛杉矶的斯台普斯中心举行的第五场比赛中，湖人队投篮状态低迷，79 次投篮中仅命中 30 个，以 96-88 惨败。在第六场比赛中，重返波特兰的他们从一开始就失去了节奏，再也无法找回状态，开拓者队以 103-93 轻松获胜。就这样，系列赛再次战成平局，决定性的第七场将在洛杉矶进行。

对于一个赌徒来说，最审慎的做法是对赌注进行对冲。打个比方，Voulgaris 可以在开拓者队以 3 比 2 的不利赔率下押 20 万美元赌他们赢得第七场。这样就能锁定一定的利润。如果开拓者队获胜，他从对冲中赚取的钱足以弥补原来 8 万美元赌注的损失，仍然能赚取 22 万美元的净利润。如果湖人队获胜，他的原始赌注仍将支付出去 —— 尽管会损失对冲的赌注，但两次赌注总计仍可净赚 32 万美元。这虽然不及 50 万美元的大赢，但也算是相当不错的收获了。

但这里有个小问题：Voulgaris 身上没有 20 万美元。他也不认识有这笔钱的人，至少没有值得信赖的人。作为一名 23 岁的机场行李员，他只能寄居在温尼伯兄弟的地下室，这趟洛杉矶之行就是他的最后一搏。

比赛初期，形势对他极其不利。开拓者队处心积虑地针对奥尼尔，打算要么把他逼到罚球线上（那里简直是他的噩梦），要么激怒他制造犯规。第二节中途，这个策略已经相当奏效：奥尼尔已经犯了三次规，场上还没有命中过一个投篮。随后在第三节，波特兰发起狂飙猛进的反击，由皮蓬命中的三分球封顶，一举领先 16 分。顿时，斯台普斯中心响起此起彼伏的嘘声和怒吼 [10]。

在这一刻，Voulgaris 几乎已经输掉了赌注。在 NBA 历史上，很少有球队能在如此不利的情况下反败为胜 —— 落后 16 分，距离第三节结束仅剩两分钟。统计显示，他们获胜的概率不到 7%，基本上可以说是必输无疑。这个赌注对他来说意味着逃离温尼伯的希望，如今已经近乎破灭。

然而，在第四节初期，波特兰队极其拼命的打法暴露出致命的弱点。他们的球员已经精疲力尽，正勉强依靠最后一丝斗志和肾上腺素支撑。相比之下，Lakers 在主场作战，观众的呐喊仿佛能为球员注入强心针。生理学研究表明，主场环境能在关键时刻为运动员提供额外的荷尔蒙激励。更重要的是，Lakers 阵中更年轻的球员此刻正处于最佳状态，体能储备充沛。

波特兰队突然间进攻陷入低谷，在第四节早期超过六分钟没有得到一分，恰好在这时湖人队开始加快比赛节奏。洛杉矶队逐步缩小比分差距：从两位数追至五分，再到三分，直到布莱恩·肖命中一记关键三分球将比分扳平（距离比赛结束还有四分钟）。随后，布莱恩特连续命中两个罚球，帮助球队取得领先。尽管波特兰队在最后几分钟的投篮有所好转，但已为时已晚。湖人队的超级双星布莱恩特和奥尼尔上演了一记雷霆般的空中配合，为比赛画上了完美的句号。

两周后，湖人队以迅雷不及掩耳之势击败印第安纳步行者，赢得了自魔术·约翰逊时代以来的首个 NBA 总冠军。鲍勃这位机场行李员（skycap）已经距离成为百万富翁不远了。

### How Good Gamblers Think

How did Voulgaris know that his Lakers bet would come through? He didn't. Successful gamblers—and successful forecasters of any kind—do not think of the future in terms of no-lose bets, unimpeachable theories, and infinitely precise measurements. These are the illusions of the sucker, the sirens of his overconfidence. Successful gamblers, instead, think of the future as speckles of probability, flickering upward and downward like a stock market ticker to every new jolt of information. When their estimates of these probabilities diverge by a sufficient margin from the odds on offer, they may place a bet.

The Vegas line on the Lakers at the time that Voulgaris placed his bet, for instance, implied that they had a 13 percent chance of winning the NBA title. Voulgaris did not think the Lakers' chances were 100 percent or even 50 percent—but he was confident they were quite a bit higher than 13 percent. Perhaps more like 25 percent, he thought. If Voulgaris's calculation was right, the bet had a theoretical profit of $70,000.

FIGURE 8-1: HOW VOULGARIS SAW HIS LAKERS BET

Outcome

Probability

Net Profit

Lakers win championship

25%

+$520,000

Lakers do not win championship

75%

–$80,000

Expected profit

+$70,000

If the future exists in shades of probabilistic gray to the forecaster, however, the present arrives in black and white. Bob's theoretical profit of $70,000 consisted of a 25 percent chance of winning $520,000 and a 75 percent chance of losing $80,000 averaged together. Over the long term, the wins and losses will average out: the past and the future, to a good forecaster, can resemble one another more than either does the present since both can be expressed in terms of long-run probabilities. But this was a one-shot bet. Voulgaris needed to have a pretty big edge (the half dozen different reasons he thought the bookies undervalued the Lakers), and a pretty big head on his shoulders, in order to make it.

FIGURE 8-2: THE WORLD THROUGH THE EYES OF A SUCCESSFUL GAMBLER

Now that Voulgaris has built up a bankroll for himself, he can afford to push smaller edges. He might place three or four bets on a typical night of NBA action. While the bets are enormous by any normal standard they are small compared with his net worth, small enough that he can seem glumly indifferent about them. On the night that I visited, he barely blinked an eye when, on one of the flat screens, the Utah Jazz inserted a seven-foot-two Ukrainian stiff named Kyrylo Fesenko into the lineup, a sure sign that they were conceding the game and that Voulgaris would lose his $30,000 bet on it.

Voulgaris's big secret is that he doesn't have a big secret. Instead, he has a thousand little secrets, quanta of information that he puts together one vector at a time. He has a program to simulate the outcome of each game, for instance. But he relies on it only if it suggests he has a very clear edge or it is supplemented by other information. He watches almost every NBA game—some live, some on tape—and develops his own opinions about which teams are playing up to their talent and which aren't. He runs what is essentially his own scouting service, hiring assistants to chart every player's defensive positioning on every play, giving him an advantage that even many NBA teams don't have. He follows the Twitter feeds of dozens of NBA players, scrutinizing every 140-character nugget for relevance: a player who tweets about the club he's going out to later that night might not have his head in the game. He pays a lot of attention to what the coaches say in a press conference and the code that they use: if the coach says he wants his team to "learn the offense" or "play good fundamental basketball," for instance, that might suggest he wants to slow down the pace of the game.

To most people, the sort of things that Voulgaris observes might seem trivial. And in a sense, they are: the big and obvious edges will have been noticed by other gamblers, and will be reflected in the betting line. So he needs to dig a little deeper.

Late in the 2002 season, for instance, Voulgaris noticed that games involving the Cleveland Cavaliers were particularly likely to go "over" the total for the game. (There are two major types of sports bets, one being the point spread and the other being the over-under line or total—how many points both teams will score together.) After watching a couple of games closely, he quickly detected the reason: Ricky Davis, the team's point guard and a notoriously selfish player, would be a free agent at the end of the year and was doing everything he could to improve his statistics and make himself a more marketable commodity. This meant running the Cavaliers' offense at a breakneck clip in an effort to create as many opportunities as possible to accumulate points and assists. Whether or not this was good basketball didn't much matter: the Cavaliers were far out of playoff contention.15 As often as not, the Cavaliers' opponents would be out of contention as well and would be happy to return the favor, engaging them in an unspoken pact to play loose defense and trade baskets in an attempt to improve one another's stats.16 Games featuring the Cavaliers suddenly went from 192 points per game to 207 in the last three weeks of the season.17 A bet on the over was not quite a sure thing—there are no sure things—but it was going to be highly profitable.

Patterns like these can sometimes seem obvious in retrospect: of course Cavaliers games were going to be higher-scoring if they had nothing left to play for but to improve their offensive statistics. But they can escape bettors who take too narrow-minded a view of the statistics without considering the context that produce them. If a team has a couple of high-scoring games in a row, or even three or four, it usually doesn't mean anything. Indeed, because the NBA has a long season—thirty teams playing eighty-two games each—little streaks like these will occur all the time.18 Most of them are suckers' bets: they will have occurred for reasons having purely to do with chance. In fact, because the bookmakers will usually have noticed these trends as well, and may have overcompensated for them when setting the line, it will sometimes be smart to bet the other way.

So Voulgaris is not just looking for patterns. Finding patterns is easy in any kind of data-rich environment; that's what mediocre gamblers do. The key is in determining whether the patterns represent noise or signal.

But although there isn't any one particular key to why Voulgaris might or might not bet on a given game, there is a particular type of thought process that helps govern his decisions. It is called Bayesian reasoning.

优秀赌徒的思维方式

Voulgaris 怎么能确定他的湖人队赌注会成功？事实上，他并不能。成功的赌徒 —— 乃至任何领域的成功预测者 —— 都不会把未来看作是稳赚不赔的赌注、绝对无误的理论或精确到极致的测量。这些都是外行人的幻想，是过度自信的陷阱。

相反，成功的赌徒会将未来视为概率的闪烁点，就像股市行情显示屏上的指标一样，随着每一个新的信息波动而上下浮动。当他们对这些概率的估计与市场提供的赔率存在显著差异时，才会决定下注。

以 Voulgaris 下注时的情况为例，拉斯维加斯给出的赔率暗示湖人队赢得 NBA 总冠军的概率仅为 13%。Voulgaris 并不认为球队能稳赢，甚至连 50% 的胜算都不到 —— 但他相信球队的获胜概率远高于 13%。他估计大约是 25%。如果这个计算是正确的，这个赌注的理论利润将达到 7 万美元。

图 8-1：Voulgaris 对湖人队赌注的概率分析结果 

| - | 概率 | 净利润 |
| --- | --- | --- | 
| 湖人队赢得冠军 | 25% | +$520,000 |
| 湖人队未赢得冠军 | 75% | -$80,000 |

预期收益

+$70,000

对于专业预测者而言，未来往往笼罩在概率的迷雾中，而现实却是清晰的黑与白。Bob 这笔看似 $70,000 的理论收益，实则是由两种可能性加权计算而来：25% 的概率能赢得 $520,000，但同时有 75% 的概率损失 $80,000。从统计学角度看，长期的输赢会趋于平衡。对于经验丰富的分析师来说，过去和未来都可以用概率模型进行描述，比当下更具可预测性。

然而，这是一次性的投注，意味着风险和不确定性更高。Voulgaris 需要具备两个关键条件：首先，对赛事有深入的专业洞察（他列举了六个认为博彩公司低估湖人队的理由）；其次，拥有足够的心理素质，能在高度不确定的环境中做出判断。

图 8-2：成功赌徒眼中的世界

随着个人资产的不断积累，Voulgaris 现在能够从容应对小概率获利的赌局。在一个平常的 NBA 比赛夜，他通常会押注三到四场比赛。尽管从普通标准来看这些赌注金额惊人，但与他的身家相比却微不足道，小到他对输赢近乎漠然。就在我拜访的那个晚上，当犹他爵士队派出身高 2.18 米的乌克兰中锋费森科上场时，他甚至没有眨眼 —— 这明显是对方已经放弃比赛，意味着他将输掉 3 万美元的赌注。

Voulgaris 的制胜法宝并非某个惊天大招，而是由无数细微情报拼接而成的信息网。他开发了一个模拟比赛结果的程序，但仅在极其明确能获得优势，或有其他信息佐证时才启用。他几乎观看每一场 NBA 比赛 —— 有现场直播，也有录像回放 —— 并独立判断哪支球队正在充分发挥实力。

他实际上运营着一个私人球探团队，雇佣助手详细记录每名球员在每一个回合的防守站位，获得了许多 NBA 球队都没有的竞争优势。他密切关注数十位 NBA 球员的社交媒体动态，仔细捕捉每一条微小信息：比如，一个球员在社交媒体上发布当晚要去的夜店，可能暗示他的注意力没有集中在比赛上。

此外，他还格外留意教练们在新闻发布会上的言辞和潜台词。例如，如果教练表示希望球队「学习进攻打法」或「打好基础篮球」，这可能暗示他想放缓比赛节奏。

对于普通人而言，Voulgaris 所观察的细节似乎微不足道。事实上，确实如此：那些显而易见的赌博优势早已被其他赌徒洞察，并最终体现在博彩赔率上。因此，要获得竞争优势，他必须更加深入地分析和挖掘隐藏的细节。

在 2002 赛季末期，Voulgaris 发现了一个有趣的规律：凡是克利夫兰骑士队参与的比赛，总分往往会异常高。在体育博彩中，人们既可以押注球队间的分数差距（点差），也可以押注双方总得分（总分）。

仔细观察后，他很快找到了原因：球队的控球后卫 Ricky Davis 是出了名的「个人英雄主义」球员。由于赛季即将结束，他即将成为自由球员，因此极力想通过个人数据吸引其他球队的注意。这导致他以近乎疯狂的节奏组织进攻，不断制造得分和助攻机会。此时的骑士队早已无缘季后赛，球队的打法甚至可以说是「及格万岁」。

更有意思的是，对手球队通常也已经与季后赛无缘。双方似乎达成了一种默契：放松防守，互相喂饼，只为刷好个人数据。结果就是，骑士队的比赛总分在赛季最后三周里，硬是从平均 192 分飙升到 207 分。

对 Voulgaris 来说，这简直就是「送上门」的商机。虽然没有绝对的「必赢」，但这样的下注几乎是稳赚不赔。

这类模式往往在事后看来显得很理所当然：当骑士队别无选择，只能专注提高进攻数据时，他们的比赛得分自然会更高。然而，对于那些只关注表面数据，忽视背景因素的投注者来说，这些微妙的规律可能会被轻易忽视。

在 NBA 这样漫长的赛季中 —— 三十支球队，每支球队打八十二场比赛 —— 某支球队连续几场比赛得分居高不下，其实并不罕见，也不一定意味着什么重大变化。大多数这类短期趋势不过是碰巧出现的统计波动，本质上可以归结为运气使然。更有趣的是，由于博彩公司同样会注意到这些趋势，并可能在赔率设置上做出过度调整，有时反向下注反而更明智。

对于 Voulgaris 这样的专业人士而言，寻找模式本身并不困难 —— 在数据丰富的环境中，这几乎是业余赌徒的标配行为。真正的挑战在于准确判断：这些看似有规律的模式究竟是随机噪音，还是值得深入挖掘的有效信号。

尽管没有某个特定的关键能够完全解释 Voulgaris 是否会对某场比赛下注，但他的决策背后确实存在一种独特的思维模式。这种思维方法就是贝叶斯推理。

### The Improbable Legacy of Thomas Bayes

Thomas Bayes was an English minister who was probably born in 1701—although it may have been 1702. Very little is certain about Bayes's life, even though he lent his name to an entire branch of statistics and perhaps its most famous theorem. It is not even clear that anybody knows what Bayes looked like; the portrait of him that is commonly used in encyclopedia articles may have been misattributed.19

What is in relatively little dispute is that Bayes was born into a wealthy family, possibly in the southeastern English county of Hertfordshire. He traveled far away to the University of Edinburgh to go to school, because Bayes was a member of a Nonconformist church rather than the Church of England, and was banned from institutions like Oxford and Cambridge.20

Bayes was nevertheless elected as a Fellow of the Royal Society despite a relatively paltry record of publication, where he may have served as a sort of in-house critic or mediator of intellectual debates. One work that most scholars attribute to Bayes—although it was published under the pseudonym John Noon21—is a tract entitled "Divine Benevolence."22 In the essay, Bayes considered the age-old theological question of how there could be suffering and evil in the world if God was truly benevolent. Bayes's answer, in essence, was that we should not mistake our human imperfections for imperfections on the part of God, whose designs for the universe we might not fully understand. "Strange therefore . . . because he only sees the lowest part of this scale, [he] should from hence infer a defeat of happiness in the whole," Bayes wrote in response to another theologian.23

Bayes's much more famous work, "An Essay toward Solving a Problem in the Doctrine of Chances,"24 was not published until after his death, when it was brought to the Royal Society's attention in 1763 by a friend of his named Richard Price. It concerned how we formulate probabilistic beliefs about the world when we encounter new data.

Price, in framing Bayes's essay, gives the example of a person who emerges into the world (perhaps he is Adam, or perhaps he came from Plato's cave) and sees the sun rise for the first time. At first, he does not know whether this is typical or some sort of freak occurrence. However, each day that he survives and the sun rises again, his confidence increases that it is a permanent feature of nature. Gradually, through this purely statistical form of inference, the probability he assigns to his prediction that the sun will rise again tomorrow approaches (although never exactly reaches) 100 percent.

The argument made by Bayes and Price is not that the world is intrinsically probabilistic or uncertain. Bayes was a believer in divine perfection; he was also an advocate of Isaac Newton's work, which had seemed to suggest that nature follows regular and predictable laws. It is, rather, a statement—expressed both mathematically and philosophically—about how we learn about the universe: that we learn about it through approximation, getting closer and closer to the truth as we gather more evidence.

This contrasted25 with the more skeptical viewpoint of the Scottish philosopher David Hume, who argued that since we could not be certain that the sun would rise again, a prediction that it would was inherently no more rational than one that it wouldn't.26 The Bayesian viewpoint, instead, regards rationality as a probabilistic matter. In essence, Bayes and Price are telling Hume, don't blame nature because you are too daft to understand it: if you step out of your skeptical shell and make some predictions about its behavior, perhaps you will get a little closer to the truth.

托马斯·贝叶斯：一个被低估的统计学先驱

托马斯·贝叶斯是一位可能生于 1701 年（也可能是 1702 年）的英国牧师。关于他的生平，几乎一无所知，但他的名字却为统计学的一个重要分支以及最著名的定理命名。有趣的是，甚至没有人确切知道他的长相；百科全书中常见的肖像很可能并非他本人 [19]。

历史记载表明，贝叶斯出生于英国东南部赫特福德郡的一个富裕家庭。由于他是非国教会成员，被禁止进入牛津和剑桥等传统学府，他最终选择远赴爱丁堡大学深造 [20]。

尽管发表的学术论文并不多，贝叶斯仍然成为了皇家学会的会员，他在学会内可能扮演着知识辩论的批评者和调解者角色。大多数学者认为，一篇以 John Noon 为笔名发表的作品属于贝叶斯 —— 这是一篇题为《神的慈悲》的论文。在这篇文章中，他深入探讨了一个古老的神学难题：如果上帝真的充满仁慈，那么世界上为何会存在苦难和邪恶？

贝叶斯的核心观点是：人类不应将自身的局限性和不完美误解为上帝的缺陷，因为我们可能无法完全理解宇宙的更宏大设计。正如他在回应另一位神学家时所写：「可笑的是，人类只看到整个存在尺度的最底层，就妄图由此推断整体幸福存在缺陷」。这段话深刻地揭示了人类认知的局限性，以及在理解宇宙本质时应保持的谦逊态度。

贝叶斯最负盛名的著作《关于机会学说中问题的求解》[24]，是在他逝世后由朋友理查德·普赖斯于 1763 年提交给皇家学会的。这篇开创性论文探讨了人们如何在获得新信息时调整和更新对世界的概率性认知。

普赖斯在解读贝叶斯的论文时，选择了一个颇具哲学意味的思想实验：想象一个初次体验世界的人（可能是传说中的亚当，或如哲学家柏拉图寓言中刚刚走出洞穴的囚徒），他第一次目睹太阳升起。最初，这个人无法判断太阳升起是日常现象还是偶然事件。但随着每一天的重复观察，他对「太阳升起是自然永恒法则」的信念会逐渐增强。通过这种纯粹的统计推理过程，他预测「明天太阳仍将升起」的概率会不断接近（尽管永远无法精确达到）100%。

贝叶斯和普莱斯的论点并非认为世界本质上是概率性或不确定的。事实上，贝叶斯坚信宇宙的神圣秩序，并热烈支持艾萨克·牛顿的科学理论，这些理论揭示了自然遵循着严密而可预测的规律。他们的根本主张是：我们认识世界的过程是一个逐步逼近真理的近似过程，随着证据的不断积累，我们对世界的理解会越来越准确。

这一观点与苏格兰哲学家大卫·休谟的怀疑主义形成鲜明对比。休谟认为，既然我们无法绝对确定太阳明天是否会升起，那么预测太阳升起就与预测它不升起同样不理性。与之相反，贝叶斯观点将理性视为一个概率递进的过程。换言之，贝叶斯和普莱斯的核心信息是：不要因为自己无法立即全面理解自然就否定认知的可能性，相反，通过不断做出预测和检验，我们能逐步接近事物的本质真理。

### Probability and Progress

We might notice how similar this claim is to the one that Bayes made in "Divine Benevolence," in which he argued that we should not confuse our own fallibility for the failures of God. Admitting to our own imperfections is a necessary step on the way to redemption.

However, there is nothing intrinsically religious about Bayes's philosophy.27 Instead, the most common mathematical expression of what is today recognized as Bayes's theorem was developed by a man who was very likely an atheist,28 the French mathematician and astronomer Pierre-Simon Laplace.

Laplace, as you may remember from chapter 4, was the poster boy for scientific determinism. He argued that we could predict the universe perfectly—given, of course, that we knew the position of every particle within it and were quick enough to compute their movement. So why is Laplace involved with a theory based on probabilism instead?

The reason has to do with the disconnect between the perfection of nature and our very human imperfections in measuring and understanding it. Laplace was frustrated at the time by astronomical observations that appeared to show anomalies in the orbits of Jupiter and Saturn—they seemed to predict that Jupiter would crash into the sun while Saturn would drift off into outer space.29 These predictions were, of course, quite wrong, and Laplace devoted much of his life to developing much more accurate measurements of these planets' orbits.30 The improvements that Laplace made relied on probabilistic inferences31 in lieu of exacting measurements, since instruments like the telescope were still very crude at the time. Laplace came to view probability as a waypoint between ignorance and knowledge. It seemed obvious to him that a more thorough understanding of probability was essential to scientific progress.32

The intimate connection between probability, prediction, and scientific progress was thus well understood by Bayes and Laplace in the eighteenth century—the period when human societies were beginning to take the explosion of information that had become available with the invention of the printing press several centuries earlier, and finally translate it into sustained scientific, technological, and economic progress. The connection is essential—equally to predicting the orbits of the planets and the winner of the Lakers' game. As we will see, science may have stumbled later when a different statistical paradigm, which deemphasized the role of prediction and tried to recast uncertainty as resulting from the errors of our measurements rather than the imperfections in our judgments, came to dominate in the twentieth century.

### The Simple Mathematics of Bayes's Theorem

If the philosophical underpinnings of Bayes's theorem are surprisingly rich, its mathematics are stunningly simple. In its most basic form, it is just an algebraic expression with three known variables and one unknown one. But this simple formula can lead to vast predictive insights.

Bayes's theorem is concerned with conditional probability. That is, it tells us the probability that a theory or hypothesis is true if some event has happened.

Suppose you are living with a partner and come home from a business trip to discover a strange pair of underwear in your dresser drawer. You will probably ask yourself: what is the probability that your partner is cheating on you? The condition is that you have found the underwear; the hypothesis you are interested in evaluating is the probability that you are being cheated on. Bayes's theorem, believe it or not, can give you an answer to this sort of question—provided that you know (or are willing to estimate) three quantities:

First, you need to estimate the probability of the underwear's appearing as a condition of the hypothesis being true—that is, you are being cheated upon. Let's assume for the sake of this problem that you are a woman and your partner is a man, and the underwear in question is a pair of panties. If he's cheating on you, it's certainly easy enough to imagine how the panties got there. Then again, even (and perhaps especially) if he is cheating on you, you might expect him to be more careful. Let's say that the probability of the panties' appearing, conditional on his cheating on you, is 50 percent.

Second, you need to estimate the probability of the underwear's appearing conditional on the hypothesis being false. If he isn't cheating, are there some innocent explanations for how they got there? Sure, although not all of them are pleasant (they could be his panties). It could be that his luggage got mixed up. It could be that a platonic female friend of his, whom you trust, stayed over one night. The panties could be a gift to you that he forgot to wrap up. None of these theories is inherently untenable, although some verge on dog-ate-my-homework excuses. Collectively you put their probability at 5 percent.

Third and most important, you need what Bayesians call a prior probability (or simply a prior). What is the probability you would have assigned to him cheating on you before you found the underwear? Of course, it might be hard to be entirely objective about this now that the panties have made themselves known. (Ideally, you establish your priors before you start to examine the evidence.) But sometimes, it is possible to estimate a number like this empirically. Studies have found, for instance, that about 4 percent of married partners cheat on their spouses in any given year,33 so we'll set that as our prior.

If we've estimated these values, Bayes's theorem can then be applied to establish a posterior possibility. This is the number that we're interested in: how likely is it that we're being cheated on, given that we've found the underwear? The calculation (and the simple algebraic expression that yields it) is in figure 8-3.

As it turns out, this probability is still fairly low: 29 percent. This may still seem counterintuitive—aren't those panties pretty incriminating? But it stems mostly from the fact that you had assigned a low prior probability to him cheating. Although an innocent man has fewer plausible explanations for the appearance of the panties than a guilty one, you had started out thinking he was an innocent man, so that weighs heavily into the equation.

When our priors are strong, they can be surprisingly resilient in the face of new evidence. One classic example of this is the presence of breast cancer among women in their forties. The chance that a woman will develop breast cancer in her forties is fortunately quite low—about 1.4 percent.34 But what is the probability if she has a positive mammogram?

Studies show that if a woman does not have cancer, a mammogram will incorrectly claim that she does only about 10 percent of the time.35 If she does have cancer, on the other hand, they will detect it about 75 percent of the time.36 When you see those statistics, a positive mammogram seems like very bad news indeed. But if you apply Bayes's theorem to these numbers, you'll come to a different conclusion: the chance that a woman in her forties has breast cancer given that she's had a positive mammogram is still only about 10 percent. These false positives dominate the equation because very few young women have breast cancer to begin with. For this reason, many doctors recommend that women do not begin getting regular mammograms until they are in their fifties and the prior probability of having breast cancer is higher.37

Problems like these are no doubt challenging. A recent study that polled the statistical literacy of Americans presented this breast cancer example to them—and found that just 3 percent of them came up with the right probability estimate.38 Sometimes, slowing down to look at the problem visually (as in figure 8-4) can provide a reality check against our inaccurate approximations. The visualization makes it easier to see the bigger picture—because breast cancer is so rare in young women, the fact of a positive mammogram is not all that telling.

FIGURE 8-4: BAYES'S THEOREM—MAMMOGRAM EXAMPLE

Usually, however, we focus on the newest or most immediately available information, and the bigger picture gets lost. Smart gamblers like Bob Voulgaris have learned to take advantage of this flaw in our thinking. He made a profitable bet on the Lakers in part because the bookmakers placed much too much emphasis on the Lakers' first several games, lengthening their odds of winning the title from 4 to 1 to 6½ to 1, even though their performance was about what you might expect from a good team that had one of its star players injured. Bayes's theorem requires us to think through these problems more carefully and can be very useful for detecting when our gut-level approximations are much too crude.

This is not to suggest that our priors always dominate the new evidence, however, or that Bayes's theorem inherently produces counterintuitive results. Sometimes, the new evidence is so powerful that it overwhelms everything else, and we can go from assigning a near-zero probability of something to a near-certainty of it almost instantly.

Consider a somber example: the September 11 attacks. Most of us would have assigned almost no probability to terrorists crashing planes into buildings in Manhattan when we woke up that morning. But we recognized that a terror attack was an obvious possibility once the first plane hit the World Trade Center. And we had no doubt we were being attacked once the second tower was hit. Bayes's theorem can replicate this result.

For instance, say that before the first plane hit, our estimate of the possibility of a terror attack on tall buildings in Manhattan was just 1 chance in 20,000, or 0.005 percent. However, we would also have assigned a very low probability to a plane hitting the World Trade Center by accident. This figure can actually be estimated empirically: in the previous 25,000 days of aviation over Manhattan39 prior to September 11, there had been two such accidents: one involving the Empire State Building in 1945 and another at 40 Wall Street in 1946. That would make the possibility of such an accident about 1 chance in 12,500 on any given day. If you use Bayes's theorem to run these numbers (figure 8-5a), the probability we'd assign to a terror attack increased from 0.005 percent to 38 percent the moment that the first plane hit.

The idea behind Bayes's theorem, however, is not that we update our probability estimates just once. Instead, we do so continuously as new evidence presents itself to us. Thus, our posterior probability of a terror attack after the first plane hit, 38 percent, becomes our prior possibility before the second one did. And if you go through the calculation again, to reflect the second plane hitting the World Trade Center, the probability that we were under attack becomes a near-certainty—99.99 percent. One accident on a bright sunny day in New York was unlikely enough, but a second one was almost a literal impossibility, as we all horribly deduced.

I have deliberately picked some challenging examples—terror attacks, cancer, being cheated on—because I want to demonstrate the breadth of problems to which Bayesian reasoning can be applied. Bayes's theorem is not any kind of magic formula—in the simple form that we have used here, it consists of nothing more than addition, subtraction, multiplication, and division. We have to provide it with information, particularly our estimates of the prior probabilities, for it to yield useful results.

However, Bayes's theorem does require us to think probabilistically about the world, even when it comes to issues that we don't like to think of as being matters of chance. This does not require us to have taken the position that the world is intrinsically, metaphysically uncertain—Laplace thought everything from the orbits of the planets to the behavior of the smallest molecules was governed by orderly Newtonian rules, and yet he was instrumental in the development of Bayes's theorem. Rather, Bayes's theorem deals with epistemological uncertainty—the limits of our knowledge.

### The Problem of False Positives

When we fail to think like Bayesians, false positives are a problem not just for mammograms but for all of science. In the introduction to this book, I noted the work of the medical researcher John P. A. Ioannidis. In 2005, Ioannidis published an influential paper, "Why Most Published Research Findings Are False,"40 in which he cited a variety of statistical and theoretical arguments to claim that (as his title implies) the majority of hypotheses deemed to be true in journals in medicine and most other academic and scientific professions are, in fact, false.

Ioannidis's hypothesis, as we mentioned, looks to be one of the true ones; Bayer Laboratories found that they could not replicate about two-thirds of the positive findings claimed in medical journals when they attempted the experiments themselves.41 Another way to check the veracity of a research finding is to see whether it makes accurate predictions in the real world—and as we have seen throughout this book, it very often does not. The failure rate for predictions made in entire fields ranging from seismology to political science appears to be extremely high.

"In the last twenty years, with the exponential growth in the availability of information, genomics, and other technologies, we can measure millions and millions of potentially interesting variables," Ioannidis told me. "The expectation is that we can use that information to make predictions work for us. I'm not saying that we haven't made any progress. Taking into account that there are a couple of million papers, it would be a shame if there wasn't. But there are obviously not a couple of million discoveries. Most are not really contributing much to generating knowledge."

This is why our predictions may be more prone to failure in the era of Big Data. As there is an exponential increase in the amount of available information, there is likewise an exponential increase in the number of hypotheses to investigate. For instance, the U.S. government now publishes data on about 45,000 economic statistics. If you want to test for relationships between all combinations of two pairs of these statistics—is there a causal relationship between the bank prime loan rate and the unemployment rate in Alabama?—that gives you literally one billion hypotheses to test.*

But the number of meaningful relationships in the data—those that speak to causality rather than correlation and testify to how the world really works—is orders of magnitude smaller. Nor is it likely to be increasing at nearly so fast a rate as the information itself; there isn't any more truth in the world than there was before the Internet or the printing press. Most of the data is just noise, as most of the universe is filled with empty space.

Meanwhile, as we know from Bayes's theorem, when the underlying incidence of something in a population is low (breast cancer in young women; truth in the sea of data), false positives can dominate the results if we are not careful. Figure 8-6 represents this graphically. In the figure, 80 percent of true scientific hypotheses are correctly deemed to be true, and about 90 percent of false hypotheses are correctly rejected. And yet, because true findings are so rare, about two-thirds of the findings deemed to be true are actually false!

Unfortunately, as Ioannidis figured out, the state of published research in most fields that conduct statistical testing is probably very much like what you see in figure 8-6.* Why is the error rate so high? To some extent, this entire book represents an answer to that question. There are many reasons for it—some having to do with our psychological biases, some having to do with common methodological errors, and some having to do with misaligned incentives. Close to the root of the problem, however, is a flawed type of statistical thinking that these researchers are applying.

FIGURE 8-6: A GRAPHICAL REPRESENTATION OF FALSE POSITIVES

### When Statistics Backtracked from Bayes

Perhaps the chief intellectual rival to Thomas Bayes—although he was born in 1890, almost 120 years after Bayes's death—was an English statistician and biologist named Ronald Aylmer (R. A.) Fisher. Fisher was a much more colorful character than Bayes, almost in the English intellectual tradition of Christopher Hitchens. He was handsome but a slovenly dresser,42 always smoking his pipe or his cigarettes, constantly picking fights with his real and imagined rivals. He was a mediocre lecturer but an incisive writer with a flair for drama, and an engaging and much-sought-after dinner companion. Fisher's interests were wide-ranging: he was one of the best biologists of his day and one of its better geneticists, but was an unabashed elitist who bemoaned the fact that the poorer classes were having more offspring than the intellectuals.43 (Fisher dutifully had eight children of his own.)

Fisher is probably more responsible than any other individual for the statistical methods that remain in wide use today. He developed the terminology of the statistical significance test and much of the methodology behind it. He was also no fan of Bayes and Laplace—Fisher was the first person to use the term "Bayesian" in a published article, and he used it in a derogatory way,44 at another point asserting that the theory "must be wholly rejected."45

Fisher and his contemporaries had no problem with the formula called Bayes's theorem per se, which is just a simple mathematical identity. Instead, they were worried about how it might be applied. In particular, they took issue with the notion of the Bayesian prior.46 It all seemed too subjective: we have to stipulate, in advance, how likely we think something is before embarking on an experiment about it? Doesn't that cut against the notion of objective science?

So Fisher and his contemporaries instead sought to develop a set of statistical methods that they hoped would free us from any possible contamination from bias. This brand of statistics is usually called "frequentism" today, although the term "Fisherian" (as opposed to Bayesian) is sometimes applied to it.47

The idea behind frequentism is that uncertainty in a statistical problem results exclusively from collecting data among just a sample of the population rather than the whole population. This makes the most sense in the context of something like a political poll. A survey in California might sample eight hundred people rather than the eight million that will turn out to vote in an upcoming election there, producing what's known as sampling error. The margin of error that you see reported alongside political polls is a measure of this: exactly how much error is introduced because you survey eight hundred people in a population of eight million? The frequentist methods are designed to quantify this.

Even in the context of political polling, however, sampling error does not always tell the whole story. In the brief interval between the Iowa Democratic caucus and New Hampshire Democratic Primary in 2008, about 15,000 people were surveyed48 in New Hampshire—an enormous number in a small state, enough that the margin of error on the polls was theoretically just plus-or-minus 0.8 percent. The actual error in the polls was about ten times that, however: Hillary Clinton won the state by three points when the polls had her losing to Barack Obama by eight. Sampling error—the only type of error that frequentist statistics directly account for—was the least of the problem in the case of the New Hampshire polls.

Likewise, some polling firms consistently show a bias toward one or another party:49 they could survey all 200 million American adults and they still wouldn't get the numbers right. Bayes had these problems figured out 250 years ago. If you're using a biased instrument, it doesn't matter how many measurements you take—you're aiming at the wrong target.

Essentially, the frequentist approach toward statistics seeks to wash its hands of the reason that predictions most often go wrong: human error. It views uncertainty as something intrinsic to the experiment rather than something intrinsic to our ability to understand the real world. The frequentist method also implies that, as you collect more data, your error will eventually approach zero: this will be both necessary and sufficient to solve any problems. Many of the more problematic areas of prediction in this book come from fields in which useful data is sparse, and it is indeed usually valuable to collect more of it. However, it is hardly a golden road to statistical perfection if you are not using it in a sensible way. As Ioannidis noted, the era of Big Data only seems to be worsening the problems of false positive findings in the research literature.

Nor is the frequentist method particularly objective, either in theory or in practice. Instead, it relies on a whole host of assumptions. It usually presumes that the underlying uncertainty in a measurement follows a bell-curve or normal distribution. This is often a good assumption, but not in the case of something like the variation in the stock market. The frequentist approach requires defining a sample population, something that is straightforward in the case of a political poll but which is largely arbitrary in many other practical applications. What "sample population" was the September 11 attack drawn from?

The bigger problem, however, is that the frequentist methods—in striving for immaculate statistical procedures that can't be contaminated by the researcher's bias—keep him hermetically sealed off from the real world. These methods discourage the researcher from considering the underlying context or plausibility of his hypothesis, something that the Bayesian method demands in the form of a prior probability. Thus, you will see apparently serious papers published on how toads can predict earthquakes,50 or how big-box stores like Target beget racial hate groups,51 which apply frequentist tests to produce "statistically significant" (but manifestly ridiculous) findings.

### Data Is Useless Without Context

Fisher mellowed out some toward the end of his career, occasionally even praising Bayes.52 And some of the methods he developed over his long career (although not the ones that are in the widest use today) were really compromises between Bayesian and frequentist approaches. In the last years of his life, however, Fisher made a grievous error of judgment that helps to demonstrate the limitations of his approach.

The issue concerned cigarette smoking and lung cancer. In the 1950s, a large volume of research—some of it using standard statistical methods and some using Bayesian ones53—claimed there was a connection between the two, a connection that is of course widely accepted today.

Fisher spent much of his late life fighting against these conclusions, publishing letters in prestigious publications including The British Medical Journal and Nature.54 He did not deny that the statistical relationship between cigarettes and lung cancer was fairly strong in these studies, but he claimed it was a case of correlation mistaken for causation, comparing it to a historical correlation between apple imports and marriage rates in England.55 At one point, he argued that lung cancer caused cigarette smoking and not the other way around56—the idea, apparently, was that people might take up smoking for relief from their lung pain.

Many scientific findings that are commonly accepted today would have been dismissed as hooey at one point. This was sometimes because of the cultural taboos of the day (such as in Galileo's claim that the earth revolves around the sun) but at least as often because the data required to analyze the problem did not yet exist. We might let Fisher off the hook if, it turned out, there was not compelling evidence to suggest a linkage between cigarettes and lung cancer by the 1950s. Scholars who have gone back and looked at the evidence that existed at the time have concluded, however, that there was plenty of it—a wide variety of statistical and clinical tests conducted by a wide variety of researchers in a wide variety of contexts demonstrated the causal relationship between them.57 The idea was quickly becoming the scientific consensus.

So why did Fisher dismiss the theory? One reason may have been that he was a paid consultant of the tobacco companies.58 Another may have been that he was a lifelong smoker himself. And Fisher liked to be contrarian and controversial, and disliked anything that smacked of puritanism. In short, he was biased, in a variety of ways.

But perhaps the bigger problem is the way that Fisher's statistical philosophy tends to conceive of the world. It emphasizes the objective purity of the experiment—every hypothesis could be tested to a perfect conclusion if only enough data were collected. However, in order to achieve that purity, it denies the need for Bayesian priors or any other sort of messy real-world context. These methods neither require nor encourage us to think about the plausibility of our hypothesis: the idea that cigarettes cause lung cancer competes on a level playing field with the idea that toads predict earthquakes. It is, I suppose, to Fisher's credit that he recognized that correlation does not always imply causation. However, the Fisherian statistical methods do not encourage us to think about which correlations imply causations and which ones do not. It is perhaps no surprise that after a lifetime of thinking this way, Fisher lost the ability to tell the difference.

### Bob the Bayesian

In the Bayesian worldview, prediction is the yardstick by which we measure progress. We can perhaps never know the truth with 100 percent certainty, but making correct predictions is the way to tell if we're getting closer.

Bayesians hold the gambler in particularly high esteem.59 Bayes and Laplace, as well as other early probability theorists, very often used examples from games of chance to explicate their work. (Although Bayes probably did not gamble much himself,60 he traveled in circles in which games like cards and billiards were common and were often played for money.) The gambler makes predictions (good), and he makes predictions that involve estimating probabilities (great), and when he is willing to put his money down on his predictions (even better), he discloses his beliefs about the world to everyone else. The most practical definition of a Bayesian prior might simply be the odds at which you are willing to place a bet.*

And Bob Voulgaris is a particularly Bayesian type of gambler. He likes betting on basketball precisely because it is a way to test himself and the accuracy of his theories. "You could be a general manager in sports and you could be like, Okay, I'll get this player and I'll get that player," he told me toward the end of our interview. "At the end of the day you don't really know if you're right or wrong. But at the end of the day, the end of the season, I know if I'm right or wrong because I know if I'm winning money or I'm losing it. That's a pretty good validation."

Voulgaris soaks up as much basketball information as possible because everything could potentially shift his probability estimates. A professional sports bettor like Voulgaris might place a bet only when he thinks he has at least a 54 percent chance of winning it. This is just enough to cover the "vigorish" (the cut a sportsbook takes on a winning wager), plus the risk associated with putting one's money into play. And for all his skill and hard work—Voulgaris is among the best sports bettors in the world today—he still gets only about 57 percent of his bets right. It is just exceptionally difficult to do much better than that.

A small piece of information that improves Voulgaris's estimate of his odds from 53 percent to 56 percent can therefore make all the difference. This is the sort of narrow margin that gamblers, whether at the poker table or in the stock market, make their living on. Fisher's notion of statistical significance, which uses arbitrary cutoffs devoid of context* to determine what is a "significant" finding and what isn't,61 is much too clumsy for gambling.

But this is not to suggest that Voulgaris avoids developing hypotheses around what he's seeing in the statistics. (The problem with Fisher's notion of hypothesis testing is not with having hypotheses but with the way Fisher recommends that we test them.)62 In fact, this is critical to what Voulgaris does. Everyone can see the statistical patterns, and they are soon reflected in the betting line. The question is whether they represent signal or noise. Voulgaris forms hypotheses from his basketball knowledge so that he might tell the difference more quickly and more accurately.

Voulgaris's approach to betting basketball is one of the purer distillations of the scientific method that you're likely to find (figure 8-7). He observes the world and asks questions: why are the Cleveland Cavaliers so frequently going over on the total? He then gathers information on the problem, and formulates a hypothesis: the Cavaliers are going over because Ricky Davis is in a contract year and is trying to play at a fast pace to improve his statistics. The difference between what Voulgaris does and what a physicist or biologist might do is that he demarcates his predictions by placing bets on them, whereas a scientist would hope to validate her prediction by conducting an experiment.

FIGURE 8-7: SCIENTIFIC METHOD

Step in Scientific Method 63

Sports Betting Example

Observe a phenomenon

Cavaliers games are frequently going over the game total.

Develop a hypothesis to explain the phenomenon

Cavaliers games are going over because Ricky Davis is playing for a new contract and trying to score as many points as possible.

Formulate a prediction from the hypothesis

Davis's incentives won't change until the end of the season. Therefore: (i) he'll continue to play at a fast pace, and, (ii) future Cavaliers games will continue to be high-scoring as a result.

Test the prediction

Place your bet.

If Voulgaris can develop a strong hypothesis about what he is seeing in the data, it can enable him to make more aggressive bets. Suppose, for instance, that Voulgaris reads some offhand remark from the coach of the Denver Nuggets about wanting to "put on a good show" for the fans. This is probably just idle chatter, but it might imply that the team will start to play at a faster pace in order to increase ticket sales. If this hypothesis is right, Voulgaris might expect that an over bet on Nuggets games will win 70 percent of the time as opposed to the customary 50 percent. As a consequence of Bayes's theorem, the stronger Voulgaris's belief in his hypothesis, the more quickly he can begin to make profitable bets on Nuggets games. He might be able to do so after watching just a game or two, observing whether his theory holds in practice—quickly enough that Vegas will have yet to catch on. Conversely, he can avoid being distracted by statistical patterns, like the Lakers' slow start in 1999, that have little underlying meaning but which other handicappers might mistake for a signal.

### The Bayesian Path to Less Wrongness

But are Bob's probability estimates subjective or objective? That is a tricky question.

As an empirical matter, we all have beliefs and biases, forged from some combination of our experiences, our values, our knowledge, and perhaps our political or professional agenda. One of the nice characteristics of the Bayesian perspective is that, in explicitly acknowledging that we have prior beliefs that affect how we interpret new evidence, it provides for a very good description of how we react to the changes in our world. For instance, if Fisher's prior belief was that there was just a 0.00001 percent chance that cigarettes cause lung cancer, that helps explain why all the evidence to the contrary couldn't convince him otherwise. In fact, there is nothing prohibiting you under Bayes's theorem from holding beliefs that you believe to be absolutely true. If you hold there is a 100 percent probability that God exists, or a 0 percent probability, then under Bayes's theorem, no amount of evidence could persuade you otherwise.

I'm not here to tell you whether there are things you should believe with absolute and unequivocal certainty or not.* But perhaps we should be more honest about declaiming these. Absolutely nothing useful is realized when one person who holds that there is a 0 percent probability of something argues against another person who holds that the probability is 100 percent. Many wars—like the sectarian wars in Europe in the early days of the printing press—probably result from something like this premise.

This does not imply that all prior beliefs are equally correct or equally valid. But I'm of the view that we can never achieve perfect objectivity, rationality, or accuracy in our beliefs. Instead, we can strive to be less subjective, less irrational, and less wrong. Making predictions based on our beliefs is the best (and perhaps even the only) way to test ourselves. If objectivity is the concern for a greater truth beyond our personal circumstances, and prediction is the best way to examine how closely aligned our personal perceptions are with that greater truth, the most objective among us are those who make the most accurate predictions. Fisher's statistical method, which saw objectivity as residing within the confines of a laboratory experiment, is less suitable to this task than Bayesian reasoning.

One property of Bayes's theorem, in fact, is that our beliefs should converge toward one another—and toward the truth—as we are presented with more evidence over time. In figure 8-8, I've worked out an example wherein three investors are trying to determine whether they are in a bull market or a bear market. They start out with very different beliefs about this—one of them is optimistic, and believes there's a 90 percent chance of a bull market from the outset, while another one is bearish and says there's just a 10 percent chance. Every time the market goes up, the investors become a little more bullish relative to their prior, while every time it goes down the reverse occurs. However, I set the simulation up such that, although the fluctuations are random on a day-to-day basis, the market increases 60 percent of the time over the long run. Although it is a bumpy road, eventually all the investors correctly determine that they are in a bull market with almost (although not exactly, of course) 100 percent certainty.

FIGURE 8-8: BAYESIAN CONVERGENCE

In theory, science should work this way. The notion of scientific consensus is tricky, but the idea is that the opinion of the scientific community converges toward the truth as ideas are debated and new evidence is uncovered. Just as in the stock market, the steps are not always forward or smooth. The scientific community is often too conservative about adapting its paradigms to new evidence,64 although there have certainly also been times when it was too quick to jump on the bandwagon. Still, provided that everyone is on the Bayesian train,* even incorrect beliefs and quite wrong priors are revised toward the truth in the end.

Right now, for instance, we may be undergoing a paradigm shift in the statistical methods that scientists are using. The critique I have made here about the flaws of Fisher's statistical approach is neither novel nor radical: prominent scholars in fields ranging from clinical psychology65 to political science66 to ecology67 have made similar arguments for years. But so far there has been little fundamental change.

Recently, however, some well-respected statisticians have begun to argue that frequentist statistics should no longer be taught to undergraduates.68 And some professions have considered banning Fisher's hypothesis test from their journals.69 In fact, if you read what's been written in the past ten years, it's hard to find anything that doesn't advocate a Bayesian approach.

Bob's money is on Bayes, too. He does not literally apply Bayes's theorem every time he makes a prediction. But his practice of testing statistical data in the context of hypotheses and beliefs derived from his basketball knowledge is very Bayesian, as is his comfort with accepting probabilistic answers to his questions.

It will take some time for textbooks and traditions to change. But Bayes's theorem holds that we will converge toward the better approach. Bayes's theorem predicts that the Bayesians will win.


## 01



概率：认知进步的梯度

我们可能会注意到，这种说法与贝叶斯在「神圣慈悲」中提出的观点极为相似。在那篇文章中，他论证了我们不应将自身的局限性误认为是上帝的缺陷。承认自身的不完美，是走向救赎的必要前提。

然而，贝叶斯的哲学本身并非天然具有宗教色彩 [27]。相反，如今被广泛认可的贝叶斯定理最典型的数学表达，是由一位很可能是无神论者的人发展的，28 即法国数学家和天文学家皮埃尔-西蒙·拉普拉斯。

正如你可能在第 4 章中记得的，拉普拉斯是科学决定论（认为宇宙运行遵循严格因果规律）的代表性人物。他坚信，只要我们准确掌握宇宙中每个粒子的位置，并能快速计算它们的运动轨迹，就可以完美地预测宇宙。那么，为什么这位坚定的决定论者会转而研究概率理论呢？

这一现象源于自然的完美与人类认知和测量能力的有限之间的巨大反差。在早期天文观测中，拉普拉斯曾面临令人困惑的难题：当时的观测数据似乎预示着木星和土星轨道的异常运行，甚至认为木星可能会坠入太阳，而土星则会漂离太阳系 [29]。这些预测后来被证明是完全错误的。为了解决这一困境，拉普拉斯将毕生精力投入到更精确地测量行星轨道中 [30]。

由于当时的观测仪器（如望远镜）非常原始，他不得不依靠概率推理（probabilistic inferences）来弥补测量的不足 [31]。在拉普拉斯看来，概率就像是连接无知与知识的桥梁。他深信，只有更深入地理解概率，科学才能真正获得进步 [32]。

在十八世纪，贝叶斯和拉普拉斯就敏锐地洞察到了概率、预测与科学进步之间的密切关联。这正值人类社会开始充分利用印刷术发明带来的信息革命，并将之转化为持续的科学、技术和经济发展。这种关联具有普遍意义 —— 无论是预测天体运行，还是预测篮球赛场上的胜负。正如我们将看到的，科学在二十世纪曾一度陷入困境：当时占主导地位的统计范式弱化了预测的重要性，并试图将不确定性归因于测量误差，而非人类判断的固有局限。




贝叶斯定理的简单数学原理

贝叶斯定理的哲学基础令人惊叹地深邃，而其数学原理却出人意料地简单。在最基本的形式中，它不过是一个包含三个已知变量和一个未知变量的代数表达式。然而，这个看似简单的公式蕴含着强大的预测潜力，能够为我们提供深刻的洞察。

贝叶斯定理处理的是条件概率。换句话说，它能告诉我们：在某个事件发生的情况下，一个理论或假设成立的可能性。

想象这样一个场景：你和伴侣同居，从出差回家时，在衣柜抽屉里发现了一条陌生的内裤。此时，你很可能会思考：我的伴侣是否出轨？这里的条件是你发现了内裤；而你想要验证的假设是被出轨的概率。相信与否，贝叶斯定理都能帮你分析这类问题 —— 前提是你了解（或愿意估算）以下三个关键数值：

首先，你需要评估在出轨假设成立的情况下，发现内衣的可能性。为了讨论这个问题，我们假设你是一位女性，伴侣是男性，而案发现场的「证据」是一条女式内裤。如果你的男友确实背叛了你，内裤出现似乎并不稀奇。不过，恰恰是在出轨的情况下，他可能会变得更加谨慎小心。因此，在他出轨的前提下，内裤被发现的概率，我们估计大约是一半。

其次，你需要考虑在他没有出轨的情况下，内衣出现的可能性有多大。如果他真的没有背叛，是否存在一些看似合理的解释？诚然，这些解释并不都让人感到舒服（比如这可能是他自己的内裤）。也许是行李不小心混在了一起，或者是他那位值得信赖的女性朋友某天晚上留宿过。甚至可能是他忘记包装的送给你的礼物。这些解释看似牵强，但并非完全不可能，就像经典的「狗吃了我的作业」式借口。综合来看，你估计这些解释的可能性约为 5%。

第三点，也是最重要的一点，你需要贝叶斯学派所说的先验概率（或简称为先验）。在发现内衣之前，你会对伴侣出轨的概率有何评估？当然，内衣已经呈现在眼前，要完全客观地评估这个概率可能很困难。（理想情况下，你应该在开始检查证据之前确定先验概率。）但有时可以通过经验数据 *empirically* 估算这个数值。例如，研究发现，在任何给定的年份里，大约 4% 的已婚伴侣会背叛配偶 [33]，因此我们将这个数值作为先验。

如果我们估算了这些值，就可以应用贝叶斯定理来计算后验概率。这是我们关注的核心：发现内衣后，出轨的可能性有多大？计算方法和推导过程如图 8-3 所示。

事实证明，这个概率仍然相当低：仅为 29%。这可能看起来令人困惑 —— 发现女式内裤难道不是非常可疑的吗？但这主要源于你最初对对方出轨的可能性抱有很低的信念。尽管一个无辜的人对内裤出现的解释比有罪的人要少，但你最初认为他是无辜的，这种初始判断在整个推理过程中权重很大。

人们的初始判断往往出奇地顽固，即便面对新的证据。这方面的一个经典例子是四十岁女性乳腺癌的发病情况。幸运的是，一位四十岁女性患乳腺癌的概率非常低 —— 仅约 1.4%。那么，如果她的乳腺 X 线检查结果呈阳性，这个概率又会发生怎样的变化呢？

研究发现，对于没有患癌的女性，乳房 X 线检查（mammogram）会有约 10% 的几率错误地判定她们患有乳腺癌。35 相反，如果一位女性确实患有乳腺癌，检查能在约 75% 的情况下准确识别出来。36 乍看之下，阳性的检查结果似乎意味着可怕的坏消息。然而，当我们用贝叶斯定理分析这些数据时，会得出一个出人意料的结论：对于一位四十多岁的女性，即便乳房 X 线检查呈阳性，她实际患乳腺癌的可能性仍然只有约 10%。

这是因为年轻女性本就很少患乳腺癌，所以这些「误诊」结果会占据主导。换句话说，即便检查显示阳性，大多数情况下仍然是假警报。正因如此，许多医生建议女性不必过早进行常规乳腺检查，而是等到五十岁左右，此时患病的可能性会显著提高。37

这类概率问题确实令人困惑。一项调查美国人统计素养的研究中，研究者以乳腺癌检测为例，惊讶地发现只有 3% 的人能正确估算概率 [38]。有时，放慢思考节奏并以可视化方式（如图 8-4）审视问题，能帮助我们纠正直觉上的错误判断。

可视化帮助我们更清晰地把握全局 — 尤其是在乳腺癌这样的罕见病中。由于年轻女性群体中乳腺癌发病率极低，单一阳性乳房 X 线检查结果并不能直接等同于患病的高风险。这提醒我们在解读医学检测结果时要格外谨慎，不能仅凭单一指标就下结论。

图 8-4：贝叶斯定理 — 乳腺癌示例

通常，我们只关注最新或最直接获得的信息，往往会忽视全局。像 Bob Voulgaris 这样聪明的赌徒已经学会了利用人们思维中的这个盲点。他对湖人队的下注之所以能获利，部分原因是博彩公司过分看重了球队前几场比赛的表现，将球队夺冠赔率从 4 比 1 调整到 6½ 比 1，尽管球队的整体实力与一支明星球员受伤后的优秀球队表现相当。贝叶斯定理要求我们更审慎地分析问题，帮助我们识别并纠正直觉判断中的偏差。

这并不意味着我们原有的观点（先验认知）总是主导新证据，或者贝叶斯定理天生会得出违反直觉的结论。有时，新证据是如此有力，以至于能够迅速颠覆我们原有的看法，让我们几乎在瞬间就能将某事从「几乎不可能」转变为「几乎必然」。

以 9 月 11 日恐怖袭击为例，这是一个令人心痛的案例。在那天早晨醒来时，我们大多数人对恐怖分子驾驶飞机撞击曼哈顿建筑的概率几乎持零概率看法。然而，当第一架飞机撞击世贸中心时，我们立即意识到恐怖袭击已成为一个明确的可能性。当第二座塔楼被击中时，我们更加确信我们正遭受蓄意攻击。贝叶斯定理（Bayes's Theorem）恰好可以解释这种认知概率变化的过程。

例如，假设在第一架飞机撞击之前，我们对曼哈顿高层建筑遭受恐怖袭击的可能性估计仅为 2 万分之 1，即 0.005%。然而，我们也会对飞机意外撞击世贸中心的概率给出很低的估计。这个数字实际上可以通过经验方法估算：在 9 月 11 日之前的 25,000 天的曼哈顿航空历史中，曾发生过两起此类事故：一次是 1945 年撞击帝国大厦，另一次是 1946 年在 40 Wall Street。这意味着在任何特定日期发生此类事故的可能性约为 12,500 分之 1。如果使用贝叶斯定理（Bayes's theorem）来计算这些数字（图 8-5a），那么第一架飞机撞击的那一刻，我们对恐怖袭击的概率将从 0.005% 上升到 38%。

贝叶斯定理的核心不是一次性更新概率估计，而是随着新证据的出现不断调整我们的判断。例如，第一架飞机撞击后，我们对恐怖袭击的可能性评估为 38%，而这个概率随后会成为第二架飞机撞击前的基准判断。当第二架飞机击中世贸中心时，通过重新计算，我们意识到遭受攻击的概率已经接近 100%——99.99%。在晴朗的纽约，一次意外尚且罕见，而连续两次则几乎是不可想象的。

我特意选择了这些令人不安的例子 —— 恐怖袭击、癌症和背叛 —— 就是为了展示贝叶斯推理的广泛应用。这里需要强调的是，贝叶斯定理并非魔法，而是一种系统的概率推理方法。它本质上只是运用基本的数学运算：加、减、乘、除。要获得有意义的结果，我们必须提供准确的初始信息，特别是对事件发生可能性的合理估计。

然而，贝叶斯定理要求我们用概率的视角看待世界，即便是那些我们不愿意归因于偶然性的问题。这并不意味着我们必须相信世界本质上是不确定的 —— 事实上，拉普拉斯认为，从行星轨道到最微小的分子运动，一切都遵循着有序的牛顿定律，但他同样对贝叶斯定理的发展做出了重要贡献。更准确地说，贝叶斯定理处理的是我们认知中的不确定性，换句话说，就是我们知识的边界和局限。

虚假阳性问题当我们未能像贝叶斯主义者那样思考时，虚假阳性（指检测结果错误地显示为阳性）将成为一个普遍性问题，不仅限于医学影像学，更是整个科学研究领域的通病。在本书引言中，我提到了医学研究者约翰·P·A·伊奥尼迪斯的重要研究。2005 年，他发表了一篇极具影响力的论文《为什么大多数已发表的研究发现是错误的》[40]。文章通过各种统计学和理论论点，令人震惊地指出：在医学和其他学术领域的学术期刊中，被认为是「真实」的研究假设，实际上很可能是错误的。

正如我们之前提到的，Ioannidis 的假设看来颇为准确；拜耳实验室发现，在自行重复验证时，无法复制医学期刊中约三分之二的阳性研究结果 [41]。验证研究发现真实性的另一种方法是检验其在现实世界中的预测准确性，而事实上，这些预测往往难以令人满意。从地震学到政治科学等诸多领域，研究预测的失败率都极其高昂。

"过去二十年里，随着信息、基因组学和其他技术的爆发性增长，我们可以测量数百万个潜在的关键变量，"Ioannidis 向我解释道。"我们原本期望能够利用这些海量信息改进预测。我并非否认我们没有取得进展。考虑到已发表的数百万篇论文，若完全没有进展那将是令人遗憾的。但显然，这些论文中真正的重大发现寥寥无几。绝大多数论文对推动知识进步的贡献微乎其微。"

这就是为什么在大数据时代，我们的预测可能更容易出错。随着可用信息呈指数级增长，需要调查的假设数量也随之爆发性增长。以美国政府为例，他们现在发布了约 45,000 个经济统计指标。如果研究者想要探索这些统计数据中任意两对指标之间的关系 —— 比如调查阿拉巴马州的银行基准贷款利率与当地失业率之间是否存在因果联系 —— 这将意味着需要检验数以十亿计的假设。

然而，数据中真正具有意义的关系 —— 那些揭示因果机制、呈现世界运作真实逻辑的关系 —— 其数量远远小于表面上看到的海量数据。这些有价值的关系增长的速度，也绝对不会跟信息本身的增长速度相提并论。事实上，在互联网和印刷技术革命之前，世界的基本真理并未增多。大多数数据不过是无关紧要的噪音，就像宇宙中绝大部分空间都是无边无际的虚无一样。

根据贝叶斯定理（Bayes's theorem，用于评估事件概率的统计方法），当某种现象在总体中的发生率很低（比如年轻女性的乳腺癌；数据海洋中的真相）时，如果不谨慎，误阳性（false positive）就可能主导研究结果。图 8-6 形象地展示了这一现象。在该图中，80% 的科学假说被正确判定为真，约 90% 的错误假说被正确拒绝。然而，由于真实发现极其罕见，约三分之二被判定为真的发现实际上是虚假的！

不幸的是，正如 Ioannidis 所揭示的，大多数进行统计检验的研究领域中，已发表研究的状态可能与图 8-6 极其相似 *。为什么错误率如此之高？从某种程度上说，这本书的整体内容都在回答这个问题。造成这种情况的原因多样 —— 部分源于我们的心理偏见，部分源于常见的方法学错误，还有部分源于不恰当的学术激励机制。然而，问题的根源更接近于这些研究者所采用的一种有缺陷的统计思维方式。

图 8-6：误阳性的图形表示

当统计学遇到理性的转折如果要说托马斯·贝叶斯最具代表性的学术对手，那非出生于 1890 年的罗纳德·艾尔默（R. A.)·费舍尔莫属，比贝叶斯逝世晚了将近 120 年。费舍尔是一位极具个人魅力的知识分子，犹如英国知识界常见的犀利辩手。他相貌堂堂却不拘小节，总是手不释烟，性格好争，对学术界的对手和假想敌从不客气。作为一位讲台上表现平平的学者，他却笔锋犀利，文字中充满戏剧性，在社交场合极具魅力。作为那个时代卓越的生物学家和遗传学家，费舍尔不乏精英主义色彩，对社会底层的高生育率颇为不满。(尽管如此，他自己还是诞下了八个孩子。)

在现代统计学的发展历程中，Fisher 可能是影响最深远的科学家之一。他不仅奠定了统计显著性检验的理论基础，还创造了相关的专业术语。有趣的是，他对贝叶斯学派持强烈批评态度 —— 事实上，他是第一个在学术文章中使用「贝叶斯」一词的人，但使用时带有明显的贬义，并直言不讳地认为贝叶斯理论「必须被全盘否决」。

Fisher 和他的同行们并不反对贝叶斯定理本身 —— 这不过是一个简单的数学恒等式。他们真正担心的是这一理论可能的应用方式。特别是，他们对贝叶斯先验概率（Bayesian prior）持谨慎态度。在他们看来，这种方法过于主观：在开始一项科学实验前，研究者需要预先主观估计某个假设的可能性。这种做法似乎与客观科学的追求相悖，有悖于科学追求绝对中立和客观性的精神。

费舍尔及其同时代的统计学家致力于开发一套统计方法，希望能够消除可能的偏见干扰。这种统计学方法如今通常被称为「频率主义」，有时也被称为「费舍尔主义」（与贝叶斯主义相对）。47

频率主义的核心思想是：统计问题中的不确定性，源于仅仅对总体的一个样本进行调查，而非调查整个总体。这一观点在政治民调等场景中尤其明确。打个比方，在加利福尼亚的一次选民调查中，研究者可能只抽样了 800 人，而非八百万潜在选民，这就产生了所谓的「抽样误差」。我们在政治民调报告中常见的「误差范围」，正是用于量化这种抽样过程中引入的误差：在八百万人口中，仅抽样 800 人会造成多大程度的统计偏差？频率主义统计方法的设计初衷，就是精确测量和 quantify 这类抽样误差。

即便在政治民意调查中，抽样误差也未必能完整呈现全貌。以 2008 年艾奥瓦州民主党选举集会（caucus）和新罕布什尔州民主党初选为例，在这段短暂的时间里，约 15,000 名选民接受了调查 [48]—— 这在一个小州而言是相当大规模的调查，理论上的抽样误差仅为 ±0.8%。然而，民调的实际误差却是这个数值的十倍：希拉里·克林顿最终以三个百分点赢得了该州，而此前的民调却预测她将以八个百分点输给巴拉克·奥巴马。抽样误差 —— 频率派统计学（Frequentist Statistics）直接考虑的唯一误差类型 —— 在这次民调中实际上是最小的问题。

同样，一些民调机构往往表现出对特定政党的系统性偏见 [49]：即便他们调查了全国 2 亿成年人，仍可能得出不准确的结果。早在 250 年前，贝叶斯（Thomas Bayes）就已洞察了这类统计学问题。用一个有偏见的测量工具进行调查，无论测量多少次，都无法准确地击中目标。

在统计学的频率学派（frequentist）方法中，研究者试图回避预测常常出错的根本原因：人为误差。这种观点将不确定性视为实验本身固有的特征，而非理解现实世界能力的固有局限。频率学派方法还有一个假设：随着数据收集的增多，统计误差将逐渐接近零，并认为这是解决问题的必要和充分条件。

在本书探讨的诸多预测困难领域中，大多数都面临有用数据匮乏的挑战。收集更多数据确实通常很有价值。然而，若不能明智地运用这些数据，单纯堆砌数据并不能成为获得精确统计结果的捷径。正如研究者 Ioannidis 所指出的，大数据时代反而可能加剧研究文献中的错误结论问题。

频率主义统计方法（一种传统的数据分析方法）并不像看上去那样客观，无论是在理论还是实践中。事实上，它依赖于大量的预设条件。这种方法通常假设测量中的不确定性服从正态分布曲线，就像一个标准的钟形图。虽然这个假设在很多情况下是合理的，但在股市这样波动剧烈的领域却显得不太恰当。

频率主义方法还要求研究者明确定义一个样本总体，这在进行政治民调时相对简单，但在许多实际应用场景中却极其武断。举个极端的例子，对于像 9 月 11 日这样的重大事件，又从何谈起「样本总体」呢？这种方法的局限性在此暴露无遗。

在统计学研究中，频率学派的方法存在一个更深层的问题：为了追求不被研究者偏见污染的「完美」统计程序，这种方法实际上将研究者与现实世界隔绝开来。频率学派的统计检验往往不鼓励研究者思考假设背后的实际背景和合理性，这与贝叶斯方法形成鲜明对比 —— 贝叶斯方法要求研究者通过先验概率来评估假设的可能性。

正因如此，我们时常会看到一些看似严谨但实际荒谬的学术论文。比如有研究声称蟾蜍能预测地震 [50]，或大型连锁店如 Target 会滋生种族仇恨团体 [51]。这些论文虽然运用了频率学派的统计检验，得出了「统计学上显著」的结论，但其荒谬程度昭然若揭。

没有背景的数据，寸步难行在职业生涯的晚期，统计学家 Fisher 的态度开始转变，甚至偶尔会称赞贝叶斯方法 [52]。他在漫长职业生涯中开发的部分方法，实际上已经成为贝叶斯方法和频率学派方法的折中。然而，在生命的最后几年，Fisher 犯了一个严重的判断失误，这恰恰印证了他原有方法的局限性。

这个问题涉及香烟吸烟和肺癌之间的关系。在 1950 年代，大量研究 —— 有些采用标准统计方法，有些采用贝叶斯方法 [53]—— 声称二者之间存在关联，这一关联如今已被广泛接受。

Fisher 在晚年花费了大量精力与这些结论抗争，并在《英国医学期刊》和《自然》等权威期刊上发表了多封信件 [54]。他并不否认研究中香烟和肺癌之间的统计关联相当强，但他认为这是将相关性误解为因果关系的典型案例，就如同英格兰苹果进口量与结婚率之间的历史性关联。他甚至提出了一个荒谬的观点：肺癌可能导致吸烟，而非相反 [56]—— 他推测患者可能为了缓解肺部疼痛而开始吸烟。

许多如今被广泛接受的科学发现，在某个时期曾被视为荒谬绝无可能。这种情况有时源于当时的文化禁忌（比如伽利略声称地球绕太阳运行），但同样常见的原因是分析问题所需的数据尚未积累。如果到 1950 年代确实缺乏关于香烟与肺癌关联的有力证据，我们或许可以原谅费舍尔的观点。然而，回溯研究当时可用证据的学者得出了截然不同的结论：当时已经存在大量证据 —— 来自不同背景的研究者在各种语境中进行的多样化统计和临床测试，牢固地证明了两者之间的因果关系。[57] 这一观点迅速成为科学界的主流共识。

那么，费舍尔为何会否定这一理论呢？一个重要原因是他是烟草公司的有薪顾问。[58] 另一个可能性是他自己是个终身烟民。此外，费舍尔本性好强，喜欢持相反观点并制造争议，对任何带有说教色彩的观点都深感厌恶。简而言之，他在多个方面都存在明显的个人偏见。

但也许费舍尔统计哲学更严重的问题在于其世界观。这种方法过分强调实验的客观纯粹性 —— 仿佛只要收集足够的数据，就能对任何假设得出完美的结论。为了追求这种纯粹性，它却忽视了贝叶斯先验或其他现实世界的复杂背景。这些方法既不要求也不鼓励我们思考假设的可能性：就像把「香烟会致癌」和「蟾蜍能预测地震」放在同一起跑线上比赛。

值得称道的是，费舍尔确实意识到了相关性并不等同于因果关系。然而，他的统计方法并未引导我们深入思考哪些相关性真正意味着因果关系。这也许就解释了为什么在用这种思维方式思考一生后，他逐渐丧失了区分重要性和偶然性的能力。

—— 贝叶斯派观点

在贝叶斯世界观中，预测是衡量认知进步的尺度。虽然我们可能永远无法以绝对的确定性了解真相，但做出准确的预测正是验证我们认知进步的关键方法。

贝叶斯学派对赌徒有着特别的敬意。无论是贝叶斯、拉普拉斯，还是其他早期概率论学者，他们常常喜欢借助赌博游戏中的例子来阐明自己的理论。(贝叶斯本人可能并非热衷赌博，但他活跃在经常打牌和台球，并以金钱为赌注的社交圈中。）赌徒不仅会做出预测，还会估算预测的概率，更重要的是，他愿意用金钱来验证自己的预测，这实际上是在向他人展示自己对世界的理解和信念。从某种意义上说，贝叶斯先验可以简单地理解为一个人对某个事件下注的赔率 — 这个赔率反映了他对事件可能性的内心判断。*

鲍勃·伏尔加里斯是一个以贝叶斯思维做赌注的特殊赌徒。他喜欢在篮球赛事上押注，正是因为这是一种验证自己和自身理论准确性的独特方式。"作为体育界的总经理，你可能会想，好的，我要签下这个球员，再签下那个球员，」他在我们采访即将结束时说道。"但实际上，你很难确定自己的判断是否正确。而在赛季结束时，通过输赢金钱，我能清楚地知道自己的判断是否准确。这种方式是一个非常实在的验证机制。"

Voulgaris 如饥似渴地收集篮球信息，因为任何一个细微的信息都可能改变他对比赛结果的概率判断。作为一名职业体育博彩专家，Voulgaris 只有在赢面超过 54% 时才会下注。这个胜率刚好能覆盖博彩公司的抽成（即从每笔获利中抽取的佣金）和投资风险。尽管 Voulgaris 技艺高超，是当今世界顶级的体育博彩专家之一，但他仍然只能准确预测约 57% 的赌注。要在这个领域做得更好，几乎是不可能的。

即便是一个将他的赔率预测从 53% 提升到 56% 的微小信息，也可能成为改变游戏结果的关键。这正是无论是在扑克桌上还是股市中，赌徒们赖以生存的细微优势。与 Fisher 提出的统计显著性概念不同，那种武断地使用脱离具体情境的标准来判断何为「显著」发现的方法，在赌博这样的实践中显得极其不合适。

但这并不意味着 Voulgaris 不主动构建关于统计数据的假设。(统计学家 Fisher 关于假设检验的理论问题并非在于提出假设本身，而是在于他推荐的检验方法。）62 事实上，提出假设对 Voulgaris 的分析至关重要。统计模式人人都能看到，这些模式很快就会反映在博彩赔率中。真正的挑战在于判断这些模式究竟是有意义的信号，还是随机波动的噪声。Voulgaris 凭借丰富的篮球专业知识，快速而精准地识别出这些模式背后真正的规律。

Voulgaris 研究篮球投注的方法堪称科学方法最纯粹的实践（图 8-7）。他观察世界，并提出深入的问题：为什么克利夫兰骑士队的比赛总得分总是超出预期？随后，他收集相关信息，并提出了一个富有洞察力的假设：骑士队比赛得分超标是因为 Ricky Davis 正处于职业生涯的「合同年」（指运动员合同即将到期的赛季），为了争取更好的下一份合同，他正以快节奏的打法全力提升个人统计数据。与传统科学研究不同的是，Voulgaris 通过实际下注来验证自己的预测，而科学家则会设计实验来检验假设。

在赛季结束前，Davis 的个人利益和动机不会发生改变。这意味着：(i）他很可能会继续以高强度和快速的节奏打球，并且，(ii）骑士队的比赛预计将继续保持高分的特点。

验证这个预测准备下注了吗？

如果 Voulgaris 能够从数据中提炼出一个有力的假设，他就可能做出更精准的投注。举例来说，当他偶然听到丹佛掘金队教练随意提到想为球迷「呈现一场精彩比赛」时，这看似只是闲聊，实则可能暗示球队将改变战术，以提高比赛的观赏性和吸引力。如果这个假设成立，Voulgaris 预计在掘金队比赛的投注中，获胜概率可以从传统的 50% 提升到 70%。

这正是贝叶斯定理（Bayes's theorem）的魅力所在：假设的可信度越高，专业分析师就能越快捕捉到赛事中的微妙变化。Voulgaris 可能只需观察一两场比赛，就能验证自己的理论，并在传统博彩市场反应之前抢得先机。与此同时，他能够理性地过滤掉那些看似重要但实际毫无意义的统计数据，比如 1999 年湖人队开局的低迷表现，避免被表面现象误导。

通向理性的贝叶斯之路

概率估计究竟是主观的还是客观的？这是一个颇为复杂的问题。

从人类认知的经验角度看，我们每个人的信念和偏见都是由个人经历、价值观、知识，以及可能的利益倾向等多重因素共同塑造的。贝叶斯推理的独特之处在于，它诚实地承认了人们在解读新证据时会受到先验信念的影响，从而提供了一种极其贴近人类思维方式的认知模型。比如，如果统计学家费舍尔最初坚信香烟致癌的可能性微乎其微（仅为 0.00001%），这就能解释为什么大量相反的科学证据都无法动摇他的原有观点。

更有趣的是，贝叶斯定理并不排斥个人持有看似绝对的信念。一个人可以坚信上帝存在的概率是百分之百，或者完全不存在，而在这种情况下，无论多么充分的证据都很难改变其根深蒂固的观点。这恰恰揭示了概率估计中不可避免的主观性：我们的信念不仅仅来自于客观数据，还深深植根于个人的价值体系和认知框架。

我并不是想告诉你什么事情是必须绝对相信的。但是，我们在表达观点时或许应该更加诚实和谦逊。当一个坚信某事完全不可能的人，和另一个认为这件事必定会发生的人争论时，双方注定无法达成任何有意义的共识。历史上，许多血腥的宗教战争，如早期印刷机时代欧洲的教派冲突，正是源于这种极端和相互对立的思维方式。

这并不意味着所有的信念都同等正确或有效。但我认为，人类无法在认知中达到绝对的客观、理性和准确。相反，我们应该致力于减少主观偏见，提高理性水平，不断修正错误认知。通过对信念进行预测，我们可以最有效地检验自身认知的可靠性 — 这可能是唯一可行的方法。

客观性追求的是超越个人视角的更高真理，而预测则是衡量个人认知与这种更高真理契合程度的最佳途径。因此，在众多认知主体中，最为客观的，往往是预测最为精准的人。相较于 Fisher 将客观性局限于实验室严格控制环境的统计方法，贝叶斯推理（Bayesian reasoning）提供了一种更灵活和动态的认知评估方式，能更好地处理不确定性和不完整信息。

贝叶斯定理的一个重要特性是，随着我们逐步获得更多证据，我们的信念会逐渐趋同，并最终接近真相。在图 8-8 中，我用一个投资者判断市场走势的例子来说明这一点。三位投资者对市场前景有着截然不同的初始看法：一位乐观投资者认为有 90% 的可能是牛市，而另一位悲观投资者则只给出 10% 的牛市概率。

每当市场上涨时，投资者就会稍微调整自己的看法，变得更加看好市场；反之，市场下跌则会削弱他们的乐观情绪。在这个模拟中，尽管每日市场波动是随机的，但长期来看，市场有 60% 的时间呈上涨趋势。

尽管过程并非一帆风顺，但最终所有投资者都会得出相同的结论 —— 市场确实处于牛市，且他们对此的信心接近 100%。这生动地展示了贝叶斯推理的一个迷人特征：随着证据的累积，不同观点会逐渐收敛，人们对真相的认知会越来越接近。

图 8-8：贝叶斯收敛

理论上，科学应该是这样推进的。科学共识是个复杂的概念，其核心是随着观点的交锋和新证据的揭示，科学界的认知逐渐接近真理。就像股市一样，这个过程并非总是线性和平顺的。科学界在接受新证据并调整既有范式时往往过于谨慎 [64]，尽管也曾出现过过快跟风的情况。但只要每个人都秉持贝叶斯推理的逻辑，即便最初的信念和假设存在偏差，最终也会被修正，逐渐趋近真相。

就当前而言，科学家使用的统计方法似乎正处于一个重大转折点。我对费舍尔统计方法缺陷的批评并非独树一帜，从临床心理学 [65] 到政治学 [66]，再到生态学 [67]，许多著名学者多年来一直在提出类似观点。然而，迄今为止，这些批评几乎未引发根本性的方法变革。

近年来，一些备受尊敬的统计学家开始质疑传统的频率统计学（基于重复随机抽样和显著性检验）是否适合本科教育 [68]。更令人瞩目的是，某些专业领域甚至考虑在学术期刊中禁止使用费希尔的经典假设检验方法 [69]。事实上，回顾过去十年的学术文献，几乎所有研究都在倡导更为灵活的贝叶斯统计方法。

以 Bob 为例，他虽然并非机械地在每次预测中都应用贝叶斯定理，但他分析篮球数据的方法本质上是贝叶斯式的。他根据已有的领域知识构建假设，并且能够自然地接受概率性的结论，这正体现了贝叶斯思维的精髓。

改变根深蒂固的学术传统需要时间。然而，贝叶斯定理本身预示着科学方法的进化趋势 —— 通过不断整合新证据和先验知识，我们终将收敛到更加精确和灵活的分析方法。从长远来看，贝叶斯主义者很可能会成为统计学研究的主导力量。

