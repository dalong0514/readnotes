Nate Silver.(2012).2018173The-Signal-and-the-Noise.Penguin Group =>  0901Rage Against the Machines

## 0901Rage Against the Machines

The twenty-seven-year-old Edgar Allan Poe, like many others before him, was fascinated by the Mechanical Turk, a contraption that had once beaten Napoleon Bonaparte and Benjamin Franklin at chess. The machine, constructed in Hungary in 1770 before Poe or the United States of America were born, had come to tour Baltimore and Richmond in the 1830s after having wowed audiences around Europe for decades. Poe deduced that it was an elaborate hoax, its cogs and gears concealing a chess master who sat in its cupboards and manipulated its levers to move the pieces about the board and nod its turban-covered head every time that it put its opponent into check.

Poe is regarded as the inventor of the detective story,1 and some of his work in sleuthing the hoax was uncanny. He was rightly suspicious, for instance, that a man (later determined to be the German chess master William Schlumberger) could always be found packing and unpacking the machine but was nowhere to be seen while the game was being played (aha! he was in the box). What was truly visionary about Poe's essay on the Mechanical Turk, however, was his grasp of its implications for what we now call artificial intelligence (a term that would not be coined until 120 years later). His essay expressed a very deep and very modern ambivalence about the prospect that computers might be able to imitate, or improve on, the higher functions of man.

FIGURE 9-1: THE MECHANICAL TURK

Poe recognized just how impressive it might be for a machine to play chess at all. The first mechanical computer, what Charles Babbage called the difference engine, had barely been conceived of at the time that Poe wrote his exposé. Babbage's proposed computer, which was never fully built during his lifetime, might at best hope to approximate some elementary functions like logarithms in addition to carrying out addition, subtraction, multiplication, and division. Poe thought of Babbage's work as impressive enough—but still, all it did was take predictable inputs, turn a few gears, and spit out predictable outputs. There was no intelligence there—it was purely mechanistic. A computer that could play chess, on the other hand, verged on being miraculous because of the judgment required to play the game well.

Poe claimed that if this chess-playing machine were real, it must by definition play chess flawlessly; machines do not make computational errors. He took the fact that the Turk did not play perfect chess—it won most of its games but lost a few—as further proof that it was not a machine but a human-controlled apparatus, full of human imperfections.

Although Poe's logic was flawed, this reverence for machines is still with us today. We regard computers as astonishing inventions, among the foremost expressions of human ingenuity. Bill Gates often polls as among the most admired men in America,2 and Apple and Google among our most admired companies.3 And we expect computers to behave flawlessly and effortlessly, somehow overcoming the imperfections of their creators.

Moreover, we view the calculations of computer programs as unimpeachably precise and perhaps even prophetic. In 2012, a pair of British teenagers were accused of defrauding investors out of more than a million dollars by promoting their stock-picking "robot" named MARL,4 which they claimed could process "1,986,832 mathematical calculations per second" while avoiding "human ‘gut feelings,'" allowing investors to double their money every few hours by following MARL's recommendations for penny stocks.5

Even when computer predictions do not inspire our credulity, they can spark our fears; computers that run programs to forecast the chance of survival for hospital patients, for instance, are sometimes written about in news accounts6 as though they are cousins of the HAL 9000, the computer from 2001: A Space Odyssey, which decided it had no more use for the astronauts and tried to suffocate them.

As we enter the era of Big Data, with information and processing power increasing at exponential rates, it may be time to develop a healthier attitude toward computers and what they might accomplish for us. Technology is beneficial as a labor-saving device, but we should not expect machines to do our thinking for us.

27 岁的爱伦·坡与许多人一样，对这台被称为「机械图灵者」的奇特机器深感兴趣。这台机器曾在国际象棋中战胜过拿破仑·波拿巴和本杰明·富兰克林。它在 1770 年于匈牙利制造，比爱伦·坡和美利坚合众国诞生还要早，并在 1830 年代巡回于巴尔的摩和里士满，此前已在欧洲各地引起多年轰动。爱伦·坡推断这是一个精心策划的骗局：机器内部的齿轮和机关实际上隐藏着一位隐藏的棋艺高手，他藏在机器的柜橱中，通过操控精巧的杠杆移动棋子，并在每次将对手逼入绝境时，让机器点头示意，头上的头巾随之轻轻晃动。

波依被誉为侦探小说的开山鼻祖 [1]，他在揭露欺骗方面展现出卓越的洞察力。比如，他敏锐地怀疑一个神秘人（后被证实是德国国际象棋大师威廉·施伦伯格）总是忙于机器的装卸，却从未在比赛过程中现身（原来如此！他藏在盒子里）。

更为惊人的是，波依在论述这台「机械图灵」（一种早期的「机器人」骗局）时，展现出对人工智能本质的卓越洞察力 —— 这个术语要到 120 年后才会被正式提出。他敏锐地表达了一种至今仍然存在的深刻忧虑：计算机是否能够模仿，甚至超越人类的高级认知功能。

图 9-1：机械图灵（早期的机器人骗局模型）

波（Poe）非常清楚地意识到，对于一台机器来说，能够下棋本身就是极其了不起的成就。在他写这篇文章的时候，第一台机械计算机 —— 查尔斯·巴贝奇（Charles Babbage）称之为差分机（difference engine，一种早期机械计算设备）—— 刚刚被构想出来。巴贝奇设计的这台计算机在他的有生之年从未完全建成，最多只能希望计算一些基本数学函数，如对数，以及进行简单的算术运算。波认为巴贝奇的工作已经令人惊叹 —— 但是，它本质上只是一台按部就班地接受输入、转动几个齿轮，然后输出结果的机器。那里没有真正的智能，仅仅是机械的重复。相比之下，一台能够下棋的计算机则因为需要复杂的判断能力而近乎奇迹。

波声称，如果这台下棋机器是真实存在的，它必定会完美无缺地下棋；因为机器不会犯计算错误。他以著名的下棋机器「土耳其人」（the Turk，一个看似能下棋的机械装置）没有完美地下棋 —— 它赢得了大多数比赛，但也输了几局 —— 作为进一步的证据，认为这不是一台真正的自动机器，而是一个由人类暗中操控的装置，带有人类判断的不确定性和局限性。

尽管 Poe 的逻辑存在缺陷，但我们对机器的敬畏至今仍然存在。我们将计算机视为惊人的发明，是人类智慧的最前沿表达。Bill Gates 经常位列美国最受尊敬的人物榜单，而 Apple 和 Google 也是最令人钦佩的公司。我们期望计算机能完美无缺且轻而易举地工作，以某种方式克服其创造者的缺陷。

此外，我们将计算机程序的计算视为无可争议的精确，甚至可能具有预言性。2012 年，一对英国青少年通过推广名为 MARL 的股票选择「智能系统」，从投资者那里诈骗了超过一百万美元。他们声称该系统每秒可以处理「1,986,832 个数学计算」，并且能够避免人类的「直觉感受」。他们承诺，只要按照 MARL 对低价股票的建议操作，投资者就能每隔几小时使资金翻倍。

即便计算机预测无法轻易赢得我们的信任，它们也能激发我们的恐惧。例如，那些运行程序预测医院患者生存几率的计算机，在新闻报道中常常被描绘得如同《2001 太空漫游》中的 HAL 9000 —— 一台决定不再需要宇航员并试图将他们窒息的机器。

随着我们步入大数据时代（即海量数据和快速计算的时代），信息和处理能力正以指数级速率增长，现在是时候对计算机及其潜在能力形成一种更理性、更健康的态度了。技术作为一种节省人力的工具确实很有价值，但我们不应期望机器能够完全代替人类思考。

### The Birth of the Chess Computer

The Spanish engineer Leonardo Torres y Quevedo built a version of the Mechanical Turk in 1912, which he called El Ajedrecista (the chess player). Although El Ajedrecista is sometimes regarded as the first computer game,7 it was extremely limited in its functionality, restricted to determining positions in an endgame in which there are just three pieces left on the board. (El Ajedrecista also did not have any stereotypical Turkish headgear.)

The father of the modern chess computer was MIT's Claude Shannon, a mathematician regarded as the founder of information theory, who in 1950 published a paper called "Programming a Computer for Playing Chess."8 Shannon identified some of the algorithms and techniques that form the backbone of chess programs today. He also recognized why chess is such an interesting problem for testing the powers of information-processing machines.

Chess, Shannon realized, has an exceptionally clear and distinct goal—achieving checkmate. Moreover, it follows a relatively simple set of rules and has no element of chance or randomness. And yet, as anybody who has played chess has realized (I am not such a good player myself), using those simple rules to achieve that simple goal is not at all easy. It requires deep concentration to survive more than a couple of dozen moves into a chess game, let alone to actually win one. Shannon saw chess as a litmus test for the power of computers and the sort of abilities they might someday possess.

But Shannon, in contrast to some who came after him, did not hold the romanticized notion that computers might play chess in the same way that humans do. Nor did he see their victory over humans at chess as being inevitable. Instead, he saw four potential advantages for computers:

They are very fast at making calculations.

They won't make errors, unless the errors are encoded in the program.

They won't get lazy and fail to fully analyze a position or all the possible moves.

They won't play emotionally and become overconfident in an apparent winning position that might be squandered or grow despondent in a difficult one that might be salvaged.

These were to be weighed, Shannon thought, against four distinctly human advantages:

Our minds are flexible, able to shift gears to solve a problem rather than follow a set of code.

We have the capacity for imagination.

We have the ability to reason.

We have the ability to learn.

It seemed like a fair fight to Shannon. But that was only the case for a few fleeting moments in the mid-1990s, when the Russian grandmaster Garry Kasparov—the best chess player of all time—went up against what was then one of the most advanced computers ever built, IBM's Deep Blue.

Before their match, humans were winning the fight—it wasn't even close. Yet computers have prevailed ever since, and will continue to do so for as long as we live.

国际象棋计算机的诞生

西班牙工程师 Leonardo Torres y Quevedo 在 1912 年制造了一台模仿人类下棋的机器，名为 El Ajedrecista（意为「国际象棋选手」）。这台机器有时被认为是最早的计算机游戏 [7]，但其功能极其有限，仅能分析棋盘上仅剩三个棋子的残局位置。(有趣的是，这台机器并没有刻板印象中的土耳其风格装扮。)

现代国际象棋计算机之父是麻省理工学院的 Claude Shannon，一位信息论的开创性数学家。1950 年，他发表了划时代的论文《为计算机编写国际象棋程序》[8]。Shannon 首次揭示了构建国际象棋程序的关键算法和技术，同时敏锐地意识到：国际象棋是检验机器信息处理能力的绝佳「试金石」。

在国际象棋中，Shannon 意识到这是一个目标极其明确的游戏 —— 击败对手，完成致命一击。这个游戏遵循相对简单的规则，没有任何偶然性或随机性的成分。然而，正如每一个下过国际象棋的人都深有体会（我自己也算不上一个出色的棋手），用这些看似简单的规则来获得胜利远非易事。要在棋局中坚持超过几十个回合，甚至最终赢得比赛，都需要极其专注的精神状态。Shannon 将国际象棋视为测试计算机潜能的关键标准。

不同于后来的一些研究者，Shannon 并不天真地认为计算机会以与人类完全相同的方式下棋，也不认为计算机战胜人类是必然的。相反，他发现计算机在以下四个方面具有潜在优势：

- 计算速度极快

- 除非程序本身存在缺陷，否则不会犯错

- 永不会因为懒惰而放弃全面分析棋局和所有可能的走法

- 他们不会因情绪影响下棋，在看似必胜的局面可能会轻易失误，或在困境中过早丧失希望，尽管局面仍有转机。

香农认为，这些特点需要与人类的四大独特优势相比较：

我们的思维富有弹性，能够灵活应变地解决问题，而不是机械地遵循固定程序。

我们拥有丰富的想象力。

我们具备理性推理的能力。

我们能够持续学习和成长。

对香农来说，这似乎是一场势均力敌的对决。但这种平衡仅存在于 1990 年代中期的短暂瞬间，当时俄罗斯棋王加里·卡斯帕罗夫 —— 史上最伟大的棋手 —— 与 IBM 的 Deep Blue 这台顶尖计算机对弈。

在这场比赛之前，人类在国际象棋领域处于绝对优势。然而此后，计算机不断取得进步，并将在可预见的未来继续保持这种优势。

### Chess, Prediction, and Heuristics

In accordance with Bayes's theorem, prediction is fundamentally a type of information-processing activity—a matter of using new data to test our hypotheses about the objective world, with the goal of coming to truer and more accurate conceptions about it.

Chess might be thought of as analogous to prediction. The players must process information—the position of the thirty-two pieces on the board and their possible moves. They use this information to devise strategies to place their opponent in checkmate. These strategies in essence represent different hypotheses about how to win the game. Whoever succeeds in that task had the better hypothesis.

Chess is deterministic—there is no real element of luck involved. But the same is theoretically true of the weather, as we saw in chapter 4. Our knowledge of both systems is subject to considerable imperfections. In weather, much of the problem is that our knowledge of the initial conditions is incomplete. Even though we have a very good idea of the rules by which the weather system behaves, we have incomplete information about the position of all the molecules that form clouds and rainstorms and hurricanes. Hence, the best we can do is to make probabilistic forecasts.

In chess, we have both complete knowledge of the governing rules and perfect information—there are a finite number of chess pieces, and they're right there in plain sight. But the game is still very difficult for us. Chess speaks to the constraints on our information-processing capabilities—and it might tell us something about the best strategies for making decisions despite them. The need for prediction arises not necessarily because the world itself is uncertain, but because understanding it fully is beyond our capacity.9

Both computer programs and human chess masters therefore rely on making simplifications to forecast the outcome of the game. We can think of these simplifications as "models," but heuristics is the preferred term in the study of computer programming and human decision making. It comes from the same Greek root word from which we derive eureka.10 A heuristic approach to problem solving consists of employing rules of thumb when a deterministic solution to a problem is beyond our practical capacities.

Heuristics are very useful things, but they necessarily produce biases and blind spots.11 For instance, the heuristic "When you encounter a dangerous animal, run away!" is often a useful guide but not when you meet a grizzly bear; she may be startled by your sudden movement and she can easily outrun you. (Instead, the National Park Service advises you to remain as quiet and as still as possible when you encounter a grizzly bear and even to play dead if necessary.12) Humans and computers apply different heuristics when they play chess. When they play against each other, the game usually comes down to who can find his opponent's blind spots first.

国际象棋、预测与启发式算法（Heuristics)

根据贝叶斯定理，预测本质上是一种信息处理活动。它通过引入新数据来检验和完善我们对客观世界的假设，旨在不断逼近更加准确和接近真相的认知。

国际象棋可以被类比为一种预测活动。玩家需要处理棋盘上的信息 —— 三十二枚棋子的位置和可能的走法。他们利用这些信息制定获胜策略，目标是将对手逼入死角，也就是国际象棋中的「将死」状态（即对手的王被困，无路可逃）。这些策略本质上代表了赢得比赛的不同路径。最终能够成功的选手，就是那个提出了最佳「获胜假设」的人。

国际象棋是一个完全依靠技术和策略的游戏，没有任何随机运气的成分。从理论上说，天气系统也是类似的，正如我们在第 4 章讨论的。然而，我们对这两个系统的认知都存在诸多不确定性。以天气为例，主要问题在于我们对初始条件的了解是不完整的。尽管我们对天气系统的基本运行规律有相当好的理解，但我们无法精确掌握构成云层、暴雨和飓风的所有分子的确切位置。因此，科学家们只能做出概率性预测 —— 给出未来天气可能的变化范围和出现的可能性。

在国际象棋这个看似简单明了的游戏中，所有规则和棋局信息都是完全公开的 —— 棋子数量有限，位置清晰可见。然而，这个游戏对人类仍然极具挑战性。国际象棋生动地展示了人类信息处理能力的局限性，同时也揭示了我们在面对复杂问题时如何做出决策。我们之所以需要预测，并非因为世界本身充满不确定性，而是因为我们透彻理解世界的能力天生受限 [9]。

无论是人工智能程序还是顶级棋手，都不得不采用某种简化策略来预测比赛走向。这些策略可以称为「模型」，但在计算机科学和决策研究领域，人们更喜欢使用「启发式」这个术语。有趣的是，「启发式」源自于希腊语词根，与激发灵感时常脱口而出的「尤里卡！」（Eureka!）同源 [10]。简单来说，启发式方法就是在无法找到精确解决方案时，运用经验法则和直觉来应对复杂问题的思维策略。

启发式方法是非常实用的工具，但同时也不可避免地会带来认知偏见和思维盲区。11 打个比方，「遇到危险动物，立即逃跑！」这个朴素的生存经验在大多数情况下确实管用，但在面对灰熊时绝对行不通。一旦你突然移动，这头强大的野兽可能会更加警觉，而且以其惊人的速度，追上你简直是轻而易举。(相比之下，国家公园管理局给出了完全不同的建议：遇到灰熊时，应该保持绝对安静，一动不动，必要时甚至要「装死」—— 也就是躺在地上一动不发。12）

就像人类和计算机在下棋时会使用截然不同的思考策略一样，双方的胜负往往取决于谁能更快地识破对手的思维盲区（即对局中的关键弱点）。

### Kasparov's Failed Prediction

In January 1988, Garry Kasparov, the top-rated chess player in the world from 1986 until his retirement in 2005,13 predicted that no computer program would be able to defeat a human grandmaster at chess until at least the year 2000.14 "If any grandmaster has difficulties playing computers," he quipped at a press conference in Paris, "I would be happy to provide my advice."15 Later that same year, however, the Danish grandmaster Bent Larsen was defeated by a program named Deep Thought, a graduate-school project by several students at Carnegie Mellon University.

The garden-variety grandmaster, however, was no Kasparov, and when Deep Thought squared off against Kasparov in 1989 it was resoundingly defeated. Kasparov has always respected the role of computing technology in chess, and had long studied with computers to improve his game, but he offered Deep Thought only the faintest praise, suggesting that one day a computer could come along that might require him to exert his "100 percent capabilities" in order to defeat it.16

The programmers behind Deep Thought, led by Feng-hsiung Hsu and Murray Campbell, were eventually hired by IBM, where their system evolved into Deep Blue. Deep Blue did defeat Kasparov in the first game of a match in Philadelphia in 1996, but Kasparov rebounded to claim the rest of the series fairly easily. It was the next year, in a rematch in New York, when the unthinkable happened. Garry Kasparov, the best and most intimidating chess player in history, was intimidated by a computer.

1988 年 1 月，盖里·卡斯帕罗夫（从 1986 年到 2005 年世界排名第一的棋手）自信地预测，在 2000 年之前，不会有任何计算机程序能战胜人类国际大师。在巴黎的一次新闻发布会上，他甚至自信地调侃：「如果哪位国际大师在与计算机对弈时遇到困难，我随时可以提供建议。」然而，就在同年，丹麦国际大师本特·拉森被一个名为深思（Deep Thought）的程序击败，这是卡内基梅隆大学几名学生的研究生项目。

相比卡斯帕罗夫，普通国际大师的水平显然有限。1989 年，当深思与卡斯帕罗夫对弈时，这台计算机被彻底击败。尽管卡斯帕罗夫一直尊重计算技术在国际象棋中的作用，并经常使用计算机来提升自己的技艺，但他对深思的评价极其谨慎。他暗示，未来可能会出现一台需要他全力以赴才能战胜的计算机。

在深思（Deep Thought）背后的程序员 Feng-hsiung Hsu 和 Murray Campbell 的带领下，他们最终加入了 IBM，并将这个系统进化为深蓝（Deep Blue）。1996 年，深蓝在费城的首场比赛中战胜了卡斯帕罗夫，但随后卡斯帕罗夫轻松赢回了比赛。然而，在第二年纽约的重赛中，一个令人震惊的时刻到来了：历史上最伟大、最令人生畏的棋手加里·卡斯帕罗夫，竟然被一台计算机所慑服。

### In the Beginning . . .

A chess game, like everything else, has three parts: the beginning, the middle and the end. What's a little different about chess is that each of these phases tests different intellectual and emotional skills, making the game a mental triathlon of speed, strength, and stamina.

In the beginning of a chess game the center of the board is void, with pawns, rooks, and bishops neatly aligned in the first two rows awaiting instructions from their masters. The possibilities are almost infinite. White can open the game in any of twenty different ways, and black can respond with twenty of its own moves, creating 4,000 possible sequences after the first full turn. After the second full turn, there are 71,852 possibilities; after the third, there are 9,132,484. The number of possibilities in an entire chess game, played to completion, is so large that it is a significant problem even to estimate it, but some mathematicians put the number as high as . These are astronomical numbers: as Diego Rasskin-Gutman has written, "There are more possible chess games than the number of atoms in the universe."17

It might seem that at the beginning of the game, when all the pieces are still on the board and the number of possibilities is most limitless, computers are at their greatest strength. As IBM's Web site bragged before the match against Kasparov, their computer could calculate 200 million positions per second. "Incidentally, Garry Kasparov can evaluate approximately three positions per second," it noted snidely.18 How did Kasparov have a chance?

But chess computers had long been rather poor at the opening phase of the game. Although the number of possibilities was the most limitless, the objectives were also the least clear. When there are branches on the tree, calculating 3 moves per second or 200 million is about equally fruitless unless you are harnessing that power in a directed way.

Both computer and human players need to break a chess game down into intermediate goals: for instance, capturing an opponent's pawn or putting their king into check. In the middle of the match, once the pieces are locked in combat and threaten one another, there are many such strategic objectives available. It is a matter of devising tactics to accomplish them, and forecasting which might have the most beneficial effects on the remainder of the game. The goals of the opening moves, however, are more abstract. Computers struggle with abstract and open-ended problems, whereas humans understand heuristics like "control the center of the board" and "keep your pawns organized" and can devise any number of creative ways to achieve them.

Moreover, because the opening moves are more routine to players than positions they may encounter later on, humans can rely on centuries' worth of experience to pick the best moves. Although there are theoretically twenty moves that white might play to open the game, more than 98 percent of competitive chess games begin with one of the best four.19

The problem for humans is that computer programs can systematize this knowledge by studying statistics. Chess databases contain the results of literally hundreds of thousands of games and like any other database can be mined for predictive insight. IBM's programmers studied things like how often each sequence of opening moves had been played and how strong the players were who played them, as well as how often each series of moves resulted in wins, losses, and draws for their respective sides.20 The computer's heuristics for analyzing these statistics could potentially put it on a level playing field with human intuition and experience, if not well ahead of it. "Kasparov isn't playing a computer, he's playing the ghosts of grandmasters past," IBM's Web site said in reference to Deep Blue's deep databases.21

Kasparov's goal, therefore, in his first game of his six-game match against Deep Blue in 1997, was to take the program out of database-land and make it fly blind again. The opening move he played was fairly common; he moved his knight to the square of the board that players know as f3. Deep Blue responded on its second move by advancing its bishop to threaten Kasparov's knight—undoubtedly because its databases showed that such a move had historically reduced white's winning percentage* from 56 percent to 51 percent.

Those databases relied on the assumption, however, that Kasparov would respond as almost all other players had when faced with the position,22 by moving his knight back out of the way. Instead, he ignored the threat, figuring that Deep Blue was bluffing,23 and chose instead to move one of his pawns to pave the way for his bishop to control the center of the board.

Kasparov's move, while sound strategically, also accomplished another objective. He had made just three moves and Deep Blue had made just two, and yet the position they had now achieved (illustrated in figure 9-2) had literally occurred just once before in master-level competition24 out of the hundreds of thousands of games in Deep Blue's database.

Even when very common chess moves are played, there are so many possible branches on the tree that databases are useless after perhaps ten or fifteen moves. In any long game of chess, it is quite likely that you and your opponent will eventually reach some positions that literally no two players in the history of humanity have encountered before. But Kasparov had taken the database out after just three moves. As we have learned throughout this book, purely statistical approaches toward forecasting are ineffective at best when there is not a sufficient sample of data to work with.

Deep Blue would need to "think" for itself.

FIGURE 9-2: POSITION AFTER KASPAROV'S 3RD MOVE IN GAME 1

棋逢对手就像其他一切事物一样，国际象棋比赛分为三个阶段：开局、中盘和残局。与其他比赛不同的是，国际象棋的每个阶段都是一次独特的智力和心理挑战，考验着选手的速度、力量和耐力，宛如一场极限的智力马拉松。

在国际象棋游戏的开局阶段，棋盘中心空无一子，兵、车和象整齐地排列在前两排，静待主人的指挥。棋局的可能性几乎是无穷无尽的。白方可以用 20 种不同方式开局，黑方也能用 20 种方式回应，仅第一轮完整走子就能产生 4000 种可能的序列。到第二轮完整走子时，可能性已增加到 71,852 种；第三轮后更是达到 9,132,484 种。

一盘完整的国际象棋游戏中，可能的变化数量之多，以至于准确估算都是一个巨大的挑战。一些数学家估计，可能的棋局数量甚至超过了天文数字。正如研究者 Diego Rasskin-Gutman 所言：「可能的国际象棋游戏数量，比宇宙中的原子数量还要多得多」[17]。这个惊人的数字展示了国际象棋策略的极致复杂性。

乍看之下，在棋局开始时，所有棋子仍在棋盘上，可能性似乎最为丰富，这应该是计算机的最大优势。就像 IBM 在对战卡斯帕罗夫前在网站上吹嘘的那样，他们的计算机每秒可以计算 2 亿种棋局位置。「顺便提一句，加里·卡斯帕罗夫每秒大约只能评估三种位置，」网站颇为得意地指出 [18]。卡斯帕罗夫怎么可能赢？

然而，国际象棋计算机在棋局开局阶段一直表现平平。虽然可能性看似无限，但目标却极其模糊。即便能每秒计算海量的走法，如果没有明确的策略引导，这些计算也将毫无意义。只有精准地引导计算能力，才能真正发挥优势。

无论是计算机还是人类棋手，都需要将一盘棋分解为阶段性目标：比如捕获对方的棋子或将对方的王置于威胁状态。在比赛中期，当棋子相互对峙并形成威胁时，可选择的战略目标数不胜数。关键在于制定战术来实现这些目标，并预测哪些走法对比赛的后续发展最为有利。

然而，开局的目标则更为抽象。计算机在处理抽象和开放性问题时往往捉襟见肘，而人类则能够理解诸如「控制棋盘中心」和「保持棋子阵型整齐」等战略性启发，并能创造性地找到多种实现这些目标的方法。

更有趣的是，由于开局对玩家来说比后续的复杂棋局更加常规，人类可以依靠数百年积累的经验来选择最佳走法。尽管理论上白方有二十种可能的开局走法，但超过 98% 的竞技象棋比赛实际上都是从四种最佳开局中选择 [19]。

对人类来说，计算机程序通过统计分析可以系统地整理和理解知识，这是一个巨大的挑战。国际象棋数据库收录了数十万场比赛的对弈结果，就像其他数据库一样，可以挖掘出有价值的预测性见解。

IBM 的程序员深入研究了棋局数据，包括每种开局移动序列的使用频率、使用这些招法的棋手水平，以及不同移动系列对双方对战结果的影响。[20] 计算机基于这些数据得出的分析策略，很可能已经与人类的直觉和经验相当，甚至已经超越了人类。

正如 IBM 网站生动地描述的那样「卡斯帕罗夫不是在与一台计算机对弈，而是在与历代大师的智慧对决。」[21] 这句话生动地展示了计算机背后蕴含的海量棋艺知识。

在 1997 年对阵深蓝的六场比赛首局中，卡斯帕罗夫的目标是迫使这台计算机脱离数据库的固有模式，重新进入不确定性的决策领域。他采用了一个相对常见的开局，将马移至 f3 方格。深蓝随后在第二步移动象（Bishop），威胁卡斯帕罗夫的马 —— 显然是因为数据库显示这种走法 historically 会将白方的获胜几率从约 56% 降低至 51%。

然而，这些数据库建立在一个普遍假设之上：几乎所有棋手在面对这种局面时都会选择将马撤回。与众不同的是，卡斯帕罗夫并未理会这个威胁，他推测深蓝可能只是在试探，转而选择推进一个兵，为后续控制棋盘中心的象铺平道路。

卡斯帕罗夫的这步棋在战略上虽然精妙，但更巧妙地达成了另一个目的。仅仅经过三步（卡斯帕罗夫）和两步（深蓝）后，他们所处的棋局位置（如图 9-2 所示）在深蓝庞大的数据库中，历史上只出现过一次 [24]。

在国际象棋中，即便是常见的走法，由于可能的变化分支实在太多，数据库的参考价值往往在十几步后就会急剧下降。在漫长的对弈中，棋手很可能会进入一个前所未有的独特棋局 —— 一个历史上没有任何两位棋手曾经达到过的位置。而卡斯帕罗夫仅仅用了三步就让深蓝的数据库失去了参考价值。正如本书反复强调的，在缺乏充分数据样本的情况下，纯粹依赖统计的预测方法注定是徒劳的。

在这一刻，深蓝必须开始真正地「思考」：依靠自身的计算能力，而非简单地检索历史数据。

图 9-2：第 1 局卡斯帕罗夫第 3 步后的位置

### The Chess Player's Dilemma: Breadth Versus Depth

The middle of a chess game (simply called the midgame) potentially favors the strengths of the computer. With the pieces free to move in the center of the board, there are an average of around forty possible moves rather than twenty for every turn.25 That might not seem like a huge difference, but because the tree of possibilities explodes exponentially, it quickly adds up. Suppose, for instance, that you want to calculate just three full turns ahead (that is, three moves each for you and your opponent, or six total). At the beginning of the game, this function is approximated by the number twenty taken to the sixth power, which is sixty-four million positions, already a gargantuan number. In the midgame, however, you have to calculate forty to the sixth power, or 4.1 billion possibilities. Deep Blue could calculate all those positions in just twenty seconds. Kasparov would require literally forty-three years to do so, even without pausing to eat, sleep, or go to the bathroom.

Great players like Kasparov do not delude themselves into thinking they can calculate all these possibilities. This is what separates elite players from amateurs. In his famous study of chess players, the Dutch psychologist Adriaan de Groot found that amateur players, when presented with a chess problem, often frustrated themselves by looking for the perfect move, rendering themselves incapable of making any move at all.26

Chess masters, by contrast, are looking for a good move—and certainly if at all possible the best move in a given position—but they are more forecasting how the move might favorably dispose their position than trying to enumerate every possibility. It is "pure fantasy," the American grandmaster Reuben Fine wrote,27 to assume that human chess players have calculated every position to completion twenty or thirty moves in advance.

It is not quite as simple as saying that "the perfect is the enemy of the good." If you want to really master a game like chess, you may need to get beyond such simple heuristics. Nevertheless, we are not capable of making perfect decisions when presented with more information than we can process in a limited amount of time. Acknowledging those imperfections may free us to make the best decisions that we can in chess and in other contexts that involve forecasting.

This is not to say that grandmasters like Kasparov don't have any calculations to perform. At the very least, Kasparov might need to devise a tactic, a precise sequence of perhaps three to five moves, to capture an opponent's piece or accomplish some other near-term objective. For each of those moves, he will need to think about how his opponent might respond—all the possible variations in the play—and whether any of them could nullify his tactic. He will also need to consider whether the opponent has laid any traps for him; a strong-looking position can be turned into a checkmate in just a few moves if a player's king is not protected.

Chess players learn through memory and experience where to concentrate their thinking. Sometimes this involves probing many branches of the tree but just a couple of moves down the line; at other times, they focus on just one branch but carry out the calculation to a much greater depth. This type of trade-off between breadth and depth is common anytime that we face a complicated problem. The Defense Department and the CIA, for instance, must decide whether to follow up on a broader array of signals in predicting and preventing potential terrorist attacks, or instead to focus on those consistent with what they view as the most likely threats. Elite chess players tend to be good at metacognition—thinking about the way they think—and correcting themselves if they don't seem to be striking the right balance.

国际象棋选手的困境：广度与深度

在国际象棋的中盘阶段，计算机展现出惊人的计算优势。当棋子可以在棋盘中央自由移动时，每一回合的可选走法会从开局时的约 20 种，激增到 40 种。这看似只是数量上的小变化，但由于可能性以指数形式成倍增长，很快就会产生巨大差异。

举个例子，如果你想提前计算三个完整回合（意味着你和对手各走三步，总共六步），计算量会急剧膨胀。在比赛开始时，这意味着需要计算 20 的 6 次方，约 6,400 万种位置变化，这已经是一个惊人的数字。而到了中盘阶段，计算量将激增到 40 的 6 次方，达到惊人的 41 亿种可能性。

对于深蓝这样的超级计算机来说，仅仅 20 秒就能完成这些复杂计算。而对于世界棋王卡斯帕罗夫这样的人类选手，即便不吃不喝不睡，也需要漫长的 43 年才能完成同样的计算过程。这种计算能力的巨大差异，充分体现了人工智能在复杂博弈中的独特优势。

像卡斯帕罗夫这样的伟大棋手深知不可能穷尽所有下棋可能性。这恰恰是精英选手区别于业余选手的关键所在。在他对国际象棋选手的经典研究中，荷兰心理学家阿德里安·德格罗特发现，业余选手往往会因执着于寻找「完美一步」而陷入分析瘫痪，最终导致无法落子。[26]

相比之下，棋艺大师们追求的是一个好的走法 —— 当然，在条件允许的情况下会选择最佳走法 —— 但他们更关注如何通过这一步棋来优化自身局势，而非穷尽每一种可能性。正如美国大师鲁本·范恩所言，认为人类棋手能够提前计算出二三十步的每一个位置，这纯粹是一种幻想。[27]

说「追求完美会阻碍好的方案」并不是那么简单。想要真正精通国际象棋这样的游戏，你需要超越这种简单的直觉判断。但现实是，当信息超出我们在有限时间内能处理的范围时，我们往往无法做出完美决策。承认这一点，反而可能帮助我们在国际象棋和其他需要预测的场景中做出最佳选择。

这并不意味着像卡斯帕罗夫这样的大师就不需要进行计算。至少，他需要设计一个战术，比如精心安排的三到五步走法，目的是吃掉对方的棋子或实现某个近期目标。在每一步中，他都必须仔细思考对手可能的应对方式 —— 预测所有可能的走法变化，并判断这些变化是否会破坏自己的战术。同时，他还要警惕对手可能设下的陷阱：如果一个选手没有保护好自己的国王，看似优势的局面可能在转瞬间变成致命一击。

优秀的国际象棋选手通过长期积累的经验，学会了在思考时精准定位关注点。在应对复杂局面时，他们会灵活调整思考策略：有时快速浏览多个可能的决策路径，有时则深入研究单一路线的细节。这种在广度和深度之间寻找平衡的思考方式，其实是解决复杂问题的通用法则。

就像国防部和中央情报局在预防恐怖袭击时，需要在广泛收集信号和聚焦最可能的威胁之间做出选择。顶尖棋手的独特之处在于他们擅长「思考自己的思考过程」（元认知），能够及时察觉并调整自身思考策略，保持最佳的思考状态。

### Strategy Versus Tactics

Computer chess machines, to some extent, get to have it both ways. They use heuristics to prune their search trees, focusing more of their processing power on more promising branches rather than calculating every one to the same degree of depth. But because they are so much faster at calculation, they don't have to compromise as much, evaluating all the possibilities a little bit and the most important-seeming ones in greater detail.

But computer chess programs can't always see the bigger picture and think strategically. They are very good at calculating the tactics to achieve some near-term objective but not very strong at determining which of these objectives are most important in the grander scheme of the game.

Kasparov tried to exploit the blind spots in Deep Blue's heuristics by baiting it into mindlessly pursuing plans that did not improve its strategic position. Computer chess programs often prefer short-term objectives that can be broken down and quantized and that don't require them to evaluate the chessboard as a holistic organism. A classic example of the computer's biases is its willingness to accept sacrifices; it is often very agreeable when a strong player offers to trade a better piece for a weaker one.

The heuristic "Accept a trade when your opponent gives up the more powerful piece" is usually a good one—but not necessarily when you are up against a player like Kasparov and he is willing to take the seemingly weaker side of the deal; he knows the tactical loss is outweighed by strategic gain. Kasparov offered Deep Blue such a trade thirty moves into his first game, sacrificing a rook for a bishop,* and to his delight Deep Blue accepted. The position that resulted, as shown in figure 9-3a, helps to illustrate some of the blind spots that result from the computer's lack of strategic thinking.

FIGURE 9-3A: POSITION AFTER KASPAROV'S 32ND MOVE IN GAME 1

Kasparov and Deep Blue each had their own ways of simplifying the position shown in figure 9-3a. Computers break complicated problems down into discrete elements. To Deep Blue, for instance, the position might look more like what you see in figure 9-3b, with each piece assigned a different point value. If you add up the numbers in this way, Deep Blue had the equivalent of a one-pawn advantage over Kasparov, which converts to a win or draw the vast majority of the time.28

FIGURE 9-3B: DISCRETE EVALUATION OF POSITION

Humans, instead, are more capable of focusing on the most important elements and seeing the strategic whole, which sometimes adds up to more than the sum of its parts. To Kasparov, the position looked more like what you see in figure 9-3c, and it was a very good position indeed. What Kasparov sees is that he has three pawns advancing on Deep Blue's king, which has little protection. The king will either need to move out of the way—in which case, Kasparov can move his pawns all the way to Deep Blue's home row and promote* them to queens—or it could potentially be mated. Meanwhile, Kasparov's queen and his bishop, although they are in the lower left-hand corner of the board for now, are capable of moving diagonally across it with relatively little obstruction; they are thus adding to the pressure the vulnerable king already faces from the pawns. Kasparov does not yet know exactly how Deep Blue's king will be mated, but he knows that faced with such pressure the odds are heavily in his favor. Indeed, the strength of Kasparov's position would soon become apparent to Deep Blue, which would resign the game thirteen moves later.

FIGURE 9-3C: HOLISTIC EVALUATION OF POSITION

"Typical computer weakness," Kasparov later said. "I'm sure it was very pleased with the position, but the consequences were too deep for it to judge the position correctly."29

"Human Outcalculates a Calculator," trumpeted the headline in the New York Times,30 which published no fewer than four articles about the game the next day.

But the game had not been without a final twist. It was barely noticed by commentators at the time, but it may have altered chess history.

### The Beginning of the End

In the final stage of a chess game, the endgame, the number of pieces on the board are fewer, and winning combinations are sometimes more explicitly calculable. Still, this phase of the game necessitates a lot of precision, since closing out a narrowly winning position often requires dozens of moves to be executed properly without any mistakes. To take an extreme case, the position illustrated in figure 9-4 has been shown to be a winning one for white no matter what black does, but it requires white to execute literally 262 consecutive moves correctly.*

FIGURE 9-4: A WIN FOR WHITE . . . IN 262 MOVES

A human player would almost certainly not solve the position in figure 9-4. However, humans have a lot of practice in completing endgames that might take ten, fifteen, twenty, or twenty-five moves to finish.

The endgame can be a mixed blessing for computers. There are few intermediate tactical goals left, and unless a computer can literally solve the position to the bitter end, it may lose the forest for the trees. However, just as chess computers have databases to cover the opening moves, they also have databases of these endgame scenarios. Literally all positions in which there are six or fewer pieces on the board have been solved to completion. Work on seven-piece positions is mostly complete—some of the solutions are intricate enough to require as many as 517 moves—but computers have memorized exactly which are the winning, losing, and drawing ones.

Thus, something analogous to a black hole has emerged by this stage of the game: a point beyond which the gravity of the game tree becomes inescapable, when the computer will draw all positions that should be drawn and win all of them that should be won. The abstract goals of this autumnal phase of a chess game are replaced by a set of concrete ones: get your queenside pawn to here, and you will win; induce black to move his rook there, and you will draw.

Deep Blue, then, had some incentive to play on against Kasparov in Game 1. Its circuits told it that its position was a losing one, but even great players like Kasparov make serious blunders about once per seventy-five moves.31 One false step by Kasparov might have been enough to trigger Deep Blue's sensors and allow it to find a drawing position. Its situation was desperate, but not quite hopeless.

Instead, Deep Blue did something very strange, at least to Kasparov's eyes. On its forty-fourth turn, Deep Blue moved one of its rooks into white's first row rather than into a more conventional position that would have placed Kasparov's king into check. The computer's move seemed completely pointless. At a moment when it was under assault from every direction, it had essentially passed its turn, allowing Kasparov to advance one of his pawns into black's second row, where it threatened to be promoted to a queen. Even more strangely, Deep Blue resigned the game just one turn later.

What had the computer been thinking? Kasparov wondered. He was used to seeing Deep Blue commit strategic blunders—for example, accepting the bishop-rook exchange—in complex positions where it simply couldn't think deeply enough to recognize the implications. But this had been something different: a tactical error in a relatively simple position—exactly the sort of mistake that computers don't make.

FIGURE 9-5: DEEP BLUE'S PREPLEXING MOVE

"How can a computer commit suicide like that?" Kasparov asked Frederic Friedel, a German chess journalist who doubled as his friend and computer expert, when they studied the match back at the Plaza Hotel that night.32 There were some plausible explanations, none of which especially pleased Kasparov. Perhaps Deep Blue had indeed committed "suicide," figuring that since it was bound to lose anyway, it would rather not reveal any more to Kasparov about how it played. Or perhaps, Kasparov wondered, it was part of some kind of elaborate hustle? Maybe the programmers were sandbagging, hoping to make the hubristic Kasparov overconfident by throwing the first game?

Kasparov did what came most naturally to him when he got anxious and began to pore through the data. With the assistance of Friedel and the computer program Fritz, he found that the conventional play—black moving its rook into the sixth column and checking white's king—wasn't such a good move for Deep Blue after all: it would ultimately lead to a checkmate for Kasparov, although it would still take more than twenty moves for him to complete it.

But what this implied was downright frightening. The only way the computer would pass on a line that would have required Kasparov to spend twenty moves to complete his checkmate, he reasoned, is if it had found another one that would take him longer. As Friedel recalled:

Deep Blue had actually worked it all out, down to the very end and simply chosen the least obnoxious losing line. "It probably saw mates in 20 and more," said Garry, thankful that he had been on the right side of these awesome calculations.33

To see twenty moves ahead in a game as complex as chess was once thought to be impossible for both human beings and computers. Kasparov's proudest moment, he once claimed, had come in a match in the Netherlands in 1999, when he had visualized a winning position some fifteen moves in advance.34 Deep Blue was thought to be limited to a range of six to eight moves ahead in most cases. Kasparov and Friedel were not exactly sure what was going on, but what had seemed to casual observers like a random and inexplicable blunder instead seemed to them to reveal great wisdom.

Kasparov would never defeat Deep Blue again.

### Edgar Allan Kasparov

In the second game, the computer played more aggressively, never allowing Kasparov into a comfortable position. The critical sequence came about thirty-five turns in. The material was relatively even: each player had their queen, one of their bishops, both of their rooks and seven of their pawns. But Deep Blue, playing white, had slightly the better of it by having the next move and a queen that had ample room to maneuver. The position (figure 9-6) wasn't quite threatening to Kasparov, but there was the threat of a threat: the next few moves would open up the board and determine whether Deep Blue had a chance to win or whether the game was inevitably headed for a draw.

FIGURE 9-6: DEEP BLUE'S OPTIONS IN 36TH MOVE OF GAME 2

Deep Blue had a couple of moves to consider. It could move its queen into a more hostile position; this would have been the more tactical play. Or it could exchange pawns with white, opening up the left-hand side of the board. This would create a more open, elegant, and strategic position.

The grandmasters commenting on the match uniformly expected Deep Blue to take the first option and advance its queen.35 It was the somewhat more obvious move, and it would be more in character for Deep Blue: computers prefer busy, complex, computationally demanding positions. But after "thinking" for an unusually long time, Deep Blue instead chose the pawn exchange.36

Kasparov looked momentarily relieved, since the pawn swap put less immediate pressure on him. But the more he evaluated the position, the less comfortable he became, biting his knuckles, burying his head in his hands—one audience member thought he caught Kasparov crying.37 Why had Deep Blue not elected to press forward with its queen? Its actual move was not manifestly inferior—indeed, it's a move he could have imagined one of his flesh-and-blood rivals, like his longtime nemesis Anatoly Karpov, trying under the right conditions. But a computer would need a good tactical reason for it—and he simply couldn't figure out what that reason was. Unless his suspicion was correct—Deep Blue was capable of foreseeing twenty or more moves down the road.

Kasparov and Deep Blue played out about eight more turns. To the reporters and experts watching the game, it had become obvious that Kasparov, who had played defensively from the start, had no chance to win. But he might still be able to bring the game to a draw. Then to the surprise of the audience, Kasparov resigned the game after the forty-fifth move. The computer can't have miscalculated, he thought, not when it could think twenty moves ahead. He knew that Deep Blue was going to win, so why deplete his energy when there were four more games left to play?

The crowd in the auditorium burst into robust applause:38 it had been a well-played game, much more so than the first one, and if Deep Blue's checkmate did not seem quite as inevitable to them as it had to Kasparov, it was surely because they hadn't thought about the position as deeply as he had. But they saved their real admiration for Deep Blue: it had played like a human being. "Nice style!" exclaimed Susan Polgar, the women's world champion, to the New York Times.39 "The computer played a champion's style, like Karpov." Joel Benjamin, a grandmaster who had been assisting the Deep Blue team, agreed: "This was not a computer-style game. This was real chess!"

Kasparov hurried out of the Equitable Center that night without speaking to the media, but he had taken his fellow grandmasters' comments to heart. Perhaps Deep Blue was literally human, and not in any existential sense. Perhaps like the Mechanical Turk two centuries earlier, a grandmaster was working surreptitiously to pull its gears behind the scenes. Perhaps Benjamin, a strong player who had once drawn with Kasparov, had not just been coaching Deep Blue but actually intervening on its behalf during the games.

With their minds so powerfully wired to detect patterns, chess champions have a reputation for being slightly paranoid. At a press conference the next day, Kasparov accused IBM of cheating. "Maradona called it the hand of God," he said of the computer's play.40 It was a coy allusion to the goal that the great Argentinean soccer player Diego Maradona had scored in an infamous 1986 World Cup match against England. Replays later revealed that the ball had been put into the net not off his head, but instead, illegally, off his left hand. Maradona claimed that he had scored the goal "un poco con la cabeza de Maradona y otro poco con la mano de Dios"—a little with the head of Maradona and a little with the hand of God. Kasparov, likewise, seemed to think Deep Blue's circuitry had been supplemented with a superior intelligence.

Kasparov's two theories about Deep Blue's behavior were, of course, mutually contradictory—as Edgar Allan Poe's conceptions of the Mechanical Turk had been. The machine was playing much too well to possibly be a computer—or the machine had an intelligence so vast that no human had any hope of comprehending it.

Still, quitting the second game had been a mistake: Deep Blue had not in fact clinched its victory, as Friedel and Yuri Dokhoian, Kasparov's most trusted assistant, sheepishly revealed to him over lunch the next day. After playing out the position on Fritz overnight, they had found a line which in just seven more turns would have forced Deep Blue into perpetual check and given Kasparov his tie.* "That was all?" Kasparov said, staring blankly at the traffic on Fifth Avenue. "I was so impressed by the deep positional play of the computer that I didn't think there was any escape."41

Although at 1-1 the match was still even, Kasparov's confidence was deeply shaken. He had never lost a competitive chess match in his life; now, he was on the ropes. And making matters worse, he had committed a chess sin of the highest order: resigning a game that he could have played to a draw. It was an embarrassing, unprecedented mistake. The journalists and grandmasters covering the match couldn't recall the last time a champion made such an error.

Kasparov resolved that he wouldn't be able to beat Deep Blue by playing the forceful, intimidating style of chess that had made him World Champion. Instead, he would have to try to trick the computer with a cautious and unconventional style, in essence playing the role of the hacker who prods a program for vulnerabilities. But Kasparov's opening move in the third game, while unusual enough to knock Deep Blue out of its databases, was too inferior to yield anything better than a draw. Kasparov played better in the fourth and fifth games, seeming to have the advantage at points in both of them, but couldn't overcome the gravity of Deep Blue's endgame databases and drew both of them as well. The match was square at one win for each player and three ties, with one final game to play.

On the day of the final game, Kasparov showed up at the Equitable Center looking tired and forlorn; Friedel later recalled that he had never seen him in such a dark mood. Playing the black pieces, Kasparov opted for something called the Caro-Kann Defense. The Caro-Kann is considered somewhat weak— black's winning percentage with it is 44.7 percent historically—although far from irredeemable for a player like Karpov who knows it well. But Kasparov did not know the Caro-Kann; he had rarely played it in tournament competition. After just a few moves, he was straining, taking a long time to make decisions that were considered fairly routine. And on his seventh move, he committed a grievous blunder, offering a knight sacrifice one move too early. Kasparov recognized his mistake almost immediately, slumping down in his chair and doing nothing to conceal his displeasure. Just twelve moves later—barely an hour into the game—he resigned, storming away from the table.

Deep Blue had won. Only, it had done so less with a bang than an anticlimactic whimper. Was Kasparov simply exhausted, exacerbating his problems by playing an opening line with which he had little familiarity? Or, as the grandmaster Patrick Wolff concluded, had Kasparov thrown the game,42 to delegitimize Deep Blue's accomplishment? Was there any significance to the fact that the line he had selected, the Caro-Kann, was a signature of Karpov, the rival whom he had so often vanquished?

But these subtleties were soon lost to the popular imagination. Machine had triumphed over man! It was like when HAL 9000 took over the spaceship. Like the moment when, exactly thirteen seconds into "Love Will Tear Us Apart," the synthesizer overpowers the guitar riff, leaving rock and roll in its dust.43

Except it wasn't true. Kasparov had been the victim of a large amount of human frailty—and a tiny software bug.

### How to Make a Chess Master Blink

Deep Blue was born at IBM's Thomas J. Watson Center—a beautiful, crescent-shaped, retro-modern building overlooking the Westchester County foothills. In its lobby are replicas of early computers, like the ones designed by Charles Babbage. While the building shows a few signs of rust—too much wood paneling and too many interior offices—many great scientists have called it home, including the mathematician Benoit Mandelbrot, and Nobel Prize winners in economics and physics.

I visited the Watson Center in the spring of 2010 to see Murray Campbell, a mild-mannered and still boyish-looking Canadian who was one of the chief engineers on the project since its days as Deep Thought at Carnegie Mellon. (Today, Campbell oversees IBM's statistical modeling department.) In Campbell's office is a large poster of Kasparov glaring menacingly at a chessboard with the caption:

How Do You Make a Computer Blink?

Kasparov vs. Deep Blue

May 3–11, 1997

In the end, Kasparov, not Deep Blue, blinked, although not quite for the reasons that Campbell and his team were expecting.

Deep Blue was designed with the goal of beating Kasparov and Kasparov specifically. The team tried to predict which opening sequences Kasparov was most likely to use and develop strong counterattacks to them. (Kasparov, indeed, averted the trap by playing opening moves that he had rarely used before in tournament competition.) Because of its mediocre performance against Kasparov in 1996 and its problems against like-minded players in training matches, meanwhile, Deep Blue's processing power was doubled and its heuristics were refined.44 Campbell knew that Deep Blue needed to probe more deeply (but perhaps more selectively) into the search tree to match wits with Kasparov's deep strategic thinking. At the same time, the system was designed to be slightly biased toward complicated positions, which played more to its strengths.

"Positions that are good for computers are complex positions with lots of pieces on the board so there's lots of legal moves available," Campbell told me. "We want the positions where tactics are more important than strategy. So you can do some minor things to encourage that."

In this sense, Deep Blue was more "human" than any chess computer before or since. Although game theory does not come into play in chess to the same degree it does in games of incomplete information like poker, the opening sequences are one potential exception. Making a slightly inferior move to throw your opponent off-balance can undermine months of his preparation time—or months of yours if he knows the right response to it. But most computers try to play "perfect" chess rather than varying their game to match up well against their opponent. Deep Blue instead did what most human players do and leaned into positions where Campbell thought it might have a comparative advantage.

### Feature or Bug?

Still, Kasparov's skills were so superior in 1997 that it was really just a matter of programming Deep Blue to play winning chess.

In theory, programming a computer to play chess is easy: if you let a chess program's search algorithms run for an indefinite amount of time, then all positions can be solved by brute force. "There is a well-understood algorithm to solve chess," Campbell told me. "I could probably write the program in half a day that could solve the game if you just let it run long enough." In practice, however, "it takes the lifetime of the universe to do that," he lamented.

Teaching a chess computer how to beat a World Champion, instead, often comes down to a banal process of trial and error. Does allotting the program more time in the endgame and less in the midgame improve performance on balance? Is there a better way to evaluate the value of a knight vis-à-vis a bishop in the early going? How quickly should the program prune dead-looking branches on its search tree even if it knows there is some residual chance that a checkmate or a trap might be lurking there?

By tweaking these parameters and seeing how it played with the changes, Campbell put Deep Blue through many trials. But sometimes it still seemed to make errors, playing strange and unexpected moves. When this happened, Campbell had to ask the age-old programmer's question: was the new move a feature of the program—a eureka moment that indicated it was growing yet more skilled? Or was it a bug?

My general advice, in the broader context of forecasting, is to lean heavily toward the "bug" interpretation when your model produces an unexpected or hard-to-explain result. It is too easy to mistake noise for a signal. Bugs can undermine the hard work of even the strongest forecasters.

Bob Voulgaris, the millionaire basketball bettor I introduced to you in chapter 8, one year decided that he wanted to bet baseball. The simulator he designed consistently recommended "under" bets on the Philadelphia Phillies and the bets weren't doing very well. It turned out that the error came down to a single misplaced character in 10,000 lines of code: his assistant had mistakenly coded the Phillies' home ballpark—Citizens Bank Park, a compact field that boosts offense and home runs—as P-H-l rather than P-H-I. That one line of code had been enough to swamp the signal in his program and tie up Voulgaris's capital in betting on the noise. Voulgaris was so dismayed by the bug that he stopped using his baseball-betting program entirely.

The challenge for Campbell is that Deep Blue long ago became better at chess than its creators. It might make a move that they wouldn't have played, but they wouldn't necessarily know if it was a bug.

"In the early stages of debugging Deep Blue, when it would make a move that was unusual, I would say, ‘Oh, there's something wrong,'" Campbell told me. "We'd dig in and look at the code and eventually figure out what the problem was. But that happened less and less as time went on. As it continued to make these unusual moves, we'd look in and see that it had figured out something that is difficult for humans to see."

Perhaps the most famous moves in chess history were made by the chess prodigy Bobby Fischer in the so-called "Game of the Century" in 1956 (figure 9-7). Fischer, just thirteen years old at the time, made two dramatic sacrifices in his game against the grandmaster Donald Byrne—at one point offering up a knight for no apparent gain, then a few moves later, deliberately leaving his queen unguarded to advance one of his bishops instead. Both moves were entirely right; the destruction that Fischer realized on Byrne from the strategic gain in his position became obvious just a few moves later. However, few grandmasters then or today would have considered Fischer's moves. Heuristics like "Never give up your queen except for another queen or an immediate checkmate" are too powerful, probably because they serve a player well 99 percent of the time.

FIGURE 9-7: BOBBY FISCHER'S FAMOUS SACRIFICES (1956)

When I put the positions into my midrange laptop and ran them on the computer program Fritz, however, it identified Fischer's plays after just a few seconds. In fact, the program considers any moves other than the ones that Fischer made to be grievous errors. In searching through all possible moves, the program identified the situations where the heuristic should be discarded.

We should probably not describe the computer as "creative" for finding the moves; instead, it did so more through the brute force of its calculation speed. But it also had another advantage: it did not let its hang-ups about the right way to play chess get in the way of identifying the right move in those particular circumstances. For a human player, this would have required the creativity and confidence to see beyond the conventional thinking. People marveled at Fischer's skill because he was so young, but perhaps it was for exactly that reason that he found the moves: he had the full breadth of his imagination at his disposal. The blind spots in our thinking are usually of our own making and they can grow worse as we age. Computers have their blind spots as well, but they can avoid these failures of the imagination by at least considering all possible moves.

Nevertheless, there were some bugs in Deep Blue's inventory: not many, but a few. Toward the end of my interview with him, Campbell somewhat mischievously referred to an incident that had occurred toward the end of the first game in their 1997 match with Kasparov.

"A bug occurred in the game and it may have made Kasparov misunderstand the capabilities of Deep Blue," Campbell told me. "He didn't come up with the theory that the move that it played was a bug."

The bug had arisen on the forty-fourth move of their first game against Kasparov; unable to select a move, the program had defaulted to a last-resort fail-safe in which it picked a play completely at random. The bug had been inconsequential, coming late in the game in a position that had already been lost; Campbell and team repaired it the next day. "We had seen it once before, in a test game played earlier in 1997, and thought that it was fixed," he told me. "Unfortunately there was one case that we had missed."

In fact, the bug was anything but unfortunate for Deep Blue: it was likely what allowed the computer to beat Kasparov. In the popular recounting of Kasparov's match against Deep Blue, it was the second game in which his problems originated—when he had made the almost unprecedented error of forfeiting a position that he could probably have drawn. But what had inspired Kasparov to commit this mistake? His anxiety over Deep Blue's forty-fourth move in the first game—the move in which the computer had moved its rook for no apparent purpose. Kasparov had concluded that the counterintuitive play must be a sign of superior intelligence. He had never considered that it was simply a bug.

For as much as we rely on twenty-first-century technology, we still have Edgar Allan Poe's blind spots about the role that these machines play in our lives. The computer had made Kasparov blink, but only because of a design flaw.

### What Computers Do Well

Computers are very, very fast at making calculations. Moreover, they can be counted on to calculate faithfully—without getting tired or emotional or changing their mode of analysis in midstream.

But this does not mean that computers produce perfect forecasts, or even necessarily good ones. The acronym GIGO ("garbage in, garbage out") sums up this problem. If you give a computer bad data, or devise a foolish set of instructions for it to analyze, it won't spin straw into gold. Meanwhile, computers are not very good at tasks that require creativity and imagination, like devising strategies or developing theories about the way the world works.

Computers are most useful to forecasters, therefore, in fields like weather forecasting and chess where the system abides by relatively simple and well-understood laws, but where the equations that govern the system must be solved many times over in order to produce a good forecast. They seem to have helped very little in fields like economic or earthquake forecasting where our understanding of root causes is blurrier and the data is noisier. In each of those fields, there were high hopes for computer-driven forecasting in the 1970s and 1980s when computers became more accessible to everyday academics and scientists, but little progress has been made since then.

Many fields lie somewhere in between these two poles. The data is often good but not great, and we have some understanding of the systems and processes that generate the numbers, but not a perfect one. In cases like these, it may be possible to improve predictions through the process that Deep Blue's programmers used: trial and error. This is at the core of business strategy for the company we most commonly associate with Big Data today.

### When Trial and Error Works

Visit the Googleplex in Mountain View, California, as I did in late 2009, and it isn't always clear when somebody is being serious and when they're joking around. It's a culture that fosters creativity, with primary colors, volleyball courts, and every conceivable form of two-wheeled vehicle. Google people, even its engineers and economists, can be whimsical and offbeat.

"There are these experiments running all the time," said Hal Varian, the chief economist at Google, when I met him there. "You should think of it as more of an organism, a living thing. I have said that we should be concerned about what happens when it comes alive, like Skynet.* But we made a deal with the governor of California"—at the time, Arnold Schwarzenegger—"to come and aid us."

Google performs extensive testing on search and its other products. "We ran six thousand experiments on search last year and probably another six thousand or so on the ad monetization side," he said. "So Google is doing on a rough order of ten thousand experiments a year."

Some of these experiments are highly visible—occasionally involving rolling out a whole new product line. But most are barely noticeable: moving the placement of a logo by a few pixels, or slightly permuting the background color on an advertisement, and then seeing what effect that has on click-throughs or monetization. Many of the experiments are applied to as few as 0.5 percent of Google's users, depending on how promising the idea seems to be.

When you search for a term on Google, you probably don't think of yourself as participating in an experiment. But from Google's standpoint, things are a little different. The search results that Google returns, and the order in which they appear on the page, represent their prediction about which results you will find most useful.

How is a subjective-seeming quality like "usefulness" measured and predicted? If you search for a term like best new mexican restaurant, does that mean you are planning a trip to Albuquerque? That you are looking for a Mexican restaurant that opened recently? That you want a Mexican restaurant that serves Nuevo Latino cuisine? You probably should have formed a better search query, but since you didn't, Google can convene a panel of 1,000 people who made the same request, show them a wide variety of Web pages, and have them rate the utility of each one on a scale of 0 to 10. Then Google would display the pages to you in order of the highest to lowest average rating.

Google cannot do this for every search request, of course—not when they receive hundreds of millions of search requests per day. But, Varian told me, they do use human evaluators on a series of representative search queries. Then they see which statistical measurements are best correlated with these human judgments about relevance and usefulness. Google's best-known statistical measurement of a Web site is PageRank,45 a score based on how many other Web pages link to the one you might be seeking out. But PageRank is just one of two hundred signals that Google uses46 to approximate the human evaluators' judgment.

Of course, this is not such an easy task—two hundred signals applied to an almost infinite array of potential search queries. This is why Google places so much emphasis on experimentation and testing. The product you know as Google search, as good as it is, will very probably be a little bit different tomorrow.

What makes the company successful is the way it combines this rigorous commitment to testing with its freewheeling creative culture. Google's people are given every inducement to do what people do much better than computers: come up with ideas, a lot of ideas. Google then harnesses its immense data to put these ideas to the test. The majority of them are discarded very quickly, but the best ones survive.

Computer programs play chess in this way, exploring almost all possible options in at least some depth, but focusing their resources on the more promising lines of attack. It is a very Bayesian process: Google is always at a running start, refining its search algorithms, never quite seeing them as finished.

In most cases, we cannot test our ideas as quickly as Google, which gets feedback more or less instantaneously from hundreds of millions of users around the world. Nor do we have access to a supercomputer, as Deep Blue's engineers did. Progress will occur at a much slower rate.

Nevertheless, a commitment to testing ourselves—actually seeing how well our predictions work in the real world rather than in the comfort of a statistical model—is probably the best way to accelerate the learning process.

### Overcoming Our Technological Blind Spot

In many ways, we are our greatest technological constraint. The slow and steady march of human evolution has fallen out of step with technological progress: evolution occurs on millennial time scales, whereas processing power doubles roughly every other year.

Our ancestors who lived in caves would have found it advantageous to have very strong, perhaps almost hyperactive pattern-recognition skills—to be able to identify in a split-second whether that rustling in the leaves over yonder was caused by the wind or by an encroaching grizzly bear. Nowadays, in a fast-paced world awash in numbers and statistics, those same tendencies can get us into trouble: when presented with a series of random numbers, we see patterns where there aren't any. (Advertisers and politicians, possessed of modern guile, often prey on the primordial parts of our brain.)

Chess, however, makes for a happy ending. Kasparov and Deep Blue's programmers saw each other as antagonists, but they each taught us something about the complementary roles that computer processing speed and human ingenuity can play in prediction.

In fact, the best game of chess in the world right now might be played neither by man nor machine.47 In 2005, the Web site ChessBase.com, hosted a "freestyle" chess tournament: players were free to supplement their own insight with any computer program or programs that they liked, and to solicit advice over the Internet. Although several grandmasters entered the tournament, it was won neither by the strongest human players nor by those using the most highly regarded software, but by a pair of twentysomething amateurs from New Hampshire, Steven Cramton and Zackary "ZakS" Stephen, who surveyed a combination of three computer programs to determine their moves.48 Cramton and Stephen won because they were neither awed nor intimidated by technology. They knew the strengths and weakness of each program and acted less as players than as coaches.

Be wary, however, when you come across phrases like "the computer thinks the Yankees will win the World Series." If these are used as shorthand for a more precise phrase ("the output of the computer program is that the Yankees will win the World Series"), they may be totally benign. With all the information in the world today, it's certainly helpful to have machines that can make calculations much faster than we can.

But if you get the sense that the forecaster means this more literally—that he thinks of the computer as a sentient being, or the model as having a mind of its own—it may be a sign that there isn't much thinking going on at all. Whatever biases and blind spots the forecaster has are sure to be replicated in his computer program.

We have to view technology as what it always has been—a tool for the betterment of the human condition. We should neither worship at the altar of technology nor be frightened by it. Nobody has yet designed, and perhaps no one ever will, a computer that thinks like a human being.49 But computers are themselves a reflection of human progress and human ingenuity: it is not really "artificial" intelligence if a human designed the artifice.

## 01

策略与战术

计算机象棋机器，在某种程度上，可以兼得两全其美。它们使用启发式方法修剪搜索树，将更多的处理能力集中在更有希望的分支上，而不是对每个分支进行相同深度的计算。但是，由于它们在计算上非常快速，所以不必过多妥协，可以对所有可能性进行稍微的评估，并对看起来最重要的可能性进行更详细的分析。

然而，计算机象棋程序并不总是能把握游戏的整体战略。它们擅长计算实现近期目标的战术，但在判断这些目标在游戏宏观方案中的重要性方面能力较弱。

卡斯帕罗夫巧妙地利用了深蓝计算机下棋的一些固有缺陷。他设法引诱深蓝追求那些看似合理，实则并不能真正改善整体战略位置的走法。与人类棋手不同，计算机象棋程序往往更倾向于处理那些可以数字化、清晰量化的短期目标，而难以像人类那样全面地评估棋局的整体态势。

计算机在博弈中的一个典型弱点就是对「权衡交换」的机械理解。比如，当一个高水平棋手提出用更好的棋子换取一个较弱的棋子时，计算机往往会毫不犹豫地接受。这种看似理性的策略，在面对像卡斯帕罗夫这样的顶级棋手时，实际上可能是一个致命的陷阱。

在与深蓝的第一场比赛中，卡斯帕罗夫就精心设计了这样一个陷阱。他牺牲了一个价值更高的车，换取对方的一个主教。对于缺乏战略思维的深蓝来说，这看起来是一笔「划算」的交易。然而，卡斯帕罗夫早已洞察到，表面上的战术损失将带来更大的战略优势。图 9-3a 展示的正是这个关键时刻，生动地揭示了计算机在复杂对弈中思考的局限性。

卡帕罗夫和深蓝各自有其简化棋局的独特方法。计算机擅长将复杂问题分解为可量化的元素。对深蓝而言，棋盘可能呈现出图 9-3b 的模样，每个棋子都被赋予精确的分值。通过数值累加，深蓝在棋局评估中比卡帕罗夫多出了相当于一个兵的优势，这种优势在大多数情况下足以决定胜负或迫使对手和棋。28

FIGURE 9-3B：位置的数值评估

人类与计算机不同，更擅长聚焦关键要素，洞察战略全局，有时整体的价值甚至会超越各部分之和。对卡斯帕罗夫而言，这个棋局（如图 9-3c 所示）是极其有利的。他的优势在于三个士兵正逼近 Deep Blue 的国王，而对方的国王几乎没有任何防护。

这个国王面临两难选择：要么避开移动 —— 这样卡斯帕罗夫就可以将士兵推进到对方底排并升变，要么面临被将杀的风险。同时，卡斯帕罗夫的王后和主教虽然暂时位于棋盘左下角，但可以沿对角线相对自由地移动，进一步加剧了对方国王所承受的压力。

卡斯帕罗夫可能尚未精确设计将杀对手的具体路径，但他清楚地知道，在如此巨大的战略压力下，胜利的天平已经倾向于他这一方。事实证明，他的判断是正确的：Deep Blue 最终在十三步后选择投降，承认了失败。

图 9-3c：位置的整体评估

「这是典型的计算机思维局限性，」卡斯帕罗夫后来评论道。"我确信计算机对当前棋局感到很满意，但它无法准确判断如此复杂的局势深层后果。"[29]

「人类智慧战胜机器计算」，纽约时报的头条如此振奋人心，[30] 第二天更是连续刊登了四篇相关报道。

然而，这场比赛并非没有最后的戏剧性转折。尽管当时评论员几乎未注意到，但这一刻可能改变了国际象棋的历史。







终局的开端

在国际象棋比赛的最后阶段，即残局（棋盘上只剩少数棋子的阶段），由于棋子数量减少，获胜组合有时可以更精确地计算。尽管如此，这个阶段仍然需要极高的精确度，因为要成功兑现微小的优势，往往需要在数十步棋中不犯任何错误。以一个极端情况为例，图 9-4 所示的位置已被证明白方无论面对黑方何种应对都能获胜，但这要求白方必须准确无误地执行连续 262 步棋。*

图 9-4：白方获胜…… 需要 262 步精准操作

人类玩家几乎不可能破解图 9-4 中的棋局。但在处理需要十到二十五步才能完成的残局时，人类玩家却积累了丰富的经验。

对于计算机而言，残局是一把双刃剑。由于战术选择已所剩无几，如果计算机无法彻底演算出最终结果，很容易陷入细节而忽视全局。不过，正如国际象棋程序有开局数据库一样，它们同样拥有残局场景的数据库。目前，所有六子以下的棋局都已被完全计算。关于七子棋局的研究也已近乎完成 —— 有些解法复杂到需要多达 517 步 —— 计算机已精确地记录了每种棋局的输赢和和棋可能性。

在这个游戏进程中，出现了一个类似黑洞的临界点：计算机已经完全掌握了局面，能够精确判断每一步棋的输赢可能性。原本抽象的战略目标，现在已经转变为具体的行动策略：例如，将某个兵推进到特定位置就能赢得比赛，或者引诱对手移动某个棋子从而达成和棋。

深蓝在与卡斯帕罗夫的第一局比赛中依然抱有希望。尽管系统分析显示它处于不利位置，但即便是顶级棋手也会平均每 75 步犯一次严重错误。卡斯帕罗夫只要有一步走错，就可能被深蓝捕捉到并扭转局面。虽然形势看似岌岌可危，但仍存在翻盘的可能。

在这场 chess 对决中，深蓝（Deep Blue）的举动让卡斯帕罗夫感到极其困惑。在第 44 回合，它做了一个出人意料的决定：将车移动到了白方底线，而不是采取常规的将对方王置于威胁状态的走法。这一步棋看似毫无意义，就像在危机四伏的时刻，突然选择放弃抵抗。

更令人惊讶的是，这步棋不仅让卡斯帕罗夫有机会将兵推进到对方阵营，还可能升变为皇后 —— 这在国际象棋中是极具战略意义的。紧接着，深蓝在下一回合竟然选择了投降，这一系列举动更是让人匪夷所思。

对于计算机而言，这种看似荒谬的战术失误是极其罕见的。卡斯帕罗夫已经习惯了深蓝在复杂局面中因计算深度不足而犯下战略性错误，比如不恰当地交换主教和车。但这一次，错误发生在一个相对简单的局面中，这正是计算机通常不会犯的类型的错误。

图 9-5：深蓝令人困惑的走法

"计算机怎么会这样主动认输？」卡斯帕罗夫当晚在广场酒店里对德国国际象棋记者、他的朋友兼计算机专家弗雷德里克·弗里德尔说道。32 对于深蓝的异常举动，有几种看似合理的解释，但没有一种能让卡斯帕罗夫感到满意。

也许深蓝是在「自取灭亡"：它知道注定会失败，干脆不再展示更多下棋策略。又或者，正如卡斯帕罗夫怀疑的，这是一场精心设计的心理战？程序员们可能在故意示弱，想要通过输掉第一局来迷惑这个自负的对手。

面对这种诡异的情况，卡斯帕罗夫本能地开始细致地分析数据。在弗里德尔和著名国际象棋分析软件 Fritz 的协助下，他发现看似标准的走法 —— 黑方将王车移至第六列并对白方国王形成将军 —— 实际上对深蓝极为不利：这一步最终将导致自己被将死，尽管要完成这一过程还需要二十多个回合。

但这一发现令人不寒而栗。他推理道，计算机只有在找到了一个更耗时的将死路径时，才会选择原本需要卡斯帕罗夫花费二十步完成的走法。正如弗里德尔回忆的：

深蓝已经将每一种可能性推演到了极致，并冷静地选择了最不致命的败局。"它可能已经预见了 20 步乃至更多步的致命走法，」加里说，庆幸自己站在这些令人敬畏的计算背后。33

曾经，在如此复杂的国际象棋中提前预见 20 步被认为是人类和计算机都无法做到的。卡斯帕罗夫曾引以为豪地说，他最自豪的时刻是在 1999 年荷兰的一场比赛中，他提前十五步预见了获胜的态势。34 深蓝当时被认为大多数情况下只能预见 6 到 8 步。卡斯帕罗夫和弗里德尔对发生的事情并不完全了然，但对普通观察者来说看似随机的失误，在他们眼中却透露出深邃的智慧。

卡斯帕罗夫从此再未战胜深蓝。

在第二场对决中，深蓝展现出极其凌厉的进攻态势，始终不给卡斯帕罗夫留下任何喘息的机会。比赛进行到第 35 步左右，双方棋势颇为胶着：双方各有一位皇后、一个主教、两个车和 7 个兵。深蓝执白，稍微占据了一些优势，不仅拥有下一步行动的机会，其皇后还能自由腾挪。

图 9-6：深蓝在第 36 步的战略选择面对当前棋局，深蓝思考了两种可能的走法。第一种是将皇后移至更具进攻性的位置，这是一个更为精细的战术选择。另一种是与对手交换兵种，打开棋盘左侧，从而形成一个更开阔、更灵活的局面。这一步看似平常，实则暗藏战略玄机。

在这场比赛中，国际象棋大师们一致预测 Deep Blue 会选择推进皇后的走法。35 这是一个看似更明显的选择，也更符合计算机的风格：计算机通常倾向于复杂、需要大量计算的局面。然而，在异常长的「思考」之后，Deep Blue 却选择了意想不到的兵换。36

卡斯帕罗夫最初露出了些许宽慰的表情，因为兵换并未对他造成直接威胁。但随着局势的深入评估，他变得越来越不安，不时咬着指关节，双手捂面 —— 一位观众甚至觉得他看到卡斯帕罗夫在哭泣。37 为什么 Deep Blue 没有选择用皇后继续施压？这个走法并非毫无道理 —— 事实上，这看起来很像他的老对手阿纳托利·卡尔波夫在特定条件下可能会采取的策略。但对于计算机来说，每一步都必须有明确的战术依据，而卡斯帕罗夫就是无法理解其中的逻辑。除非他的直觉是对的 ——Deep Blue 可能已经能够预见二十步甚至更多步之后的局面。

卡斯帕罗夫和 Deep Blue 又继续了约八个回合的对弈。对于观战的记者和专家来说，卡斯帕罗夫从一开始就采取防守策略，获胜的希望已经渺茫。尽管如此，他仍可能将比赛扳回平局。出乎意料的是，卡斯帕罗夫在第四十五步后选择了投降。他心想，对于一台能够预测二十步棋局的计算机来说，绝不可能出现计算失误。他清楚地知道 Deep Blue 将获得胜利，因此何必在还剩四场比赛的情况下白白消耗自己的精力？

观众席上爆发出热烈的掌声：38 这是一场精彩的比赛，远胜于第一场。尽管深蓝的致命一击对观众来说不像对卡斯帕罗夫那样看似势不可挡，但这无非是因为观众未能像他那样深入地分析棋局。不过，他们对深蓝的钦佩更多：这台计算机下棋竟如此「人性化」。"真是漂亮的下棋风格！」女子世界冠军苏珊·波尔佳对纽约时报如此赞叹。39"这台计算机的下棋风格犹如冠军，宛如卡尔波夫。」曾协助深蓝团队的特级大师乔尔·本杰明也表示赞同："这哪里像是电脑下棋，这分明是最纯粹的国际象棋较量！"

卡斯帕罗夫当晚匆匆离开平等中心，未与媒体交谈，但其他特级大师的评论已深深刺痛了他的内心。他开始怀疑：深蓝是否真的只是一台机器？也许，就像两个世纪前那个著名的「机械图灵机」一样，暗中可能另有隐情。说不定，曾与他战平的本杰明不仅仅是在指导深蓝，更可能在背后暗中操控着这场比赛的胜负。

以他们那些对模式近乎执着的大脑，国际象棋冠军以略显偏执的性格而闻名。在第二天的新闻发布会上，卡斯帕罗夫指责 IBM 作弊。"马拉多纳称之为上帝之手，」他谈及这台计算机的下棋时说 [40]。这是对阿根廷著名足球运动员迭戈·马拉多纳在 1986 年世界杯对阵英格兰的那场臭名昭著的比赛中进球的委婉暗示。后来的回放显示，球并非用头顶，而是非法地用左手送入球门。马拉多纳曾说这个进球是「一部分是马拉多纳的头脑，另一部分是上帝之手」。同样地，卡斯帕罗夫似乎认为 Deep Blue 的电路得到了超越性智能的补充。

卡斯帕罗夫关于 Deep Blue 行为的两个理论，当然是相互矛盾的 —— 就像历史上著名的「机械土耳其人"(一个看似能下棋的自动机器人，实际上由隐藏的人类操控）一样。这台机器下得太好了，不可能是一台普通计算机 —— 或者这台机器拥有如此庞大的智能，以至于没有人类能够完全理解它。

然而，认输第二局最终被证明是个严重的失误：Deep Blue 事实上并未锁定胜局，这一点由弗里德尔和卡斯帕罗夫最信任的助手尤里·多霍伊安在第二天的午餐中略显尴尬地向他透露。他们通宵使用 Fritz 象棋软件复盘后发现，只需再走七步，就能迫使 Deep Blue 陷入永久被将军的境地，为卡斯帕罗夫赢得平局。*"就这样？」卡斯帕罗夫茫然地望着第五大道上川流不息的车辆，喃喃自语，"我对计算机令人惊叹的战略深度如此敬畏，以至于根本没想到还有翻盘的可能。"41

尽管比赛目前战成 1-1 平局，卡斯帕罗夫的自信已经被深深地击垮。作为一名从未在任何竞技性国际象棋比赛中尝过败绩的棋王，他此刻处于前所未有的险境。更令人难堪的是，他犯下了国际象棋最大的禁忌：放弃了本可以争取平局的残局。这一前所未有的错误令报道比赛的记者和国际象棋大师们也为之震惊，他们无法回忆起上一次有冠军犯下如此严重的失误。

卡斯帕罗夫意识到，他无法依靠曾帮助他夺得世界冠军的强势棋风战胜深蓝。为此，他决定采取更为谨慎和出其不意的策略，就像一个精心探测程序弱点的黑客。在第三场比赛中，他选择了一个足以打乱深蓝预设数据库的开局，但这一招异常却未能为他带来优势，最终不得不接受平局。

在第四和第五场比赛中，卡斯帕罗夫的表现有所改善，在局面上曾多次占据上风。然而，深蓝强大的残局数据库为其提供了极大的优势，使卡斯帕罗夫最终无法取得决定性突破，两场比赛再次以平局收场。此时，这场人机对决的比分已经是双方各胜一局，三场平局，悬念全部集中在最后一局。

在最后一场比赛的当天，卡斯帕罗夫出现在 Equitable Center，看起来疲惫和沮丧；弗里德尔后来回忆说，他从未见过卡斯帕罗夫如此阴沉的心情。执黑方，卡斯帕罗夫选择了所谓的卡罗 - 卡恩防御（Caro-Kann Defense）。卡罗 - 卡恩被认为相当薄弱 —— 黑方历史上用这种防御的胜率仅为 44.7%—— 尽管对于像卡尔波夫这样精通此防御的选手来说，并非完全无可救药。但卡斯帕罗夫不熟悉卡罗 - 卡恩；他在锦标赛中极少使用这种防御。仅仅几步之后，他就显得紧张，花很长时间做出被认为相当常规的决定。在第七步时，他犯了一个严重的错误，过早地提出了一个马的牺牲。卡斯帕罗夫几乎立即意识到了自己的错误，瘫坐在椅子上，并毫不掩饰自己的不悦。仅仅十二步之后 —— 比赛开始还不到一小时 —— 他就投降了，愤怒地离开了棋桌。

深蓝获得了胜利，但赢得的却不够振奋人心，反而显得有些不痛不痒。卡斯帕罗夫是否仅仅因为疲惫不堪，不得不选择了一个不太熟悉的开局？还是正如大师 Patrick Wolff 推测的那样，他是故意输掉这场比赛 [42]，意在削弱深蓝的成就？他选择的卡罗 - 卡恩防御 —— 恰恰是他曾经频繁战胜的对手卡尔波夫的标志性开局，这其中是否藏着什么玄机？

然而，这些微妙的细节很快就被公众的想象力所淹没。在大众眼中，这仿佛是机器战胜人类的决定性时刻！就像科幻电影中 HAL 9000 接管太空船，又如歌曲「Love Will Tear Us Apart」中精确的十三秒，当合成器压倒吉他音节，摇滚乐黯然失色 [43]。

事实上，情况并非如此。卡斯帕罗夫不过是人性脆弱和一个微小软件漏洞的受害者。

如何让国际象棋大师露出破绽

Deep Blue 诞生于 IBM 的托马斯·J·沃森中心 —— 一座俯瞰韦斯特彻斯特县山麓的美丽、新月形的复古现代建筑。在其大厅里陈列着早期计算机的复制品，与查尔斯·巴贝奇设计的那些如出一辙。尽管建筑略显陈旧 —— 木制墙板过多，内部办公室布局略显拥挤 —— 但许多杰出的科学家曾在此工作，其中包括数学家贝努瓦·曼德尔博特，以及经济学和物理学领域的诺贝尔奖得主。

2010 年春天，我拜访了沃森中心，见到了穆雷·坎贝尔。这位温和儒雅、依然保持年轻气质的加拿大人，是该项目的核心工程师之一，从项目还叫 Deep Thought、在卡内基梅隆大学时就开始参与。(如今，坎贝尔掌管着 IBM 的统计建模部门。）在坎贝尔的办公室里，悬挂着一幅大海报，卡斯帕罗夫目光专注地盯着棋盘，海报标题赫然写着：

如何让计算机眨眼？

卡斯帕罗夫 vs Deep Blue

1997 年 5 月 3 日–11 日最终，眨眼的是卡斯帕罗夫，尽管其原因与坎贝尔团队原本的预期略有不同。

深蓝系统的设计目标直指一个对手：卡斯帕罗夫。研发团队不仅仅是开发一款国际象棋程序，更是在精心设计针对卡斯帕罗夫的对策。他们试图预测卡斯帕罗夫最可能采用的开局序列，并为之准备强有力的反制策略。聪明的卡斯帕罗夫岂会轻易中计？他果然选择了一些在比赛中罕见的开局招法，成功避开了对手的陷阱。

由于在 1996 年对阵卡斯帕罗夫时表现不尽如人意，加上在训练赛中暴露出诸多不足，深蓝团队立即行动起来。他们将系统的处理能力翻了一番，并对系统的决策算法（启发式算法）进行了细致的优化和改进。

坎贝尔深知，要与卡斯帕罗夫的战略思维匹敌，深蓝需要在搜索博弈树时更加深入且精准。为此，他们还做了一个巧妙的设计：微调系统，使其在面对复杂局面时略有倾向。

"对计算机来说，最理想的棋局是那种棋盘上棋子众多、可选走法繁多的复杂位置，」坎贝尔向我解释道，"我们更希望看到战术发挥作用的局面，而不是依赖长远战略。所以，我们会通过一些细微的调整来鼓励这种局面的出现。"

从某种程度上说，深蓝比其前身和后继者都更接近人类棋手的下棋风格。虽然博弈理论在国际象棋中不像在扑克等信息不完全的游戏中那样重要，但开局阶段是个特殊情况。有时故意下出稍微不完美的一步，可以打乱对手的节奏，瓦解对方数月的准备 —— 反之亦然，如果对手懂得应对的话。大多数计算机追求「完美」下棋，而不会根据对手调整策略。但深蓝不同，它像人类棋手一样，会选择那些具有战略优势的走法。

另一面：特性还是缺陷？

尽管如此，卡斯帕罗夫在 1997 年的实力如此强大，以至于最终深蓝能获胜，只是编程的问题。

从理论上讲，让计算机下国际象棋是相当直接的：如果允许国际象棋程序的搜索算法无限制地运行，那么所有棋局都可以通过穷举法解决。"解决国际象棋有一种众所周知的算法，」坎贝尔告诉我，"如果给程序足够的时间，我半天就能写出能破解这个游戏的程序。」然而在现实中，"这需要整个宇宙的生命周期，」他无奈地叹息。

实际上，教会一台国际象棋电脑战胜世界冠军，往往是一个枯燥的反复试验过程。比如：在残局中多分配计算时间，在中局中减少时间，是否会整体提升性能？在开局阶段，有没有更精确的方法来权衡骑士和主教的战术价值？即便知道分支中可能存在极小概率的将杀或陷阱，程序应该以怎样的速度剪除那些看似毫无希望的搜索路径？

通过细致调整参数并观察其变化影响，Campbell 让 Deep Blue 经历了多轮测试。但有时它仍会出现令人困惑的走法，呈现出奇怪且出人意料的下棋策略。每当此时，Campbell 都会面临程序员经典的疑问：这个新的下棋策略是程序进化的灵光乍现，意味着它的技能正在不断提升？还是仅仅是一个技术缺陷？

在更广泛的预测领域，我的核心建议是：当你的模型产生意外或难以解释的结果时，要谨慎地倾向于将其视为「bug」。将随机噪声误解为有意义的信号太过容易了。事实上，bug 可能会瞬间摧毁即使是最优秀的预测者的所有努力。

Bob Voulgaris，这位我在第 8 章介绍过的百万富翁体育博彩专家，有一年决定尝试棒球赛事的下注。他开发的模拟预测系统一直建议对费城费城人队采取「总分低于」的下注策略，但这些下注收效甚微。最终查明，问题源于 10,000 行代码中的一个微小的输入错误：他的助手在输入费城人队主场球场 —— 公民银行公园（一个有利于进攻和本垒打的紧凑型球场）的信息时，错误地将球队缩写从 P-H-I 误写成了 P-H-l。这看似微不足道的一行代码，却足以让整个预测系统失效，使 Voulgaris 的资金被无效的预测消耗。这个令人沮丧的错误直接导致他彻底放弃了棒球下注程序。

对于 Campbell 来说，面临的挑战在于，Deep Blue 早已在国际象棋领域超越了其创造者。机器可能会走出人类程序员意想不到的棋步，而程序员往往难以判断这究竟是创新性策略，还是系统性错误。

卡姆贝尔回忆道："在深蓝系统早期调试时，每当它下出一个不同寻常的棋步，我就会说：' 哦，这里似乎有问题。' 我们会立即深入代码，仔细排查并最终找出问题所在。但随着时间推移，这种情况越来越少。当它不断做出这些非常规走法时，我们查看后惊讶地发现，它已经洞察到了人类难以察觉的深层策略。"

国际象棋史上最令人惊叹的走法，或许要数 1956 年 Bobby Fischer 在「世纪之战」中的经典对局（图 9-7）。年仅 13 岁的 Fischer 在与大师 Donald Byrne 的比赛中，接连做出两步令人瞠目结舌的棋招。他先是不动声色地牺牲了一个马，看似毫无意义；随后又故意将自己的皇后暴露在外，转而推进象的攻势。这看似疯狂的走法事实上极其精妙 ——Fischer 精准把控的战略优势，在几个回合后就完全显现出来。

然而，无论是当时还是现在，很少有棋手敢于打破常规，做出如此大胆的牺牲。因为在棋类比赛中，"除非能换取对等价值或直接获得胜利，否则不要轻易放弃重要棋子」这类经验法则深深根植于每一个棋手的思维模式。这些经验准则之所以如此牢固，正是因为它们在绝大多数情况下都能为棋手提供保护。

当我将这些棋局位置输入到我的普通笔记本电脑，并用国际象棋软件 Fritz 分析时，程序仅仅在几秒钟内就识别出了 Fischer 的精妙走法。更有趣的是，对于 Fischer 之外的任何走法，程序都认为是极其糟糕的错误。通过穷尽搜索所有可能的走法，程序找出了那些需要突破常规下棋策略的特殊局面。

我们不应该说计算机「有创造力」，因为它找到这些走法主要是依靠强大的计算能力。但它还有另一个独特优势：不受传统棋艺思维的束缚，能够在特定情境中选择最佳走法。对人类棋手来说，这需要超越常规思维的勇气和洞察力。人们对费舍尔的技艺赞叹不已，正是因为他年轻，能够充分发挥想象力的广度。我们思维中的局限性往往源于自身，并可能随着年龄增长而日益明显。计算机同样存在盲区，但它们通过穷尽所有可能的走法，可以绕过人类思维的局限。

不过，Deep Blue 并非完美无缺。在采访即将结束时，坎贝尔略带调侃地提到了 1997 年与卡斯帕罗夫对弈第一局中的一个小插曲。

"游戏中出现了一个错误，这可能导致卡斯帕罗夫误解了深蓝的真正能力，」坎贝尔告诉我。"卡斯帕罗夫并未意识到这个异常举动是程序的技术故障。"

这个技术故障发生在与卡斯帕罗夫对弈的第一场比赛的第四十四步；当程序无法正常选择走法时，系统启动了应急机制，随机选择了一个下棋策略。这个 bug 本身并不重要，发生在比赛已经接近尾声且明显处于劣势的阶段；坎贝尔和团队在次日已经修复了这个问题。"我们在 1997 年早些时候的一场测试赛中曾遇到过类似情况，原以为已经解决，」他告诉我。"没想到还是有一个细节被我们忽略了。"

事实上，对于深蓝来说，这个技术缺陷（bug）绝不是不幸的：恰恰相反，它很可能是击败卡斯帕罗夫的关键。在广为流传的卡斯帕罗夫与深蓝对战的故事中，问题源于第二场比赛 —— 在那里，他犯了几乎闻所未闻的错误，放弃了本可能打平的棋局。究竟是什么驱使卡斯帕罗夫犯下这个失误？原因是他在第一场比赛中对深蓝第四十四步的莫名其妙举动产生了严重的心理压力 —— 计算机以看似毫无意义的方式移动了自己的城堡。卡斯帕罗夫推断，这种违反常理的走法一定是超凡智能的征兆。他从未想过，这仅仅是一个系统设计缺陷。

尽管我们依赖二十一世纪的先进技术，我们仍然保留着像埃德加·艾伦·坡那样对这些机器在生活中角色的局限性认知。计算机通过一个技术缺陷成功扰乱了卡斯帕罗夫的心理。

计算机的制胜武器计算机在执行计算任务时速度快得惊人。更重要的是，它们可以始终如一地进行精确计算 —— 不会感到疲倦、不会受情绪影响，也不会在分析过程中改变计算策略。

但这并不意味着计算机能够产生完美的预测，甚至不一定是合理的预测。"垃圾入，垃圾出"(GIGO）这一缩写精准概括了这一问题。如果向计算机输入错误数据，或设计不合理的分析指令，计算机就无法创造奇迹。同时，在需要创造性思维和想象力的任务中，如战略制定或构建世界运行机制理论，计算机的表现往往十分有限。

因此，对于预测者而言，计算机最为有用的领域是天气预报和规则明确的复杂系统（如博弈类）。这些系统遵循相对简单且已充分理解的规律，尽管需要反复求解系统方程才能生成准确预测。相比之下，在经济预测和地震预测等领域，计算机的贡献微乎其微，主要原因在于我们对系统根本原因的理解仍较为模糊，且数据噪音较大。在 20 世纪 70 和 80 年代，随着计算机开始广泛进入学术和科研领域，人们对计算机辅助预测寄予厚望，然而此后进展缓慢，成果甚微。

许多研究领域处于数据和理解的灰色地带。数据质量介于优秀与一般之间，我们对数据产生的系统和过程有部分认知，但还远未达到完全理解的程度。在这种情况下，可以借鉴国际象棋超级计算机 Deep Blue（深蓝）的程序员所使用的方法 —— 反复试错来改进预测。这恰恰是当今大数据（Big Data）领域最具代表性公司的核心商业策略。

走进位于加利福尼亚州山景城的 Google 总部，你会发现这里的氛围充满了创意与趣味。鲜艳的色彩、开放式的排球场，以及各种奇特的双轮交通工具，模糊了严肃与轻松的界限。Google 的员工，即便是工程师和经济学家，也常常显得异常活泼和富有创造性。

"这些实验是持续不断的，」谷歌首席经济学家 Hal Varian 在我们会面时说道。"你应该把它看作一个有生命的有机体。我曾经说过，当它真正 ' 活' 起来时，我们应该感到担忧，就像科幻电影《终结者》中的人工智能系统天网（Skynet）*。不过，我们已经与当时的加州州长 Arnold Schwarzenegger 达成了合作协议。"

谷歌对搜索和其他产品进行了大量的测试。"去年我们在搜索上进行了约六千次实验，在广告收入转化方面大概还有六千次，」他说。"也就是说，谷歌每年大约进行一万次实验。"

这些实验有些非常引人注目 —— 偶尔会涉及推出全新的产品线。但更多的实验几乎察觉不到：仅仅是将标志移动几个像素，或者微调广告的背景颜色，然后观察这些细微变化对点击率和收入的影响。根据实验想法的潜在价值，这些实验可能只会应用于谷歌用户中的极小部分，比如 0.5%。

当你在 Google 上搜索某个关键词时，可能从未想过自己正在参与一个「实验」。然而，从 Google 的视角来看，情况却大不相同。Google 返回的搜索结果及其在页面上的排序，实际上是对你可能认为最有价值信息的精准预测。

如何量化这种看似难以把握的「有用性"？假设你搜索「最好的新墨西哥餐厅」，这究竟意味着什么？你是想规划一次阿尔伯克基之旅？还是寻找最近开业的墨西哥餐厅？又或者是希望找到提供 Nuevo Latino 菜系的餐厅？理想情况下，你应该构建一个更精确的搜索查询。但既然你并未如此，Google 会采取一种巧妙的方法：召集一个由 1,000 人组成的专家小组，向他们展示各类网页，并请他们在 0 到 10 的尺度上评估每个页面的实用价值。最终，Google 会根据这些页面的平均评分，从高到低的顺序为你呈现搜索结果。

面对每天数以百万计的搜索请求，谷歌显然无法对每一个请求都进行详细评估。但是，正如 Varian 向我解释的，他们会对一系列具有代表性的搜索查询采用人工评估方法。通过这种方式，他们能够找出哪些统计指标最能准确反映人工评估的相关性和实用性。

在谷歌的网站评估体系中，最著名的统计指标是 PageRank [45]，它根据有多少其他网页链接到目标网页来计算分数。然而，PageRank 只是谷歌用于模拟人工评估的 200 多个信号中的一个 [46]。

这项工作的复杂性不言而喻 —— 要将数百个信号应用于近乎无穷的搜索查询场景。这也是为什么谷歌如此重视持续的实验和测试。你今天熟知的谷歌搜索，尽管已经相当出色，但明天很可能会有些微的改进和调整。

谷歌（Google）的成功之道在于将严格的测试精神与自由奔放的创新文化巧妙结合。公司为员工提供充分的激励，鼓励他们发挥人类擅长而计算机难以匹敌的能力：大胆构思，源源不断地提出创意。随后，谷歌利用其庞大的数据资源对这些创意进行严格筛选。绝大多数创意会迅速被淘汰，但最优秀的创意将脱颖而出。

这种方法类似于计算机下棋的策略：穷尽所有可能的选项，在一定深度上进行分析，并将计算资源集中在最有前景的攻击路线上。这个过程极其接近贝叶斯推理（一种基于概率和先验知识不断更新假设的方法)：谷歌的搜索算法始终处于持续优化状态，永远保持开放和迭代的心态。

然而，在大多数情况下，我们无法像谷歌那样快速验证创意。谷歌能够从全球数亿用户那里近乎实时地获得反馈，这是常人难以企及的。同样，我们也缺乏像深蓝（Deep Blue）项目那样的超级计算机支持。因此，我们的进步注定将是缓慢而渐进的。

尽管如此，亲自验证我们的预测 —— 实际观察它们在现实世界中的效果，而不是停留在统计模型的舒适空间里 —— 可能是加速学习过程最有效的方法。

突破我们的技术认知局限从某种程度上说，我们自身就是技术发展的最大障碍。人类缓慢的进化步伐已经跟不上技术的飞速发展：生物进化需要成千上万年，而计算机处理能力却每两年就会翻一番。

我们穴居时代的祖先，天生具备敏锐的模式识别能力 —— 能在刹那间判断树丛中沙沙作响是微风拂动还是凶猛的灰熊临近，这对生存至关重要。然而在如今这个数据充斥、信息爆炸的快节奏世界里，这种与生俱来的本能反而可能误导我们：面对一串随机数字，我们往往会幻想出根本不存在的模式。(善于操纵的广告商和政客们，正是巧妙地利用了我们大脑中这些原始而敏感的神经回路。)

国际象棋的故事，为我们呈现了一个意味深长的结局。卡斯帕罗夫和深蓝的程序员原本被视为死敌，但他们最终证明了计算机的处理速度和人类智慧在预测领域可以实现惊人的互补。

值得注意的是，当今世界上最精彩的国际象棋对局，可能既不完全由人类，也不完全由机器主导。47 2005 年，ChessBase.com 网站举办了一场别开生面的「自由式」国际象棋赛事：选手可以任意使用计算机程序辅助，并通过互联网寻求建议。尽管赛场上不乏国际大师，最终的冠军却是来自新罕布什尔州的两位二十多岁的业余选手 Steven Cramton 和 Zackary「ZakS」Stephen。他们的制胜秘诀在于巧妙整合三个不同的计算机程序。48

Cramton 和 Stephen 的成功，源于他们既不盲目崇拜技术，也不惧怕技术。他们清楚地知道每个程序的长处和短处，更像是运筹帷幄的教练，而非被动的棋手。这种理性且灵活的态度，正是人机协作的最佳注解。

当你遇到「计算机认为洋基队将赢得世界大赛」这类说法时要格外谨慎。如果这只是对更精确表述的简要概括（比如「计算机程序预测洋基队将获胜"），那么这种表达是无可厚非的。在当今信息爆炸的时代，拥有计算速度远超人类的机器确实非常有帮助。

但如果预测者似乎真的相信计算机具有某种意识，或者认为模型有自己的思维，这可能恰恰表明没有真正的思考在发生。预测者的偏见和局限性很可能会原封不动地映射到他的计算机程序中。

我们应该把技术视为一直以来的本来面目 —— 推动人类进步的工具。我们既不应盲目崇拜技术，也不必对其心存畏惧。至今没有人成功设计出（或许永远无法设计）一台像人类一样思考的计算机。然而，计算机本身就是人类智慧和创新能力的缩影：如果是由人类精心设计，那么它就不仅仅是一个简单的「人工」智能。

