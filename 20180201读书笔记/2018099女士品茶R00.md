# 2018099女士品茶R00

## 记忆时间

## 卡片

### 0101. 主题卡——科学的对象

K·皮尔逊的革命所留下来的是这样一个观念：科学的对象并不是不可观测事物本身，而是数学分布函数，以描述与所观测事物相联系的概率。

今天，医学研究运用精巧的分布数学模型来确定治疗方法对长期存活的可能效果；社会学家和经济学家用数学分布来描述人类社会的行为；物理学家用数学分布来描述次原子粒子。科学里没有哪一个方面从这场革命中逃脱。有的科学家宣称，概率分布的使用只是一时的权宜之中，最终我们会找到一种途径回到 19 世纪科学的决定论。爱因斯坦有句名言，他不相信上帝在和宇宙玩骰子，就是这种观点的例子。其他人则相信，大自然基本上是随机的，真实性只存在于分布函数之中。不管一个人的基本哲学是什么，事实仍然是，K·皮尔逊关于分布函数和参数的思想统治了 20 世纪的科学，并在 21 世纪初仍保持着优势。

### 0102. 主题卡——随机消除未知的影响因素

第二篇研究收成变动的论文也是发表在《农业科学期刊》上，时间是 1923 年。这篇论文并不处理罗森斯特过去实验所积累下来的数据，取而代之的是新实验：一组不同的人工肥料组合对不同品种马铃薯的影响。费歇尔到了罗森斯特后，实验有了明显的改善。不再将某种实验的人工肥料用于整个农场，现在他们把土地划成小的地块，每个地块进一步区分作物的行，地块中的每一行都给予不同的处理。

基本的想法是简单的，之所以简单，那是因为一经费歇尔提出后，它就简单了，但这之前却没有人想到它。任何人观察土地上的作物时，都会很明显地感到有的地块土质好于其它地块。在某些角落，作物长得又高又密，而其它角落，作物则又细又稀。这可能是由于排水方式、土壤类型的改变、未知养分的出现、多年生野草的抵制，或者一些其它未能预见的原因。如果农业科学家要测试两种人工肥料间的区别，他可以将一种施于地块的其它角。但这会将肥料的效应与土壤或者排水等的效应混淆在一起。如果试验在相同的地块不同的年份进行，又会把肥料的效应与气候变化的效应相混淆。

如果同一年里，在相同作物上进行肥料的比较，土壤的差别就会减到最低程度，但他们仍然存在，因为所处理的作物不会有绝对相同的土壤条件。如果我们使用足够多的成对比较，在某种意义上，土壤差异所造成的区别就会被平均掉。假定我们要比较两种肥料，其中一种磷肥的含量是另一种的两倍，我们将地分成小块，每一块有两行作物。我们总是将磷肥多的施于北边这行，南边的那行则施磷肥少的。做到这里，反对的声音就会出来了。如果土壤的肥力梯度（fertility gradient）由北向南，那么北边这行的土质就会比南边那行稍好一点，土壤差异的影响就不会被平均掉。

别急！我们正要做调整，在第一个地块，我们把磷肥多的施在北边，到了第二地块，它将被施在南边，就这样来回调整。我的读者中可能有的已经画出地块的草图，将施磷肥较多的行标上了记号。它会指出，如果肥力梯度从西北向东南，施以额外的磷肥的行将总是比别的行土质好。也会有人指出，如果肥力梯度从东北向西南，结论正好相反。好啦，另一个读者发问了，到底谁对了呢？肥力梯度究竟如何分布？我们的答案只能是：天晓得！肥力梯度这个概念是抽象的，当我们选择从北到南或从东到西时，肥力的真正形态可能以非常复杂的方式上下变动。

我可以想象得出来，当费歇尔提出小地块定型处理将得到更为细心的实验时，罗森斯特的科学家们之间也会有这样的讨论。我也可以想象，当讨论集中到如何确定土地的肥力梯度时，费歇尔笑咪咪地坐在一边，听任他们卷入复杂的争论。他已经考虑过这些问题，并有了简明的答案。了解他的人这样描绘费歇尔：即使是争论触及到他，他仍是静静地坐在那里，吞云吐雾，等等容他给出答案的时机。终于，他拿开嘴上的烟斗，说道：「用随机的方法吧！」

2『随机消除未知的影响因素。做一张主题卡片。』——已完成

的确简单，科学家以随机的方式设计同一地块里不同行家作物的处理，由于随机处理没有固定模式，任何可能的肥力梯度结构都在平均意义上被抵消掉了。费歇尔猛地起身，兴奋地在黑板上写了起来，一行又一行数学符号，手臂在数学公式间挥来挥去，抵消公式两端相同的因子，最后出现的可能是生物科学中最为重要的工具了，在精心设计的科学实验中，如何分解各种不同处理的效应？费歇尔将这个方法称作「方差分析」（ananlysis of variance）。在《作物收成变动研究Ⅱ》中，方差分析第一次面世。

### 0103. 主题卡——费歇尔学派与皮尔逊的两种统计观

哲学上的分歧使费歇尔与K·皮尔逊在研究统计分布的方法上分道扬镳。K·皮尔逊把统计分布视为对他所分析数据的集合的真实描述。而按照费歇尔的观点，真实分布只是一个抽象的数学公式，搜集的数据只能用来估计这个真实分布的参数。既然所有的估计都有误差，那么费歇尔提出来的一些分析的手段，可以把这种误差的程度降到最低，或者可以更经常地得出比其他任何手段都更接近真实分布的答案。

在 20 世纪 30 年代，看上去是费歇尔在这场辩论中获胜了，但到了 70 年代，皮尔逊学派的观点东山再起。直到写这本书时，统计学界在这个问题上已经分裂成两派，尽管K·皮尔逊本人几乎不接受他的天才继承者们的观点。费歇尔用他条理清晰的数学头脑廓清了残存在K·皮尔逊观点中大量的混淆，正是这些混淆使得K·皮尔逊没有意识到自己观点的深层本质，因此，后来东山再起的皮尔逊方法已经无法回避费歇尔的理论成果。当把统计模型应用于现实时，存在着一些很严重的问题。因此，本书打算在多处探讨这些哲学问题，这里就是其中的一处。

K·皮尔逊把测量值的分布视为一个真实的存在。在他的方法里，对于一个给定的情况，有一个庞大的然而却是有限的（finite）测量值的集合。在理想情况下，科学家会搜集所有的这些测量值，并确定其分布参数。如果无法搜集到全部测量值，那么就搜集一个很大的并且具有代表性的数据子集（subset）。由这些大量的、且具代表性的子集计算出来的参数会与完备集合的参数相同；此外，那些用来计算完备集合参数值的数学方法也适用于有代表性的子集的参数估计，而不会有严重的误差。

但依照费歇尔的观点，测量值是从所有可能出现的测量值中随机选取的，依据随机选取的数据计算得出的一个参数的任何估计值，其结果本身也具有随机性，因此，也会服从一种概率分布。为了能清楚地区分参数的估计值与参数本身这两个不同的概念，费歇尔把这个估计值称为「统计量」（statistic）；不过现代术语往往称其为「估计量」（estimator）。假设我们有两种不同的方法可以得到一个统计量，以估计某个特定的参数。例如老师想了解一个学生对知识掌握到什么程度（参数），就在全班进行了几次测验（测量），并且计算出测验的平均分数（统计量）。那么，究竟是用中位数（median）作统计量「更好」呢，或是取这几次测验中的最高分与最低分的平均值「更好」呢，还是去年最高分与最低分然后把其余的测验成绩加以平均「更好」？

既然统计量是随机的，那么讨论这个统计量的某个值的准确性到底有多大是毫无意义的。我们需要的是一个判别的准则，这个准则以统计量的概率分布为依据，就像K·皮尔逊所指出的那样，对一组测量进行估计，必须根据它们的概率分布，而不是根据个别观测值。评判哪一个是好的统计量，费歇尔提出了如下三个准则：1）一致性（consistency）：得到的数据越多，计算出来的统计量接近参数真值的概率就越大；2）无偏性（unbiasedness）：如果用很多组不同数据集多次测量某一特定的统计量，那么该统计量的这些测量值的平均数应该近似于这个参数的真值；3）有效性（efficiency）：统计量的值不会完全等于该参数的真值，但是用来估计一个参数的大多数统计量应该与真值相去不远。这些阐述似乎有点含混不清，这是因为我在竭尽全力地把一些本来精确的数学公式，用一些一般性的文字表述出来。实际上，费歇尔的这些准则都可以用恰当的数学式来表达。

费歇尔之后的统计学家又提出了其他的准则，费歇尔自己也在后来的论文中提出了一些次要准则。剔除所有这些准则中的混乱不清的东西之后，剩下的最重要的元素就是，应该把统计量本身视为随机的，而好的统计量一定有好的概率特性。对于某一特定数据集，我们永远不知道一个统计量的值是否正确，只能说我们用一种方法得出来一个符合这些准则的统计量。

在费歇尔提出的三项基本准则中，「无偏性」准则最引人关注，这或许是由于「偏误」（bias）这个词带有某种贬义。一个有偏的（biased）统计量似乎是谁都不想要的某个东西。美国食品和药物管理局的正式指导准则就提出警告，要大家使用「避免有偏」的方法。有一种非常奇怪的分析方法（将在第 27 章里详细讨论），叫做「意向治疗」（intent to treat），已经成为占优势的医学试验法，因为，这种方法仍能保证结果是无偏的，尽管它忽略了有效性的准则。

事实上，一些有偏的统计量的应用常常极为有效。据费歇尔的研究，用来确定净化城市供水系统中氯浓度的标准方法，依据的就是一个有偏（但满足一致性与有效性）的统计量。所有这一切也是科学社会学（the sociology of science）中的一类研究课题——为准确定义一个概念而创造出来的一个词，怎样将情感好恶的包袱也带到了科学中来，并对人们的行为产生了影响。

### 0104. 主题卡——假设检验

假设我们要检验那位女士能否品尝出两杯茶的不同：是把牛奶倒进了茶水里，还是把茶水倒进牛奶里。我们给她两杯茶，告诉她一杯是茶水倒入牛奶里，另一杯是牛奶倒入茶水中。她尝了尝，正确区别开了这两杯茶。有可能她是凭猜测，猜对的机会是一半对一半。我们再给她同样的这样两杯茶，她又说对了。如果她仅仅靠猜测，那么连续两次都猜对的机会是四分之一。如果我们再给她两杯茶，假如她仍然能正确地分辨出来。若这人结果完全是猜出来的，此时猜对的机率则只有八分之一。我们继续两杯两杯地让她品尝更多杯茶，而她依然每次都能够正确地识别出来。某种意义上，我们就不得不相信她真的能品尝出其中的差别了。假定她说错了一次，假定说错的这一次就发生在第 24 组，而其他的全对，那么我们能否依然认为她真的有分辨不同奶茶的能力呢？假如她的错误是二十四分之四呢？或是二十四分之五呢？

假设检验（或者说显著性检验）是一种正规的统计方法，是在「待检验的假设为真」的假设前提下，用来计算以往观测到的结果发生的概率。当观测结果发生的概率很低时，我们得出原假设不成立的结论。重要的一点是，假设检验提供了一种拒绝某个假设的工具。上述例子中，待检验的假设是：那位女士只是凭猜测。假设检验的目的不是让我们接受某个假设，即使与那个假设有关的概率非常高也不能接受。

1-2『有点明白假设检验了，先假设那个女士是喝不出来的，那么我通过做实验检测，她和了 20 杯只有 1 杯说错了，那么我观察到「女士不能分辨」的概率是很低的，只有 1/20（5%）的概率，从这个低概率我们得出原假设「不能分辨」不成立的结论，即女士可以分辨出。假设检验做一张主题卡片。』——已完成

在这个普遍被接受的概念发展的早期，「significant」（显著的）这个词只是用来指「概率低到足以拒绝的程度」，数据如果可以用来拒绝某个分布，则它就是显著的。在 19 世纪后期的英语里，这个词仅仅是指计算结果意味着或表明了什么意思。进入 20 世纪之后，英语「significant」这个词在原有含义的基础上又扩展了其他的解释意义，也指某些事情是非常重要的。在某个待检验的假设条件下，统计分析仍沿用「significant」这个词「显著的」含义来表示计算结果发生的概率很低，在这个层面上，「significant」这个词有一个精确的数学涵义。但令人遗憾的是，使用统计分析的人常把显著性检验统计量理解为某种更接近这个词的现代语意的东西。

现在运用的显著性检验方法，其中大部分都是费歇尔构造出来的。他把判定具有显著性的那个概率，称为「P 值」（P-value）。他对 P 值的涵义和有效性坚信不疑。在《研究工作者的统计方法》一书中，很多地方都专门介绍了怎么计算 P 值。正如我在开头的时候谈到的，这是一本专门给想要应用统计方法的非数学专业人士写的书。在这本书中，费歇尔并未解释这些检验是如何推导出来的，也从没有明确指出究竟多大的 P 值才算是显著的。他只是举出一些计算实例，并说明结果是否显著。在一个例子中，他给出一个小于 0.01 的 P 值，并且说明「一百个值当中，只有一个值会偶然超过（计算出来的检验统计量），因此，很显然，计算结果之间的差异具有显著性。」

1929 年，费歇尔在《心灵研究学会刊》（Proceedings of the Society for Psychical Research）上发表的一篇论文中，几乎等于定义了一个在任何情况下都将是显著的特殊的 P 值。「心灵研究」（psychical research）提到试图用科学的方法来证明「超视力」的存在。心理学的研究人员大量运用了统计学的显著性检验来证明，在受实验者完全随意猜测这种假设条件下，其结果是不可能的。费歇尔在他这篇论文中，先是谴责某些作者完全错误地使用了显著性检验，接着他申明说：

运用生物学的方法对生物界进行观察的时候，统计学的显著性检验是必不可少的。其作用就在于防止我们被一些非主要的偶发事件所欺骗。并不是因为我们希望去研究或试图去查明这些偶发事件，而是因为它们与许多我们无法控制的其他境况联系在一起。一个观测的结果，倘若在我们正在寻找的真正原因根本不存在的情况下，几乎从未发生过，可以判断这个观测具有显著性。如果偶然发生的机率低于二十分之一，通常的做法是判断其结果具有显著性。对实际调查者来说，显著性水平的选择是任意的，但便于应用。不过，它并不意味着可以让自己每 20 次实验中就被骗一次。显著性检验只是告诉他什么是应该忽略掉的，也就是说应该把所有那些无法得到显著性结果的实验忽略掉。当他知道如何设计一个实验，而这个实验几乎一定能给出一个显著性的结果时，他也只能说明，这仅是一种实验上可以验证的现象。所以，对那些孤立的具有显著性的结果，他不知道如何才能让它们再现出来，只能留待以后再做进一步的调查研究了。

注意「…… 知道如何设计一个实验，而这个实验几乎一定能给出一个显著性的结果……」这句话，正是费歇尔使用显著性检验的核心之所在。对费歇尔而言，显著性检验只有在连续实验的相互联系中才有意义，所有这些实验的目的在于解释特定处理的作用。读过费歇尔的应用性论文之后，你会在他的引导下相信，使用显著性检验是为了得出三种可能的结论之一：如果 P 值很小（通常小于 0.01），他断言某种结果已经显现出来；若 P 值很大（通常大于 0.2），他宣称即便真的存在一个结果，也会因为该结果发生的可能性太小，所以不可能有任何显示出这个结果的大规模的实验；如果 P 值介于前两者之间，他讨论了应该如何设计下一个实验，才能得到一个更好的结果。除了上述情况，费歇尔从来没有明确说明科学家应该怎么解释 P 值。对费歇尔而言，看上去是如此显而易见的事，对读者来说可能并不清楚。

我们将在第 18 章回过头来重新审视费歇尔对显著性检验的态度。费歇尔始终坚持，从来都没有显示过吸烟有害健康，这也正是他的一个较大错误的核心之所在。费歇尔对有关吸烟和健康的证据做了犀利的分析，我们暂且把它放下，以后再谈。现在把话题转到 1928 年，看看当时 35 岁的耶日·奈曼的数学教育。

在他的职业生涯之初，奈曼好不容易才找到工作，成为华沙大学（the University of Warsaw）的一个年轻的教师。当时，刚刚独立的波兰因资金短缺，没钱资助学术研究，也很少有给数学家的职位。1928 年，他在伦敦的生物统计实验室呆了一个暑假，并认识了 E·皮尔逊和他的太太艾琳（Eileen）以及他们的两个女儿。E·皮尔逊是 K·皮尔逊的儿子，但是父子两人在个性上的天壤之别可谓绝无仅有：K·皮尔逊精力充沛，有支配控制他人的欲望；E·皮尔逊却腼腆谦虚。K·皮尔逊喜欢追逐新观念，常在数学概念还相当模糊，甚至还存在某些错误的时候，就忙着发表论文；E·皮尔逊则极其小心谨慎，甚至为每一步计算的细枝末节担忧。

E·皮尔逊与奈曼的深厚友谊长存在两人 1928-1933 年间的通信中。这些信件展示了他们对社会科学卓越的洞察力，以及两颗富于独创精神的心灵是如何提出各自的想法，或批评对方的想法，并共同解决难题的。E·皮尔逊踌躇地指出奈曼的提议或许不可行，这时他表现出谦逊的一面；奈曼巧妙地剖析复杂的问题，并抓住每个难题的重要本质，这时展现出他的独创力。有人如果想知道数学研究为什么是需要经常进行合作的事业的话，我建议他看看奈曼与 E·皮尔逊的通信。

E·皮尔逊对奈曼提出的第一个问题是什么呢？回想 K·皮尔逊的 χ2 拟合优度检验，他创立这种方法来检验观测数据是否与理论分布相符。但事实上根本不存在像 χ2 拟合优度检验的这种东西。分析人员有无数种方法可用来对给定的一组数据进行检验，似乎没有任何准则能够判定如何在这么多的选择中挑选出「最好的」。每次用到检验的时候，分析人员必须做出一个相当随意的选择。对此，E·皮尔逊问了奈曼以下的问题：如果我用了 χ2 拟合优度来检验一组服从正态分布的数据，但我没能得到一个显著的 P 值，那么我怎么知道这组数据确实服从正态分布呢？也就是说，我怎么知道至今尚未发现的另一种 χ2 检验或者另一种拟合优度检验不会已经产生了一个显著的 P 值，而允许我在拟合数据的时候拒绝这个正态分布呢？

奈曼把这个问题带回华沙，并由此而开始了两人之间的书信往来。奈曼与小皮尔逊都对费歇尔建立在似然函数基础上的估计概念印象深刻。通过检查与拟合优度检验联系在一起的似然函数，他们开始了调查研究。两人联名发表的第一篇论文介绍的就是那些研究的结果。这是他们撰写的三篇顶尖论文当中最难的一篇，它几乎彻底变革了关于显著性检验的全部思想。当他们继续探索这些问题时，奈曼极度清晰的洞察力使问题在蒸馏中不断提纯，精炼出最基本的元素，使他们的研究成果变得更为清晰，也更容易理解。

虽然读者对此可能不太相信，但在数学研究领域，一个人写文章的风格确实发挥着很重要的作用。有些数学文献的作者似乎写不出让人容易理解的文章；有些人则似乎以写成一行又一行的数学符号与注释为乐事，一篇论文中充斥着无比繁琐的细节，以至于把总的思考都迷失在了微不足道的细节中。与之相反，有些作者却总是有能力用非常简单而有说服力的方式表达复杂的思想，数学的发展在他们的表达中显得如此的鲜明而平实。只有在回顾已经学到些什么时，读者才会确实认识到结果的伟大力量。奈曼就是这样的作者，读他的论文是件令人愉快的事，数学观点自然地展开，使用的符号简单得令人无法相信，结论的显现竟如此的自然，以至于让人感到难以理解，不禁要问，为什么很久以来居然没有人发现这项结论？

在他们一开始合作的时候，E·皮尔逊就问耶日·奈曼，在检验一组数据是否为正态分布时，如果没能得到一个显著性的 P 值，那么怎样才能看这组数据是正态分布的呢？他们的合作从这个问题开始，然而，E·皮尔逊最初的这个问题，却打开了一扇通往更广阔领域的大门。在显著性检验中，如果得到的是一个不显著的结果，那么它的涵义是什么呢？如果我们找不到拒绝一个假设的证据，我们能做结论说这个假设为真吗？

费歇尔其实已经间接地回答了这个问题。费歇尔把比较大的 P 值（代表没有找到显著性证据）解释为：根据该组数据不能做出充分的判断。依据费歇尔的解释，我们绝对不会得出这样的推理，即没有找到显著性的证据，就意味着待检验的假设为真。这里引用费歇尔的原话：

相信一个假设已经被证明是真的，仅仅是由于该假设与已知的事实没有发生相互矛盾，这种逻辑上的误解，在统计推断上是缺乏坚实根基的，在其它类型的科学推理中也是如此。当显著性检验被准确使用时，只要显著性检验与数据相矛盾，这个显著性检验就能够拒绝或否定这些假设，但该显著性检验永远不能确认这些假设一定是真的，…… 如果显著性检验真的被人们理解到这种程度，那么就说明显著性检验的道理已被人们认识清楚了……

在这之前，K·皮尔逊常常利用他的卡方拟合优度检验来「证明」某些数据符合某些特定的分布。在费歇尔把更精确的方法引入到数理统计之后，K·皮尔逊的方法就不再为人接受了。但问题仍然存在。为了知道应该估计哪些参数，为了确定这些参数与所研究的科学问题之间有何关系，我们必须假设该数据符合某一特定的分布。统计学家们常常会利用显著性检验来证明数据符合何种分布。

在他们的通信往来中，E·皮尔逊与奈曼经常探讨一些由显著性检验中浮现出来的悖论，不假思索地使用一项显著性检验，可能会把一个显然为真的假设拒绝掉。但费歇尔从未陷入这种尴尬，因为对他来说，显著性检验怎样被误用他是非常清楚的。奈曼问：用什么标准来判断一项显著性检验的应用是正确的还是不正确的呢？逐渐地，随着 E·皮尔逊与奈曼的书信往来，加上奈曼在暑期到英国的几次访问以及 E·皮尔逊的几次波兰之旅，假设检验的基本思想已经浮出水面 。

现在，在所有基础统计学的教科书中，都可以发现一个简化的奈曼－皮尔逊假设检验理论公式。该公式结构简单，我发现大部分的大学一年级学生很容易看懂，因为已经被编纂整理过，所以这个公式很精确，也很有说服力。假设检验理论必须这样来写，当然这也是教科书所需要的写法，也只能这样来写。这种直接表述假设检验的方法已经被一些政府和社会机构所接受，如美国食品及药品管理局、美国环保署，许多医学院在给将来做医学研究的人授课时，采用的也是这一套方法。此外，这种方法也逐渐地被应用到了司法界，当法院处理某些需要鉴别的歧视性案子时，就经常会用到这种方法。

当由奈曼和 E·皮尔逊创建起来的这种理论以奈曼的这种直接而简化的方式来讲授时，由于集中于公式中有错误的一面，从而曲解了他的发现。奈曼的主要发现是，除非至少有两个可能的假设，否则显著性检验根本就没有意义。也就是说，你不可能检验一组数据是否服从正态分布，除非你认为该组数据也可能会被其它的一些分布或分布集来拟合。这些备择假设的选择，决定了显著性检验的执行方式。当一个备择假设为真时，该备择假设被接受的概率奈曼称之为该检验的效力（power）。在数学里，要清晰阐述一种思想，通常要给某一特定的概念赋予清楚明确的定义。为了区别被用来计算费歇尔 P 值的假设与其它可能的一个或多个假设，奈曼和 E·皮尔逊把被检验的假设称为「零假设」（null hypothesis），称其它可能的假设为「备择假设」（alternative hypothesis）。在他们的理论公式中，计算 P 值是为了检验零假设，而检验的效力则是指在备择假设为真的条件下 P 值的表现效果。

奈曼由此得出两个结论。第一个结论是，检验的效力是用来测量一个检验方法好坏的指标，两种检验方法中效力较强的方法就是较好的方法；第二个结论是，备择假设不能太多。统计分析师不能这样来表述，某一组数据来自于一个正态分布（零假设），或者它来自于任何其它可能的分布。这种备择假设集涵盖的范围太广了，没有哪种检验方法会有那么强的效力能处理所有可能的备择假设。

在 1956 年，芝加哥大学的 L·J· 萨维奇与拉杰·拉克·巴哈杜尔（Raj Raghu Bahadur）证明，对于一个零假设未通过的情形，并不一定要求有很多的备择假设。他们构建了一个相对较小的备择假设集，除此之外的所有检验的效力均为零。在 20 世纪 50 年代，奈曼就发展出了有限制的假设检验的想法，其中的备择假设集被定义得非常狭窄。他证明得出了这样的结论：这种检验方法比那些处理较多备择假设的检验方法效力更强。

在很多情况下，假设检验的目的是用来推翻零假设的，而这个零假设就好比我们所要攻击的稻草人。举例来说，当我们比较两种药的临床效果时，待检验的零假设是两种药的效果一样。但是，如果真是如此，研究工作就永远不必进行了。所以，「两种处理的效果相同」这一零假设，就是我们所要攻击的稻草人，应该被我们研究的结果来推翻。因此，根据奈曼的思想，该项研究的设计必须使最终数据有最大的检验效力，这样才能推倒这个稻草人，即表明这两种药的效果有多大的不同。

### 0105. 主题卡——概率

遗憾的是，为了对具有内部一致性的假设检验设计出一种数学方法，奈曼必须处理一个已被费歇尔扫到地毯下的问题。这是一直困扰假设检验的一个问题，尽管奈曼的纯数学解非常简洁巧妙。这也是统计方法应用到一般的科学领域中通常会碰到的问题。从更一般的意义讲，这个问题可以这样来概括：在现实生活中，概率的意义是什么？

2『概率的概念实在太重要了，直接做一张主题卡片。』——已完成

统计学的数学公式可用来计算概率。而这些计算出来的概率可使我们应用统计方法解决科学中的问题。就所用到的数学而言，概率的定义很明确。但这种抽象的概念怎样和现实相联系呢？当科学家试图决定什么为真、什么不为真时，他该如何解释统计分析的概率陈述呢？在本书的最后一章，我将讨论这个一般性的问题，并分析长久以来设法解答这些问题所做的努力。但现在，我们将分析促使奈曼找到他的答案的特殊情况。

前面我们谈过，费歇尔利用显著性检验产生了一个他称为 P 值的数字。这是一个计算出来的概率，是在零假设为真假定下，与观测数据有关联的一个概率。例如，假定我们要检验一种新药，对做过乳房切除手术的妇女来说，这种药可以防止乳腺癌的复发。我们把这种药的效果与一种安慰剂作比较。此时的零假设（那个稻草人）就是，该新药不比安慰剂好。现在，假定 5 年之后，用安慰剂的妇女有一半乳腺癌复发，但用新药的完全没有复发，这样能证明新药「有效」吗？答案当然得看这个 50% 代表多少病人。

如果在这项研究中，两组各仅有 4 名病人，也就是总共有 8 名病人，而其中 2 人在 5 年后复发。假定我们任选一个 8 人团体，把其中两人做上标记，接着把人随机分成两组，每组 4 人，那么做标记的两个被分在同一组的概率大约是 0.30。因此，如果每组只有 4 名妇女，「所有复发的妇女都落在安慰剂组」是不显著的。如果该项研究中每一组包含 500 名妇女，且乳腺癌复发的所有 250 名妇女都落在安慰剂姐，这是极度不可能的，除非新药真的有效。如果新药并不比安慰剂有效，这 250 名妇女都落在同一组的概率就是 P 值，计算出来的结果将小于 0.0001。

P 值是一个概率，它就是这样被计算出来的。既然 P 值被用来表明一个假设（P 值就是在该假设下计算出来的）为假的概率，那它的实际意义又是什么呢？答案是，P 值是在极可能为假的条件下，与观测值相关联的一个理论概率。P 值与现实没什么联系，它是一种对似是而非问题的间接测量。它不是我们错误理解的新药有效的概率，它也不是出现任何一种类型误差的概率。但是，为了决定哪一种检验方法比别的检验方法更好，奈曼必须想出一种办法把假设检验放进一个架构里，使得与根据检验所做出的决策相联系的概率能够计算出来的。因此，他需要将假设检验的 P 值与现实生活联系起来。

1872 年，英国哲学家约翰·维恩（John Venn）提出了一个数学概率的公式。这个公式使得概率在现实生活中有了含义。他把一个重要的概率定理转了一个方向，这个定理就是大数定律（law of large numbers）。大数定律指出，如果某事件有给定的概率（比如掷一个骰子，得到六点这一事件的概率是六分之一），而且如果我们重复地进行相同的试验时，该事件发生的次数的比率就会越来越接近这个概率值。

1『好亲切，第一次比较深入的了解大数定理是在「魔鬼数学」那本书里，如同一只上帝之手（钳子），把抛硬币的概念限制在上下 50% 的区间里。（2020-11-07）』

维恩指出，与一个给定事件相联系的概率，是该事件从长期来看所发生的次数的比率。按照维恩的意见，概率的数学理论并没有隐含大数定律，反而是大数定律隐含了概率的思想。这就是以频数为基础对概率的定义。1921 年，约翰·梅纳德·凯恩斯（John Maynard Keynes ）推翻了这种定义方式，认为它不是一种有用的或有意义的解释，并指出这种定义具有根本性的矛盾，因而无法在许多要求计算概率的情况不应用概率的频数定义。

在用正规的数学方法来构造假设检验时，奈曼又重新回到了维恩的概率的频数定义上。奈曼利用这个定义来证明他在假设检验中对 P 值解释的合理性。在奈曼－皮尔逊的公式中，科学家设定一个固定的值，比如 0.05，之后，当显著性检验的 P 值小于或等于 0.05 时，就拒绝零假设。按照这种理解，从长期来看，该科学家会正好有 5% 的机会拒绝一个正确的零假设。假设检验当前就是这样来讲授的，奈曼所采用的频数方法被得到强调。我们太容易把奈曼－皮尔逊的假设检验公式看作是概率的频数方法的内容，因而太容易忽略奈曼所提的观点中更重要的见解，即为了检验零假设这个「稻草人」，必须要有一组定义明确的备择假设。

费歇尔误解了奈曼的见解。他把注意力集中到了显著性水平的定义上，但却忽略了检验效力和需要定义一组备择假设这些重要的思想。在批评奈曼时费歇尔写到：

奈曼认为他自己修正并改善了我早期所做的关于显著性检验的工作，结果「改进了自然知识」，不过实际上他只是用技术性与商业性的形式，也就是大家所熟知的接收程序，重新解释了这些检验方法罢了。现在，在当代世界里，这种接收程序变得十分重要。例如，当英国海军总部接到某工程公司的大批材料时，我认为要安排很仔细的检查与检验，以降低残次品被接收的频率，…… 不过在我看来，这种管理运作与透过物理或生物实验的科学发现工作相比，它们之间的逻辑上有很大的差别，所以拿这两者做类比是没有多大帮助的，而把它们当成是同一回事，更是一种决定性的误导。

1-2『看到上面的信息，突然间想到，我们工程上管道的探伤比例检测，里面的 5%、10% 比例，是不是也是概率的一种应用？待验证。（2020-11-07）』——未完成

尽管存在对奈曼基本观点的这些扭曲，假设检验还是成为科学研究中应用得最多的统计工具。奈曼提出的精巧数学构思，在科学的很多领域中都占有一席之地，变成了一种固定的观念。大部分的科学期刊都要求论文的作者在做数据分析时要采用假设检验方法，甚至连科学期刊之外的领域也开始这么做。美国、加拿大与欧洲的药物管理机构，纷纷把假设检验方法的使用列为对药品检查的强制性要求，就连法庭允许原告用这种方法证明自己受到就业歧视。假设检验已经渗透到统计学的所有分支学科中。

奈曼－皮尔逊的理论攀升到统计学的巅峰地位，一路上也不是没有挑战的。费歇尔从一开始就攻击它，而且在他有生之年一直在攻击这个理论。1955 年，费歇尔在《皇家统计学会期刊》上发表一篇文章，题目是「统计方法与科学归纳」，而在他的最后一本书《统计方法与科学推论》（Statistical Methods and Scientific Inference）里，更进一步详述了他的看法。

其他一些人则捡取藏在奈曼－皮尔逊理论背后的观点来进一步发展。在第二次世界大战期间，亚伯拉罕·沃尔德扩展了奈曼利用维恩关于频数的定义，发展成了一个叫统计决策理论（statistical decision theory）的领域。埃里希·莱曼（Erich Lehmann）给出了用来判断一个好的假设检验可供选择的标准，后来在 1959 年，他还写了一本有关假设检验问题的权威性的教科书，这本书至今仍然是该领域对奈曼－皮尔逊假设检验理论描述得最完整的一部著作。

2『上面这本教科书，2005 年出到了第三版，已下载原文书籍「2020083Testing-Statistical-Hypotheses3Ed」。』

### 0106. 主题卡——置信区间

在 20 世纪 80 年代末期，美国国家科学院（National Academy of Science）如今国内一批顶尖的科学家组成一个委员会，讨论臭氧层破洞的问题。臭氧层可保护人类不受紫外线辐射的伤害，但由于人类使用的喷雾剂中含氟氯碳化物，可能破坏外层空间的臭氧层。这个委员会（主席为约翰·图基（John Tukey），是本书第 22 章讨论的主角）不做是或否的二分法回答，而是决定以概率分布的形式建立氟氯碳化物对臭氧层的影响模型。于是，他们计算出了臭氧层每年平均变化的区间估计值。虽然使用的数据量不是很多，但他们发现，该估计区间的下边界值暗示，每年臭氧层将以一个较大的幅度减少，而这将使人类的生命在 50 年内受到严重的威胁。

区间估计现在已经普及到几乎所有的统计分析领域。当一项民意调查指出 44% 的一般民众认为总统干得不错时，通常会加上一个附注，说明这个数字「具有正负 3 个百分点的误差」。上述民意调查结果的意思是，44% 被调查的民众认为总统干得不错。由于这是个随机的调查，所求的参数是全国所有的民众中认为总统干得不错的人数的百分比。由于样本的容量较小，因此一个合理的猜测是，总体的参数值应落在 41%（44%－3%）与 47%（44%+3%）之间。

怎样计算区间估计值？怎样解释一个敬意估计值的涵义？我们能对一个区间估计值做出相应的概率表述吗？我们有多大的把握确信总体参数的真值会落在所估计的区间里？

1934 年，耶日·奈曼在皇家统计学会做了一个演讲，题目是「论代表性方法的两个不同方面」（On the Two Different Aspects of the Pepersentative Method）。他的论文是关于抽样调查分析的。正如奈曼作品的一贯风格，这篇文章非常优美，导出了形式简单具直观易懂的数学表达式（当然是经过奈曼的推导之后才会如此）。但全文最重要的部分却在附录里，奈曼在这个附录中提出了一个很直接的方法，用来创建区间估计，并确定所得的区间估计值有多准确。奈曼称这个新的方法为「置信区间」（confidence intervals），而把置信区间的两端称为「置信界限」（confidence bounds）。

G·M·鲍利（G. M. Bowley）教授是大会的主席，起身致谢辞。他先用几段话讨论了论文的主要部分。接着就说到了附录：

我不太确定是否应该要求给出一个说明，或者直接提出质疑。论文的字里行间暗示，论文很难读懂，而我可能是被这个暗示误导的人之一（在这段话之后，他举出一个例子，表明他完全理解了奈曼提出的方法）。我只能说，从我一看到这篇论文开始，我就很认真地读它，而且昨天我还很仔细地读了奈曼博士对这篇论文的补充资料。我指的是奈曼博士的置信界限。我不太有把握地说，这里的「置信」是不是一个「置信诡计」。

2『置信区间，做一张主题卡片。』——已完成

鲍利接着举了一个例子说明奈曼的置信区间，然后继续说道：

这个方法真的会将我们引向深入吗？我们会比艾萨克·托德亨特（Isaac Todhunter，一位 19 世纪末的概率学家）知道的更多吗？它会让我们超越 K·皮尔逊和埃奇沃思（Edgeworth，数理统计发展早期的先驱之一）吗？它真的会引领我们到我们所需要的地方去吗？就是说我们所从中抽取样本的总体其比重会正好落在这些界限内吗？我看并不见得，…… 我不知道我是否已把我的想法表达清楚了，…… 自从我看到这个方法，我就觉得它是个难题。其理论陈述没有说服力，除非有人能说服我，否则我还是怀疑它的有效性。

鲍利对置信区间这个新方法的疑惑，是自从置信界限的概念被提出来以后大家对它的普遍迷惑之一。显然，奈曼在推导其结果过程中所用的四行优美的微积分式子，在抽象的概率数学理论上是正确的。它也确实能算出一个概率值。但这个概率值究竟代表什么则并不清楚。数据是观测得来的，参数是固定的值（尽管是未知的），因此参数取某个特定值的概率只有两个结果，或者是 100%（如果它就是那个值），或者是 0（如果它根本不是那个值）。然而，一个 95% 的置信区间涉及的是 95% 的概率。这个概率指的是什么？奈曼在此绕过了这个问题，把他的创造称为置信区间，回避使用概率这个词。但是鲍利及其他同行一眼就看穿了这个手法。

费歇尔也在批判者之中，不过他没有抓住这个要点。他所讨论的内容空洞又含混，而且根本不是奈曼论文里的内容。因为费歇尔根本没有完全弄清楚区间估计值的计算过程。在他的评论里，他所指的是「信念概率」（fiducial probability），而奈曼的论文里并没有这个词汇。长久以来，费歇尔一直试图解决这个问题 —— 怎样确定与一个参数的区间估计相关联的不确定度？费歇尔从一个很复杂的角度来解决这个问题，有点像他的似然函数。不过他很快就证明，用这种方式研究这个公式并不符合概率分布的要求。费歇尔称这个函数为「信念分布」（fiducial distribution），但他后来又违反了他自己的思路，使用了其他人在处理适当概率分布时可能会用到的相同数学方法。费歇尔所希望的结果，是从观测数据中得到参数的一组合理的值。

这也正是奈曼所得的结果，而且如果该参数为正态分布的平均数时，两个方法会得到相同的答案。据此费歇尔认为奈曼窃取了他的偏偏分布的思想，只是换了个名字而已。费歇尔对他的信念分布的研究从来没有取得进一步的发展，因为他的方法在遇到更复杂的参数（比如标准差）时就不管用了。奈曼的方法对处理任何类型的参数都是有效的。费歇尔似乎从未理解这两种方法之间的差异，直到死前他还坚持认为，奈曼的置信区间最多只是他的信念区间（fiducial intervals）概念的推广。他坚信，在碰到足够复杂的问题时，奈曼的显然是推广的方法也不会奏效 —— 就像他自己的信念区间方法一样。

不管碰到的问题有多复杂，奈曼的方法没有失败，这也是该方法在统计分析中得到广泛应用的原因之一。奈曼置信区间中的真正问题，倒不是费歇尔所提出的那个，而是鲍利在一开始讨论时就点出来的问题，即这个方法中的概率到底指的是什么？奈曼的回答又回到了现实生活中概率的频数定义上。正如他在这篇论文里所说的（他在稍后的另一篇探讨置信区间的论文里，对这一点做了更清楚的解释），不应该从每一个结论的角度看待置信区间，而应该其视为一个过程。从长期来看，对于一直计算 95% 的置信区间的统计学家来说，他们将发现，在总次数中，参数的真值将有 95% 的机会落在所计算的区间内。请注意，对奈曼来说，与置信区间相联系的概率并不是我们「答对」的概率，而是统计学家使用某种方法从长期来看做出正确陈述的频率。这个数字与当前的估计值有多「准确」根本没有任何关系。

尽管奈曼定义这个概念时非常仔细，尽管许多像鲍利这样的统计学家也都非常小心，力图保持对概率概念的清晰理解并使其不被误用，但在科学领域中对置信区间的普遍应用却导致了许多草率的思维。举例来说，有人使用 95% 的置信区间来表示他有「95% 的把握」保证参数的真值会落在这个区间里，这是很普遍的。我们在 13 章会碰到：L·J·萨维奇和布鲁诺·德费奈蒂（Bruno de Finetti），并介绍他们对个人概率的研究，他们的研究结果证明了使用上述陈述的合理性。但是，计算某人对某一件事的把握程度，与计算一个置信区间完全是两回事。统计文献里有很多文章都谈到，根据一组相同的数据，以萨维奇和德费奈蒂的方法所推导出的参数范围，和以奈曼的方法为基础推导出的置信界限，两者之间是截然不同的。

尽管在奈曼的方法中人们对概率的涵义仍存有疑问，但是奈曼的置信界限已经成为计算区间估计值的标准方法。许多文学家计算 90% 或 95% 的置信界限，而且看上去好像他们有把握认为，该区间包含了参数的真值。

时至今日，已无人再谈论或在写作中涉及费歇尔的「信念分布」的话题了。该思想已随费歇尔的去世而消失。费歇尔竭力让他的思想能发挥作用，他做了大量的相当聪明而且非常重要的研究工作，其中有些研究成果已成为当今的主流，而其它部分则仍停留在费歇尔搁笔时的不成熟状态。

在费歇尔的研究过程中，他曾有好几次差点儿就建立一门统计学业的分支学科，也就是他所称的「逆概率」（inverse probability），但每次他都半途而废。逆概率的思想起源于 18 世纪的一位业余数学家雷韦朗·托马斯·贝叶斯（Reverend Thomas Bayes），贝叶斯与很多同时代的顶尖科学家都有密切的书信往来，并经常提出一些很复杂的数学问题给他们。有一天，他随意玩弄一些概率的标准数学公式，用简单的代数把其中两个式子结合在一起，竟发现一些令他很惊讶的结果。

下一章，我们来谈谈贝叶斯异论（Bayesian heresy），并且看看为什么费歇尔拒绝使用这种逆概率。

### 0107. 主题卡——贝叶斯定理

从 8 世纪的早期，威尼斯共和国是地中海一带的一个主要的强权国家。在其政权鼎盛时期，威尼斯控制了大部分的亚得里亚海岸，以及克里特岛和赛浦路斯岛，同时还垄断了东方通往欧洲的商业贸易路线。威尼斯共和国由一群贵族家族所统治，这些家族之间保持着某种民主的程序。整个国家名义上的领袖是总督，从公元 697 年该共和国成立起，到 1797 年被奥地利吞并，总共有 150 余任总督，有的任期很短，只有 1 年或不到 1 年，也有的任期长达 34 年。在总督去世之后，该共和国会遵守一项很复杂的选举程序，他们先从贵族家族的长者当中，以抽签的方式选出一小群元老，这些被选出的元老还会再挑选一些人加入到他们之中，之后再从这一扩大的元老群中以抽签方式选出一小群人。这样的程序进行几次之后，会选出一群最后的总督候选人，总督就在这群人当中产生。

在威尼斯共和国历史的早期，每阶段的抽签都要准备一批大小相同的蜡球，有的蜡球里什么都没有，有的蜡球里面却有一张小纸条，上面写着「元老」二字。到了 17 世纪，最后几个阶段用的道具是大小完全相同的金球与银球。公元 1268 年，当多杰·拉伊涅里·泽诺（Doge Rainieri Zeno）总督去世时，在第二阶段有 30 位元老，于是准备了 30 个蜡球，其中 9 个蜡球内藏有「元老」纸条。一个小孩被带过来，他从装有蜡球的篮子中取出一个蜡球，交给第一位元老候选人，这位元老候选人就打开蜡球，看看自己是否能够成为下一阶段的元老候选人。接着，小孩从篮子中取出第二个蜡球，交给第二位元老候选人，第二位再打开蜡球，以此类推。

在小孩选出第一个蜡球前，候选人群中的每个成员被选为下个阶段元老的概率是 9/30。如果第一个蜡球是空的，剩下的候选人中每个人有 9/29 的概率成为元老。但如果第一个蜡球里有纸条，则其余人被选中的机会就剩下 8/29。一旦第二个蜡球被选定且被打开，则下一个人被选中成为元老的概率同样会减少或增加，是减少还是增加取决于前次的抽球结果。这样继续抽下去，直到所有的 9 个纸条都被抽出为止。而在这时，剩下的候选人下一阶段成为元老的概率就降为零。

这是条件概率的一个例子。某一特定候选人被选为下一阶段元老的概率，取决于在他的选择之前被选出的蜡球。J·M·凯恩斯曾指出，所有的概率都是条件概率。用凯恩斯所举的一个例子：从他的图书室的书架上随机地选择一本书，而选中的书是精装本的概率，也是一种条件概率，其条件取决于他的图书室里究竟有多少书，以及他怎样「随机」地选取。一个病人患小细胞肺癌的概率，是以该病人的吸烟史为条件的。对一个控制实验，检验没有处理效果这一零假设所计算出来的 P 值，是以该实验的设计为条件的。条件概率的重要方面是，某些已知事件（例如在彩票发行过程中，某一组特定数字能赢）的概率，会随前提条件的不同而不同。

在 18 世纪，为处理条件概率而导出的公式都是根据以下的思想做出的，即条件事件要发生在所研究的事件之前。但是到了 18 世纪后期，R·T·贝叶斯在摆弄条件概率的公式时，忽然有个惊人的发现，这些公式都是内部对称的！

假设有两个事件在一段时期内发生，就像先洗牌，再发出 5 张扑克牌。我们称这两个事件分别为「前事件」（the events before）和「后事件」（the events after）。以「前事件」为条件讨论「后事件」的概率是有意义的。如果牌没有洗好，当然会影响玩家得到一对 A 的概率。贝叶斯发现，我们也可以「后事件」为条件计算「前事件」发生的概率。这是没有道理的。就像玩家已经拿到一对 A 之后，再来确定整副牌里有 4 张 A 的概率。或是已知一个病人已患了肺癌，再来计算他是吸烟者的概率。或者是已经知道了有个叫 C·A·史密斯的人是唯一得到大奖的人，然后再计算州立彩票游戏公平不公平的概率。

贝叶斯把这些计算结果搁置起来，没有发表。在他死后，这些论文才被发现，而后才被发表出来。从那里起，贝叶斯定理就困扰着许多统计分析数学家。绝对不是毫无道理，贝叶斯将条件概率倒转过来反倒很有意义。当流行病学家试图想找出某种罕见医学病状的可能原因时，例如雷氏症候群（Reye’s syndrome），他们通常是利用病例控制研究方法（case-control study），在这种研究中，他们首先搜集一组患有该病症的病人，然后拿去与控制组的病人做比较，控制组的病人没有患这种疾病，但在其他方面与患有这种疾病的病人类似。于是，流行病学家在已知控制组病人已患有该疾病的条件下，计算某些先前治疗或先前条件导致该病的概率。吸烟对心脏病和肺癌都有影响，就是这样首次被发现的。镇静剂对新生儿畸形的影响，也是从这种病例控制研究中发现的。

直接应用贝叶斯定理，可以把条件概率反转过来，比这更为重要的，是使用贝叶斯定理估计分布的参数。有一种建议，可以把一项分布的参数本身看作是随机的，然后计算与这些参数相关的概率。例如，我们可能想要比较两种癌症治疗方法，并希望得到结论说「我们有 95% 的把握认为使用治疗方法 A 会比使用治疗方法 B 的 5 年期存活率高」。我们只要应用贝叶斯定理一两次就可以解决这个问题。

2『贝叶斯定理，做一张主题卡片。』——已完成

有很多年，以这种方式使用贝叶斯定理被认为是一种不适当的作法。当用于参数时，关于概率代表什么涵义有很多质疑。毕竟皮尔逊革命（Pearsonian revolution）的整个基础在于，科学的测量结果本身不再是我们所感兴趣的问题，相反，正如 K·皮尔逊所指出的那样，我们所感兴趣的是这些测量结果的概率分布，而科学的调查研究的目的就是要估计出控制这些分布的那些参数值（固定的但却是未知的）。所以，如果这些参数被视为是随机的（而且以观测的测量结果为条件），那么这种方法就不再有这样清楚的意义了。

在 20 世纪的早些年，统计学家非常谨慎，避免使用人们所说的「逆概率」。有一次在皇家统计学会上，对费歇尔的一篇早期论文进行讨论时，就有人质疑他使用了逆概率，他坚定地为自己辩护，否认这项可怕的指控。在第一篇关于置信区间的论文里，奈曼似乎使用了逆概率的概念，但只是作为一个数学方法，用来得到一个计算结果，而在他的第二篇论文里，他证明不了不用贝叶斯定理也能得到相同的结果。到了 20 世纪 60 年代，这种方法的潜在力量与用途已开始吸引越来越多的研究者跟踪研究，这个贝叶斯异论变得越来越受尊重了。到了 20 世纪末，它已经达到了如此高的接受水平，如今在一些期刊像《统计年报》（Annals of Statistics）和《生物统计》上，几乎半数以上的文章现在都使用贝叶斯方法。不过，贝叶斯方法的应用仍然会经常遭到质疑，尤其是在医学领域。

在解释贝叶斯异论时碰到的一个困难是，目前有好几种不同的分析方法，而这些方法的应用又至少有两种完全不同的哲学基础。长期以来，看上去好像完全不同的思想却经常贴着相同的标签 —— 贝叶斯。后面我将说明贝叶斯异论的两个种理论：贝叶斯层次模型（Bayesian hierarchal model）和个人概率（personal probability）。

### 0201. 术语卡——观测值分布的四参数

用来确定分布函数的这些数字与测量中的数字不属于同一类型，这些数字决不会被观察到的，但可以从观测值散布的方式中推导出来。这些数字后来被称为参数（parameters——源自希腊语，意思是「几乎测量」（almost measurements））。能够完整地描述K·皮尔逊体系中数字的四个参数分别被称为：1）平均数（the mean）——测量值散布状态的中间值；2）标准差（the standard deviation）——测量值的散布与平均值偏离有多远；3）对称性（symmetry）——测量值在平均值一侧规程的程度；4）峰度（kurtosis）——个别的观测值偏离平均值有多远。

用K·皮尔逊偏斜分布体系去考虑问题，思路会有一种微妙的转移。在K·皮尔逊之前，科学所处理的事情都是真实的。开普勒试图发现行星如何在空间运行的数学规律；威廉·哈维的实验打算确定血液如何在某一特定动物的静脉和动脉中游动；化学则处理元素和由元素组成的化合物。然而，开普勒所试图追踪的「行星」实际上是一组数据，用来给地球上的观测者所看到的天空中微弱的光点定位。单匹马身上血液通过静脉流动的实际情形，也许与在另一匹马或者一个人身上所可能看到的不同。没有人能够生产出纯铁的样本，尽管谁都知道铁是一种元素。

K·皮尔逊提出，这些观测到的现象只是一种随机的映像，不是真实的，所谓的真实是概率分布。科学中真实的东西并不是我们所能观测到或能把握到的，它们只是通过用来描述我们所观测事物随机性的数学函数来反应。科学调查中我们真正想确定的，是分布的四个参数。从某种意义上说，我们永远不能确定这四个参数的真实数值，而只可能从资料中估计它们。

K·皮尔逊并没有意识到这关键的一点，他以为，如果我们能够搜集到足够的数据去估计参数，就会得到参数的真实数值。而他的年轻对手费歇尔指出，K·皮尔逊的许多估计方法并不是最优的，在 20 世纪 30 年代末期，当K·皮尔逊临近他漫长生命的终点之际，一位杰出的波兰年轻数学家耶日·奈曼（Jerzy Neyman）表明，K·皮尔逊的偏斜分布体系并没有包含所有可能存在的分布，许多重要问题不能用K·皮尔逊的体系解决。

### 0202. 术语卡—— t 检测

如果不算别的，所有的科学家都受惠于戈塞特的一篇短文，该文的题目是「平均数的可能误差」（The Probable Error of the Meam），1908 年发表在《生物统计》上。是费歇尔点出这篇杰出论文的一般性意义。对戈塞特来说，有一个特定的问题需要解决，一到晚上，他就习惯性地带着耐心和小心投入于这个问题。发现了结论，他就用其它资料来检查，重新验证他的结果，努力去确认是否遗漏了什么细微的差别，考虑他必须设定哪些假设，并一再重复计算自己的发现。他提前采用了现代计算机基础上才出现的蒙特卡罗技术（Monte Carlo techniques），这是一种一再模拟的数学模型，以确定相关数据的概率分布。然而，当时他没有计算机，只能不辞辛苦地加总数据，从上百个样本中计算平均数，并绘制所得出频率的图表，所有这些都靠手工完成。

戈塞特所专注的特定问题是小样本（small sample）问题。K·皮尔逊计算了某一分布的 4 个参数，这是在单一样本就积累了上千个测量数据的基础上完成的，因为使用了大样本，他设定所得到的参数估计是正确的。费歇尔要证明他的错误。根据戈塞特的经验，科学家很少能三八线以有如此大的样本，更为典型的实验通常能够看到 10 到 20 个观测数据，他还理解到，这种现象在所有的学科中都很普遍。在一封给K·皮尔逊的信中，他写道：如果我是你遇到的用小样本工作的唯一一人，那你太特异了，在这个题目上我与斯特拉顿（Stratton）（剑桥大学的一位研究员）相伴，他曾经用 4 个样本来做说明。

K·皮尔逊所有的工作都假定：样本足够大，以至于确定参数可以没有误差。戈塞特设问：如果是小样本会怎么样？我们将如何处理自己的计算中肯定会出现的随机误差？

晚间，戈塞特坐在自己的餐桌旁，取出一小组数据，算出平均值和标准差估计值，再将二者相除，并将结果绘在图纸上。他发现这个比率与K·皮尔逊的四个参数相关，并与K·皮尔逊的偏斜分布系列中的某一分布相配。他的伟大发现在于：你不必知道原始分布的 4 个参数的确切值。前两个参数估计值的比率有一个可以制表的概率分布，不管数据从哪里来，或者标准差的真实值是多少，计算这两个样本估计值的比率，你就可以得到一个已知的分布。

正如弗雷德里克·莫斯特勒（Frederick Mosteller）和约翰·图基（John Tukey）所指出的那样，没有这一发现，统计分析注定要使用无限次的回归，没有「学生」的 t 检验 （这是该发现后来的称谓），分析者将不得不估计观测数据的 4 个参数，再估计这 4 个参数估计值的 4 个参数，接着估计 4 个新估计值的 4 个参数……这样继续下去，没有机会得到最终的结果。戈塞特表明，分析者可以在第一步就停止这种估计。

戈塞特的工作有一个基本的假设，即原始测量值服从正态分布。多年以来，科学家使用着「学生」的 t 检验，许多人渐渐相信，并不需要这项假设。他们经常发现：不管原始测量是否服从正态分布，「学生」的 t 检验都有相同的分布。在 1967 年，斯坦福大学（Stanford University）的布拉德利·埃弗龙（Bradley Efron）证明了这一点，更确切地说，他发现了不需要戈塞特假设的一般条件。

随着「学生」t 检验的发展，我们不知不觉地习惯于统计分布理论的应用，这一理论在科学界广为流传，相伴而来的是更深层次的哲学问题，这就是我们所说的「假设检验」（hypothesis tests）或「显著性检验」（significance tests）的使用。后面我们会剖析这个问题，现在我们只想强调：「学生」提供了几乎每个人都使用的科学工具，尽管没有多少人真正理解它。

### 0203. 术语卡—— LD-50

在费歇尔统计方法的引导下，不久，布利斯说开始了他在实验室内的实验。他把昆虫分成几组，养在广口玻璃瓶里，然后用不同成分和不同剂量的杀虫剂来实验。在他做这些实验的过程中，发现了一个值得关注的现象：无论他配制的杀虫剂尝试有多高，在用药之后总会有一两只昆虫还活着；此外，无论他怎么稀释杀虫剂，即便只是用了装过杀虫剂的容器，试验结果也总会有几只昆虫死掉。

有了这些显著的变异，如果能依据皮尔逊的统计分布建立一个数学模型来分析杀虫剂的作用，这将是非常有用的。但是如何建立这个模型呢？你很可能会回想起高中代数课上，当书本翻到解文字题时那令人头疼的时刻：A 先生和 B 先生共同在静止的水中划船；或者在平稳流动的水中逆流而上；或者他们会把油与水混在一起；或者让他们来来回回地运球。无论哪一种问题，这种文字应用题总是给出一些数字，然后问一个问题，可怜的学生就必须把这些文字转换为数学公式，并解出未知数 x。

你或许能回想起当初是如何哗哗地翻查着教科书，拼命地寻找一个类似的并且已经解出答案的例题，然后把文字应用题的新数字塞进这道例题所用的公式中去。对高中的代数课而言，总有人已经把相关问题的数学公式列了出来，要么老师知道这些数学公式，要么能在与教科书配套的教师手册里找到这些公式。然而，试想有这样一个文字应用题，没有人知道如何将它转化为数学公式，没有人知道问题当中哪些数据是多余的，哪些应该是没用的，而一些至关重要的信息又常常缺失，况且教科书中也没有事先已经解出来的类似例题。这就是当你设法把统计模型应用到现实生活中去的时候所面临的情景，这也正是当布利斯打算采用概率分布这种新的数学思想来分析他的杀虫剂实验时所遭遇的困境。

为此，布利斯发明了一种他称之为「概率单位分析」（probit analysis）的方法，这项发明需要一种非凡跨越的原创性思想。这种方法中的任何思想，甚至哪怕是应该如何去做的启示，都未曾出现在费歇尔的「学生」的、亦或其他什么人的著作中。他之所以使用「概率单位」（probit）这个词，是因为他的模型建立了「杀虫剂的剂量」与「使用该剂量时一只虫子会死掉的概率」这两者间的关系。他的模型中生成的最重要的参数谓之「半数致死剂量」（50 percent lethal does），通常用「LD-50」来表示，是指杀虫剂能以 50% 的概率杀死虫子的剂量。或者说，如果施用这种杀虫剂来对付大量的虫子，那么用「LD-50」的剂量，将有 50% 的虫子被杀死。布利斯模型的另一个推论则是：对一只特定的用做实验标本的虫子，要确定杀死它所需要的剂量是不可能的。

2『 LD-50，做一张术语卡片。』——已完成

布利斯的概率单位分析已被成功地应用于毒物学（toxicology）。从某种意义上说，源于概率单位分析的认识已经形成了毒物学这门科学的主要基础。16 世纪的医师P·A·帕拉赛瑟斯有一句名言：使用过量，什么都是毒药。概率单位分析为帕拉赛瑟斯首创的这个信条奠定了数学基础。按照帕拉赛瑟斯的这个信条，只要剂量足够大，任何东西都可能成为毒药；而只要剂量足够小，任何东西都是无害的。而布利斯则为了这个信条增加了与那些个案结果联系在一起的不确定性。

之所以会有那么多愚蠢的吸毒者，在古柯硷、海洛因或安非他命的作用下，或已毙命于街头，或变得极度虚弱，原因之一就在于，他们看到其他人同样服用这些毒品却没有死于中毒。他们就如同布利斯实验用的那些虫子，环顾四周，看到有些同伴依然活着。然而，即使知道某些个体还活着，也无法确定一个给定个体能否幸免于一死。我们根本没有任何办法能够预见某一独特个体对药物剂量的反应。就像皮尔逊统计模型里的那些个别观测值一样，它们都不是科学研究所关注的「事件」。惟有那些抽象的概率分布及其参数（如 LD-50，半数致死剂量）才是能够估计的。

布利斯的概率单位分析一经提出 ，其他研究人员也跟着提出了各种不同的数学分布。现代用来计算「LD-50」半数致死剂量的计算机程序，通常都会提供几种不同的模型让用户选择，这些模型都是在布利斯的原创基础上经过改进之后提出来的。用实际数据所做的研究表明，尽管在估计非常低的概率时，如「LD-10」，由这些不同模型得出的估计值是有差别的，但在「LD-50」上的估计值都非常接近。

1『真的好神奇，偏离 50% 越远，其估算所需要的样本量越大。（2020-11-06）』

我们完全可以运用概率单位分析或选择其他模型来分别估计一个不同的致死剂量，如「LD-25」或「LD-80」（25% 的死亡剂量，或 80% 的死亡剂量）。不过，离 50% 点越远，就越需要更大规模的实验才能得到理想的估计值。我自己就曾参与过一项研究，要确定某种能在老鼠身上致癌的化合物的 LD-01（1% 的致死剂量）是多少。我们的实验用了 65000 只老鼠，最终的分析结果表明，我们还是没能得到使 1% 老鼠致癌的化合物剂量的理想估计值。依据那项研究的数据推算，要想得到一个可接受的 LD-01 的估计值，我们得需要几亿只老鼠！

### 0204. 术语卡——中心极限定理

读完这本书的前八章，你也许会以为统计革命只是发生在英国。从某种意义上说，这倒也是事实，因为最先将统计模型应用于生物研究和农业研究的，的确是在英国，还有丹麦。在费歇尔的影响下，统计学方法很快就传到了美国、印度、澳大利亚和加拿大。正当统计模型的实际应用在说英语的国家和地区推广之际，由于欧洲大陆长期形成的一种数学传统，使得欧洲的数学家正在研究与统计建模有关的理论问题。

这些理论问题中，最为重要的是中心极限定理（central limit theorem）。直到 20 世纪 30 年代初，这还是个未经证明的定理，或者说只是一个猜想（conjecture），因为许多人都信其为真，却没有一个人能证明它成立。费歇尔早在研究似然函数值的理论时，就曾假设这个定理是成立的；而回溯到 19 世纪初，法国数学家皮埃尔·西蒙·拉普拉斯也用这个推论证明了他的最小平方法（method of least squares）。此外，心理学这门新兴科学也是根据中心极限定理开创了智力测验技术与精神疾病量表。

2『中心极限定理，做一张术语卡片。』——已完成

大量数据集合的平均数都有一个统计分布，而中心极限定理则阐明，无论初始数据是怎么来的，这个分布都可以用正态概率分布来逼近。这个正态概率分布与拉普拉斯的误差函数（Laplace’s error function）相同，有时也叫做高斯分布（Gaussian distribution），而在浅显通俗的普及书里，也常被称为「钟形曲线」（bell-shaped curve）。在 18 世纪晚期，亚伯拉罕·棣莫弗（Abraham de Moivre）已经证明，由机会博弈（games of chance）所得数字的简单集合符合中心极限定理。然而，在此之后的 150 年里，对这个猜想的证明没有丝毫的深入进展。

用正态分布来描述大部分数据都是正确有效的，因此，中心极限定理普遍被认为是一个正确的猜想。一旦假定数据服从正态分布，数学上的处理就容易多了。正态分布具备某些非常优良的性质：如果有两个随机变量服从正态分布，那么两变量之和也同样服从正态分布。就一般而言，

正态变量的各种类型的和与差也都服从正态分布。因此，由正态随机变量（variate）推演得出的许多统计量，其自身也服从正态分布。正态分布只有K·皮尔逊四个参数中的两个——平均数和标准差，另外两个参数对称性偏度（symmetry）和峰度（kurtosis）均为零。因此，一量知道了平均数和标准差这两个参数值，其他的一切也就一清二楚了。

费歇尔曾指出，由一组数据得出的平均数与标准差的估计值就是他所说的充分估计量（sufficient estimator），因为这两个参数值已经把这些数据中所有的信息都包括在内了。既然这两个参数值已经涵盖了能够从那些原始测量值中揭示出的一切，就根本没有必要去占有任何原始测量值了。如果有足够的测量值可以用来相当精确地估计出平均数与标准差，就不再需要其他任何测量值了，任何为搜集这些数据所做的努力，都不过是浪费时间而已。例如，有两个重要指标服从正态分布，如果你正打算得出这样一个正态分布的那两个参数，那么你只需要收集大约 50 个测量值就足够了。

1『如果一组数据符合正态分布，要得到其均值和方差，仅仅 50 个测量值即可，大大出乎自己意料，哈哈。（2020-11-06）』

正态分布的这种数学上便于处理的特性，使科学家能够构建一个复杂关系模型。只要其基本分布是正态的，费歇尔的似然函数通常就有了以简单代数进行处理的一种形式。即便模型复杂到必须用迭代运算法去解的程度，只要其分布是正态的，用纳恩·莱尔德（Nan Laird）和詹姆斯·韦尔（James Ware）的 EM 演算法去解，就变得轻而易举了。由于正态分布在数学上的计算处理非常敏捷，因此在建模时，统计学家常常要假定所有的数据都服从正态分布。不过，做这样的假定就不能不援引中心极限定理。

但是，中心极限定理是否成立？说得更准确一点，它在什么条件下成立？

在 20 世纪 20 年代和 30 年代，斯堪的纳维亚地区、德国、法国和苏联的一批数学家，运用 20 世纪早期发明的一套新的数学工具，倾心于上述这些问题的研究。但就要达到的时候，整个人类文明都正面临着一场日益迫近的浩劫——那些极权主义的国家的恶性膨胀。

不过，在这些黑暗没有完全成为现实之前，欧洲的数学家们就已经解决了中心极限定理的证明问题。芬兰的亚尔·瓦尔德马·林德伯格和法国的保罗·利维分别发现了能够使中心极限定理这个猜想成立所必需的一组重叠的条件。这证明了至少存在三种解这个问题的方法，而且证明了中心极限定理不是只有一个单个的定理，而是有一组定理，其中每个中心极限定理都能从略有区别的一组条件中推导出来。到了 1934 年，中心极限定理（组）终于不再是猜想了，一个科学家必须要做的只是要证明林德伯格·利维条件（Lindeberg-Lévy Conditions）成立，那么中心极限定理就成立，于是，他就可以随意地把正态分布设为一个合适的模型。

然而，就一个特定情况而言，要证明林德伯格·利维条件成立很难。但在理解林德伯格·利维条件上倒有几分安慰，因为他们描述的条件看上去是合理的，而且在大多数情况下都是成立的。不过要证明其成立却是一个棘手的问题，这也正是战后远在北卡罗莱纳大学辛苦工作的瓦西里·霍夫丁（Wassily Hoeffding）在这个故事中竟会有如此重要地位的原因。1948 年，霍夫丁在《数理统计年报》（Annals of Mathematical Statistics）上发表了一篇论文，题目是「渐近正态分布的一组统计量」。

回想费歇尔曾把统计量（statistic）定义为：从观察到的测量值得出的、可用来估计其分布参数的一个数值。

费歇尔还建立了有用的统计量应该具备的一些准则，在这个过程中，他还指出了利用皮尔逊的许多方法导出的统计量不符合这些准则。有很多种计算统计量的不同方法，其中的很多统计量都能满足费歇尔提出的准则。一旦计算出统计量，为了要用它，我们必须知道它的分布。如果它服从正态分布，用起来就容易多了。霍夫丁提出了一种他所谓的「U-统计量」（U-statistics），并指出一个统计量如果属于这种「U-统计量」，则满足林德伯格·利维条件。

正因为如此，我们只须指出一个新的统计量是否与霍夫丁的定义相一致，而不必去解那些很困难的数学来证明林德伯格·利维条件成立。霍夫丁所做的一切就是用一组数学必要条件取代另外一组。然而，霍夫丁的条件事实上很容易检查。因此，霍夫丁的论文发表之后，几乎所有的论文在证明一个新统计量服从正态分布的时候，都是通过证明该统计量是一个「U统计量」来完成的。

### 0205. 术语卡——运筹学

纳粹的这种反理智主义、反犹太主义倒行逆施的结果之一，就是让第二次世界大战的同盟国因此而丰收了许多才华横溢的科学家与数学家，在他们的鼎立相助下打赢了这场战争。英国生物学家彼得·布莱克特（Peter Blackett）向海军部建议，武装部队应该请一些科学家来协助解决战略和战术上的问题。无论是哪个专业研究领域的科学家们，他们都训练有素，能够应用逻辑和数学模型来解决问题。他建议组成科学家的攻关小组，让这些小组从事有关战争问题的研究，由此诞生了一门新学科——「运筹学」（operational research，在美国称之为 operations research）。

从事不同领域研究的科学家组成的科研小组联合起来共同研究，决定用远程轰炸机对付潜艇的最佳使用方案；为防空武器提供射击表；决定靠近前线的军火补给站的最佳选址；甚至还要解决军队的食物补给问题。

战争结束后，运筹学的应用由战场搬到了商场。那些在战争期间被征募到军队去服务的科学家已经证明了用数学模型和科学的思维来解决战事中的战术问题是多么有用。同样的步骤和许多相同的方法也能用来组织工厂里的生产，找出仓库与销售部门之间的最优关系，解决许多别的商务问题，均衡有限的资源，或改进生产与提高产量。从那时候起，大公司里大部分都设立了作业研究部门，而这个部门所从事的多数工作都与统计模型有关。

我在辉瑞公司工作的时候所做的几个项目，其目的都是为了改善对药物研究进行控制和提取新产品进行测试的方法，在所有这些研究中涉及到的一个重要方面就是，当条件可以满足时，有能力用正态分布去处理问题。

2『运筹学，做一张术语卡片。』——已完成

### 0206. 术语卡——混沌理论

回想一下，在统计革命之前科学所处理的那些「事件」，要么是已有的测量，要么是生成这些测量值的自然事件。伴随着统计革命，科学的事件变成了能左右测量值分布的参数。在早期的确定性方法中，有一个信条是，越精确的测量，对所考察的自然客体的描述也就越精确；而在统计方法中，分布参数有时候不必有一个自然客体，无论多么精确的测量系统，分布参数的估计值终究是有误差的。例如，在确定性方法中，重力常数是描述物体如何向地球下落的一个恒定不变的值；而在统计方法中，我们对重力常数的测量值永远都不会是一样的。为了「通晓」落体的性质，这些测量值分布的离散状态才是我们想要确立的。

1963 年，混沌理论专家爱德华·洛伦兹（Edward Lorenz）做了一个后来时常被引用的演讲，演讲题目为「巴西一只蝴蝶翅膀的翩翩舞动，会引起德克萨斯州的龙卷风吗？」洛伦兹的主要论点是，混沌的数学函数对初始条件非常敏感，初始条件的些微差异，经过多次迭代之后，中以导致全然不同的结果。洛伦兹相信，由于存在这种对初始条件微波差异的敏感性，以至于对所研究的问题不可能得出一个确定的答案。隐含在洛伦兹演讲中的是确定性假设，即理论上每一个初始条件都是促成某个最终结果的一个起因。这个被称之为「蝴蝶效应」（butterfly effect）的观念，已经被那些混沌理论的普及者们当作一个深邃而睿智的真理接受下来了。

然而，没有任何科学的证明揭示了这样一种因果关系的存在，也没有任何数学模型有准确的依据表明客观现实中存在着这一效应。它只是一种信念的表述而已，就其科学的有效性而言，它与关于鬼神的描述相去无几。而统计模型是用分布参数来对科学探索明确地进行解释，它们也是建立在对现实世界的一种信念所做的描述上。然而，我自己在科学研究上的经历让我确信，比起对信念的确定论的陈述，统计上的陈述更有可能是真实的。

2『混沌理论做一张术语卡片。』——已完成

### 0207. 术语卡——贝叶斯层次模型

20 世纪 70 年代早期，由于弗雷德里克·莫斯特勒（Frederidck Mosteller）和大卫·华莱士（David Wallace）早期的工作和贡献，原文分析的统计方法有了很大的进展，他们俩人曾运用统计方法来判定《联邦主义论文集》（Federalist）中一些匿名文章的作者。自 1787 年，在纽约州带头鼓动通过新的美国宪法期间，詹姆士·麦迪逊（James Madison）、亚力山大·汉密尔顿（Alexander Hamilton）和约翰·杰伊（John Jay）写了大约 70 篇文章，支持通过宪法。但这些文章都是匿名发表的。19 世纪初，汉密尔顿与麦迪逊两人开始确认这些两个人都声称有著作权的论文，其中有 12 篇文章他们都认为是自己写的 。

1『上面的这个例子，识别出汉密尔顿他们的笔记，非常肯定之前有听说过，好像是吴军的专栏课里。（2020-11-07）』

在用统计方法对这些署名有争议性的文章进行分析时，莫斯特勒与华莱士找出了几百个无「特定内容」的英文词汇，如「if」、「when」、「because」、「over」、「whilst」、「as」、「and」等。这些字在句子里只有语法上的意义，本身并没有什么特定的含义，这些字的使用主要取决于作者的语言使用习惯。在这上百个没什么特定含义的字里，他们发现，大约有 30 个字在这两位作者的其他著作中使用频率不同。

例如，麦迪逊使用「upon」这个字的频率，是每千字平均 0.23 次，但汉密尔顿对这个字的使用频率很高，平均每千字高达 3.24 次（在 12 篇署名有争议的文章里，有 11 篇根本没有用「upon」这个字，而在剩下的那一篇文章中，平均每千字就出现 1.1 次）。这些平均的频率并不是描述一千字中任何特定组合。这些数值本身并不是整数，这就意味着这些频率并不是在描述任意一个观测的文字序列。这些数值其实是两位不同作者在写作时用字分布的其中一个参数的估计值。

对于某篇文章著作权的争议，所要解决的问题是：这些文章中用词的分布形态，是来自与麦迪逊相联的概率分布呢？还是来自与汉密尔顿相联的概率分布？这些分布各有各有参数，其中能够定义出各自作品的特定参数各不相同。参数值只能根据他们的论文来估计，而且这些估计可能是错的。因此，要想区分哪个分布可应用在一篇署名有争议的文章上，充满了这种不确定性。

估计这种不确定性水平的一种方法是，这两个人的分布参数的确切值，是来自于描述 18 世纪晚期所有北美洲有教养的人用英文写作时用字习惯的参数分布。例如，汉密尔顿每千字中用到「in」这个字 24 次，麦迪逊则是每千字用 23 次，而同时代的其他作家，使用「in」这个字的频率在每千字 22 至 25 次之间。

由于受到当时和当地一般用字分布形态的制约，每个人分布的参数是随机的，并且具有一个概率分布。这样一来，制约汉密尔顿和玫迪逊使用这些无特定含义的字的参数本身也有参数，我们可以称之为「超参数」（hyper-parameter）。根据当时和当地其他作者发表的文章来分析，我们就能估计出这些超参数。

英语语言总是随着时间和地域的变化而变化。例如在 20 世纪的英语文学里，使用 in 的频率通常是每千字少于 20 次，这表明从汉密尔顿和麦迪逊的时代到现在的 200 多年里，英语的用字型态已经稍微有所转变。我们可以把这些定义 18 世纪北美用字习惯参数分布的越参数，看作是它们本身也有一个相对于所有时间与空间的概率分布。因此，除了用 18 世纪的北美作品，我们还可以搜集其它地区和其它时期的英语文献，来估计这些超参数的参数，我们可以称这些参数为「超－超参数」（hyper-hyperparameter）。

通过重复使用贝叶斯定理，我们就能决定这些参数的分布，然后再决定这些超参数的分布。从原则上来说，我们可以用超－超－超参数求出超－超参数的分布，进而把这种层次分析引向深入，依次类推。但在我们的例子里，显然没有必要进一步分析，以免增添更多的不确定性。利用超参数与超－超参数的估计值，莫斯特勒与华莱士就能算出与下面这个陈述有关的概率：是麦迪逊还是汉密尔顿写了这篇文章。

自 20 世纪 80 年代早期以来，贝叶斯层次模型已经成功地解决了许多工程上和生物学上的难题。比如，一些数据看上去似乎是来自于两个或两个以上不同的分布，这个问题就属于这类难题。分析家可以建议，有一个未观测到的变量存在，而这个变量可以定义已知的一个观测结果究竟来自于哪个分布。这个差别标识本身是个参数。但它还有一个概率分布（含有超参数），这个概率分布可以纳入到似然函数当中来进行分析。莱尔德和韦尔的 EM 演算法特别适合于解决这类问题。

统计文献中对贝叶斯方法的广泛使用充满了混淆与争议。大家可以提出得出不同结果的不同方法，但却没有明确的标准来决定哪个是对的。通常，保守肖像统计学家反对使用贝叶斯定理，而贝叶斯学派的人彼此对他们模型的细节看法也不一致。这种混乱的状况亟需另一个像费歇尔这样的天才出现，找出一个统一的原则来解决这些争议。当我们进入 21 世纪的时候，还没有这样的天才出现。因此，相关的问题还是像在 200 多年前的贝叶斯时代一样，令人困惑。

2『贝叶斯层次模型，做一张术语卡片。』——已完成

### 0208. 术语卡——个人概率

另外一种贝叶斯方法其基础看上去要坚实得多。这就是个人概率（personal probability）的概念。个人概率的意思自从 17 世纪贝努里一开始研究概率时就已经产生了。实际上，概率（probability）这个英文字创造的初衷，就是用来处理主观不确定性的。

L·J·萨维奇和布鲁诺·德费奈蒂在 20 世纪 60 年代和 70 年代，推导出了个人概率背后的许多数学模式。我在 20 世纪 60 年代末期曾参加一场在北卡罗来纳大学举办的统计学会议，会上萨维奇在演讲中曾阐述他的一部分想法。萨维奇认为，世界上并没有「已被证明的科学事实」这样的事情。有的只是一些陈述，而那些自认为是科学家的人对这些陈述持有很高的赞成概率。他举例说，在场听他演讲的人对「地球是圆的」这项陈述一定持有很高的认同概率，但若我们有机会对全世界的人做一次普查，则我们很可能发现在中国中部的许多农民对上述陈述持有很低的概率。讲到这里的时候，萨维奇不得不被迫停下来，因为校园晨一群学生正在会堂外游行通过。他们还高喊着口号「停止上课！罢课！罢课！停止上课！」这些学生在要求全校的学生罢课，以抗议越南战争。等到他们走远，四周又恢复平静，萨维奇才看看窗外，然后说：「看来，我们可能是认为地球是圆的人中的最后一代。」

个人概率有许多不同的版本。其中一个极端是萨维奇－德费奈蒂的方法，该方法认为每个人都有其自己独特的一套概率。而另一个极端则是凯恩斯的观点，他认为概率是一种信仰程度（the degree of belief），这种信仰是一个在特定的文化环境中一个有教养的人可能期望持有的信念。按照凯恩斯的观点，一个特定文化环境中的所有人（萨维奇所说的科学家或中国中部的农民）对某一特定的陈述，会持有一个一般的概率水平。由于这个概率水平取决于文化和时间，因此从某种绝对的意义上为说，很有可能这个适当的概率水平是错的。

萨维奇和德费奈蒂则主张每个人都有自己特定的一套个人概率，他们还描述怎样运用一种叫做「标准赌博」（standard gamble）的技巧把这种人人概率求出来。为了让整个文化中的人能共享既定的一套概率，凯恩斯不得不弱化相关的数学定义，概率不再是一个精确的数字（例如 67%），而是一种将想法排序的方法（例如，明天可能下雨的概率大于可能下雪的概率）。

不管个人概率的概念是如何被准确定义的，贝叶斯定理在个人概率中的应用方式，看上去与大多数的想法相吻合。贝叶斯方法一开始是假设在一个人的头脑中有一组先验概率（a prior set of probabilities），接下来这个人经过观测或实验产生了数据，然后再拿这组数据来修正先验概率（prior probability），生成一组后验概率（a posterior set of probabilities）：

```
先验概率 → 数据 → 后验概率
```

1-2『原来自己之前认知的贝叶斯定理，只是真正「贝叶斯定理」里有关个人概率的一些知识。个人概率，做一张术语卡片。（2020-11-07）』

假设这个人想确定是否所有的大乌鸦都是黑的。她首先存有一些关于「这个陈述是真的」概率的先验知识。例如，起初她可能对大乌鸦一无所知，对「所有大乌鸦都是黑的」这句话半信半疑，相信比例是 50:50。数据则包括她对大乌鸦的观测。假如她看到了一只大乌鸦，而且这只大乌鸦是黑色的，她的后验概率就会增加。因此下一次她再观测大乌鸦时，她的新的先验概率（也就是上一次的后验概率）就会大于 50%，如果她继续观测大乌鸦而且都是黑的，这个概率还会继续上升。

另一方面，一个人也有可能在进行观测之前就已经带着非常强的事前主见，其程度非常强，需要有很大量的数据才能改变这个事前主见。在 20 世纪 80 年代，美国宾夕法尼亚州的三里岛核电厂发生了近乎是灾难性的事故。反应炉的操作员面对一个很大的操作盘，通过上面的各种仪表和指示灯来了解反应炉的运转情况。这些指示灯当中有一些是警告灯，其中有的出过问题，以前曾经发出过假的警告。当时操作员有个事先的成见，当他们看见任何一个新的警告灯亮时，总是认为它是假的信号。结果，即使当警告灯的型态及相关的指示器都一致显示反应炉的水位过低时，他们仍然置之不理。他们的先验概率太强了，以至于新的数据也无法使后验概率产生多大的改变。

假定只有两种可能性，就像前面署名有争议的联邦主义论文的例子：它不是麦迪逊写的就是汉密尔顿写的。于是，在应用了贝叶斯定理之后，就会得到了一个先验胜率（prior odds）与后验胜率（posterior odds）之间的简单关系，这里的数据可以归纳成一种称为「贝叶斯因子」（Bayes factor）的东西。这是一种根本不用参考先验胜率来刻画数据的一种数学计算。有了这个计算工具，分析家就可以告诉读者，插入任何他想要的先验胜率，乘以计算出来的贝叶斯因子，再计算后验胜率。莫斯特勒与华莱士对 12 篇署名有争议的文章，每篇都是这样处理的。

此外，他们对文章里的那些无特定含义的字出现的频率，还进行了两种非贝叶斯分析。这样他们有了四种方法来判断有争议文章的作者：层次贝叶斯模型，计算的贝叶斯因子，以及两个非贝叶斯分析方法。结果如何呢？所有 12 篇文章都压倒性地指向麦迪逊。实际上，如果使用计算的贝叶斯因子，那么对某几篇文章来说，读者认为是汉密尔顿写的先验胜率可能要大于 100000:1 才有办法让后验胜率为 50:50。

### 0301. 人名卡——戴维·萨尔斯伯格

戴维·萨尔斯伯格，本书作者。美国知名统计学家。康涅狄格大学统计学博士，美国国家统计学会「ASA」会员，先后任教于哈佛大学公共卫生学院、康涅狄格大学、宾州大学、罗德岛学院及三一学院，著有多部统计学专著，《女士品茶》是其代表作。

### 0302. 人名卡——耶日·奈曼

耶日·奈曼（Jerzy Spława-Neyman，1894-1981），波兰数学家和统计学家。能够用非常简单而有说服力的方式表达复杂的思想。跟费歇尔（两人是对头）一起奠定了近代统计学。下面是书籍「2020081Fisher-Neyman-and-the-Creation-of-Classical-Statistics」封面的一段信息：

Classical statistical theory—hypothesis testing, estimation, and the design of experiments and sample surveys—is mainly the creation of two men: Ronald A. Fisher (1890-1962) and Jerzy Neyman (1894-1981). Their contributions sometimes complemented each other, sometimes occurred in parallel, and, particularly at later stages, often were in strong opposition. The two men would not be pleased to see their names linked in this way, since throughout most of their working lives they detested each other. Nevertheless, they worked on the same problems, and through their combined efforts created a new discipline.

### 0401. 任意卡——给定一组随时间波动的数据，我们可以将之分解为不同来源导致的结果

回顾一下高尔顿所发现的「向平均数回归」，他试图找到一个数学公式，将随机事件彼此联系在一起。费歇尔接过高尔顿「回归」（regression）这个词，建立了某个给定地块小麦收成与年份之间的一般数学关系，这个相当复杂分布的参数描述了小麦产量产业化的不同方面。要深入理解费歇尔的数学式，你得有坚实的微积分基础，得对概率分布理论有好的辨别力，还要对多维几何学有感觉，但理解他的结论并不那么难。

他将小麦产量的时间趋势分成几个部分，一个是由于土地退化导致产量稳定地整体性地下降；另一个是长期的缓慢的变化，每个阶段都要花几年时间；第三个是一组更快的移动变化，考虑的是气候在不同年份的差异。自从费歇尔开创性的尝试，时间序列的统计分析在他的思想和方法的基础上，建立了起来，现在我们有了计算机，可以用更巧妙的演算法进行大规模的计算，但基本的思想和方法仍然未变。给定一组随时间波动的数据，我们可以将之分解为不同来源导致的结果。时间序列分析用来检验：美国太平洋海岸拍激的海浪是不是印度洋风暴的起因。这些方法使研究人员能够区分地下核爆破与地震，能够精确地为病理学上的心中节律定位，能够确定环境管制对空气质量的影响，其应用范围还在继续扩大。

## 听书

在这本书里，作者从 20 世纪在全球掀起的统计革命入手，为我们揭开了统计学背后的哲学思辨、各种统计方法的诞生和应用，以及整场统计革命的发展进程，可以说，这是关于统计学发展历程的一次全景式呈现。1）统计学的底层逻辑是什么；2）统计学如何帮助我们处理复杂的数据，用已知去预测未知；3）统计学在 20 世纪如何发展壮大，并快速席卷整个科学界和我们的日常生活。

在第一部分，我们说了统计学是干什么的，它的底层逻辑是什么。皮尔逊提出的实验数据的随机性和概率分布的概念，彻底改变了人们认知世界的方式和科学研究的对象。统计学，这门收集数据、分析数据、解读数据的学科，也开始逐渐深入人心。在第二部分，我们介绍了目前统计学基本框架，包括描述统计和推论统计。描述统计针对的是已知的样本，是当下；推论统计针对的是未知的总体，是未来。然后我们又结合具体的历史，梳理了统计学的发展历程，如果我们把统计学从默默无闻到席卷各个学科看做是一场革命的话，那么这场革命的导火索就是战争。受战争的影响，统计学快速发展，扩展到了几乎所有科学领域；到了 20 世纪末，统计学虽然还占据着主导地位，但也受到了很多挑战。尤其是到了互联网时代，大数据技术的发展让我们能够很容易获得整体的数据，那统计学这个从样本来估计整体的学科，还会有那么大的价值吗？这本书的作者最后也表示了自己的怀疑，虽然我们已经抛弃了「决定论」，开始用统计学中的「概率」和「相关」思想来认识世界，但谁能保证这次就是绝对正确的呢？我们认识世界的方法，未来也许会再次因为某次革命而改变。

在开始听书之前，我想先问你一个问题：你发现没有，如果你在网上买过东西，商家就会根据你的网购经历，给你推荐很多相关的商品。比方说你买了婴儿奶粉，商家除了给你再推荐奶粉，还会给你推荐婴儿车、婴儿床。还有，你可能也听过，很多互联网公司都会基于后台收集到的各种数据，做出自己产品的「用户画像」，让分散在整个互联网上的用户，从无数抽象的数据，变成一个或者几个具象化的人物，然后再有目的地优化自己的产品。那你知道支撑大数据和算法科技的，是哪一门学科呢？可能你也想到了，对，就是专门处理数据的统计学。

《女士品茶》这本书里，作者从 20 世纪在全球掀起的统计革命入手，为我们揭开了统计学背后的哲学思辨，各种统计方法的诞生和应用，以及整场统计革命的发展进程，可以说，这是关于统计学发展历程的一次全景式呈现。这本书一经面世，就被奉为统计学中的神作，打个比方，《女士品茶》这本书在统计学领域的地位，就像是哲学界的《苏菲的世界》。

接下来，我就从以下三个方面为你介绍这本书的核心内容。首先，我就从「女士品茶」这个书名开始，给你说说统计学是干什么的，这个学科的底层逻辑是什么。接着，我再具体跟你说说，统计学作为一门应用科学，它的基本理论框架包括哪些内容，它又是如何帮助我们去处理复杂的数据，用已知去预测未知的。最后，我们再结合具体的历史事实，看看统计学是如何在 20 世纪逐步发展壮大，并快速席卷了整个科学界和我们的日常生活的。

### 01

我们先来说第一部分。你可能会好奇，一本统计学的书，怎么取了《女士品茶》这么个名字呢？这个故事其实来自于 1935 年，统计学家费希尔出版的《实验设计》。某个下午，英国剑桥的一群大学老师和他们的妻子一起喝下午茶。其中一位女士突然就说：把茶加到牛奶里，和把牛奶加到茶里，两种方法调出来的下午茶喝起来味道不同。在座的科学家们纷纷表示不屑，无论是先加茶还是先加奶，混合以后的成分可是一样的啊。但口说无凭，为了验证这位女士的观点，其中一位又矮又瘦的男士就设计了一个实验，一群有钱又有闲的科学家们就这样兴致勃勃地投入到了这场实验中。

但「女士品茶」其实只是个引子，这场实验的最终结果如何作者其实也没提，不过这个故事却反映出了统计学的本质。作为一门应用科学，统计一直是从问题出发的，它的本质就是借助一些数学工具来解决一些现实问题，小到验证一位女士关于品茶的观点，大到预测国家的一场金融风暴。我们也可以这么说，统计学就是基于问题，收集数据、分析数据、解读数据的过程。

这个内涵贯穿了整本书，每当作者介绍一个新的概念时，都会穿插大量的背景介绍，让你了解当时面对的是一个什么样的问题，然后再结合统计学霸们的生平轶事以及主要成果，你就能明白他们是怎么利用统计学，来解决问题的。

我们一开始就说了，《女士品茶》这本书说的，是发生在 20 世纪的一场统计革命，就是这场革命，让统计学从一门默默无名的小学科，发展成了席卷整个科学界的基础工具。既然是革命，必然就会涉及到观念的转变。那这场统计革命涉及的，是什么观念呢？

我们现在都知道，无论是人类的演化发展，还是具体的生活小事儿，其实都充满了随机性，牵扯到「概率」的问题。但以前的人们可不是这么认为的。在 20 世纪的统计革命开始前，人们认识世界有个坚定的信念，叫做决定论。当时的人们认为，一切自然现象的出现和存在，都是有原因的，并且遵循着一定的法则。这种信念强调的是因果关系，就像谚语说的「种瓜得瓜种豆得豆」一样。在决定论的支配下，人们坚信在理论上，我们可以掌握一切知识和规律，并且未来的一切事情都是可以准确预测的。而统计需要做的，就是尽可能精确地记录数据，数据越准确，预测才越精准。

然而现实并不像科学家想象的那么完美。很早以前就有人发现，哪怕是一模一样的实验条件，每次出来的实验结果都有细微的差别。但在决定论的观念支配下，科学家们都认为这是各种外界因素的干扰导致的。当时谁都没有怀疑是人们认知世界的方式错了，也许客观世界本身并不是绝对精准。

直到 19 世纪末 20 世纪初，有一小撮人的发现开始动摇决定论的统治地位，掀起了 20 世纪这场统计革命的序幕。这群人就是高尔顿，高尔顿的学生皮尔逊，皮尔逊的朋友戈赛特，以及通过戈赛特认识了皮尔逊、并在后来与皮尔逊结下梁子的费希尔。是不是听起来觉得这些人物关系很复杂？这可是一群有故事的人，关于他们的恩恩怨怨在此就不多做介绍了，感兴趣的话你可以去翻翻书，我就主要给你介绍一下这些人对这场统计革命的贡献。

首先是高尔顿，他发现了「回归现象」。从遗传学的角度来看，父母高的话，孩子也应该高，父母矮的话，孩子也应该矮呀。但是实际测量的数据却不是这样的。整体来看，孩子的身高其实都有一个逐步向人类平均身高靠拢的现象，高尔顿将这种数据向总体平均值靠拢的现象称为「均值回归」。

其实，高尔顿提出的概念，已经和后来成熟的统计思想非常接近了。不过，他当时并没有捅破这层窗户纸。首次将这种思想以公式的形式完整表达出来的，是他的学生卡尔·皮尔逊。

1895 年，皮尔逊第一次在科学史上明确地阐述了实验数值的随机性，而所有出现的观测值都可能符合某种规律性。科学的目的，就是找到几个指标来描述这种规律性。他告诉大家都别为自己的实验误差纠结了，世界本来就是测不准的，每次的实验结果都是随机出现的，至于怎么出现有它自己的规律，科学研究的主要工作不在于研究具体数据，而在于发现这种规律性。这种思想对当时的科学界来说，就像是一枚重磅炸弹。

可以说，皮尔逊的统计思想颠覆了人们认知世界的方式，决定论的观点渐渐被取代，人们开始认识到，万事万物不见得一定是因果关系，而是相互作用相互影响的相关关系，人们也逐渐接受了实验结果的随机性。这种事物间的相关性以及数据分布的随机性，也得到了科学界的普遍认可，直到现在已经深深地渗入到我们的日常生活中了。

皮尔逊的思想不仅改变了人们认知世界的方式，同时也直接改变了科学研究的对象。在此之前，科学研究的对象都是看得见摸得着的东西，是每一次实验收集到的具体数据。而此后，科学实验收集的是一大堆具有随机性的数据，而描述这些数据的数学函数成为了科学真正的研究对象，科学家不再关注某个具体的实验数据，而是某种实验数据出现的可能性，也就是概率。这样，统计学就成了处理概率的基本工具，成了几乎所有学科的研究基石。

皮尔逊的思想虽然具有颠覆性，但由于他自己的数学能力有限，有些概念和数学推导并不成熟，后来戈赛特和费希尔重新定义了一些统计概念，纠正了皮尔逊的一些错误。尤其是费希尔，他在一般性的统计方法和统计思想上，都做出了巨大贡献，而且很多理论和概念都是凭他一己之力从无到有建立起来的，极具原创性。他提出的实验设计方法、方差分析法、回归分析方法等，很快成为了许多学科的研究基础，他出版的教材和论文也极大地推进了统计学在各领域的应用。所以总的来说，整个 20 世纪的统计革命虽然起源于皮尔逊的思想，但整个理论框架和研究方法体系却是由费希尔搭建起来的。

以上就是我们要说的第一部分的内容，这部分的重点是统计革命背后的理念变革。我们说了，统计学就是基于问题，收集数据、分析数据、解读数据的学科，人们对统计学的接纳，同时也伴随着对「决定论」的抛弃。以前的人们是按照「决定论」的想法来理解世界的，但是皮尔逊首先提出了实验数据的随机性和概率分布的概念，这一思想颠覆了当时人们认知世界的方式和实验研究的对象。后来，费希尔又搭建了统计的整个理论框架和研究方法体系，后人也是在这个基础上不断完善发展这门学科的。

### 02

说完了统计学的底层逻辑，了解了统计革命背后的哲学思辨，下面我们再来说说，在现实生活中，统计学究竟是如何处理复杂的数据，用已知去预测未知的。这也是我们要说的第二个核心内容。

前面我们提到统计学一直是从问题出发的，它的产生起源于我们探索世界的需要。你想，我们所处的世界包含各种各样的事物，我们想全部观察一遍几乎是不可能的，人口普查不可能年年搞，了解新药疗效也不可能让每个病人都试一下，但是观察一部分我们还是可以做到的。在统计学里，这个真实的世界或者我们想研究的事物，被称为「总体」，而从总体找到一部分具有代表性的个体，就是找「样本」，统计学就是帮助我们利用样本的信息来推测总体情况的工具，也就是从局部到整体，从已知到未知的过程。

当我们使用统计学的时候，一般有两种目的。要么，是为了分析现有的样本数据，要么，是估计未知的总体情况。根据不同的目的，统计学可以划分为两大部分，一部分是描述统计，一部分是推论统计。

这两个词儿听起来可能不太好理解，我来给你解释一下。简单说，描述统计其实就是处理样本数据的过程，通过对杂乱无章的原始数据进行整理，让这些数据能够直观简练地呈现出来，并作为我们认识事物的客观依据；而推论统计则带有猜测的成分，是从样本到总体的过程，通过整理出来的样本数据信息来估计总体、预测未来。可以说，这两种统计方法的功能不一样，描述统计针对的是已知的样本，是当下；推论统计针对的是未知的总体，是未来。

大面儿上了解了它们的区别，我再分别给你举例说明一下。

我们先说「描述统计」。其实描述统计理解起来并不复杂，它无非从几个角度来描述数据，告诉我们数据整体处于什么样的水平，数据内部分布是比较平均还是参差不齐，在某个具体的行业或领域内跟其他数据横向相比处于什么样的水平，或者从历史的角度纵向来看又处于怎样的水平。实际工作中当我们分析某个企业的薪酬水平、某国的 GDP 数据时，基本就是从这些维度思考的。

描述统计虽然是一种处理数据的方法，但它作为一种思维方式同样指导着我们的工作和生活。比如，我们有时会听到「用户画像」这样一个概念，是不是听起来很高大上？但其实它本质上就是一种描述统计。数据团队在制作「用户画像」的过程中，首先会根据需要选取关键的指标或者维度，然后收集各个维度的数据或相关信息，比如收入水平、教育水平、产品使用频率等，这就是一个计算平均值的过程；最后将这些信息整理，抽象出一个用户的信息全貌，给用户贴标签，这个过程就是把各个指标的平均值综合起来然后用文字描述出来。当然具体的操作要比这些复杂得多，但其本质并没有区别，只不过描述统计处理的是数据，而用户画像有可能处理的是文字而已。

了解了描述统计的含义和功能，我们再来说说「推论统计」。

前面我们提到，推论统计本质上就是用样本信息推测总体情况，利用已知信息去估计未知的过程，这其中含有「猜」的成分，既然是「猜」就必然存在如何判断猜得准不准的问题。因此在统计教材中，这部分章节涉及大量的统计方法和计算公式，还有复杂的逻辑推理过程，让很多人头痛不已。然而无论是使用什么分析方法，本质上都不外乎是这么两种思路，那就是「参数估计」和「假设检验」。

所谓的「参数估计」，就是直接从样本出发，利用样本计算出的数据来估计总体情况，它又分为点估计和区间估计两种，简单来讲就是你在估计的时候用的是一个具体的数值还是一个数值范围。现实生活中，其实我们每天都在「被估计」，每当你刚浏览完某个产品的信息，紧接着平台就会给你推荐一大堆相关产品。但细心的话，你可能会发现虽然买的是同样的东西，但不同的平台随后给你推荐的产品却不太一样。这是因为，他们抓取的样本数据或者具体算法不同，但背后的统计思想并没有差别，无外乎用现有的大多数人的样本数据来预测你的偏好。

除了「参数估计」，推论统计里，还有一种重要的方法就是「假设检验」。简单来说，「假设检验」就是从总体出发，先对总体情况提出一个假设，称之为「零假设」。然后通过实验收集数据，将收集到的数据跟这个零假设进行比较，看看之前的差异大不大，大到什么程度才能认为实验方法是有效的。其实「假设检验」的思路跟我们生活中的目标管理很像，先定目标，执行完后看看目标是否达成。这个分析方法，在学术研究领域，是非常常见的。当然科学家们做的「假设检验」要比这复杂严谨得多，但基本思路就是这么简单。

现在假设检验的思想已经渗透到了现代科学教育中，并成为科学家和工程师的常规思考方式，他们在进行科学研究、发表科学论文的时候，基本都会用到这种思路。通常「零假设」都是一些通过多次验证的共识性的结论，想要推翻它可不容易，而科学研究就是一步一步地、小心翼翼地在试图推翻「零假设」的过程。

到这里第二部分的内容就说完了，我们再来回顾一下。我们说，按照不同的分析目的，统计方法可以分为描述统计和推论统计。描述统计主要是对数据进行整理，简单直观地呈现出数据，而推论统计则是利用样本信息去推论总体的过程，用已知去预测未知。描述统计和推论统计是紧密联系的，可以说，描述统计是基础，推论统计是目的，客观准确的描述为准确的推论提供了依据。

### 03

前面两个部分我们介绍了统计学是干什么的，也说了统计革命背后的哲学思辨和统计理论的基本框架。在最后一部分，我就结合具体的历史，一起来看看统计学到底是如何一步步发展壮大，并在现在科学研究领域得到快速应用的。

如果我们把统计学从默默无闻到 20 世纪席卷各个学科，看做是一场革命的话，那么这场革命是怎么从星星之火发展到燎原之势的呢？这还得从统计学最初的状况开始说。

说起统计学，你可能觉得这是个挺现代的学科。但其实「统计」的概念由来已久，从人类文明出现以来，统计就已经存在了。从最开始的结绳记事，到后来随着各种政权的出现，为了方便管理，各国都会成立专门的机构负责统计国家信息，比如中国古代的户部。统计的英语单词 statistic 就源于城邦 state，可见统计学跟国家政治的渊源是很深的。

但是，出现得早不见得发展得也成熟。事实上，直到 19 世纪，统计所做的工作主要就是客观地记录数据，以便当权者快速地了解信息。在统计革命到来之前，统计学的发展是极为缓慢的。这是因为，20 世纪初欧洲的数学家们依然沉浸在纯数学的抽象世界里，认为统计学就是一种简单粗暴的加减乘除运算，毫无技术含量可言，所以就不太重视这个学科。

统计学的高度发展，其实是从 20 世纪 30 年代开始的，这个发展的直接原因，就是战争。这是为什么呢？你听我接着给你解释。

30 年代，希特勒的纳粹主义和种族政策几乎毁掉了整个欧洲的数学界，大批优秀的数学家逃往美国，这在很大程度上抑制了欧洲统计学的发展，统计革命的重心转移到美国。美国当时正经历着大萧条，整个国家处于瘫痪状态，罗斯福刚刚上任，华盛顿政府迫切需要了解全国上下的情况到底有多糟糕。就这样，抽样调查应运而生，在美国政府部门的推动下，民众开始接纳随机抽样方法，后来逐步应用到政治性民意测验领域。目前全球最著名的调查公司，像尼尔森、盖洛普等，之所以都是美国公司，也可以说跟当初这场普及全民的抽样调查活动息息相关。

到了 40 年代的「二战」时期，为了战争的需要，大量统计学家开始参与到作战研究中，统计学发挥了重要的作用，这也让许多纯数学家真正重视起统计学。当时美国军方相信实验设计和统计方法可以充分应用到作战研究中。普林斯顿大学数学系主任威尔克斯在国防研究委员会内部成立了一个研究小组，这个小组招募了一些非常聪明的青年数学家和统计学家。他们通过设计实验，分析数据，利用统计的方法检验武器装备、破解敌方密码，进行军事部署等。这个小组的研究甚至还影响了最终的战争决策。

口说无凭，你听我给你举个真实的例子。二战末期，美国陆军得知日本开发了一种非金属地雷，而当时所有方法都无法探测到这种地雷。日本军方沿着美军可能入侵的路径，将这种地雷随机地埋在了日本的各个海滩上。据估计，光这种地雷就能造成数十万人死亡。美国必须尽快找出摧毁这种地雷的办法。这时候，统计学的作用就体现出来了。普林斯顿小组开始设计用各种方法摧毁地雷的实验，包括用飞机从空中投放炸弹来引爆日军埋的地雷，但最终所有的实验和计算都表明，这些方法没用。所以美国最终决定直接向日本投放原子弹，这个决策，可以说直接影响了整个二战和人类发展的进展。

可以说，战争让统计学大放异彩，发挥了重要的作用，并且取得了很多创新成果。这激发了许多科学家的爱国热情，并让很多理论数学家重新认识了统计学。战争结束后，这些数学家和统计学家们回归到各自的领域，为科学的发展做出了重要贡献。在此后的几十年里，许多实验和统计分析方法，也得到了系统地梳理和完善。统计成为各学科数据的研究基础，在经济学、社会学、心理学、流行病学、生物学等领域都有重要应用。

那统计学是不是就此成了学科里的「老大哥」，大家没它不行呢？并不是。尤其是到了 20 世纪末，这场统计革命在逐步走上巅峰的时刻也开始受到诸多挑战。为啥这么说呢？理由有这么三个。

首先，统计方法的过度应用受到了批判。这场统计革命进行了近 100 年的时间，概率分布的观念已经深深地渗透到现代科学教育中，很多科研工作者们严格按照假设检验的思想去求证，只关心显著性，却很少去思考这些方法背后的思想内涵。这种过度应用其实也受到了许多统计学家的批判。毕竟，标准的统计方法本身并不足以解决问题，研究人员需要关注问题本身，而不是天天盯着数据看它显不显著。

其次，新的学科及技术的出现，削弱了统计学的影响力。尤其是随着互联网的发展，大数据技术的迅猛崛起，轻点一下鼠标，就能获得所有数据。当总体的数据都可以轻易获得的时候，我们还需要推论统计吗，这些经过反复论证的数学公式还有存在的意愿吗？这也是统计学家们需要思考的问题。

最后，作者从根儿上，对这场统计革命提出了质疑。在过去，几乎所有认可接受过科学方法培训的人，都把皮尔逊的观点当成了理所当然的事情，也很少有人考虑这种观点背后的哲学内涵了。但是有学者认为现实是非常复杂的，人类构造的科学模型永远也无法完整地描述现实。在某一阶段可能某一模型符合现有数据，随着数据的积累，就需要对模型进行修改，以满足新的发现。

统计革命就是这种模型更替的例子。虽然大众都接受了概率论的观点，但是概率这种看不见摸不着的东西真的存在吗？我们认知世界的方式真的正确吗？如果这一点没法确认，那这场统计革命就像是建构在沙土上的摩天大厦。也许有一天，我们会发现这场统计革命不过只是人类认知历程中的又一次错误尝试。我们认知世界的方式又会经历怎样的变革呢？

## 书评

### 01. 女士品茶读书笔记

从公共邮箱中下载到课上所说的基本著作之后，和很多人一样，我选择了《女士品茶》这本比较通俗易懂的入门读物。就如读完了《苏菲的世界》后对整个哲学有了基本的认识，这不是一本女性读物，也不是一本专门讲茶的读物，而是从一个温暖的下午几位大师和他们的夫人们对其中一位女士的观点进行验证引领我们走入统计的世界：把茶加入到奶里和把奶加入到茶中会使味道品起来不同。

很有意思的是整本书并不是把这个看似很简单并且从某些角度看起来仅仅是一个很无关重要的消遣的实验作为一个引子，而是将这个例子作为一条线索贯穿了整本书，从第一章的纯粹的验证这位女士的结论是否正确开始，如何在这位女士没有区分能力的情况下设计实验让她无法仅凭猜测正确，如何在这位女士有区分能力的时候容忍区分出错的概率，比如十次重复实验之后区分对了九次的情况下是否值得我们相信这个女士是有区别能力。这些对于这个很简单的实验设计形象化了数理课中很多的概念化的东西，最大似然估计，假设检验，中心极限，大数定律。

不愧是一本入门的著作，作者在每一次引入一个新的概念的时候都会有一定篇幅的背景介绍和相关奇闻异事，作为一个基本没有系统学习过统计学的理科生来说，虽然在很多的时候我不明白这些公式是怎么推出来的，也不知道这些变量是怎么求，怎么算。但能基本上明白这些公式，这些变量的设置是要做什么用的。

通读一遍了花了自己一整天的时间，pdf 亮丽的白底黑字，加上每一页都是密密麻麻的文字，幸亏还有每一位天才的生平起到承上启下的作用，不会泪流满面。但是粗略的读完书之后，对于上课的注意力集中倒是起到了不少的作用，至少不会因为忘记如何积分，如何计算极限，看着满满的一黑板公式而失去了听课的信心。

我在想，有多少人会思考如何去理解每一个公式是怎么来的，它是做什么用的，为什么它是需要的，是不是可以更加优化的使用而不关心最后这门课能得到多少分去学习数理统计，就如大师们《实验设计》的作者费歇尔一直在思考如何更加优化的设计实验方案去验证这位女士的结论，至于这个实验的结果到底如何，成不成功，已经成为了次要。如果大师们仅仅为了去验证这位女士的结论的话，我想这一切真的就是一种很简单的消遣了。

还是回归到这本书的内容，很喜欢书中对于真实世界的描述，我们所见的都是一个概率内发生的事情，「充满随即性的大自然里，真实性只存在分布函数之中」。费歇尔大师把观测的现象认为是随即的映像，真正我们想把握的只是分布的四个参数。

诚然，阅读这本书对于想提高自己的统计学能力基本作用为零。但是我还是会在仅仅只有几周后考试的情况下很认真的阅读完这本书。而且我相信如果还有机会和时间的话还会很认真的去读第二遍。不仅仅是这本书让能让自己明白为什么会有统计，哪些时候我是可以用到统计学的，更上深一点便是能明白我在学的什么知识，我想即使很多年之后我已经不在使用例如统计，高数这类专业知识的时候。我也能明白哪些专业术语是怎么回事，用最简单的最通俗的语言去说明白。

很显然，作为一个不是专门研究数学的理科研究生，让我写出一个关于这本书的完整的介绍和梳理整本书的知识结构是一件很困难的事情。而且其中有一大部分的内容在我脑海中只有一个模糊的影像。虽然看的是一本中文译本，虽然整本书中一个公式，一个数学公式都没有。但是每一个我们所接触的统计学方法都变成了一个个生动有趣的故事。我在做题的时候看到实验设计的时候，自然会想起那个温暖的午后那一群大师对奶加入到茶和茶加入奶中的验证，在看到显著性检验的时候会想起费歇尔的经典名言「如果没有随机化的实验设计，你无法从实验结果中证明任何事情」。

有没有好处？对于最后的成绩我不知道，但是至少我在做题和分析的问题的时候，让我有了更大的乐趣，在对待现实的各种事情的时候，多了一份各个角度的情况分析和多次验证的观点。也许某一天就会因此看到不同的世界，这可能就是我阅读这本书最大的收获吧。

### 02. 天天生活在大数据统计里，总得懂点什么吧

有一天我要给客户介绍微博的各个推广位，右边及底部的广告位一直跳出我昨晚搜索过的蕾丝内衣。性感的肉体不停的闪现。给客户介绍的那几分钟是我为数不多的人生尴尬之一。后来我知道这是网页的抓取功能，有专业的名称 ——「爬虫」。只要你在淘宝或者别的网页搜索过特定名词，不管你打开什么网页，广告位总是你刚搜索完的物种。这是一种自动获取网页内容的程序。是搜索引擎的重要组成部分，搜索引擎优化很大程度上就是针对爬虫而做出的优化。以上，可以俗称大数据统计。

我曾经服务过的一家公司是「海关数据」的整合公司，用海关编码可以查询到这款产品的进出口数据，包括中国的每年的出口数据，美国、俄罗斯、加拿大等各国的进口数据。通过中国的海关出口单据、海外的到港数据及各种提单进行完美整合的一款产品。这有什么用呢？举个例子，你是生产毛绒玩具的生产商，通过毛绒玩具的 HS 编码，你会在平台上找到这款产品在之前的 5-10 年每年的出口数量是多少，进口国最大的国家是哪一国。进口这些产品的商家是什么公司，运气好的可以找到这些进口商的联系方式。进出口知识丰富的可以通过一张提单的数据反推出一款产品的成交价格是多少，这家企业一年的进口数量是多少。接下来，针对这个企业的报价单就可以完美呈现自己生产的毛绒玩具有多符合这个客户的需求。《货币战争》早就告诉我们提前知道一些数据对自己有多管用。通过数据统计分析得出自己想要的信息，这就是大数据的魅力。

我可以再举个例子，购买过这款产品的有一个客户，他们是几个开外贸公司的年轻人，购买了一款产品的海关数据，涵盖该产品的各国概况、准入标准、各国政策、以及 10 年内产品的进出口数据。经过一段时间的潜心研究后，他们发现了在某洲的一个地区 led 灯的进出口数量都为零。但是这个地方的周边地区都已经在大量采购 led 灯泡了。他们直接买了机票飞到该国，实地考察当地市场，一家一家商超及经销商的去洽谈 led 灯泡的销售。一年后，他们收获了这个地区的 2000 万订单。

有些人可能觉得统计没有这么强大的能力。那么说个最简单的，一家餐厅刚开始营业，并不能确定自己每天的销售数量，但是第二天，店主可以通过第一天的销售大致预估准备第二天的食材，第三天可以通过前几天的销售准备当天的食材，一个月之后是不是可以通过数据统计分析得出餐厅下个月的备货数量了？这就是统计学啊！

一家超市卖薯片。他想知道哪个口味的薯片卖得最好，那么最好的办法就是整理自己的出库小票。用一个月、一年、三年的数据来得到最接近事实的数据。同理也可用于薯片生产商。

现在做电商，各大平台都会提供相应的数据分析，可以让你看到你想销售的产品在该平台一年有多少销量、你设定的关键词有多少搜索量、这款产品主要分布在哪些区域、价格区间是多少，购买对象集中在哪个区域，什么年龄段。这似乎已经成为了做好电商的必备工具。这就是大数据分析。

虽然我们现在把大数据、统计、分析说的很神奇，但是这其实始于 20 世纪 20 年代的一位女士，她提出将茶倒进牛奶与将牛奶倒进茶中所产生的味道不一样。罗纳德·艾尔默·费希尔听到了这个说法，他决定用一组实验来验证这位女士的这句话。第一次统计分析便是记录在册的这次：提出论点 —— 提出假设 —— 进行实验验证。

数据统计、实验统计是怎样改变我们这个世界的运作和生活的呢？我还有很多例子可以举，但是要知道这段历史和其中的故事大家可以来阅读这本《女士品茶》，书本会告诉你统计学是如何变革来科学和生活。书中介绍一个新的概念时，穿插了大量的背景介绍，再辅以相关奇闻异事。就算你对概念一窍不通，但读完一个章节，你就能明白其中的特定概念。书里讲的故事，可比我前面讲的内容有趣多了。天天生活在大数据里，总得知道点什么吧！比如：大家都知道「概率」的意思吧，但是在这本书里非常细致了讲了概率的出现，各种大拿提出的理论，以及最后「概率」的各种野史。

最后我想说句，我一直觉得能写这种书的人特别牛，不仅要博览群书、逻辑清晰，还要是个特别有耐性的人，唯有将读者都当成「弱智儿童」才可以将这些概念介绍得如此细致，如此不让你接着提问为什么。

### 03. 引领我们测量上帝旨意的方法

《女士品茶》是著名统计学家大卫·萨尔斯伯格撰写的统计学通俗作品。本书以「女士品茶」的故事为开始，但与喝茶和女士没什么关系，只是用「品茶」故事作为引子，通过生动有趣却不失严谨的实例论述了统计学原理，并使用大量的大众化的语言通俗地阐述了统计学的最大似然估计，假设检验，中心极限，大数定律等基本概念和方法，深刻地揭示了现代统计学发展的过程，展示了统计研究的工作方法。作者使用平和亲近的表述方式，让我们体验了一场关于统计学的奇妙认知之旅。

在社会高速发展的今天，各行各业的发展都同统计学有着千丝万缕的联络。统计学可以为行业反应真实数据，帮助行业管理人员梳理出其中所需要的数据，从而根据专业的整合分析，能够宏观把控事态的发展方向，从而使得决策更加具有相对科学的预见性。比如城市交通拥堵的治理、人口普查等等，都少不了统计学的参与。有了统计这个定量分析的工具，很多科学研究就更加有效，结果也更加有说服力，更便捷地确定问题是什么。直到现在，大部分的研究都还是需要统计分析的过程，统计对科学研究的进步发展的意义是里程碑式的。

南丁格尔有一句名言：如果要想了解上帝在想什么，我们就必须学统计，因为统计学就是在测量上帝的旨意。通过《女士品茶》，我们能够清楚地看到统计学的巨大威力：

1、费歇尔在农场里计量农作物与气候，雨量，杀虫剂，肥料之间的关系，在发表了《研究工作者的统计方法》这一系列举世著名的论文的同时，也改善了农业生产。

2、戈赛特先生在吉尼斯酿造公司通过解决测量在麦芽浆发酵是其所用的酵母数量，确定了泊松分布在现实生活中的实例和统计分布新观念的应用，同时也解决了该公司生产上的一个重大问题。

3、蒂皮特在棉花工业研究协会为找出最脆弱的纤维强度，发现了极致分度，也找出了最脆弱的纤维强度，从而提高了棉花的产量。

4、为解决靠近前线的军火补给站的最佳选址，以及解决军队的食物补给问题，产生了运筹学。战后又将其应用到了商业上，提出最优解，均衡有限资源，改进生产和提高产量等问题。

当然，统计学的用处数不胜数，不能穷举，只能用大数定律来做简单的涵盖。统计学作为一门学科，同时也是一项重要技能。在生活、物理、社科乃至商业活动、政府决策，都能找到统计学的影子。随着互联网时代的发展，数字化进程不断加快，人们越来越多地希望能够从大数据中总结出一些经验规律从来为决策提供重要依据。

1、应用于政府决策。人口学中的统计学应用、社会发展与评价、持续发展与环境保护、资源保护与利用、宏观经济监测与预测、政府统计数据收集与质量保证等都依赖于各类科学的统计方法。最常见的就是人口普查和交通流量监控。近年来，CPI 指数、PMI 指数等宏观经济指数，也都为国家宏观调控提供了重要依据。

2、应用于金融行业。在金融业行业，统计学被广泛应用于金融风险研究，既为管理层宏观调控金融市场提供科学的理论依据，又对投资个人和机构实施风险控制进行指导。常见于利率、汇率以及债市等。

3、应用于企业管理。利用统计学知识可以对企业进行财务风险分析、顾客行为分析、商品市场的变化趋势及经济环境的研究等。特别是在顾客行为分析方面，利用大数据进行产品营销，提供顾客满意度。每年淘宝、天猫、京东等大型平台均利用大数据进行顾客分析；搜狗输入法通过个人录入进行相关统计，为客户提供一手资料，等等。

4、应用于旅游行业。随着旅游行业的不断拓展，统计学已经广泛应用于旅游行业，通过对旅客流量、宾馆入住率、餐饮收入等指标，进行预测，有效调控景区人流量，提高游客体验度。

等等，等等。

统计学不仅仅是统计数字，还具有调查、收集、分析、预测等功能。对于我们研究社会，研究世界；改造社会、改造世界具有非常重要的意义。想要学好、用好统计学，建议认真研读这本被称为「关于统计学历史与变革的书」——《女士品茶》。这里没有僵化枯燥的数字公式，有的只是统计学瑰伟的魅力。

PS：大名鼎鼎的中统、军统的全称分别是：中国国民党中央执行委员会调查统计局、国民政府军事委员会调查统计局。

### 04. 有关本书的八卦

其实我还没看过这本书，才知道有中译本，不知翻译如何。这是 08 年 4 月的文章了，在三聚氰胺事件发生很早以前。在三联周刊上看到了一篇文章介绍女士品茶实验，从一个有意思的故事开始讲统计。豆瓣上有英文书《Lady Tasting Tea》，似乎 book.google 上有。

故事开始是某女士在下午茶时说，冲奶茶时先放奶再加茶，和先加茶后加奶冲出来的味道不一样，周围的绅士们视为无稽之谈。这时 Fisher 出来说话，设计一个实验来测试一下这位女士是否能喝出两种冲泡法的区别，让她在不知情的情况下尝奶茶，猜这杯是先加奶还是先加茶。为了避免蒙中，茶的杯数要足够多，但也不能无限制的喝下去，那么为了确定那个女士能猜到多准，最少该喝多少杯呢？这个实验很著名，是个似然估计问题。描述的具体点，假设这个女士猜中的概率为 p，现在要从试验结果估计 p，如果要求估计精度为 0.05，那这位女士至少要喝多少杯呢？对概率论有自信的人来算算吧。

三联的文章说，那女士全部猜中了。这个结果我一点不意外，因为按我的经验，两种冲泡法是有明显区别的，先倒茶再加奶的冲泡法口感和香味都要好一些。原因可能在于奶的温度。我早上泡奶茶的时候，是差不多 2 份红茶（500 ml）加 1 份奶（250 ml），茶是热的，大概在 80-90 度，牛奶总是冷的，和室温相同，如果是将冷牛奶倒进热红茶，那么开始倒进去的牛奶被加热，和红茶会有反应，香气也散发出来。如果反过来，则红茶一倒进去就被冷却了，奶和茶的反应不大，香味也差一些。如果是等温的热牛奶加热红茶，那么先后的次序可能就没关系了，但我没试过。

为什么那位女士喝的出来而男人们觉得不可能？我想女人的味觉分辨能力也许确实好一些，但男女味觉的差异没有那么大。应该是男人们在喝茶的时候总在聊天和做别的，没有注意吧。所以，这个实验不光涉及统计学，还涉及化学、生理学和心理学呢。

### 05. 统计学并不是你想象的那么枯燥

一开始以为，这是一本讲解关于品茶的书，也许会涉及如何优雅地喝茶的问题罢，但没有想到，这是一本与统计学有关的书，算得上是一本很严肃的书了！不过值得幸运的是，很显然，本书的作者美国人戴维·萨尔斯伯格也意识到，假如这本本来主题很严肃书如何只适用于理科生的话，它的受众面可想而知就会有多么窄了！因此在本书的《后记》中，作者特意提及，《女士品茶》这本书的「目标群体是几乎没有经历过数学培训的读者」，因此，他选取的例子也多是「那些无须使用数学符号、只用文字便可解释的例子」。所以，回到标题来，这本副题为「统计学如何变革了科学和生活」的书，主标题却使用了相当轻松的「女士品茶」这几个字，切入点正是一个发生在近百年前的一个下午关于品茶的故事。

日常生活中，涉及到统计学的问题有很多很多，比如：父母越高，孩子就越高吗？丈母娘究竟与房价的涨落有没有因果关系？抽烟真的有害健康吗？广州恒大队还能够继 2013 年、2015 年之后在第三个奇数年即 2017 年的时候第三次夺取亚冠吗？…… 甚至于购买彩票、到菜市场买菜，各行各业的人都有可能接触到他所关心的种种需要用到统计学的问题。看似高深莫测的统计学，其实与我们的日常生活密切相关。不需要去记忆那些各种各样的公式，只需要跟着戴维·萨尔斯伯格的脚步，看一看英国科学家弗朗西斯·高尔顿以及他在伦敦建立的一家生物统计实验室的工作，再到卡尔·皮尔逊对科学与数学模型的着迷，再到威廉·西利·戈塞特先生在吉尼斯酿酒公司工作之余所做的更为知名的活儿，再到罗纳德·费希尔与皮尔逊父子之间的似乎是不可调和的恩怨，再到确定药毒品与毒药剂量反应关系的基本统计模型的发明者 —— 美国人切斯特·布利斯的杀虫剂实验，再到在数学深度和细节上都超越了费希尔、号称「数学界的莫扎特」的安德雷·尼古拉耶维奇·柯尔莫哥洛夫，甚至还有弗洛伦斯·南丁格尔 —— 也就是那位护理行业的开创者，她同时也是一位自学成才的统计学家…… 这一系列的人和故事看下来，对于「统计学如何变革了科学和生活」这个话题也就觉得顺理成章了！

甚至到如今，统计学已经越来越脱离了统计学家的小圈子，得到了越来越广泛的应用，成为了一门更加实用的科学。比如，在公共政策问题中，统计模型就孕育出了一门新的学科 —— 风险分析；概率也越来越为更多的普通人所知晓，并应用于每一件他们所关心的事情当中：公共卫生官员想要弄明白艾滋病的平均潜伏时间；在街头的福利彩票、体育彩票购买店里，虽然明知每一次开出的号码都是随机的，但人们还是乐此不疲地要从以往的各期开出的数字中总结、归纳出某种规律来，以便增加自己的中奖机率…… 事实上，统计学本来就是致力于收集数据、解读数据、从数据中总结出规律，继而预测乃至改变未来的一门学科，统计学并不神秘，而是一门科学的学科。至今，当我们已经进入了大数据时代的时候，数据的容量已经超出了我们的想象，处理数据也越来越多地依靠那些超级电脑们来进行，但相关统计学原理在生活的应用依然是方兴未艾，在天文学、社会学、流行病学、法律或者天气预报中都得到了广泛的应用。即使是刚刚踏入校门的小学生们，大概也想弄明白与他们休戚相关的一个问题：下次考试排在前十名的机率有多大？

我们对日常生活的种种感性认识，有些符合统计学的原理，但更多的却只是似是而非。但我们都应该知道，生活中虽然处处充满了偶然性和必然性，但一切的随机事件都是有征兆可循的，随机事件并不是没有规律、不可捉摸、无法预测的，总会有一个数学模型能够用来恰如其分地描述这些随机事件，继而给出一个合理的解释。一句话，统计学并不是你所想象的那么枯燥的一门学科，它一定会让对它倍感兴趣的你得到你想要的一切…… 甚至，通过本书，一个读者能够对统计学从此产生足够的兴趣，并一头扎进统计学的研究「海洋」里，那就更有收获了！

回到本书的标题上来，戴维·萨尔斯伯格总算是给出了那个问题的答案：那位坚持认为「将茶倒进牛奶里和将牛奶倒进茶里的味道是不同的」女士，她猜中了所有的答案，一个也没有错。也许换一位女士，或者再增加样本，都会导致错误，但那已经不很要紧了！统计学里还是能够容得下这一些甚至更多的有趣的小插曲的……

### 06. 从整体上去看待概率统计，而不是只会公式推导

事实上，感觉学生 t 分布是非常重要的，无论是对历史还是对理论上的进展，可为何这个分布无论何时都只是被人一带而过呢？皮尔逊，我觉得更多的是现在大家比较熟悉的大样本的情况；而费歇尔的思想，则是说参数是随着样本而变化的，因此基本上永远无法得到正确的值，因为总是具有随机性的，这样的话，只能说，以概率 1 无法得到真正正确的分布参数。

看完 1/3 后，突然觉得自己根本没有理解统计思想，所用到的更多的是一种数学计算而已，对其思想，我想是需要了解和思考的。如果我是大学教授概率统计的老师，或者研究生阶段教授随机过程的老师，我会告诉我的学生去读读这本书，这样子或许我的学生即使没有从事概率统计的研究，也能理解，他们所学的东西并不是数学公式而已，其具有思想、具有灵魂、具有发展历史、更具有我们日常生活中司空见惯的应用。全书翻译的还可以，说有台湾版本的，可有些地方作者翻译的怎么都读不通，不知道是翻译时漏掉东西了，还是没理解原作者的意思，误翻译了。

### 07. 读书笔记：《The Lady Tasting Tea》

这本书是我完整意义上读完的第一本英文著作。出国快一年了，之前也尝试过阅读一些英文小说，可是都很难完整的读完。因为都还是所谓的名著，于是我自然的将没有读完的原因归结为自己没有耐心，或者是英文还不够好。直到我那天在一个订阅的博客上看到这本书的书评，那段时间正好在频繁的使用统计方法来分析手头的数据，于是自然而然的对这本所谓的和统计有关的小说产生了兴趣，于是便借来一读。

实话实说，我大学时候统计学的很烂，于是造成今日不得不狂补各种统计学基础知识，实在是悔不该当初。诚然，阅读这本写给没有数学基础的读者的小说并不会对提高我的统计学能力，书中所讲的各种统计学理论和方法我虽大多都有耳闻，但是大多也只是耳闻罢了。书中的那些统计学家在作者的笔下像一个个武林高手，Pearson 的固执，Gosset 的低调，Fisher 的天才，还有那许多我记不住名字的高手们，共同演绎了二十世纪这场绚丽多彩，又跌宕起伏的统计学革命。

书中我认为比较精彩的一段是写如何证明吸烟和肺癌之间的关系。许多统计学家和医学家经过研究，发现吸烟和肺癌的发生率之间存在关系，于是进而想要推导出吸烟会增加患肺癌的风险。听起来很合理，但是有人不同意，有个大烟民不同意，这个大烟民就是 Fisher。Fisher 对这些学者的研究进行了有力的反驳，相关关系并不等于就是因果关系，我自个儿吸烟几十年了，身体还是倍儿棒。这边厢各路医学家和统计学家人多势众，那边厢 Fisher 同志赤膊上阵，力敌穷雄，好不精彩！虽然最终无论是医学界还是公众都接受了吸烟会导致患肺癌风险增加这一事实，不过 Fisher 依然坚持自己的观点，照吸不误。

我认为这本书的最大的优点在于生动，将平常我们所接触的那些统计学方法生动写成了一个个有趣的故事。好处很明显，以后我再用到 Student's T-test 的时候，会自然而然的想起那个夹在 Pearson 和 Fisher 两位巨人之间，位置有些尴尬的 Gosset，而对于所谓的显著性检验，我也会想起 Fisher 的观点，那就是如果没有随机化的实验设计，你无法从实验结果中证明任何事情。

很显然，我凌乱的记忆并不能保证我能写出一篇清晰流畅的书评，因此这本书有时间我还会再读一遍甚至买一本收藏的。很高兴这本书也有中文译本。我想说的是，别被什么「统计学如何革命了二十世纪的科学」这种名号给唬住了，其实这本书里一个数学符号，一个数学公式都没有，尽可以把它当做一本科普小说。

## 08. 充满随机性的大自然里，真实性只存在于分布函数之中

借来这本书半年了还只读了前两章，昨天和老师碰面说小论文他提起才在睡不着的半夜起来读。书的第一章就是女士品茶试验，Fisher 的实验启示：科学是从审慎的观察、思考和实验发展而来，从潜在实验结果的数据模型开始工作，从实验数据开始，计算与所考虑科学问题相应的结果。

观测到的现象只是一种随机的映像，不是真实的，所谓的真实是概率分布。科学中真实的东西并不是我们所能观测到或能把握到的，它们只是通过用来描述我们所观测事物随机性的数学函数来反应。科学调查中我们真正想确定的，是分布的四个参数。从某种意义上说，我们永远不能确定这四个参数的真实数值，而只可能从资料中估计它们。不管原始测量是否服从正态分布，「学生」的 t 检验都有相同的分布。没有这一发现，统计分析注定要使用无限次的回归，这样继续下去，没有机会得到最终的结果。

前三章后没有细读，但都是我们目前使用的基本方法的基础，自由度；每本统计数都会出现的一致、无偏和有效三准则；至今仍在各种机器学习算法中出现的 EM 法；第八章致死的剂量没看懂，有兴趣的童鞋自己读下吧，据书中说是毒理学的主要基础；拟合优度检验和 chaos 结合在一起让我脑袋也混沌了。

P 值、假设检验这是生物医学中最常用的统计方法，应该值得每个人尊敬。但我常常听到有些废物这么说：我现在文章也会写了，P 也能弄到小于 0.05 了。研究来研究去，就为了个 P，这对于我们国家来说应该是悲哀吧。

置信区间、贝叶斯估计、非参方法，再说下去就像 shelton 所说的：警告，严重剧透了。但仍忍不住说句 intension to treatment, aka ITT，这种随机对照试验中的方法竟然也和前文那些伟大的名字列在一起，让我觉得自豪。（也不知道为啥自豪，又不是我发明的）。

这本书的好处是告诉你统计方法不是 spss 里面的冰冷按钮，他们是活生生的发现，你也许能从泛黄的可能是用羽毛笔写的收稿中获得你的灵感。统计也许不是工具，也许就是科学也许不是，谁知道呢？真正的发现就在分布函数中，你要做的就是找到他，可能大部分的人所能做的工作就是这样吧。当你不再是使用工具，而是发明工具，你就是下一个 Fisher，可能你现在就在世界上某个角落努力呢。

### 09. 统计学与概率论

如果只是看看书名还真要让一大帮粗心男士错过，通过女士对奶冲茶和茶冲奶的判断来引出大量统计学的研究背景，学术和生活有时候真的是分不开，而大家耳熟能详的永远是物理学那个顺从地心引力掉下来的苹果，却不那么关注和数字密切相关的数学理论，当然，数学这门课程对于大部分人来说也确实足够枯燥。

记得大学时候首先学习的是微积分，这是一门太过于恐怖的学科，大部分文史类学科的学生一定都是这门认为的，在度过漫长又痛苦的两年微积分学习后，紧随而来的是统计学和概率论，这两门学科总是让人觉得应该配套起来学习，尤其是在概率论中统计学是它的实验基础。

数学类知识的实验远远没有物理化学那么生动和实际，永远都是枯燥的建模和数字计算。

《女士品茶》深入浅出地描绘了统计学不断变革的发展史，带领读者一一回顾「统计」这门应用范围最广的科学，了解若干重要理论的发展过程与应用，亲近那些隐身幕后的统计学家，看看统计学究竟为今天这个世界，带来了什么样的改变。这是一部大数据时代不容错过的实用之书，大数据时代，一切以数据说话，如何解读数据便与每个人的日常生活息息相关，统计学的本质就在于解读数据，读懂了本书，你就是大数据时代的明白人。—— 内容简介

《女士品茶》作者戴维·萨尔斯伯格，康涅狄格大学统计学博士，原辉瑞公司资深统计研究员，美国国家统计学会会员，先后任教于哈佛大学公共卫生学院，康涅狄格大学、宾州大学、罗德岛学院及三一学院，著有多部统计学专著，本书是其代表作。该书由刘清山翻译，译者同时还译有《横向领导力》、《物种起源》等作品。

有的时候确实无法理解数学家们的生活状态，总觉得他们的世界里所有的一切都是由数字组成，就好像我们不再是一堆化学元素或者生物细胞，而是密密麻麻的数字，这种数字甚至可以跨物种的比较，除了数字就是各种曲线图和计算公式，好像这些数字一旦进入到公式中，就可以以一定的几率开始变化，而每一点细微的变化对公式的推导成功，都能让他们欣喜若狂。

从偶然一天的下午茶，到自然灾害的出现，甚至已成文明的现有技术，都可以成为统计学重新推翻或者深挖掘的对象，我甚至在想那些已经成为其他科学领域的经典实验，统计学是否曾经或者现在都在质疑并重新测量确认着，即便是同属于数学领域里的概率，统计学是否也还在不断地计算和实验着？这个是在说不好，统计学质疑着一切也在证明这一切，这些原本不确定的因素因为统计学而变得确定，同样那些被坚定确认的情况也因为统计学而变得不确定，这就是统计学的严谨和权威。

说实话我不算是严格的数学爱好者，但是相比之下，我还是比较喜欢统计学和概率论，它们在生活和工作中太具有可实践性，如果想对世界进一步的从数学角度认知，这本《女士品茶》不妨一读。

### 10. 概率与统计，走过百年

在 australia 读 master 期间读了《女士品茶》这本科普读物，里面对现代统计学的一切有关理论介绍的东西全然没看懂，尽管我仍要把部分原因再次归结为翻译的质量，但我清楚地知道这是我此生不适合进行尖端学术研究的又一佐证 —— 无法理解微积分、线性代数以外的数学物理工具。总的来说这是一本不错的简短的科技发展史，消除了我自大二学习概率论与数理统计以后对这门学科似清晰实模糊的印象以及种种困惑。

自 18 世纪起，在应对大工业生产中大批量产品、样品的化验，质量控制的实际需要中诞生了早期的抽样、样本分析、整体评估的实践活动。之后陆续诞生了日后统计学理论中可谓之精华的各种分布模型：正态分布，student 分布等等（实在记不住太多），外加各种假设检验。。。到如今大多数实验室工作者所做的就是使用这些数学模型对自己的数据结果加以处理、分析、结论，至于使用者是否理解统计学繁琐晦涩的外表下所要传达的东西就是另外一回事了，平心而论这真的是一个只有少数思想超越时代的人才能染指的领域。

举个例子，正态分布公式高中老师讲过大学老师教过，可从来没人告诉过你这个怪异 —— 相比于其它所熟悉的一切数学领域的公式如初等数学、解析几何，etc—— 难于记忆，外加 3 个希腊字母 miu，sigma，pi 汇成的公式的来历，教科书上都是直接给出的。实际上这个分布是经由数学推导得来的，但推导的历程就犹如现代概率统计理论一样高深难于捉摸 —— 对于我这样的凡夫俗子。此世间的很多事情的结果都可用这一分布模型描述。借用一本书上的话：「神说，要有正态分布，就有了正态分布。神看正态分布是好的，就让随机误差就服从了正态分布。」

抛一枚硬币出现正反面的概率是 1/2，掷骰子一面为上的概率是 1/6，这些凭直观得来的理所当然的结论属于古典概率的范畴。当研究对象的容量无比庞大的时候 —— 就如工业化大生产中的情形 —— 我们的感觉就不再是得心应手而是迷茫了。牛顿的《自然哲学的数学原理》曾给予蒙昧时期的人们极大的鼓舞，在牛顿的数学和物理世界里，规定了初始状态和外界施加的作用，此后一切时间里的运动状态就都是我们所能掌控的了，钥匙就是牛顿运动定律。今天我们将人们在经典物理学建立起来的科学体系中所拥有的思维方式和价值观念称之为机械式的世界观，就像我们今天可以通过计算预测哈雷彗星回归周期是 76 年。

然而现代统计理论的出现挑战了人们的传统认识，举例来说，对一个尺寸进行测量 —— 极为精确的那种，目的是想要得到世间独一无二绝对正确的真理级结果 —— 得到的是一系列而非单一的测量数据，同时这些数据服从正态分布。。。简言之现代概率理论传达的世界观是我们所能观察到的其实是客观存在出现的概率。偏巧 20 世纪初的量子力学领域的一些发现推波助澜了人们对于牛顿经典力学体系的怀疑。。。有意思的是 einstein 这个时候站出来说了句彪炳史册的话：上帝不会掷骰子！大神还是认为在合理的理论体系下，这个世界可以是可知的。我估计也就因为他是 einstein，换做别人早被唾沫淹死了。

对于我这种没有慧根的人，probability and statistics 好像是一种哲学而非科学，我全然不懂但也能些微感受到其中的美。

## 作者后记

在写这本书之前，我已经将那些对统计发展有贡献的女士和先生们分成了两组，一组是我在书中提及到的，一组是我没有提及的。第一组人可能对我在书中只提及他们一小部分的工作而感到不满意，第二组人可能会因为我根本就没有提及他们的工作而表示抗议。为了表达我对他们的敬意，我有必须解释一下我取舍的原则。

对第一组取舍的原因在于：现代科学的范畴太大了，任何人都不可能知道它所有的支派。因此，在有些研究领域，统计方法的应用可能非常广泛，但是我却不知道。

在 20 世纪 70 年代，我曾查找过关于计算机在医学诊断中应用的资料。在查找过程中，我发现有三个互相独立的支派，在任何一个支派内人们互相引述论文，并且都发表在同一份期刊内，但是，不同派别的科学家却很少了解其他派别的人在做什么。这还只是在医学界这样一个小小的相关领域中的情形，在更广阔的科学界，可能有很多人群在应用统计方法，并且可能有一些成果在我从来没听过的期刊中发表。

我对统计革命结果的认识，来自于对一些数理统计主流期刊的阅读。不阅读这些主流期刊或者不在这些期刊中发表文章的统计学家，就像发展模糊集合论「fuzzy set theory」的工程师，他们可能做了很多值得记载的工作，但是因为他们不在我知道的科学或数学期刊上发表文章，那么他们的工作就不会被包括进来。

有些东西我是知道的，但还是被省略了。我不想写一本关于统计方法论发展的全面的历史书，因为这本书的读者定位是一些不懂或者略懂数学的人，所以我不得不选择一些能用文字而不是用数学符号来解释的例子，这就更进一步限定了我的选择。

另外，我还想让这本书读起来比较流畅，如果我用了数学符号，我可能就可以说明了众多主题间的关系了。但是没有数学符号，这本书很容易退化为一种观念的介绍，这些观念间没有什么关系。

这本书需要一条主线将各个主题组织起来，我所选择的贯穿 20 世纪统计学复杂理论的主线是与别人不一样的，一旦这条主线确定了，我就不得不忽视了统计学的很多方面，而实际上，我对它们同样非常感兴趣。

在我的书中，很多人我都没有提及到，这并不代表他们的工作不重要，更不代表我认为他们的工作不重要。仅仅是因为本书的结构限制，我没有办法将他们的研究写进来，只好放弃。

我希望读者读了本书后能有所启发，去进一步了解统计革命的内涵。我希望有人在读后甚至能钻研这个题目，加入统计研究的行列。

在参考书目中，我选择了一些供没有数学学习背景的人阅读的图书和文章。在这些书中，其他许多统计学家尝试向我们解释了统计所学带给他们的乐趣，那些想进一步了解统计革命的读者将会喜欢其中的一些书。

## 0101. 女士品茶

那是 20 世纪 20 年代后期，在英国剑桥一个夏日的午后，一群大学的绅士和他们的夫人们，还有来访者，正围坐在户外的桌旁，享用着下午茶。在品茶过程中，一位女士坚称：把茶加进奶里，或把奶加进茶里，不同的做法，会使茶的味道品起来不同。在场的一帮科学精英们，对这位女士的「胡言乱语」嗤之以鼻。这怎么可能呢？他们不能想象，仅仅因为加茶加奶的先后顺序不同，茶就会发生不同的化学反应。然而，在座的一个身材矮小、戴着厚眼镜、下巴上蓄着的短尖髯开始变灰的先生，却不这么看，他对这个问题很感兴趣。

他兴奋地说道：「让我们来检验这个命题吧！」并开始策划一个实验。在实验中，坚持茶有不同味道的那位女士被奉上一连串的已经调制好的茶，其中，有的是先加茶后加奶制成的，有的则是先加奶后加茶制成的。

写到这里，我可以想象，部分读者会对这种实验不以为意，认为它不过是一帮精英们于夏日午后的一个小消遣。他们会说：「这位夫人能不能区分两种不同的注茶方式，又有什么大不了的呢？这个问题并没有什么科学价值，这些大人物更应该把他们的天才用在对人类有所裨益的事情上去。」

不幸的是，不管外行对科学及其重要性怎么想象，从我个人的经验来看，大多数科学家之所以从事科研活动，只是因为他们对结果感兴趣，或者能够在工作中得到理性的刺激。好的科学家很少会想到工作的最终重要性，剑桥那个晴朗夏日的午后也是这种情景。那位夫人也许能、也许不能正确地品出不同的茶来，但这无关紧要，因为，实验的真正乐趣，在于找到一种判断该女士是对还是错的方案来。于是，在蓄着胡须先生的指导下，大家开始讨论应该如何进行实验判断。

接下来，在场的许多人都热心地加入到实验中来。几分钟内，他们在那位女士看不见的地方调制出不同类型的茶来。最后，在决战来临的气氛中，蓄短胡须的先生为那位先生为那位女士奉上第一杯茶，女士品了一小会儿，然后断言这一杯是先倒的茶后加的奶。 这位先生不加评论地记下了女士的说法，然后，又奉上了第二杯……

### 1.1 科学的合作性质

这个故事是我在 20 世纪 60 年代后期，从一个当时在场的先生那里听到的。这位先生就是休·史密斯（Hugh Smith），但他都是以 H·费尔菲尔德·史密斯（H. Fairfield Smith）的名义发表科研论文。我认识他的时候，他在位于斯托尔斯（Storrs）的康涅狄格大学（the University of Connecticut）任统计学教授，而我则是两年以前在这个大学拿到了统计学博士学位。在宾州大学（the University of Pennsylvania）教了一阵子书后，我加入到了辉瑞公司（Pfizer Inc.）的临床研究部门。这是一家大型制药公司，它的研究园区坐落在格罗顿（Groton）离斯托尔斯大约一个小时的车程。当时，我是那里唯一的统计学家。在辉瑞期间，我要处理许多疑难的数学问题，还要负责给他们讲解这些问题，并告诉他们，对这些问题，我个人的结论是什么。

在辉瑞工作期间，我发现，科研工作几乎不能独立完成，通常需要不同智慧的结合。因为，这些研究太容易犯错误了。当我提出一个数学公式作为解决问题的工具时，这个模型有时可能并不适合；或者我就所处理情况而引入的假设并不真实；或者我发现的「解」是公式中的失误部分推导出来的；甚至我可能在演算中出了错。

无论何时，我去斯托尔斯的大学拜访，与史密斯教授探讨问题，或者，与辉瑞的化学专家、药理专家坐在一起讨论，我提出的问题都会受到欢迎，他们对这种讨论充满兴趣和热情。对大多数科学家来说，工作中令他们最感兴趣的，就是解决问题时那种兴奋感。因此，在检验并试图理解问题时，他们期盼着与他人交流。

### 1.2 实验的设计

剑桥那个夏日午后的情形正是如此，那个留着短胡须的先生就是罗纳德·艾尔默·费歇尔（Ronald Aylmer Fisher），当时他只有三四十岁。后来，他被授予爵士头衔。1935 年，他写了一本叫《实验设计》（The Design of Experiments）的书，书的第 2 章就描述了他的「女士品茶」实验。在书中，他把女士的断言视为假设问题，他考虑了各种可能的实验方法，以确定那位女士是否能做出区分。设计实验时的问题是，如果只给那位女士一杯茶，那么即使她没有区分能力，她也有 50% 的机会猜对。如果给两杯茶，她仍可能猜对。事实上，如果她知道两杯茶分别以不同的方式调制，她可能一下子全部猜对（或全部猜错）。

2『已下载原文书籍「2020072The-Design-of-Experiments」，但下的这本显示是第 8 版，应该是后来根据 Fisher 的原书改版的。（2020-11-03）』

同样，即便这位女士能做出区分，她仍然有猜错的可能。或者是其中的一杯与奶没有充分地混合，或者是泡制时茶水不够热。即便这位女士能做出区分，也很有可能是奉上了 10 杯茶，她却只是猜对了其中的 9 杯。

在这本书中，费歇尔讨论了这个实验的各种可能结果，他叙述了如何确定这样一些问题：应该为那位女士奉上多少杯茶？这些茶应该按什么样的顺序奉上？对所奉各杯茶的顺序应该告诉那位女士多少信息？依据那位女士判断的对错与否，费歇尔搞出了各种不同结果的概率。但在讨论中，他并没有指明这种实验是否真的发生过，也没有叙述这次实验的结果。

费歇尔书中有关实验设计的著述是科学革命的要素之一，这场革命在 20 世纪前半叶席卷了科学的所有领域。早在费歇尔出道以前，科学实验已经进行了几百年。在 16 世纪后期，英国的威廉·哈维（William Harvey）用动物做实验，他将不同动物静脉和动脉里的血液堵住，试图追踪血液从心脏到肺，回流到心脏，流向全身，再回到心脏的循环路线。

费歇尔没有发现实验是增长知识的方法。费歇尔之前，实验对每个科学家而言都是有其特性的。优秀的科学家可以做出产生新知识的实验，而二流的科学家常常从事的是积累数据的实验，但对知识增长没有什么用处。为说明这点，可以举发生在 19 世纪后期的一个例子。那时的科学家就测量光速做了许多无关要旨的努力，而直接到美国物理学家艾伯特·米切尔森（Albert Michelson）用光线和镜子建造了一个特别精巧的系列实验，才第一次得到好的估计。

在 19 世纪，科学家很少发表实验结果。他们所做的是论述自己的结论，并发表能证明结论真实性的数据。格雷戈尔·门德尔（Gregor Mendel）没有展示出他全部豌豆培育实验的结果，他叙述了他的系列实验，然后写道：「两组系列实验的前 10 个数据可以用来说明……」在 20 世纪 40 年代，费歇尔检验了门德尔用来说明结论的数据，发现这些数据过分完美，以至于失真，它们并没有表现出应该具有的随机程度。

尽管科学从审慎思考、观察和实验发展而来，但从来不清楚应该怎样从事实验，实验的全部结果通常也没有展现给读者。

19 世纪末和 20 世纪初的农业研究中，上述情况尤为明显。20 世纪早期费歇尔在农业实验站工作，在费歇尔去那儿工作之前，这个实验站已经进行了约 90 年的肥料构成（称之为人工肥料）实验。在一个典型的实验中，工人将磷肥和氮肥的混合物撒在整块田中，然后种植作物，测度收成和整个夏季的雨量。这里有精巧的公式用来「调整」某年或某块地的产量，以便与另一块地、或同一块地的另一年产量相比，这被称为「肥力指数」。每一个农业实验站都有自己的肥力指数，而且都认为自己的指数是最精确的。

90 年的实验结果不过是一堆未经发表、了无用处的混乱数据。看来某些品种的小麦对某种肥料反应优于其它品种，但只是在降雨过量的年份如此。其它实验似乎显示：第一年用钾硫化物，第二年用碳酸硫化物，会使某些品种的马铃薯增产，而对其它品种并非如此。因此，就这些人工肥料，充其量可以说，其中有些在有的时候，可能或大概有效。

作为一个卓越的数学家，费歇尔审视了农业科学家用来修正实验结果的肥力指数，这些指数是用来解释不同年份气象变化所造成的差异的，他还检查了其它农业实验站所用的同类指数。当简化为基本的代数式时，这些指数不过是同一公式的不同表现形式，换句话说，看似激烈争斗的两个指数，其实起着同样的修正作用。1921 年，费歇尔在农业科学领域的领军期刊《应用生物学年报》（the Annals of Applied Biology） 上发表了一篇论文，文中他指出了采用哪种指数并没有什么差异，并且，所有修正都不足以调整不同地块上的肥力差异。这篇非凡的论文终止了一场持续 20 多年的科学论战。

费歇尔接着检查了过去 90 年来的雨量和收成数据，指出年度间不同气候的影响远远大于不同肥力的影响。用费歇尔后来在他的实验设计理论里发明的一个词来说，「混合」（confounded）的，这意味着用已有的实验数据是不能将二者分开的。90 年的实验和 20 年的科学论战几乎是无谓的浪费。

这使得费歇尔专注于实验和实验设计的思考。他的结论是：科学家需要从潜在实验结果的数据模型开始工作，这是一系列数据公式，其中一些符号代表实验中将被搜集的数据，其它则代表实验的全部结果。科学家从实验数据开始，并计算与所考虑科学问题相应的结果。

让我们考虑一个关于一个老师和某个学生的简单例子。这个老师非常想找出一些关于这个孩子学习情况的测试数据，为了达到这个目的，老师对孩子进行了一组考试，每一个考试都在 0 到 100 之间评分，任何一个单一的考试都不可能对孩子知识的掌握提供可靠的评估；这个孩子可能是没有学习多少考试所涉及的内容，但是知道不少考试以外的事情；可能是这个孩子在参加考试那天头疼；还可能是参加考试那天早上孩子与父母发生了争执。由于种种原因，单一考试不能对知识量提供好的估计，所以老师进行了一组考试，然后计算出所有考试的平均分来评价孩子的知识量。这样的估计结果会更好，多少分是孩子知识量的实验结果，而每一个单独考试的分数则是数据。

那么老师应该如何组织考试？是搞那种只包括几天前所教授内容的系列考试，还是每次考试都从考试前所教授的全部内容中提取一部分？考试是一个星期搞一次，还是每天搞一次？或者在每个教学单元结束时搞？所有这些都是实验设计涉及到的问题。

如果农业科学家想知道某种人工肥料对小麦生长的效用，就要构建一个实验以取得效用估计时所需要的数据。费歇尔表明，实验设计的第一步是建立一组数学公式，用以描述待搜集数据与欲估计结果之间的关系，因此，任何有用的实验必须是能够提供估计结果的。实验必须是有效的，能够让科学家测定出气候的差异和不同肥料的使用对产量差别的影响。特别是，有必要包括同一实验中打算加以比较的实验处理（treatments），即那些后来被称为「控制组件」（controls）的东西。

在他那本关于实验设计的书中，费歇尔提供了几个实验设计的范例，并导出优秀设计的一般原则。然而，费氏方法中所涉及到的数学非常复杂，多数科学家设计不了自己的实验，除非他们遵循费歇尔书中提出的实验设计中的某个模式。

农业科学家认识到费歇尔工作的伟大价值，在大多数说英语的国家中，费氏方法很快便成为农业科研的主流学派。从费歇尔的原创性工作出发，用来论述不同实验设计的完整科学文献发展起来。这些设计被应用到农业以外的领域，包括医学、化学和工业质量管理。在许多案例中，所涉及的数学高深且复杂，但此时此刻，我们不妨停下来想想，科学家不可能不假思索地动手实验，这通常需要长时间的审慎思考，而且，其中通常会有大量的、高难的数学。

至于前面所说的女士品茶——那个在剑桥晴朗的夏日午后所做的实验中，那位女士怎样了呢？费歇尔没有描述这项实验的结果，但史密斯教授告诉我，那位女士竟然正确地分辨出了每一杯茶！