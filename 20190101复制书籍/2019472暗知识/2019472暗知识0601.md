# 0601. 暗知识神迹 —— 机器能否超越人类

导读

AI 的作用将不止于颠覆商业，还会有更深刻和长期的影响。本章负责开脑洞，理解了本章就能知道下一代该如何做好准备。这一章也可以直接跳进来读，但最好能先读前两章。

我们在上一章描述了 AI 在短期内会对商业和生活造成的影响，但我们很难想象更长期（30~50 年）的影响。虽然预测长远的未来很难，但是如果能深刻理解 AI 的本质，就能对未来的方向有感觉。2007 年苹果手机的发布开启了移动互联网的一波巨浪，当时对移动互联网有两种不同的观点。一种观点认为移动互联网和个人电脑互联网有完全不同的性质，会出现全新的杀手级应用。另一种观点（主要是个人电脑互联网的部分大佬）认为手机无非是个人电脑的延伸，比原来的网站、搜索和游戏等多了一块显示屏幕而已。笔者是中国最早从事移动互联网的专业人士，基于手机和个人电脑的本质区别在于手机的定位功能，笔者曾经预测未来杀手级应用一定和定位功能有关，而且不会是当时大家都能想到的找加油站、订餐馆这样的「浅层定位应用」，也一定会产生新的巨头。果不其然，出行类的应用成为移动互联网的杀手级应用，创造出了 Uber、滴滴出行这样的个人电脑互联网巨头之外的新的移动互联网巨头。

基于深度学习的 AI 本质

数据之间相关性的发现和记忆

读过第三章的读者能体会到神经网络最本质的特点是发现并记忆数据中的相关性。例如，看了很多汽车的图片后就会发现汽车都有四个轮子。人的大脑对图片这类直观的数据间的相关性也能发现一部分并记住，这就是默知识。但当数据量很大，又不直观时，例如股票市场的数据、复杂系统（例如人体、核电站）内部的数据，人就不行了。而神经网络却应付自如，一眼就能发现数据之间的关系并记住，这就是暗知识。下回再遇到类似的数据，马上就能做出判断。随着神经网络的规模增大（神经元数目和神经元之间的连接数目），机器能够处理人根本无法企及的大规模的复杂数据。

海量记忆基础上的细微差别的识别

机器学习需要大量的数据，主要是让机器「看到、记住」数据中呈现出的各种模式。有点像小孩玩万花筒，数据就是装入万花筒中的彩色玻璃碎片，不停地转动玻璃棱镜就是不同的算法（对应神经网络中不同的连接）。一组有限的数据中埋藏着无数排列组合出来的图样。因为机器的记忆比人的记忆准确，而且量大，机器可以每秒转几亿次万花筒，很快就能看完并且记住所有的图样。所以机器学习可以发现数据中隐藏的所有细微区别。

基于以上原理，机器学习适合做极其复杂的决策，例如制定像健康保险这样极其复杂的公共政策，策划诸如诺曼底登陆这样包含大量变量的军事行动。

这两个 AI 的本质其实也正是暗知识的两个特点。基于以上两个特点，我们看看未来会出现哪些远超人类的颠覆性的超级应用。

科研加速

一个科学研究的过程可以分为以下几个步骤。

（1）提出问题或选择要解决的问题。

（2）学习研究关于这个问题已经发表的研究文献。

（3）根据研究文献和研究者的经验提出假设。

（4）设计验证假设的实验。

（5）进行实验和整理实验数据。

（6）根据实验结果判断假设是否成立。

（7）如果假设不成立，返回第（2）步或第（3）步，提出新的假设。

在这个流程中最花时间的有三个环节：研究文献、做实验和整理数据。在这三个环节中，机器学习都可以部分甚至全部取代人。获取相关的文献，阅读、理解并总结已经成为科研的瓶颈之一。根据渥太华大学的研究，自从 1965 年以来共有 5 000 万篇科学文章发表，现在每年新发表的文章是 250 万篇。关于某个能够抑制癌细胞的蛋白质的论文就达到 70 000 篇。一个科学家即使一天读 10 篇文献，每个工作日都读，一年也只能读 2 500 篇，所以大部分的研究结果都会被束之高阁。使用 AI 可以通过自然语言理解找到相关的所有文献。例如一个叫作 Iris（艾瑞斯）的 AI 软件可以这样做科研：首先从一个关于这个研究题目的演讲开始。这个演讲通常是本领域的一位著名科学家做的几十分钟的概述性报告，例如 TED（美国著名讲坛）大会的演讲。Iris 先使用自然语言处理算法分析演讲的脚本，挖掘从开放渠道获取的学术文献，查找到与讲座内容相关的关键论文，然后将相关的研究论文分组并进行可视化，Iris 目前可以达到 70% 的准确率，下一步是用人工帮助标注文献使机器匹配精度增加。当机器能够理解文献的内容和结构时，至少可以帮助科学家总结出在一个科研领域中已经提出的问题，已经提出过的假设及其验证，已经做过的实验和结果。机器甚至能根据文章的逻辑自洽性对文章结果提出疑问。用机器阅读文献的一个重要作用是能够对前人的工作一览无余，不至于做许多重复性的工作。

今天的科研越来越依赖于实验，而实验的准备、操作和数据整理经常耗时耗力。机器学习可以大大加快实验进程。2001 年的诺贝尔物理奖颁发给了美国的埃里克·康奈尔（Eric Cornell）等三位实验物理学家。他们的成果是用激光器和磁场创造出了自然界不存在的物质的第四种状态：玻色 - 爱因斯坦凝聚态。物质在自然界的三种状态根据温度不同分别是固态、液态和气态。当温度降低至非常接近绝对零度时（实验上永远无法达到绝对零度），物质就会进入凝聚态（一种气态的、超流性的物质状态）。凝聚态物质有很多特性，例如对地球磁极和引力场极为敏感，光线在该物质中会延迟，等等。基于印度科学家玻色的计算，爱因斯坦于 1924 年预测了这种物质的存在以后，科学家一直想在实验室验证出来。1995 年，这三位科学家经过多年的实验，用一套非常复杂的实验装置终于制造出了物质的凝聚态。图 6.1 是这个实验的示意图，透镜内有一小块物质，透镜外有许多激光束。激光打在物质上可以约束物质内分子的运动，从而降低物质的温度。图 6.2 是实验设备的核心部分，图 6.3 是实验设备的全貌。可以看出，这套实验装置非常复杂，可以设置的参数非常多，如果每一种参数的排列组合都去试，到宇宙终结可能都试不出来。而人有许多直觉可以大大加快实验。获奖的三位物理学家摸索了很多年才终于造出了凝聚态。2016 年 5 月 17 日，来自澳大利亚新南威尔士大学和澳大利亚国立大学的研究团队使用机器学习从头开始操作这样的实验（反复设置调整实验设备的各种参数直到产生凝聚态物质），机器学习竟然不到一个小时就成功制造出了这种凝聚态物质。该团队希望通过进一步借助 AI 以更快的速度构建更大的这类物质。

图 6.1 凝聚态设备示意图：不同方向的激光束约束分子运动造成凝聚态物质（腔体内）

图片来源：https://plato.stanford.edu/entries/physics-experiment。

图 6.2 凝聚态实验设备的核心部分

图片来源：https://plato.stanford.edu/entries/physics-experiment。

图 6.3 凝聚态实验设备全貌

图片来源：https://plato.stanford.edu/entries/physics-experiment。

科学实验的第三个环节是收集整理数据，这更是 AI 的优势。其实在科学界目前还有一个瓶颈就是研究论文的审核，要发表的论文太多，能有水平和时间对其进行审核的人太少。机器学习可以大大加快这个过程，例如可以检查该论文是否抄袭或者和已经发表的结果有冲突等。

科学研究中最难被机器取代的是提出假设，但是 IBM 的一个团队宣称他们的系统可以做到。也就是说，他们的 AI 可以通过挖掘学术文献自动产生科学假设。而且，宣称他们的算法可以用来做出新的科学发现。他们的目标是将文本挖掘与可视化和分析结合起来，以便识别事实，并提出「新的、有趣的、可以测试的、可能是真实的」假设。

人类过去 500 年来的进步主要依靠科学技术的进步，而且这种进步还在加速。随着 AI 的发展，科学发现可能会加速，这意味着技术进步会进一步加快，反过来又会加快科学的进步。例如量子计算依赖于材料科学的进展，一旦量子计算取得突破，计算能力就可能比现在提高几个数量级，AI 能力的提高又会进一步加快科学进展和加速实验速度，如此循环下去。

另外一个加速是用 AI 改进 AI。谷歌和 Facebook 都开始研究自动机器学习，通过强化学习的模型，让机器不仅不断地调整参数，而且能够选择不同的神经网络模型。在很多情况下自我学习的性能都可以和人设计出来的性能相比，机器有时还会选择人类想不到的模型，甚至有人开始探索如何在机器学习里模仿人类的想象和创新。2017 年底，谷歌推出由 AI 自主「孕育」出的「子 AI」，该「子 AI」被取名为「NASNet」，研究人员在 ImageNet 图像分类和 COCO 目标识别两个数据集上，对 NASNet 进行了测试，在验证集上的预测准确率达到了 82.7%，比之前公布的人工智能产品的结果好 1.2%，效率也提高了 4%。目前这些研究还处在早期阶段。一旦这类循环加速技术成熟，就会使技术迅速达到一个新的高度。

科学的本质是受控实验。人类通过控制一组变量（例如物理实验中的物体位置和受力等，化学实验的温度和压力等）来测量另外一些变量（例如物理实验中物体的速度，化学实验中的气体体积）的变化。科学定律就是可控变量和测量变量之间的关系。当人类完全掌握了某一类关系后，就可以通过制造仪器把原来的测量变量变为可控变量，用增大的可控变量集再来继续发现它们和新的测量变量的关系，这就是科学进步的本质，所以仪器就是某一类科学定律的物化。科学的进展完全依赖于能否完全掌握某个科学定律并且把该定律变成仪器。所以科学的进展可以分为三个步骤。

（1）提出假设：某一组可控变量和另一组可测量变量可能的关系。

（2）设计实验：验证可控变量和可测变量之间的关系。

（3）如果实验不能验证，就重新回到步骤（1）。如果能够验证，就把验证过的关系制造成仪器，使原来的可测变量变为可控变量。然后回到步骤（1）。

机器学习在每个步骤中都能加快速度。在步骤（1），机器学习可以通过阅读历史文献提出大量可能的组合。虽然在大量的备选假设中最终还要科学家定夺为哪个做实验，但机器可以帮助科学家想得更全面。在步骤（2）最花时间的是改变可控变量的值来测量可测变量，这正是机器的拿手好戏。在收集、整理、分析数据方面机器比人要快，也更准确。在步骤（3）制造仪器方面又分为设计、实验和制造三个步骤，机器学习在实验和制造上都能加快速度。可以想象在不久的将来会出现「机器人研究生」，人类科学家给机器一个大致的研究方向，当机器遇到困难时请教一下导师，剩下的大部分研究工作就是机器自己做了。它们不知疲倦，7 ×24 小时做研究，阅读速度是人类研究生的一亿倍，测量分析数据速度是人类研究生的一万倍。只要有电力和算力，世界上可以有几十亿个这样的「研究生」在研究人类关心的各种课题。

唐诗高手

机器学习不仅在科学技术的进步上大显神威，而且也开始进入人文领域。下面的四首律诗中有两首是人写的，两首是机器写的。

云峰

白云生处起高峰，

鬼斧神工造化成。

古往今来谁可上，

九重宫阙握权衡。

画松

孤耐凌节护，

根枝木落无。

寒花影里月，

独照一灯枯。

悲秋

幽径重寻黯碧苔，

倚扉犹似待君来。

此生永失天台路，

老凤秋梧各自哀。

春雪

飞花轻洒雪欺红，

雨后春风细柳工。

一夜东君无限恨，

不知何处觅青松。

在告诉读者答案之前，先看看机器写诗的原理。把机器写诗的原理讲得最清楚的莫过于《红楼梦》里的林黛玉。在《红楼梦》第四十八回中，被薛宝钗带进大观园的姑娘香菱让黛玉教她写诗：

黛玉道：「什么难事，也值得去学！不过是起承转合，当中承转是两副对子，平声对仄声，虚的对实的，实的对虚的，若是果有了奇句，连平仄虚实不对都使得的。」香菱笑道：「怪道我常弄一本旧诗偷空儿看一两首，又有对的极工的，又有不对的，又听见说‘一三五不论，二四六分明'。看古人的诗上亦有顺的，亦有二四六上错了的，所以天天疑惑。如今听你一说，原来这些格调规矩竟是末事，只要词句新奇为上。」黛玉道：「正是这个道理，词句究竟还是末事，第一立意要紧。若意趣真了，连词句不用修饰，自是好的，这叫作‘不以词害意'。」香菱笑道：「我只爱陆放翁的诗‘重帘不卷留香久，古砚微凹聚墨多'，说的真有趣！」黛玉道：「断不可学这样的诗。你们因不知诗，所以见了这浅近的就爱，一入了这个格局，再学不出来的。你只听我说，你若真心要学，我这里有《王摩诘全集》你且把他的五言律读一百首，细心揣摩透熟了，然后再读一二百首老杜的七言律，次再李青莲的七言绝句读一二百首。肚子里先有了这三个人作了底子，然后再把陶渊明、应玚，谢、阮、庾、鲍等人的一看。你又是一个极聪敏伶俐的人，不用一年的工夫，不愁不是诗翁了！」

黛玉说的第一件事是格律，押韵合辙，平仄对仗。这是律诗的基本规则，属于作诗的明知识。而词语之间的相关性，也即一个词出现在另一个词后面的概率，对诗人来说则是默知识。学习这些默知识是机器最擅长的，机器通过大量的阅读，对每个词后面出现什么词都有了「感觉」。黛玉说的第二件事是训练集要大，要多样化。陆游一生写了万余首诗，但一个诗人毕竟有局限性，例如陆游的诗题材单调，意境空疏。如果香菱只学陆游的诗就会像黛玉说的那样「一入了这个格局，再学不出来的」，这就是机器学习里面当训练数据集太小时出现的「过度拟合」问题。所以黛玉让香菱学王维、杜甫、李白等不同风格的诗人，王维的空灵幽远，杜甫的悲天悯人，李白的潇洒豪放，都会避免「过度拟合」，多种风格的混合才能出新意。

机器作诗的原理和人学作诗类似，本质上也是模式识别，通过大量学习识别然后记忆平仄、对仗、押韵、词句的常见组合，即一个词出现在另一个词后面的概率。诗歌是文字的一部分，是一个前后有相关性的序列数据流，第三章里提到过，RNN 最适合序列数据处理。产生诗歌的思路有两种。第一种思路是将诗歌的整体内容作为训练语料送给 RNN 语言模型进行训练。训练完成后，先给定一些初始内容，然后就可以按照语言模型输出的概率分布进行采样得到下一个词，不断地重复这个过程就产生完整的诗歌。具体步骤如下：首先由用户给定的关键词生成第一句，然后由第一句话生成第二句话，由第一句话和第二句话生成第三句话，重复这个过程，直到诗歌全部生成。该模型由三部分组成。

（1）卷积语句模型（Convolutional Sentence Model，CSM）：这个卷积模型用于获取一句话的向量表示。

（2）复发上下文模型（Recurrent Context Model，RCM）：句子级别的 RNN，根据历史生成句子的向量，输出下一个要生成句子的上下文向量。

（3）复发生成模型（Recurrent Generation Model，RGM）：字符级别的 RNN，根据 RCM 输出的上下文向量和该句之前已经生成的字符，输出下一个字符的概率分布。解码的时候根据 RGM 模型输出的概率和语言模型概率加权以后，生成下一句诗歌，由人工规则保证押韵。

第二种思路是把写诗看成一个翻译过程。将上一句看成源语言，把下一句看成目标语言，用机器翻译模型进行翻译，并加上平仄押韵等约束，得到下一句。通过不断地重复这个过程，得到一首完整的诗歌。

现在到了揭开谜底的时候：第二首和第四首诗是机器写的，仔细看还是能看出来。一首好诗首先是要语句自然流畅，意境浑然天成。第二首的第一句「孤耐凌节护」根本不知所云。除了句子不通顺，两首机器写的诗还很难让读者有画面感。一首好诗重要的是意境，正如黛玉所说：「词句究竟还是末事，第一立意要紧。若意趣真了，连词句不用修饰，自是好的，这叫作‘不以词害意'。」目前机器写诗像一个缺乏天资的但极为刻苦的诗歌爱好者，怎么做都无法有「意境」。能够打动人的好诗需要「触景生情」，并且能引起读者的共鸣。这更是目前机器学习还无法企及的境界。最绝妙的诗歌除了以上几点，还要能出奇出新，打破常规，使用从来未使用过的词句组合但又合情合理。正如黛玉在进一步提点香菱时所说：

「可领略了些滋味没有？」香菱笑道：「领略了些滋味，不知可是不是，说与你听听。」黛玉笑道：「正要讲究讨论，方能长进。你且说来我听。」香菱笑道：「据我看来，诗的好处，有口里说不出来的意思，想去却是逼真的。有似乎无理的，想去竟是有理有情的。」黛玉笑道：「这话有了些意思，但不知你从何处见得？」香菱笑道：「我看他《塞上》一首，那一联云：‘大漠孤烟直，长河落日圆。'想来烟如何直？日自然是圆的：这‘直'字似无理，‘圆'字似太俗。合上书一想，倒像是见了这景的。若说再找两个字换这两个，竟再找不出两个字来。还有‘渡头余落日，墟里上孤烟'：这‘余'字和‘上'字，难为他怎么想来！我们那年上京来，那日下晚便湾住船，岸上又没有人，只有几棵树，远远的几家人家做晚饭，那个烟竟是碧青，连云直上。谁知我昨日晚上读了这两句，倒像我又到了那个地方去了。」

上面香菱喜欢的这些诗句都超越了技巧层面，进入灵感和画面的幽微层面。这些都不是今天以学习数据之间相关性为特征的机器学习所能企及的。所以真正的诗人完全不必担心被 AI 取代，但那些无病呻吟，鹦鹉学舌或天资平平的诗歌爱好者只能和机器诗人去 PK 了。

同样的道理，AI 还可以写小说。只要让机器大量阅读一位作者的著作，机器就能学会这个作者的文字风格。和作诗、画画一样，如果让机器阅读了许多作家的书，机器的写作风格就是「混搭」的。和作诗一样，机器写的小说可能情节完整，文字通畅，但永远不会有伟大作家笔下流淌的情感和闪烁的灵魂。

有读者一定会问，这些「灵感」和「意境」是否也是一种默知识，甚至暗知识？当机器更复杂时是否终将能模仿？这个问题并不容易回答。但暂时的回答是「不能」，原因是今天的机器没有自我意识，所以没有情感。我们在本书的最后会讨论这个问题。

真假凡·高

同样的原理，机器在看过大量的绘画作品后也能够模仿画家的风格。图 6.4 是一张典型的北欧城市图片。

图 6.4 一张典型的北欧城市图片

图片来源：https://www.businessinsider.com.au/the-science-how-vincent-van-gogh-saw-theworld-2015-9。

机器可以把这张图片改造成凡·高的风格。图 6.5 左边是凡·高的名画《星空》，右边就是北欧城市图片的「星空化」。

图 6.5 用凡·高名画《星空》风格画的北欧城市

图片来源：Leon Gatsy of Bethge Lab in Germany https://www.businessinsider.com.au/thescience-how-vincent-van-gogh-saw-the-world-2015-9。

机器当然也可以把这张图片「马蒂斯化」，图 6.6 中左边是马蒂斯的名画《戴帽子的女士》，右边还是那张北欧城市图。

图 6.6 用马蒂斯风格画的北欧城市

图片来源：Leon Gatsy of Bethge Lab in Germany https://www.businessinsider.com.au/thescience-how-vincent-van-gogh-saw-the-world-2015-9。

从这两张改造的画来看，机器的模仿可以说是惟妙惟肖，其中色彩、笔触、线条的模仿是人类无法企及的。这种模仿是典型的默知识，从这个例子可以看出机器对默知识的掌握比人类要精细得多。

AI 不仅会模仿，而且会创造自己的风格。图 6.7 是来自罗格斯大学计算机系艺术与人工智能实验室、Facebook 人工智能研究院（FAIR）、查尔斯顿学院艺术史系三方联合小组用机器生成的绘画。该研究小组在论文中称，该研究中提出的人工智能系统是一个创意性的对抗网络（Creative Adversary Network，CAN），它是在之前介绍过的生成式对抗性网络系统的一种扩展。

图 6.7 创意对抗网络生成的图画

图片来源：罗格斯大学计算机系艺术与人工智能实验室。

生成对抗网络能够迭代进化、模仿指定数据特征，已经是公认的处理图像生成问题的好方法。自从提出以来相关的研究成果不少，在图像增强、超分辨率、风格转换任务中的效果可谓是惊人的。根据生成对抗网络的基本结构，鉴别器要判断生成器生成的图像是否和其他已经提供给鉴别器的图像是同一个类别（特征相符），这就决定了最好的情况下输出的图像也只能是对现有作品的模仿。如果有创新，就会被鉴别器识别出来，就达不到目标了。因此用生成对抗网络生成的艺术作品也就注定会缺乏实质性的创新，艺术价值有限。图 6.8 是用生成对抗网络模型实现的图像分辨率增强和风格转换。

图 6.8 用生成对抗网络模型实现的图像分辨率增强和风格转换

图片来源：罗格斯大学计算机系艺术与人工智能实验室。

为了使艺术品更具有创造性，该研究团队在生成对抗网络的基础上提出了创意对抗性网络，研究团队通过 15—20 世纪 1 119 位艺术家的 81 449 幅涵盖了多种风格的绘画作品训练神经网络。然后邀请人类参与者评估人工智能的艺术作品与现实艺术家的两组作品。这两组作品是创造于 1945—2007 年的抽象表现派作品，以及 2017 年巴塞尔艺术博览会作品。图 6.9 上面的 12 张是由创意对抗网络生成的人类评价最高的画，下面 8 张是评价最低的画。图 6.10 就是历年巴塞尔艺术博览会的获奖作品。

可以看到，机器生成的艺术作品风格非常多样，从简单的抽象画到复杂的线条组合都有，内容层次也有区分。而研究人员也发现它们的系统可以欺骗人类观察员。将人类观察艺术家创作的作品和机器创作的作品时的反应进行对比，发现人类无法将机器生成的作品和当代艺术家以及一家顶级艺术博览会上的作品区分开来。

图 6.9 由创意对抗网络生成的图画

图片来源：罗格斯大学计算机系艺术与人工智能实验室。

图 6.10 历年巴塞尔博览会的获奖作品

图片来源：罗格斯大学计算机系艺术与人工智能实验室。

创意性对抗网络是如何工作的呢？与生成对抗网络系统一样，创意性对抗网络也使用两个子网络。鉴别器被赋予了一套有风格标签的海量艺术作品，例如文艺复兴时期、巴洛克风格、印象主义或表现主义，而生成器则无法获得任何艺术作品。当它生成一个作品时，它会从鉴别器接收两个信号：一个是将图像分类为「艺术或非艺术」，另一个是「能否分辨图像是哪种艺术风格」。

「艺术或非艺术」与「能否分辨艺术风格」是两种对立的信号，前一种信号会迫使生成器生成能够被看作是艺术的图像，但是假如它在现有的艺术风格范畴中就达到了这个目标，鉴别器就能够分辨出图像的艺术风格了，然后生成器就会受到惩罚。这样后一种信号就会让生成器生成难以分辨风格的作品。所以两种信号可以共同作用，让生成器能够尽可能探索整个创意空间中艺术作品的范围边界，同时最大化生成的作品尽可能游离于现有的标准艺术风格之外。

这种「创作」在本质上是非常隐蔽的一种「混搭」，和作诗一样，普通人很难分辨真伪。判断诗还可以用「意境」「画面感」，而判断画，特别是抽象画几乎没有人类可以依赖的直觉。所以和作诗机器人不同，这里的作画机器人掌握的不只是默知识，而且进入了暗知识的领地。所以由对抗生成网络这种机器「混搭」并迭代出来的画的确可以乱「真」。这样的机器可以在短期内大量探索不同的风格，让艺术家选择或给艺术家以灵感。

基于类似的原理，AI 作曲也到了几乎可以乱真的地步。AI 作曲领域的领先公司 Aiva Technologies 创造了一个 AI 作曲家 Aiva（Artificial Intelligence Virtual Artist，人工智能虚拟艺术家），并教它如何创作古典音乐。而古典音乐一直以来被视为一种高级的情感艺术，一种独特的人类品质。Aiva Technologies 已经发布了第一张专辑，名为 Genesis，专辑包含不少单曲。并且 Aiva 的音乐作品能够用在电影、广告，甚至是游戏的配乐里。2017 年初，Aiva 通过法国和卢森堡作者权利协会（SACEM）合法注册，成为人工智能领域第一个正式获得世界地位的作曲家，其所有的作品都以自己的署名拥有版权。

Aiva 背后使用了强化学习技术的深度学习算法。强化学习告诉软件系统接下来要采取什么动作以通过最大化其「累积奖励」来达到某种目标。强化学习不需要标注过的输入和输出数据，AI 可以通过数据自行改进性能，这使 AI 更容易捕获在创意艺术如音乐中的多样性和变化。Aiva 就是通过品读巴赫、贝多芬、莫扎特等最著名的作曲家的古典乐章的大数据库来了解音乐作品的艺术性，自行谱写出了一些新的乐曲。

下一场空战

美国军方曾经公布了一段无人机打击塔利班武装分子的视频。在内华达州戈壁滩的空调机房中，几个年轻军人坐在视频终端前面，操纵着半个地球之外的阿富汗山区的无人机，当视频上准确锁定地面的车辆目标后，操作员就像打视频游戏一样按动手柄上的按钮，塔利班的军车顿时起火，没死的塔利班武装分子跳下卡车四处逃命。在夜视仪下，这些逃命的塔利班武装分子像在白昼一样看得清楚，操作员一一锁定他们，按下按钮，目标变成一团火海。这里的操作无非是辨别和锁定目标，具有人工智能的机器已经远远超出人类。内华达机房的操作员完全可以被取代，一切由机器完成。

美国空军开发的一款叫作 ALPHA 的自动飞行软件，不仅在每一场和真人的对决中都打败了空军飞行教练员，甚至该软件在驾驶一架比对手飞行速度慢，导弹射程短的飞机时也能打败对手。飞机的自动驾驶其实比汽车自动驾驶更适合机器操作。第一，飞行员的大量训练时间是学会读懂驾驶舱内琳琅满目的仪表和通过各种仪表数据判断该如何操作，这正是机器学习的拿手好戏。第二，空中飞行的周边环境远远比地面驾驶简单。同时，飞机上的各种传感器可以准确地感知飞机的空间坐标、高度、速度、平衡、风力、温度等，在这种情况下的驾驶非常适合机器。虽然空战中的周边环境瞬息万变，但仍然不会像地面一样拥挤。第三，也是最重要的一点，反应快。人类从大脑判断到肌肉动作至少要 0.1~0.3 秒的时间，而机器可以在百万分之一秒内完成。目前的飞机和武器系统的反应时间都以人类反应时间为下限，因为武器反应再快人跟不上也没用。但未来的飞机和武器设计就是要能够达到机械反应速度的极限，因为作为操控员的人工智能的反应时间主要是计算时间，将远短于武器的机械反应时间。几乎可以预计下一代军用飞机将以自动和自主性操控为主，一架人类驾驶的飞机一定打不过机器操纵的飞机。

目前无人机已经广泛使用在反恐和局部侦察与战斗中，但这只是序曲。以人工智能为核心能力的新型武器必将成为下一轮军备竞赛的主要目标。人工智能对未来军事和战争的影响将主要体现在以下方面。

新型自主性武器的开发

最早的自动化的武器就是导弹，但我们通常并不把导弹称为人工智能武器。这里的区别在于是自动化（automated）还是自主化（autonomous）。自动化是确定性地输入感知信号产生确定性的输出反应，而自主化是不确定性地输入感知信号产生一定概率分布的输出反应信号，甚至是一个从未见过的输入，通过推理、常识和经验产生一个最佳的输出。五角大楼国防科学委员会在 2016 年发布的一份报告是这样描述的：「要实现自主，一个系统必须具备基于其对世界、自身和形势的认识与理解，独立构建和选择不同的行动路线以便实现其目标的能力。」一个预先设定了打击目标的导弹是自动化武器，一个放飞到塔利班巢穴上空的会随机应变的捕食者无人机是自主性武器。未来自主性武器将率先在各类飞行器上全面普及，进而开始应用于水上和水下，包括水面舰船与潜艇以及各种机器鱼。最后是陆地，包括车辆、坦克和各种机器人，骡、狗、蛇等。目前，以色列已经部署了一种自主的防辐射无人机 Harop，可以飞行长达 6 个小时，只在敌人防空雷达亮起的时候进行攻击。俄罗斯武器生产公司 Kalashnikov 已经制造出了一把全自动 AK-47 步枪，通过使用 AI 确定目标瞄准射击，而该武器准备向俄罗斯军方供应。

电池容量是野战机器人的瓶颈

大型自主性武器的能源主要还是热能量密度高的石化燃料。但是内燃机的传动远不如电力灵活方便，一个四旋翼的无人机要用内燃机驱动传动部分会非常复杂。所以很多小的自主性武器例如无人机，机器人、骡、狗、蛇等最理想的动力来源是电池驱动，但是以目前的锂电池容量密度（约 300 瓦时／千克）和每年的改进程度（约 5%），在短期内很难有能够支持机器运行长达一天的电池，在野外充电和换电池也都是很大的问题。除了锂电池，目前另一个比较有希望的是氢燃料电池，与锂电池相比，其优势是充电快（几分钟而不是几个小时），单位体积或重量的能量密度也更高，所以未来军用电池很可能以氢燃料电池为主。

军用技术将落后于民用技术

人工智能和电子、信息产业类似，由于该技术在民生中的巨大商业前景，民用和商用对该技术的总投入要大于军事上的投入。民用和商用通过市场竞争机制也会吸引人工智能方面一流的人才（如创业的回报巨大）。由于开放性的学术交流和开源软件，民用技术将进展神速，巨大的商业前景也会造成空前激烈的市场竞争。这一切都会推动人工智能在民用和商用方面快速进展。而军用技术的发展则会落后于民用技术，许多军用技术研发最便宜的方法都是依托在民用技术之上。

大规模协同作战的演进

一场战役的规模常常受信息获取和传导的限制。在今天有了铺盖天地的无线通信后，人类接收信息的速度和反应时间又进一步成了瓶颈。当信息接收和反应都由机器接管后，一次战斗和战役的规模可以大大增加。如果都是机器之间互相协调，那么几百万台机器可以瞬间协同行动。最近美国国防部新型武器研发部公布了一段几百台微型无人机「群舞」的视频。当战斗机在沙漠中撒下几百台无人机后，这些无人机会自动组成飞行队形对一大片地形实施侦察，还可以随时改变队形。当个别无人机离队时，队形会自动调整，当离队的无人机回到群体后，队形又会自动改变。5G 通信网络的到来也将加速机器协同的进程。5G 的高带宽、低功耗、低时延的特点能够保证更多的机器以更少的耗电量，做出更为敏捷的协作。2018 年韩国平昌冬奥会，在 5G 试验网络的支持下，英特尔公司用 1 218 架无人机组成了奥运五环、运动员、和平鸽等图案进行灯光秀表演，刷新了「同时放飞数量最多的无人机」的吉尼斯世界纪录。（见图 6.11）

图 6.11 在韩国平昌冬奥会上 1 218 架无人机组成的奥运五环

图片来源：https://zhuanlan.zhihu.com/p/33766210。

军事组织的混成化、单官化和扁平化

军队之所以分为不同的兵种，主要原因是武器的使用和场景不同，一个人很难成为多面手，分工有利于提高掌握该武器的技能。但当武器自身越来越自动化和自主化时，分工的必要性就降低了，混合使用武器的好处越来越凸显。所以今后的战争可能不再是陆军和陆军打，空军和空军打，海军和海军打，而是所有的军种一起打。军种之间的界限会越来越模糊，甚至会取消现有的军种。

由于未来战争前端主要是自动化和自主化武器在拼搏，所以需要的血肉之躯会越来越少，一个人可以协调操控大批自主化武器。作为传统的作战第一线的「士兵」将消失，每个作战人员都是一个指挥员，所以未来的趋势不是「单兵化」而是「单官化」。

军队有最严格的层级结构。传统军事对个人依赖很小，制胜的保障是一个巨大团体的协调行动。层级结构能保障命令和信息在巨大人群中最快地传递和严格地执行。由于战斗人群规模的缩小和个体（单官）能力大大增加，所以未来军队将像今天的高科技公司一样越来越重视个体能力和能动性。这一切都会导致未来的军队组织越来越扁平化。

军事组织从以武器为中心转向以数据为中心

军事组织的结构取决于什么样的结构最能打胜仗。传统军事组织围绕武器组织、物流组织，新军事组织将围绕数据组织。未来战争的前端主要是钢铁机器，后端则是大量人和计算能力负责数据收集与处理。由于数据的复杂性，组织将划分为数据收集、存储、处理、决策。每一种武器及其行动轨迹和效果，对后台军事人员来说就是一组数据。飞机和舰船没有任何区别。未来的后勤能力主要是对机器的能源进行供给和补充。

战役的机器参谋部

指挥像诺曼底登陆这样的大型战役要处理的信息无穷多，同时要面对各方面的不确定性，即使一个天才军事指挥官也不可能处理如此巨量的信息，所以在传统战争中偶然性巨大。在未来战争中，一场战役已经在计算机中模拟了许多遍。变量越多，不确定性越强，机器学习算法就越得心应手。当然最后还是要指挥官做决定，但传统的参谋部的工作许多会被机器取代。正如机器能赢得了围棋世界冠军，谁的机器参谋部算法更聪明，谁赢得战争的机会就大。

未来最大的挑战不仅是谁能开发出最先进的人工智能武器，也是谁能通过实战数据的快速迭代训练出最佳模型，更是谁能最先在实战中演化出最佳的人 - 机混成。而且这种混成比例和结构会随着机器能力的提高一直改变。人工智能将再一次改变战争的形态，这个新形态不以消灭肉体为主，而是以机器之间的搏斗为主，这对人类来说越来越像一场狂热的足球赛。和体育比赛不同的是只要机器人败了，活人就乖乖投降。

AI 武器的伦理

目前国际法对人工智能武器没有任何具体规定，国际社会也没有明确支持限制或禁止此类武器系统的条约。学界对此也争议不断，许多重量级科学家反对人工智能武器化。2015 年，包括马斯克和霍金在内的 1 000 多名人工智能专家签署了一封公开信，呼吁禁止自主化武器，他们甚至称完全人工智能的发展可能招致人类历史的终结。2018 年谷歌公司仅仅因为向美国军方的一个项目 Maven 提供了 TensorFlow 的接口，就有近 4 000 名谷歌员工联合签名请愿公司不要和军方合作，因为这个项目的目标是为军方提供先进的计算机视觉，能够自动检测和识别无人摄像机捕获的 38 种物体，甚至有十几名员工因此要辞职。国际机器人武器控制委员会（ICRAC）也发布一封联名公开信，超过 300 位人工智能、伦理学和计算机科学的学者公开呼吁谷歌结束该项目的工作，并支持禁止自主武器系统的国际条约。

自主化武器很可能加剧全球军备竞赛。2016 年美国国防部发表新报告表示，美国需要「立即采取行动」加速 AI 战争科技的开发工作，未来 AI 战争不可避免，建议五角大楼在这方面加强发展，否则会被潜在的敌人超越。2017 年 7 月，中国推出了《新一代人工智能发展规划》，该规划将人工智能指定为未来经济和军事力量的转型技术。它的目标是，到 2030 年，中国将利用「军民融合」战略成为人工智能领域的卓越力量。2017 年 9 月，普京对刚开学的俄罗斯孩子说：「人工智能就是未来，不仅对俄罗斯而言，更是对整个的人类社会。谁成为这个领域的领导者，谁就将成为世界的统治者。」马斯克在推特上回应道：「在国家层面上人工智能优势的竞争是最可能导致第三次世界大战的原因。」这种军备竞赛可能会使国际局面特别不稳定，除了几个超级大国，其他国家也会效仿。

人工智能很可能将加速全球军事力量不对等和战争的发生。拥有人工智能技术、战争经历和战争数据的国家能够让自主化武器迭代速度更快。目前，美国、俄罗斯、以色列等国家拥有较多战争的文字、视频记录。通过监控恐怖组织、社交媒体、其他国家行动的数据，并把这些数据喂给人工智能让它们快速升级。另外，自主化武器更易流通和被滥用，或被其他国家和恐怖分子获得。即使达成了禁止军事机器人的协议，自主化武器技术也非常易于转让，并将普及开来。另外，因为该类武器能够将人员伤亡降到最低，所以政客发动战争的阻碍因素又减少了一项，毕竟美国等地民众对战争造成士兵牺牲的抗议比战争花费更让政府头疼。

自主化武器失控和错判的风险将一直存在，比如软件代码错误，或者受到网络攻击。这可能导致机器失灵或攻击自己人，或由于系统升级太快，人类伙伴无法及时响应。很难对自动化武器的可靠性进行测试，会思考的机器的行事方式也可能会超出人类控制者的想象。无论是在人机交互的回路之内（人类不间断监控操作，并保有关键决策的负责人），还是在回路之上（人类监督机器，并可以在任务的任何阶段干预机器）或者跳出回路（机器执行任务时没有人员干预），人们应该如何与不同程度的自主机器交互仍然有待研究。西方军事机构坚持认为，人类必须始终处于人机交互的回路之中。但是看到了完全自主系统所带来的军事优势，不是每个国家都会这么审慎。

群体学习和光速分享

一个很有意思的例子是谷歌关于机械手学习的实验。如图 6.12 所示，在盘子里放一些各种形状的物体，预先没有任何编程指令，让机械手通过上方的摄像头自己摸索着把每个物体从盘子里拿出来。可以想象，这个学习过程需要很长时间，因为一开始机械手在空中乱抓，直到蒙对了一个的时候它才能找对地方，然后又要学会抓取不同形状的物体。更复杂的是一个物体紧挨着另一个物体，机械手必须学会先把边上的物体挪开。这台机器学习大约需要 80 万次的摸索，如果每 10 秒抓取一次，那么一台机器要 24 小时不停地学习 100 天。

图 6.12 机械手学习从盘子中抓取不同的物体

图片来源：https://spectrum.ieee.org/automaton/robotics/artificial-intelligence/google-largescale-robotic-grasping-project。

但当谷歌让 14 台机器一起学习的时候，学习的时间就缩短到了 100/14=7 天。这 14 台机器都互相联网，当一台机器找对地方或学会了一个技能时，其他所有的机器瞬间都学会了。这种机器之间的交流不仅是无障碍的而且是以光速进行的。（如图 6.13）

图 6.13 谷歌的 14 台互相联网的机械手同时学习抓取物体

图片来源：https://spectrum.ieee.org/automaton/robotics/artificial-intelligence/google-largescale-robotic-grasping-project。

人类的知识传播阻力重重，有成本问题，有利益问题，还有学习者的接受能力问题。未来机器之间的群体学习、无私共享和光速传播一定会带来不可思议的奇迹。我们今天可以想象的奇迹有以下几方面。

（1）机器可以在极短的时间内掌握极难的技能。例如驾驶飞机通常需要几百小时的飞行训练，战斗机需要更长的时间，如果是 1 万个机器模型用不同的数据一起学习，可能一秒就能达到王牌飞行员的水平。

（2）数年内让几千万人失业。目前硅谷 Vicarious 公司在开发机械手的通用软件，可以安装在任何类型的机械手上来取代目前各种加工、筛选、检测、物流中的人力。一旦这种类型的软件成熟，取代人工的成本就是一些塑料和齿轮加上几个芯片。

（3）超级规模的协同行动。协调人类的大规模行动很难，例如让分布在世界各个国家的 100 万人在同一个时间唱同一首歌就是一个几乎无法完成的任务，但是让 100 万台机器同时跳一支舞却很容易。人类最大规模的协同行动通常是战争，未来的战争可能是天空中突然出现几万架无人机，战斗在几秒内结束。

（4）通用机器人智力增长惊人。如果未来能够有通用机器人，让散布在世界各地的从事各种工作的机器人的大脑相互联结，你就会惊奇地发现它们每分钟都在学会新的东西。从新生儿到成人的几十年的学习会压缩到几分钟甚至几秒。一台新机器人刚接通电源就会变成读过万卷书、行过万里路的「老江湖」。

人类哪里比机器强

看完上面的讨论读者可能非常郁闷，难道我们人类就没有比机器强的地方了吗？撇开情感，如果只讨论智力和智能，人比机器强在哪里？这个问题要分成两个部分来谈，一是目前人比机器强在哪里？二是人可能永远比机器强在哪里？

和目前的神经网络相比，人类在认知方面比机器强在以下几个方面。

（1）学习识别物体不需要大数据。机器要认识一只猫也许要几万张图片，图片的颜色或构图稍微变化一下或者有遮挡、残缺，机器就不行了。而人类能够从小数据中迅速提炼归纳出规律，一个婴儿可以看见一只猫后就认识了所有的猫。也许正如莫桑维克悖论所阐述的，高级推理所需要的计算量不大，反倒是低级的感觉运动技能需要庞大的计算资源。

（2）机器没有常识和物理世界的模型。人类在一个陌生环境摸索一阵后，能很快在大脑中建立起模型来。

（3）机器没有自主和自发的通用语言能力（目前人类输入的语法规则或通过数据训练出来的「语言」能力只能处理限定场景，否则就能通过图灵测试了）。

（4）机器没有想象力（需要大量常识，反事实假设及推理能力）。

（5）机器没有自我意识。

（6）机器没有情感和同理心。

总体来说，基于神经网络的机器学习的主要功能是记忆和识别，其他一切能力都是建立在这个基础上的。基于神经网络的机器大脑更像一个低等动物的大脑，只具有对外界的反应能力，虽然这种反应能力的精密和复杂程度远超人类和其他动物。

如果未来人工智能的基础还是神经网络，随着训练数据集的增大和处理能力的增强，上面的（1）就会得到改善甚至可以达到人类的水平。其中（2）也有可能用穷尽法解决。但是很难想象机器会具有通用语言能力、想象力，更谈不上自我意识。

简单地说，虽然基于神经网络的人工智能在记忆和识别这两个基础智能方面超过了人，但在推理、想象等高级智能方面还和人相去甚远。未来最佳的结合就是人类和机器合作，互相取长补短。

人机融合

人类和机器该如何合作？脑机接口（BMI：brain-computer interface）是科学家研究的一个重要方向，指创建在人类或动物大脑与外部设备之间的直接连接通路。被脑机接口串联的人脑能够与外部设备之间互相传送信号，交换信息。可以预料，当这项技术发展到一定的程度，人们就能够通过「外挂」外部设备的方式，来提高生物体脑部的感知、运算等能力，以及通过脑电波更为直接地对外部机器下达命令，或与其他人类进行协同。

最激进的方法之一就是马斯克提出的 Neuralink，研发出一种「神经蕾丝」对接在人脑的神经网络上，直接接收人脑的信号。马斯克认为机器「思维」和输入输出都非常快，而人类通过语言或键盘的输入输出比机器慢好几个数量级，这将是人类和机器相比最大的劣势。不打破这个瓶颈，人类总有一天会受制于机器。Neuralink 要解决的是突破人类的信号输入和输出瓶颈，但他的想法有一个基本漏洞：人类的高级思维必须依赖语言。如果脱离了语言我们就完全无法进行高级思维（如逻辑推理、描述场景等）。如前所述，目前的基于神经网络的机器学习能力主要是对环境的识别能力，还没有升华到语言和逻辑推理。而人类只能通过语言进行沟通。这也是我们在前文所说的，人类的「明知识」无法和机器的「暗知识」沟通。

在硅谷，另一位成功的企业家布莱恩·约翰逊（Bryan Johnson）也成立了一家公司叫 Kernel，宣称要能够对神经网络的底层功能直接读和写，他号称要投入一亿美元来打造这个技术。Kernel 和 Neuralink 当前的主要目的是让这些机器和人脑一起工作，当这些设备用于治疗脑部疾病时，设备不光向大脑发送信号以便作为治疗的手段，也会收集这些病症的特征数据。正如约翰逊所说的，这些设备可以采集到关于人脑工作原理的大量数据，从而反哺所有神经科学的研究领域。约翰逊认为，如果我们拥有来自大脑更多区域、更高质量的神经数据，那么它能为神经科学的研究带来更多可能性，只是我们目前还没有合适的工具去获知这些数据。但 Kernel 公司的技术顾问，斯坦福大学神经科学家大卫·伊格曼（David Eagleman）教授认为在一个健康人的脑中动手术植入一个电脑接口根本不可能。先不说死亡、感染、免疫排斥等危险，连往哪接目前都不知道。脑神经科的医生动开颅手术和脑神经手术都是在万不得已的情况下，例如患者的大脑有严重疾病或损伤。伊格曼认为更有可能的情况是，科学家会发现更好的从外部读取和模拟大脑的方法。今天，医生通过功能性核磁共振成像仪（FMRI）等技术读取大脑的信息，并通过经颅磁刺激等方法改变其行为，但这些仍然是较为简单的技术。伊格曼认为，如果科学家能够对人脑有更好的了解，那么他们可以大幅改进这些方法，或基于它们而发明更有用的方法。例如，科学家可以通过基因技术去改变神经元，从而使机器可以从体外对神经元进行「读写」，或者也可以通过「吞服」纳米机器人实现同样的目的，所有这些方法都比植入神经网络靠谱。

其实马斯克并非第一个提出这个设想的人，这方面的研究历史至少有 100 年之久，商业化的努力也一直前赴后继。外科医生已经能够把某些设备移植到人体内，脑神经科的手术目前主要是植入深度神经刺激信号，用来治疗癫痫、帕金森病等，重建患者的视觉、运动等能力。例如通过植入电极来抑制癫痫发病时的神经脑电信号，在这些情况下，冒一些风险是值得的。IBM 的科学家在开发一个类似的项目，通过分析在癫痫发作时的大脑信号，做出可植入人体并能抑制癫痫发作的仪器。（见图 6.14）

图 6.14 用于治疗癫痫的 RNS 系统装备

图片来源：IBM Treat epilepsy with RNS。

目前主要的成功案例来自一名叫作威廉姆·多贝尔（William Dobelle）的科学家。1978 年，多贝尔在一位盲人的脑内植入了由 68 个电极组成的阵列，这种尝试使盲人产生了光幻视（视网膜受到刺激时产生的感觉）。在随后的调试中，接受这种治疗的盲人能够在有限的视野内看到低分辨率、低刷新率的点阵图像。2002 年，接受新一代系统治疗的患者恢复了更多的视力，甚至可以在研究中心附近驾车慢速前行。同一阶段，在恢复运动功能方面，脑机接口研究也取得了显著的进展。（见图 6.15）

图 6.15 双目失明的延斯在仿生眼的帮助下得到了一定程度的视力

图片来源：jensnaumann.green-fi rst.com。

刚才提到除了植入电极还有一种可能的方法是在头上戴一个「电极罩」，采用「黑箱」方法解读人脑。只要罩在头上的电极罩能够从大脑中稳定地检测到足够复杂的信号，用此时人的语言或动作作为输出，通过机器学习的方法建立输入（检测到的脑电信号）和输出（语言或动作）的一一对应。这里的假设是对应每一个输出的输入都是相同或类似（例如每次竖大拇指的脑电波都相同）的且能稳定地检测这些信号。这种方式没有在大脑内植入电极，信号没有那么清晰，数据量没有那么大，也没有那么稳定，受到的干扰也会更强一些。

虽然通过头戴式装备获取微弱的脑电波信号的方式难度很大，但是经过几十年的发展，科学家已经开始取得突破，尤其是在残疾人部分能力的重建上。1988 年，美国科学家已经实现了用大脑控制虚拟打字机的操作，瑞典科学家更是实现了轮椅按人脑意识控制前进。2006 年，日本研制出「混合辅助腿」，能够帮助残疾人以每小时 4 千米的速度行走。在 2014 年世界杯上，身患截瘫的巴西青年朱利亚诺·平托身穿一套奇怪的「机械战甲」，在工作人员的帮助下开出了世界杯的第一脚球，这背后就是使用脑机接口技术 + 外骨骼成功让一个瘫痪患者恢复了行动能力。（见图 6.16）

另外，该类技术已经能够实现远程控制机器、玩游戏等。2008 年 1 月，杜克大学的研究团队让身在美国达勒姆实验室的猴子用意识控制了远在日本京都实验室内机器人的行走。2013 年 3 月，英国研究人员开发出第一种用于控制飞船模拟器的「脑机接口」装置，美国科学家又创建了计算机模拟程序，戴在头上后通过人脑的意念便可以控制飞船模拟飞行。2017 年 10 月，美国亚利桑那州立大学以人为导向机器人和控制实验室的负责人 Panagiotis Artemiadis 宣布正在研发一种导航系统，能够让驾驶员只借助自己的思维同时操控一群无人机。

图 6.16 为巴西世界杯开球的志愿者朱利亚诺·平托

图片来源：http://hiphotos.baidu.com/feed/pic/item/f603918fa0ec08fab12d60f453ee3d6d55f bdab0.jpg。

脑机接口技术的意义在于能够让人的大脑能力获得提升，或实现能力重建，甚至是实现远程控制。本质上普通人只能用自己的意识来控制自己的身体，而脑机技术能够让人类实现通过意识操控远在千里之外的机器人，更重要的是，通过机器人（肢体）的传感器，这些感觉可以实时传回到人类的大脑 —— 在某种程度上人类已经实现了肉体的无限延伸和空间的穿越，这已经颠覆了人类的认知。脑机接口的远程控制有望在诸多领域实现应用，例如智慧机器人去危险的火灾、电力、搜救等领域工作，同样也可以在地质勘探、农业、物流等领域实现应用。

通过连接到云端提升语言能力

谷歌技术总监库兹韦尔（Kurzweil）认为，由于智能手机能提供海量的计算和数据，所以它已经让我们远远比 20 年前的人聪明。有朝一日，我们不再需要手持设备，通过植入大脑皮质的芯片就可以让我们连接到云端。我们可以通过与人工智能结合而变得更加智能，通过更多潜在的方式去共享语言（例如能立刻接入英语词典）。库兹韦尔认为这些和我们现在的习惯差别不大，只是用大脑中的芯片替代了翻译。

逝者「还魂」

通过给人工智能系统灌输某个人的照片、视频、音频、信件、日记、邮件、账单以及任何能表现他个性的东西，可以造出逝者的「化身」，我们戴上头盔就可以在虚拟世界和他交流互动。库兹韦尔表示他已经造出了他过世多年的父亲的「化身」，他认为这是一个将父亲带回亲人身边的方式，虽然目前把逝者带回人工智能世界还不完全真实，但以后会更加接近。

