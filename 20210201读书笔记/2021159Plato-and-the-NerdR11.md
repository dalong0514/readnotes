## 记忆时间

## 目录

0101 Shadows on the Wall

0201 Inventing Laws of Nature

0301 Models of Models of Models of Models of Things

## 0101. Shadows on the Wall

· · · in which I examine the very idea of「facts」and「truths,」showing that: collective wisdom about them can be better than individual wisdom; a narrative about facts can be more interesting than the facts themselves; facts and truths may be invented or even designed, not just discovered; facts and truths may be wrong; and it can cost billions to show that facts are true. And, oh yes, nerds are misunderstood, and science and engineering get confused.

0101 墙上的影子

在本章，我讨论了「事实」和「真理」的概念，并将阐明：关于事实和真理的集体智慧可能比个体智慧更好；关于事实的叙述可能比事实本身更加有趣；事实和真理可能是被发明甚至是被设计出来的，而不仅仅是被发现的；事实和真理可能是错误的；而且要证明事实的真实性，很可能会花费数十亿美元的巨资。哦，是的，技术呆子被人们严重误解了，科学和工程也被混淆在一起。

### 1.1 Nerds

I am a nerd. According to the Merriam-Webster dictionary, a nerd is

an unstylish, unattractive, or socially inept person; especially: one slavishly devoted to intellectual or academic pursuits.

a person who is very interested in technical subjects, computers, etc.

Who but a nerd would start a book with a quote from the dictionary? I wouldn't expect a nerd to write very well, particularly not for a general audience. Actually, I'm quite sure this book would be much better if it were written by someone else. But I can't get anyone else to write it, so I will compensate by quoting the writing of others, even from dictionaries.

The previous definition was presumably written by a trustworthy expert on the subject of nerdiness. We expect that the publishers of dictionaries go to some effort to ensure that the definitions are written by experts. In contrast, we cannot assume that a Wikipedia page about nerds would be written by experts. Anyone with Internet access can modify the contents of a Wikipedia page. There is no vetting of expertise. Nevertheless, the page for「nerd」largely concurs with Merriam-Webster but offers more:

Though originally derogatory,「Nerd」is a stereotypical term, but as with other pejoratives, it has been reclaimed and redefined by some as a term of pride and group identity.

Now I am reassured that I can be proud to be a nerd. Continuing with an etymology,

The first documented appearance of the word「nerd」is as the name of a creature in Dr. Seuss's book If I Ran the Zoo (1950), in which the narrator Gerald McGrew claims that he would collect「a Nerkle, a Nerd, and a Seersucker too」for his imaginary zoo. [citations to Merriam-Webster and the American Heritage Dictionary] The slang meaning of the term dates to the next year, 1951, when Newsweek magazine reported on its popular use as a synonym for「drip」or「square」in Detroit, Michigan…. At some point, the word took on connotations of bookishness and social ineptitude.

I like this narrative better than the dictionary definition because it focuses on how the word came about and how it evolved rather than what it is. Most facts are more interesting when we understand how they came to be facts rather than just accepting them as if they were always there.

But is this Wikipedia article authoritative? The article points out that American satirist「Weird Al」Yankovic's song「White and Nerdy」states that editing Wikipedia is a stereotypical nerd interest. I am therefore reassured that this article is likely written by experts on nerdiness.

There is a big difference in style between a dictionary definition and a narrative about culture. A dictionary definition is usually understood to give a fact, a truth. Merriam-Webster defines「definition」as「an explanation of the meaning of a word, phrase, etc.」This definition gives definitions the aura of facts and truths, deemphasizing their instability and fluidity with human culture.

Most of us approach technology as if it too were a compendium of facts and truths. We assume that technology advances because people discover more facts and truths. Because the discovery of facts and truths is the realm of science, science therefore drives technology. But I doubt that the technology of Wikipedia came about as a consequence of the discovery of facts and truths.

Wikipedia is a software system created by Jimmy Wales and Larry Sanger, who put the first version online in 2001. I don't know them, but one of my prejudices is that many software people are nerds, so there is a reasonable chance they too are nerds.

According to the Wikipedia article on Wikipedia, Sanger coined its name as「a portmanteau of wiki and encyclopedia.」Following the link to the page on「wiki,」we learn that a wiki is a website that「allows collaborative modification of its content and structure directly from the web browser.」That page tells us that「wiki」is a Hawaiian word meaning「quick」and credits Ward Cunningham with inventing the wiki. I hope you will agree that it would be odd to say that Cunningham「discovered」the wiki, so presumably this was not an advance creditable to science. But the nuanced relationship between discovery and invention and between science and engineering is not always so clear.

Cunningham's 2001 book with Bo Leuf describes the wiki concept as follows:

A wiki invites all users to edit any page or to create new pages within the wiki Web site, using only a plain-vanilla Web browser without any extra add-ons. Wiki promotes meaningful topic associations between different pages by making page link creation almost intuitively easy and showing whether an intended target page exists or not. A wiki is not a carefully crafted site for casual visitors. Instead, it seeks to involve the visitor in an ongoing process of creation and collaboration that constantly changes the Web site landscape. (Leuf and Cunningham, 2001)

I love that web browsers come in「plain vanilla」flavors. I wonder what other flavors are available.

This description starts to give us the sense that a wiki, and particularly Wikipedia, is as much a cultural artifact as a technological one. And as with all cultural artifacts, it didn't suddenly pop into existence at the instant of invention. In fact, inventions almost never do and nearly always have a strongly cultural element. The「meaningful topic associations between different pages」were in fact already present in the World Wide Web, which according to its Wikipedia article was「invented by English scientist Tim Berners-Lee in 1989.」

It is interesting that this article identifies Sir Timothy John Berners-Lee (he was knighted by Queen Elizabeth II for his work) as a「scientist.」His recognized contributions were certainly not of the nature of discovery of facts and truths and certainly not about the natural world, the main focus of science. Berners-Lee did get a bachelor of arts degree in physics, unquestionably a science subject, from Oxford, so I suppose calling him a scientist is justified. But I see no evidence that he is a successful scientist.

Or maybe I am misunderstanding what it means to be a scientist. Returning to trusty old Merriam-Webster, a scientist is「a person who is trained in a science and whose job involves doing scientific research or solving scientific problems.」Hmm… Not very helpful. Looking up「science,」we find it is「knowledge about or study of the natural world based on facts learned through experiments and observation.」By this definition, if Berners-Lee's career goal was to study the natural world, then I would have to conclude that his career has not (yet) been very successful. If, in contrast, his career goal was to invent and engineer artifacts that had never before existed, then he has been spectacularly successful, richly deserving the knighthood. He created mechanisms that are today used by nearly every person in the developed world. He changed the world.

Berners-Lee's contributions are arguably more cultural than technical. The cultural context of the web and Wikipedia goes back even further. Vannevar Bush, [1] in a 1945 article「As We May Think,」states,

Wholly new forms of encyclopedias will appear, ready-made with a mesh of associative trails running through them, ready to be dropped into the memex and there amplified. (Bush, 1945)

The memex is Bush's hypothetical microfilm viewer that has a structure analogous to that of hypertext, the essential feature of Berners-Lee's web. Berners-Lee's technical contribution was to make Bush's vision a reality.

So why is Berners-Lee identified as a scientist? Possibly whoever wrote the Wikipedia article intended this as an honorific in the sense that「engineer」would not be. In his wonderful book, The Black Swan , from which I get the title of this book, Nassim Taleb used the term「Platonicity」for the「desire to cut reality into crisp shapes」(Taleb, 2010). My classification of people, including myself, as「engineers」or「scientists」(or even as「nerds」) stems from such Platonicity. But humans are complex and defy classification. You may be surprised that I, a nerd, am also an amateur artist (see figure 1.1 ).

Taleb argues that Platonicity, the desire to categorize, the obsessive focus on taxonomy,「makes us think that we understand more than we actually do.」

What I call Platonicity, after the ideas (and personality) of the philosopher Plato, is our tendency to mistake the map for the territory, to focus on pure and well-defined「forms,」whether objects, like triangles, or social notions, like utopias (societies built according to some blueprint of what「makes sense」), even nationalities.

The arbitrariness of categories such as「scientist」and「engineer」is an example of Platonicity. It makes us sanguine in our understanding of the world, but it can be misleading. In the rest of this chapter, I will focus on the difficulties in distinguishing discovery from invention, invention from design, and scientist from engineer.

Figure 1.1 Self-portrait of a nerd. Acrylic on canvas (2007).

[1] Vannevar Bush, in the Wikipedia article on him, is identified as an「engineer, inventor and science administrator.」Bush, who died in 1974, was a towering figure. He was an MIT professor, dean of the MIT School of Engineering, and founder of Raytheon, a major U.S. defense contractor. During World War II, Bush coordinated several thousand scientists in the application of science to warfare. He started the Manhattan Project, which led to the development of nuclear weapons. At the end of World War II, Bush pressed for increased government support for science. His arguments led to the creation of the National Science Foundation (NSF), which today is one of the premier supporters of research in science and engineering.

1.1 技术呆子

我就是一个典型的技术呆子。《韦氏大词典》中，技术呆子是指：

穿着不时髦、自身没有吸引力或者完全不善于社交的人，特指专心致力知识或学术事业的人，对技术主题、计算机等非常感兴趣的人。

除了我这个技术呆子，还有谁会以词典的释义作为一本书的开场白呢？我不指望像我这样的技术呆子能把一本书写得很好，尤其是对普通的读者而言。实际上，我十分确定，如果让别人来写这本书，一定会比我写的好很多。但是，我找不到其他人来完成这项任务。为了让本书的内容更加丰富，我会不时地引用他人的观点作为补充，当然也包括词典里的释义。

上面的定义大概是一位令人信赖的专家就技术呆子这个主题而给出的。我们衷心期望词典的出版商能够确保这些定义是由真正的专家编写的。然而，我们还不能确定一个关于技术呆子的维基百科页面是不是由专家编写的。因为任何可以上网的用户，不需要专业资格的审查，就都能修改维基百科页面上的内容。尽管如此，「技术呆子」的维基页面在很大程度上与《韦氏大词典》上的定义是一致的，但也提供了更多的信息：

虽然「技术呆子」最初是一个带有刻板印象的贬义词，但与其他贬义词一样，这个词已被一些人重新定义为一个有着自豪感和群体认同感的术语。

现在，我的内心不再纠结了，可以毫不犹豫并自豪地称自己为技术呆子了。下面是关于这个词的来源：

「技术呆子」这个词用来指称一类人，最初出现在苏斯博士的《如果我来经营动物园》（1950）一书中。书里的讲述者杰拉尔德·麦格鲁声称，他要为想象中的动物园搜集「一个圣诞控（Nerkle）、一个呆子，外加一匹泡泡纱（Seersucker）」。（引用《韦氏大词典》和《美国传统词典》。）这个词的俚语意思可以追溯到后一年，也就是 1951 年，当时《新闻周刊》报道了该词在密歇根州的底特律被广泛地用作「乏味之人」或「与环境格格不入的人」的同义词。…… 在某种程度上，这个词语带有「书生气」和「社交低能」的意味。

比起词典里的定义，我更喜欢这个描述，因为它关注这个词的生成和演变过程，而不只是简单地介绍它是什么。当我们理解了事实是如何演变为事实的，而不是仅仅接受它们，就好像它们一直就在那里，那么大多数事实都会变得更为有趣。

但是，这篇维基百科的文章是否具有权威性呢？文章指出，美国歌曲恶搞专家艾尔·扬科维奇（绰号「怪人艾尔」）的歌曲《又白又宅》是这样说的：「编辑维基百科是一个刻板的书呆子感兴趣的工作。」因此，我确信这篇文章很可能是由某个书呆子专家撰写的。

词典释义与文化叙述在风格上有很大的区别。词典里的定义通常是给出一个事实或一个真理。《韦氏大词典》将「定义」定义为「对一个词、短语等的意义的解释」。这一释义给「释义」赋予了事实和真理耀眼的光环，却弱化了它们在人类文化中的不稳定性和流动性。

我们中的大多数人对待技术就好像它也是事实和真理的概要。我们会理所当然地认为技术进步是因为人们发现了更多的事实和真理。由于事实和真理的发现属于科学范畴，因此可以理解为科学推动了技术的发展。但是，我不相信维基百科的技术是由于事实和真理的发现才产生的。

维基百科是由吉米·威尔士和拉里·桑格创建的软件系统，第一个版本于 2001 年上线发布。尽管我并不认识他们，但是，我的成见之一就是，许多软件开发人员都是技术呆子，所以可以合情合理地认为他们也就是这类人。

根据维基百科上的文章，桑格创造了它的名字「维基和百科全书的合成词」。根据「维基」页面上的链接，我们了解到维基是一个「允许通过网络浏览器直接对其内容和结构进行协作修改」的网站。它还让我们了解到，「wiki」是一个夏威夷土语，意思是「快速」，感谢沃德·坎宁安发明了维基这一概念。我希望你能同意我的观点，如果说坎宁安「发现」了维基，这听起来会令人感到奇怪，所以这大概不算是科学的进步吧。但发现与发明以及科学与工程之间的微妙关系并不总是那么清晰可辨。

坎宁安与博·勒夫在 2001 年合著的著作中对维基的概念做了如下描述：

维基旨在邀请所有用户编辑维基网站的任何页面，或者创建新的页面，仅是使用普通的 Web 浏览器就能完成，而且不需要任何额外组件。维基促进了不同页面之间有意义的主题关联，其使页面链接的创建非常简单，并会显示目标页面是否存在。维基不是一个为普通访问者精心设计的网站，相反，它试图让访问者参与到不断改变网站布局的创建与协作过程中。（勒夫和坎宁安，2001）

我很喜欢网页浏览器具有「朴素」的风格。当然，我也希望知道还有什么不同的风格。

上面这段描述给了我们这样一种感觉，那就是，类似于维基这样的系统，尤其是维基百科，它既是一种文化产品，也是一种技术产品。和所有的文化产品一样，它并不是在被发明的那一刻突然出现的。事实上，它几乎从来不是被发明的，而且几乎总是充满强烈的文化元素。「不同页面之间有意义的主题关联」实际上已经出现在万维网上了。根据维基百科的文章我们可以知道，万维网是「由英国科学家蒂姆·伯纳斯·李在 1989 年发明的」。

有趣的是，该文认为蒂姆·伯纳斯·李爵士（他因卓越的工作成就被伊丽莎白二世封为爵士）是一名「科学家」，尽管他的公认贡献并非发现事实和真理的本质，当然也不是关于自然世界 —— 科学的主要焦点。伯纳斯·李在牛津大学获得物理学学士学位，毫无疑问物理学是一门科学学科，所以我认为称他为科学家是有一定道理的。但是，我还没看出他是一位成功的科学家。

也许是我误解了当科学家到底意味着什么。让我们回到值得信赖的、古老的《韦氏大词典》看看它是如何定义科学家的。词典中解释，科学家指的是「受过科学训练的人，其工作涉及科学研究或者解决科学难题」。嗯，这个定义好像不是很有帮助。让我们再来查查「科学」的意思。可以看到，科学是指「关于自然世界的知识或研究，其基础是通过实验和观察所获得的事实」。根据这个定义，如果伯纳斯·李的职业目标是研究自然世界，那么我不得不得出这样的结论：他的职业生涯（还）不是很成功。相比之下，如果他的职业目标是发明和设计从未存在过的人工制品，那么我们可以说他的确取得了惊人的成功，完全配得上爵士这一荣誉。他创造了今天发达国家几乎每个人都在使用的一组机制。他改变了世界。

可以说，伯纳斯·李的贡献更多是在文化方面，而不是在技术领域。网络和维基百科的文化背景可以追溯到更早时期。万尼瓦尔·布什在 1945 年的一篇题为「诚如所思」的文章中写道：

百科全书的一些全新形式将会出现，它们中间会有许多相互关联的痕迹，它们将被存入麦克斯存储器里，并在那里被放大。（布什，1945）

麦克斯存储器是布什假想出的微缩胶片阅读器，其结构类似于超文本，这是伯纳斯·李发明的万维网的主要特征。伯纳斯·李的技术贡献是使布什的梦想成为现实。

那么，为什么伯纳斯·李会被认定是科学家呢？可能是写维基百科这一词条的人想要表达「科学家」是一种有荣誉的身份，而「工程师」不是。在纳西姆·塔勒布精彩的著作《黑天鹅》中，我获得了本书书名的灵感。塔勒布用「柏拉图主义」一词来表示「将现实分割为清晰形状的愿望」（塔勒布，2010）。我把人（包括我自己）归类为「工程师」或「科学家」（甚至是「技术呆子」），就是源于这种柏拉图主义。然而，人是复杂的，很难被准确归类。你可能会感到惊讶，我是一个技术呆子，同时竟然也是一个业余的艺术家（见图 1.1）。

塔勒布认为，柏拉图主义，这一对分类的渴望以及对分类学的痴迷，「让我们误以为我们理解的比实际的要多」。

在哲学家柏拉图的思想（和个性）形成之后，我称其为柏拉图主义，它使我们倾向于把地图误认为是地域，并倾向于关注纯粹和明确界定的「形式」，无论是有形物体，如三角形，还是无形的社会观念，如乌托邦（根据某种「有意义」的蓝图建立的社会），甚至是民族。

诸如「科学家」和「工程师」等分类的任意性是柏拉图主义的一个例子。它使我们对世界的理解变得乐观，但也可能产生误导。在本章的其余部分，我将聚焦于区分发现与发明、发明与设计以及科学家与工程师等方面的困难。

图 1.1 技术呆子的自画像（2007 年）。

### 1.2 Artificial and Natural

Herbert Simon, a hugely influential twentieth-century thinker and winner of both the Turing Award in computer science and the Nobel Prize in economics, in his book, The Sciences of the Artificial , makes a distinction between「artificial」and「natural」phenomena:

The thesis is that certain phenomena are「artificial」in a very specific sense: they are as they are only because of a system's being molded, by goals or purposes, to the environment in which it lives. (Simon, 1996)

A system is artificial if it is「being molded, by goals or purposes.」But in this statement, who does the molding? Simon presupposes it is humans. It could instead be God or some other teleological cause, and then no distinction would exist between the「sciences of the natural」and the「sciences of the artificial.」One could even take as a definition of God as He who molds, by goals or purpose, our entire natural world. But there is a distinction between the artificial and the natural. A big one, Simon says.

Simon's examples of artificial phenomena include political systems, economies, engineered artifacts, and administrative organizations. The「molding」of such systems「by goals or purposes」is the process of design .

Everyone designs who devises courses of action aimed at changing existing situations into preferred ones. (Simon, 1996)

Engineering , as a discipline, is fundamentally about design in this sense. Wikipedia, which as you may have realized by now, is my first recourse for many research problems, defines engineering this way:

Engineering is the application of mathematics, empirical evidence and scientific, economic, social, and practical knowledge in order to invent, innovate, design, build, maintain, research, and improve structures, machines, tools, systems, components, materials, and processes. (retrieved March 1, 2016)

It then points out the obvious,「the discipline of engineering is extremely broad,」and gives the origin of the term:

The term Engineering is derived from the Latin ingenium , meaning「cleverness」and ingeniare , meaning「to contrive, devise.」

Note that the word is not derived from「engine,」as many people might assume. Instead,「engine」is derived from the same Latin roots.

Wikipedia effectively leverages recent triumphs of engineering. But is it authoritative? It creates collective wisdom, subjugating the role of individual experts, If you are old enough, you may remember the encyclopedias of the twentieth century, such as the Encyclopedia Britannica . According to Wikipedia, the Britannica

is written by about 100 full-time editors and more than 4,000 contributors, who have included 110 Nobel Prize winners and five American presidents.

The Britannica is built in a very different way than Wikipedia. The editors recruit top experts to contribute to articles. The focus is on the individual experts, who, through their reputation, lend authority to the text.

Not Wikipedia. Anyone can edit a Wikipedia page. So how can these pages have any authority? At one level, Wikipedia replaces authority with accountability. Figure 1.2 shows the edit history of the Wikipedia page for Engineering quoted earlier. Notice near the bottom of the figure the most recent edit of this page, on February 25, 2016. This edit is annotated with the comment,「Reverting possible vandalism.」Indeed, the previous edit, which was made less than a minute earlier, has the comment,「This is all a lie.」That edit removed quite a bit of text, including the previous definition of Engineering, and replaced it with,「This is al a lie」[sic]. The entire history of these edits is accessible on the Wikipedia site.

Figure 1.2 Edit history for the Wikipedia page on Engineering, retrieved March 1, 2016.

So who reversed the vandalism? The user is identified as「ClueBot NG.」Clicking on that name reveals the page shown in figure 1.3 . It turns out that ClueBot NG is a「bot,」which Wikipedia defines as「a software application that runs automated tasks (scripts) over the Internet.」On the page in figure 1.3 , listed as item 8, is a description of the「Vandalism Detection Algorithm,」which evidently is a piece of software that classifies an edit as either「vandalism」or「not vandalism,」and if it is vandalism, it reverses the edit. The methods used to perform classification are statistical machine learning methods, linchpins of the currently hot area of data science. I will examine how this mechanism is analogous to an immune system and why that is important in chapter 9 , and I will explain the principles behind how it works in chapter 11 .

Figure 1.3 User page for the most recent editor shown in figure 1.2 , retrieved March 1, 2016.

It is worth pausing and reflecting on how profoundly different all of this is compared with a twentieth-century encyclopedia. I will have more to say about this later, but one of the trends of the twenty-first century is the subjugation of the individual expert, the high authority, the intellectual hero. In the twentieth century, the phrase「triumphs of modern physics」would evoke in our minds Einstein, Bohr, Schrödinger, Heisenberg, and a few others. Of course, many others contributed, many of them also recognized as heroes. Experts do contribute to Wikipedia articles, but their text may be modified and elaborated on by anyone, including vandals. And readers rarely check to see who wrote the text. The authority of the author seems to be irrelevant. The text reflects a collective wisdom, not an individual one.

We now face an interesting conundrum. Which is closer to the truth, the collective wisdom or the individual one? This question gets ensnarled by what we mean by「truth.」The answer is different if truths can be created rather than just being discovered.

1.2 人工的与自然的

赫伯特·西蒙，20 世纪最具影响力的思想家，计算机科学的图灵奖和诺贝尔经济学奖得主，在他的《人工科学》一书中对「人工的」现象和「自然的」现象进行了区分。

1『又看到了偶像赫伯特·西蒙，哈哈。（2021-10-24）』

其观点是，某些现象在非常具体的意义上是「人工的」：它们之所以如此，仅仅是因为一个系统为其所处环境的目标或目的所塑造。（西蒙，1996）

如果一个系统是「被某些目标或目的塑造」的，那么这个系统就是人工的。但是，在这个陈述中，到底是谁塑造了这个被提及的系统呢？西蒙假定塑造者是人类。它也可以是上帝或其他目的论的原因，这样的话，「自然科学」和「人工科学」之间就不会再有任何区别了。人们甚至可以把上帝定义为通过目标或目的塑造我们整个自然世界的人。但是，人工的和自然的之间确实存在差异。按照西蒙的说法，它们之间存在着很大的差异。

西蒙举的人工现象的例子包括政治制度、经济、工程产物和行政组织。「按照目标或目的」对这类系统进行「塑型」就是该类系统的设计过程。

每个人都在设计行动方案，目的是将现有的情况转变为自己喜欢的那样。（西蒙，1996）

工程学，作为一门学科，从本义上讲是关于设计的。正如你现在可能已经意识到的那样，维基百科总是我解决许多研究问题的首选资源，它对工程学的定义是这样的：

工程学是为了发明、创新、设计、建造、维护、研究和改进结构、机器、工具、系统、部件、材料和过程而对数学、实证以及科学、经济、社会和实用知识的运用。（2016 年 3 月 1 日检索）

然后，它又指出一个显而易见的事实，即「工程学科是极其宽广的」，并给出了该术语的起源：

「工程」一词源于拉丁文「ingenium」，意思是「聪明」；拉丁文「ingeniare」的意思是「发明，设计」。

请注意，这个词并非像许多人可能认为的那样源自「engine」（引擎）一词。相反，「engine」也源自与之相同的拉丁语词根。

维基百科有效地利用了最近取得的工程成就。但是，它是否具有权威性呢？它创造了集体智慧，并压制了专家个体的作用。如果你现在已有一定的年纪，就可能知道一些 20 世纪的百科全书，例如，《不列颠百科全书》。维基百科是这样描述《不列颠百科全书》的：

该书是由大约 100 名全职编辑和 4 000 多名参编者共同编写的，其中包括 110 名诺贝尔奖获得者和 5 位美国总统。

《不列颠百科全书》的编纂方式与维基百科的创建方式截然不同。编辑们聘请了顶尖的专家为词条撰稿。其重心在于专家个体，他们可以通过自己的声誉为内容增添权威性。

然而，维基百科的创建方式却并非如此。任何人都可以编辑维基百科的页面。那么，这些页面又如何才能具有权威性呢？从某种程度上讲，维基百科以责任取代了权威。图 1.2 给出之前引用的维基百科中工程学页面的编辑历史。请读者们注意，该图的底部显示此页面是在 2016 年 2 月 25 日被最新编辑的。

这条编辑的注释是「恢复可能的破坏」。事实上，对不到一分钟之前的这条编辑，有这样的一条评论：「这只是一个谎言。」这条编辑删除了相当多的文本，包括以前对工程学的定义，并将其替换为「这只是一个谎言」（原文如此）。这些编辑工作的全部历史都可以在维基百科网站上被找到。

图 1.2 维基百科中工程学页面的编辑历史，2016 年 3 月 1 日检索。

那么究竟是谁逆转了这种破坏行为呢？这个用户被标识为「ClueBot NG」。单击该名称将会显示出如图 1.3 所示的页面。原来 ClueBot NG 是一个「虚拟机器人」，维基百科将其定义为「在互联网上运行自动化任务（脚本）的软件应用程序」。在图 1.3 所示的页面上，列在第 8 项的是对「恶意破坏行为检测算法」的描述，这显然是一个软件。该软件将对词条的编辑操作归类为「恶意破坏」或「非恶意破坏」。如果是恶意破坏，它就会逆转编辑。用于进行分类的方法是统计机器学习法，其是当前数据科学热点领域的关键方法。我将在第 9 章研究这一机制是如何与免疫系统相类似的，以及它为什么会如此重要。我将在第 11 章解释其背后的原理。

图 1.3 最新编辑器的用户页面，如图 1.2 所示，2016 年 3 月 1 日检索。

现在，我们有必要停下来思考一下，与 20 世纪的百科全书相比，这一切究竟有多大的不同。这是值得我们思考的问题。稍后我还会对此发表更多的看法。然而，21 世纪的发展趋势之一将是对专家个体、高端权威以及知识分子精英形成压制。在 20 世纪，「现代物理学的胜利」这样的字眼将在我们的脑海中唤起有关爱因斯坦、玻尔、薛定谔、海森堡和其他几个人的辉煌记忆。当然，还有很多人也在物理学方面做出了贡献，其中许多人也被认为是英雄。不可否认，专家们确实为维基百科的词条做出了贡献，但是他们的文字可能会被任何人改动和编写，其中也有恶意的破坏者。然而，大多数读者很少会去查看是谁编写的这个文本。可以说，作者的权威性似乎变得无关紧要了。词条的文本展现的是集体智慧，而不是个体智慧。

我们现在正面临一个很有趣的难题。集体智慧和个体智慧哪一个更接近真理？这个问题被我们所说的「真理」困扰着。如果说真理可以被创造出来，而不仅仅是被发现，那么这个问题的答案将会不同。

### 1.3 Design and Discovery

In contrast to Simon's「sciences of the artificial,」the「sciences of the natural」study what nature has given us. The goal is to uncover the「secrets of nature,」presupposed to exist disembodied, independent of humans. These secrets occupy neither time nor space; they do not come into existence when they are discovered, occupying a time, nor do they exist at the place they are discovered.

The idea that these secrets exist disembodied dates back at least to Plato, who postulated ideal「Forms,」objective and eternal truths that are impossible to know completely. Plato states that these Forms are the only objective truths, and that the ultimate goal of a「philosopher」(a lover of knowledge) is to understand these forms. The Forms represent the most accurate reality, and Plato calls knowledge of them「the Good.」

Plato's Allegory of the Cave (see figure 1.4 ) suggests that human perception of reality is always imperfect. In the allegory, prisoners are chained with their backs to a low wall (bottom right in the figure). Their heads face the blank wall of the cave on which shadows are cast (top right) from a fire (top center). The shadows are of puppets and figures manipulated from behind the low wall, and the shadows on the cave wall constitute the only knowledge of reality that the prisoners experience. If a prisoner is released and can face the fire creating the light, then he will resist accepting the reality of the fire or the puppets casting shadows. If the prisoner is further allowed to exit the cave, then he will be blinded by the sun and further resist the reality of that external「ideal」world. And if a prisoner does accept some of the truths he is exposed to and tries to convey those truths to the prisoners behind the low wall, then they will reject his ideas as absurd.

Figure 1.4 Plato's Allegory of the Cave by Jan Saenredam, 1604. [ c The Trustees of the British Museum.]

The allegory underscores the difficulty of achieving the Good and explains why those individuals who do successfully convince others of some newly discovered, seemingly objective truth, the Einsteins and Bohrs of the world, are eventually deemed to be heroes.

Simon contrasts these objective truths with those of artificial phenomena.「If natural phenomena have an air of ‘necessity' about them in their subservience to natural law, artificial phenomena have an air of ‘contingency' in their malleability by environment.」Their「subservience to natural law」presupposes a Platonic, disembodied existence of that natural law, regardless of whether it can be known.

A contrasting view is that laws of nature are models, created by humans, for how the physical world works. This view has gained considerable currency in the last few decades, perhaps beginning with Thomas Kuhn's groundbreaking and controversial 1962 book, The Structure of Scientific Revolutions , which postulated that scientific theories are framed by「paradigms,」which are very much human ways of thinking about the world.

In either case, calling natural laws「laws」is a bit odd. It's almost as if nature is required to follow them, as citizens are required to follow the laws of a state. But what happens when nature violates a law of nature? Nature is not punished! Instead, the law becomes invalid. Imagine if a state worked that way. Each time a driver exceeded a speed limit, the speed limit would become invalid. But what about「laws of nature」? How can an ideal truth become invalid? And yet we've seen laws of nature become invalid many times.

David Deutsch, a British physicist at Oxford and a pioneer of quantum computing, in his 2011 book, The Beginning of Infinity , argues that science is more about「good explanations」than about laws of nature. Deutsch attributes these explanations to humans rather than some preexisting disembodied truth:

Discovering a new explanation is inherently an act of creativity. (Deutsch, 2011, p. 7)

A「law of nature,」in contrast, has a more humble role, that of codifying a connection between the past and the future:

[A]ny purported law of nature — true or false — about the future and the past is a claim that they「resemble」each other by both conforming to that law. (Deutsch, 2011, p. 6, emphasis in the original)

Deutsch goes further to reject empiricism, arguing that neither laws of nature nor good explanations are derived from observation of the physical world:

Experience is indeed essential to science, but its role is different from that supposed by empiricism. It is not the source from which theories are derived. Its main use is to choose between theories that have already been guessed. (Deutsch, 2011)

Here Deutsch echoes the thesis put forth earlier by the Austrian-British philosopher of science Karl Popper (1902–1994), who stated that these guesses, hypotheses about nature, arise from「creative intuition」and can only be tested empirically after they have been advanced (Popper, 1959). Deutsch points out that most of reality in the physical world is not directly observable to any human being. Black holes, quarks, and nuclear fusion in the sun involve scales, forces, and temperatures that no human has ever experienced. They are just as inaccessible as Platonic Forms, observable at best only as shadows on the wall. It cannot possibly be observations of black holes that lead to our theories about them, because we cannot observe them.

Plato recognized that the ideal truths of Forms could not be fully known by humans. But because they cannot be fully known by humans, isn't it more practical to view what we do know about nature as human-constructed models or what Deutsch calls good explanations? This would be more humble, tacitly acknowledging that even our most fervently held beliefs about nature are subject to improvement. I'm not saying that there are no truths, but just that we should always be required to question them.

Such humility is intrinsic in the Wikipedia model of collective wisdom. No individuals, no authorities, no matter how many accolades follow their names, can be trusted as the holders of「the truth.」Knowledge should and must evolve. And as knowledge evolves, doesn't「the truth」also evolve? Of course, a realist might reply that it is belief not knowledge that evolves. For that realist, if a belief isn't true, it isn't (and never was) knowledge.

Deutsch points out that deference to authority was replaced during the enlightenment by empiricism, where ideas and theories are based on testing and experience. But he argues that experience alone is insufficient because so much of the physical world operates in conditions that cannot support human life and therefore cannot be directly experienced.

Empiricism never did achieve its aim of liberating science from authority. It denied the legitimacy of traditional authorities, and that was salutary. But unfortunately it did this by setting up two other false authorities: sensory experience and whatever fictitious process of「derivation,」such as induction, one imagines is used to extract theories from experience. (Deutsch, 2011)

Again echoing Popper, he argues that rather than deriving knowledge from experience, knowledge comes from a fundamentally creative process of conjecture, followed, often much later, by cleverly devised experiments that support the guesses (usually by failing to falsify them). Such clever experiments usually observe only indirect side effects. In other words, knowledge is engineered.

The next chapter will focus on the role that models play in both science and engineering, but for now suffice it to say that there is a tension here between design and discovery . Some artificial phenomena are not explicitly designed but rather emerge accidentally from human activity. The field of economics, for example, is full of the study of such emergent phenomena. The rules by which these artificial phenomena operate are arguably discovered rather than designed. And although many other artificial phenomena are designed, surely they too are subject to natural laws, which in the Platonic view at least must be discovered. But our knowledge of the natural laws is imperfect, so we must construct models of those laws using mathematics, for example. Are not these models designed?

Sir Isaac Newton's laws of motion are now known to be violated by nature, in that they fail at relativistic speeds and quantum scales. Those laws take the form of mathematical formulae, such as Newton's second law, [2]

F = ma, (4096)

which states that force equals mass times acceleration. This looks like an expression of a Platonic Form, but it is wrong! Despite being wrong, we don't hesitate to say that Newton「discovered」it, and people would look at us funny if we said that Newton「invented」it.

For some phenomena, we do not hesitate to use the word「invention」for their discovery. Consider the transistor, credited to John Bardeen, Walter Brattain, and William Shockley of Bell Labs (see figure 1.5 ). [3] They got the 1956 Nobel Prize in Physics「for their researches on semiconductors and their discovery of the transistor effect.」They demonstrated the transistor effect with a device made of gold and germanium, although today transistors are realized mostly using silicon crystals with carefully introduced impurities called dopants. Note the careful phrasing in the Nobel Prize citation,「their discovery of the transistor effect.」Nobel Prizes are not issued for inventions, only for discoveries. Yet most of us would say that the transistor was invented at Bell Labs in the 1950s.

But actually, a U.S. patent was awarded to Julius Lilienfeld in 1930 for the 1925 invention of a type of transistor now called a field-effect transistor (FET) (Lilienfeld, 1930). So if the transistor effect is a Platonic Form, then it was actually discovered earlier by Julius Lilienfeld. But patents are not issued for discoveries, only for inventions. According to the U.S. Patent and Trademark Office, you cannot patent「laws of nature, natural phenomena, and abstract ideas.」A patent may be issued for a「novel use」of a law of nature, of course, because presumably everything is subject to the laws of nature. Such a novel use is an invention, not a discovery.

To be fair to the Nobel Prize committee, Lilienfeld's FET was actually significantly different from the one developed by Bardeen, Brattain, and Shockley. The Bell Labs transistor was of a type known today as a bipolar transistor. Interestingly, today, bipolar transistors are used only in niche applications because of their significantly higher energy requirements. FETs are used much more commonly, having become the workhorses for digital technology. An iPhone today contains billions of FETs.

Figure 1.5 John Bardeen, Walter Brattain, and William Shockley, who received the 1956 Nobel Prize in Physics for the discovery of the transistor effect.

It is not uncommon for inventions and discoveries to be messy in this way. The intellectual history of an idea is rarely clear, and yet, as a culture, we insist on singling out the「heroes」who bring these ideas to the fore. [4]

The tension between discovery and invention is not new. Is the transistor effect a「natural phenomenon」that has always existed, waiting to be discovered? As far as I know, nobody has ever found in nature sandwiches of gold and germanium or doped silicon operating as transistors. So transistors must not be natural phenomena. But when these sandwiches are constructed by man, nature takes over and regulates the movement of electrons in the material so as to realize the transistor effect. So a transistor appears to be a novel use of a law of nature.

But the movement of electrons in crystalline materials with impurities was not well understood until the transistor had been fabricated and studied; in fact, the phenomenon continues to be better understood to this day under more study. Is a natural law that had no manifestation in nature prior to a human-constructed invention, and that was not understood as a natural law until after such construction, a Platonic Form? It seems to me questionable to claim that the transistor effect exists and has always existed, timeless and disembodied. To me, this stretches my understanding of the word「exists」beyond the breaking point.

This debate about natural laws dates back a long time. Aristotle, a student of Plato's, questioned the Platonic ideal Forms, arguing that knowledge is based on the study of particular things, and that generalizations arise from that study rather than preexisting in a disembodied Form. Aristotle used the term「natural philosophy」for the study of phenomena in the natural world, what we now call「science.」Aristotle's world of facts is extensible; it can grow with study of the natural world. Plato's world of facts is fixed; all the facts are there as Forms, with many of them still waiting to be discovered.

But it seems that facts can become wrong. Despite being wrong, Newton's second law is amazingly useful. Engineers use it all the time to design cars, airplanes, robots, bridges, toys, and so on. It provides a good model for how particular things behave, as long as they are not traveling near the speed of light and are not being examined at subatomic scales. It cannot be a Platonic Form because it is violated by nature. It can, however, constitute knowledge in the Aristotelian sense because it generalizes nicely the behavior of macroscopic objects.

[2] My former PhD thesis advisor, Dave Messerschmitt, once told me that when you publish a book, every equation you put in the book cuts your readership in half. I will call this principle「Messerschmitt's Law,」although Dave tells me he did not discover this law. But I first heard it from him. Throwing caution to the wind, I am putting in an equation, but in an attempt to have some discipline, I will number each equation with an estimate of the remaining readership. Here, I've assumed optimistically a starting readership of 8,192, so the presence of this equation has cut it to 4,096. The next equation will be numbered 2,048. These are powers of 2 to make it easier to evenly divide by 2 each time and to underscore that I really am a nerd. If and when I get down to equation (1), I can write whatever I want because I will presumably have no more readers. As a side note, my PhD thesis had several dozen equations in it. It makes me wonder whether Dave ever read it.

[3] Shockley moved in 1956 from New Jersey to Palo Alto, California, and started Shockley Semiconductor Laboratory in what would later become known as Silicon Valley. Eight of Shockley's employees left his company in 1957, the year I was born, to found Fairchild Semiconductor, the first successful high-tech company in Silicon Valley. Many other Silicon Valley giants, including Intel, were founded by former Fairchild employees. Arguably, Shockley's move to Palo Alto was the founding of Silicon Valley.

[4] And then become embarrassed when those heroes disappoint us, as Shockley did by becoming a proponent of eugenics later in his life.

1.3 设计和发现

与西蒙的「人工科学」相比，「自然科学」研究的则是大自然赋予我们的东西。其目标是揭示那些独立于人类而存在的「自然的奥秘」。这些奥秘既不占用时间，也不占用空间；它们不是在被发现的时候产生的，也不是在被发现的地方存在的。

然而，认为这些自然的奥秘无形存在的想法至少可以追溯到柏拉图时代。柏拉图假定了理想的「型相」，并认为客观的和永恒的真理是不可能被完全知晓的。柏拉图认为这些「型相」是唯一的客观真理，而「哲学家」（知识的爱好者）的最终目标就是理解这些型相。这些型相代表了最准确的现实，而且柏拉图把对这些型相的理解称为「善」。

著名的柏拉图《洞穴之喻》（见图 1.4）说明，人类对现实的感知总是不完美的。在这个寓言故事中，囚徒们背靠一堵矮墙被锁在一起（图的右下角）。他们的头朝向洞穴的空白墙壁，墙上有火光（上中部）照射所产生的影子（右上）。这些影子是矮墙后面被操纵的木偶和人物在火光下形成的，而洞穴墙壁上的影子构成了囚徒们体验的唯一现实知识。如果一个囚徒被允许回头并可以看到创造光明的火焰，那么他将拒绝接受火焰或木偶投射出影子的现实。如果囚徒进一步被允许离开洞穴，那么他将会被太阳蒙住眼睛，并进一步抗拒外部「理想」世界的现实。假如一个囚徒确实接受了他所接触到的一些真相，并试图将这些真相传达给矮墙后的那些囚徒，那么他们会认为他的想法是荒谬的，并且会拒绝接受。

图 1.4 柏拉图的《洞穴之喻》，萨恩列达姆，1604 年，大英博物馆。

这则寓言强调了实现善的困难，并解释了为什么那些成功说服他人相信一些新发现的、看似客观事实的人，例如我们这个世界的爱因斯坦和玻尔，最终会被认为是英雄。

西蒙将客观真理与人工现象做了对比。他认为，「如果自然现象在服从自然法则的过程中有一种‘必然性'的意味，那么人工现象在受环境影响的可塑性方面则有一种‘偶然性'的意味」。然而，它们「服从于自然法则」的先决条件是，不论是否可以被认识到，自然法则都是柏拉图式的、无形的存在。

一种截然相反的观点认为，自然法则是人类创造的模型，用来描述物理世界的运作方式。这一观点在过去几十年里得到广泛传播，它或许是从托马斯·库恩于 1962 年出版的具有开创性和争议性的著作《科学革命的结构》开始的。该书假设科学理论是由「范式」构成的，而范式则是人类思考世界的方式。

在上述两种情况下，称自然规律为「法则」会令人觉得有点儿奇怪。就如同公民必须遵守国家法律一样，大自然也一定要遵循自然法则。那么，当大自然违背自然法则时会发生什么呢？违背了自然法则，大自然也不会受到惩罚！相反，自然法则却变得没有效力了。我们设想一个国家是这样运作的，每当司机超速时，限速就会失效。但是「自然法则」会怎样呢？一个理想的真理怎么会变得无效呢？然而，我们的确已经多次看到自然法则失效的情形了。

牛津大学物理学家戴维·多伊奇是量子计算的先驱，他在 2011 年出版的《无穷的开始》一书中认为，科学更多是关于「好的解释」的，而并非关于自然法则的。多伊奇将这些解释归因于人类，而不是一些早已存在的、无形的真理：

本质上，发现一种新的解释就是一种创造性活动。（多伊奇，2011:7）

相比之下，「自然法则」的作用更为卑微，它们不过是将过去与未来的联系编纂成文罢了：

任何流传的关于未来和过去的所谓自然法则 —— 无论是对是错 —— 都声称它们彼此「相似」，都符合这一法则。（多伊奇，2011:6）

多伊奇进一步驳斥了经验主义的观点，并认为自然法则和好的解释都并非源于对物理世界的观察：

经验对于科学而言确实是必不可少的，但是，经验所起的作用与经验主义所设想的不同。它不是理论的来源。它的主要用途是在已经被猜想的理论之间做出选择。（多伊奇，2011）

在这里，多伊奇的观点呼应了奥地利籍英国科学哲学家卡尔·波普尔（1902-1994）早期提出的论点。波普尔指出，这些关于自然的猜想和假设来自「创造性直觉」，只有在它们被提出之后才能得到经验的验证（波普尔，1959）。多伊奇认为，物质世界中的大多数现实并不是任何人都能直接观察到的。例如，太阳中的黑洞、夸克和核聚变等现象，包含着人类从未经历过的规模、力和温度。它们就像柏拉图型相那样难以接近，充其量只能像墙上的影子那样被观察到。不可能是对黑洞的观察导致我们提出了有关黑洞的理论，因为我们无法直接真实地观察它们。

柏拉图认识到，型相的理想真理不可能被人类完全了解。因为它们不可能被人类完全了解，所以，我们把对自然的认识看作人类构建的模型或多伊奇所说的解释不就更加实际吗？这会使我们谦逊地承认，即便我们那些最坚定的关于自然的信念也有待改进。请读者不要误解我的意思，我并不是说不存在真理，而是说我们应该对真理永远保持质疑的态度。

这种谦逊是维基百科集体智慧模式内在固有的特质。任何个人，任何权威，无论他声名多么显赫，都不能被认为是「真理」的持有者。知识应该也必须进化。随着知识的进化，「真理」不也在进化吗？当然，现实主义者可能会回答说，进化的是信念，而不是知识。对那个现实主义者来说，一个信念如果不是真实的，它就不应该是（而且从来都不是）知识。

多伊奇指出，对权威的尊重早在启蒙时代就被经验主义取代了。经验主义的思想和理论都是建立在检验和经验的基础上的。但他认为，仅凭经验是不够的，因为物理世界大部分都是在无法支持人类生存的条件下运作的，因此无法被直接体验。

经验主义从来都没有达到把科学从权威中解放出来的目的。它否认了传统权威的合法性，这是有益的。但不幸的是，它又建立了另外两个错误的权威 —— 感官体验和虚拟的「推导」过程，如归纳法等，即人类头脑里的想象被用来从经验中提炼理论。（多伊奇，2011）

多伊奇再次呼应了波普尔的观点，他认为知识不是从经验中获得的，而是从一个基本的创造性的猜想过程中获得的。通常在很久以后，人们往往用一些精心设计的实验来支持猜想（通常是由于不能伪造它们）。这种有目的的实验通常只能观察到间接的副作用。换句话说，知识是被设计出来的。

下一章将重点讨论模型在科学和工程中所起的作用，但就目前而言，设计和发现之间存在着一种紧张关系。有些人工现象不是被刻意设计出来的，而是在人类活动中偶然出现的。例如，经济学领域就充满了对这种涌现现象的研究。这些人工现象的运作规则可以说是被发现的，而不是被设计出来的。虽然有许多其他的人工现象的确是被设计出来的，但它们也会受到自然法则的支配，而自然法则至少在柏拉图式的观点中是必须被发现的。但是，我们对自然法则的认识是不完善的，所以我们必须用数学的方法来构建这些法则的模型。难道这些模型不是被设计出来的吗？

众所周知，艾萨克·牛顿爵士的运动定律现已为大自然所违背，因为它们在相对速度和量子尺度下会失效。这些定律以数学公式的形式出现，例如牛顿第二定律：

F = ma, (4 096)

这一定律表示力等于质量乘以加速度。这看起来很像一种柏拉图式型相的表达，但它是错误的！尽管它是错的，我们还是会毫不犹豫地说牛顿「发现了」它。如果我们说牛顿「发明了」它，那么人们一定会觉得我们很可笑。

对于某些现象，我们会毫不犹豫地使用「发明」这个词来表达发现了它们的意思。以贝尔实验室的约翰·巴丁、沃尔特·布拉顿和威廉·肖克利（见图 1.5）发明晶体管为例。他们「由于对半导体的研究和对晶体管效应的发现」而获得了 1956 年的诺贝尔物理学奖。他们用一种由金和锗材料制成的器件演示了晶体管效应，尽管今天晶体管的实现主要是使用掺杂了特定杂质的硅晶体。请注意诺贝尔奖颁奖词中的谨慎措辞，「他们发现了晶体管效应」。诺贝尔奖好像并不是为发明而颁发的，而仅仅是为发现而颁发的。然而，我们大多数人会说晶体管是 20 世纪 50 年代在贝尔实验室被发明的。

但事实上，朱利叶斯·利林菲尔德在 1925 年发明了一种现在被称为场效应晶体管（FET）的晶体管，并在 1930 年获得了一项美国专利的授权（利林菲尔德，1930）。因此，如果晶体管效应是一种柏拉图式的型相，那么它实际上是由朱利叶斯·利林菲尔德在更早的时候发现的。但专利并不是为发现而颁发的，而是为发明而颁发的。根据美国专利和商标局的规定，人们不能为「自然规律、自然现象和抽象概念申请专利」。当然，专利可能是为自然法则的一种「新用途」而颁发的，因为任何事物都可能受到自然法则的约束，这种新颖的用途就是一项发明，而不是一项发现。

公平地讲，对诺贝尔奖委员会而言，利林菲尔德发明的场效应晶体管实际上与巴丁、布拉顿和肖克利开发的晶体管有着显著差异。

图 1.5 约翰·巴丁、沃尔特·布拉顿和威廉·肖克利因发现晶体管效应而获得 1956 年诺贝尔物理学奖。

贝尔实验室研究的晶体管是一种今天被称为双极型晶体管的晶体管。有趣的是，由于双极型晶体管对能量的要求较高，其现在的应用已经变得非常小众了。而场效应晶体管的使用则更为普遍，并已成为数字技术的主力军。在今天，一部苹果手机里可以有数十亿个场效应晶体管。

发明和发现以这种方式变得混乱的情形并不少见。一种思想的知识历史很少是清晰的，然而，作为一种文化，我们应该坚持挑选出那些把这些思想带到前台的「精英」。发现和发明之间的紧张关系由来已久。晶体管效应是一种一直存在并有待被发现的「自然现象」吗？据我所知，还没有人在自然界中发现过由金和锗构成的「三明治」或用作晶体管的掺杂硅。所以晶体管一定不是一种自然现象。但当这些「三明治」被人类制造出来的时候，自然就会接管并调节这些材料中的电子流动，从而实现晶体管效应。因此，晶体管似乎是自然法则的一种新颖应用。

但是，直到晶体管被制造和研究之后，人们对电子在掺杂过的晶体材料中的运动才有了更好的理解。事实上，直到今天，随着更多研究的开展，人们对这一现象的了解还在不断加深。自然法则是指在人类创造发明之前在自然界中没有表现出来的法则，而且是在这样的创造之后才被理解的法则。这是一个柏拉图型相吗？然而，在我看来，声称晶体管效应一直存在，而且是一种永恒的、无形的存在的说法是有问题的。对我来说，这一说法已经超出我对「存在」这个词的理解极限。

这场关于自然法则的争论由来已久。亚里士多德是柏拉图的学生，但是他对柏拉图式的理想型相进行了质疑，并认为知识是建立在对特定事物进行研究的基础之上的，归纳的知识是从这种研究中产生的，而不是以一种无形的型相预先存在的。亚里士多德将对自然界中的现象的研究称为「自然哲学」，也就是我们现在所说的「科学」。亚里士多德的事实世界是可扩展的，它随着人们对自然世界的不断研究而增长。然而，柏拉图的事实世界是固定不变的，所有的事实都以型相的形式存在着，且其中的许多仍然有待被发现。

但是，事实似乎可能会出错。以牛顿第二运动定律为例，尽管它是错误的，但是仍然非常有用。工程师们一直在用它设计汽车、飞机、机器人、桥梁、玩具等等。它为刻画特定事物的运动行为提供了一个很好的模型，只要它们的运动速度没有接近光速，就不需要在亚原子刻度上被检验。但是，牛顿第二运动定律不可能是柏拉图式的型相，因为它已然被自然违背。然而，牛顿第二运动定律可以构成亚里士多德意义上的知识，因为它很好地归纳了宏观对象的行为。

1『这里对柏拉图「知识」和亚里士多德「知识」的阐释醍醐灌顶，所以才说亚里士多德是科学的鼻祖。这里的信息值得反复研读。（2021-10-24）』

### 1.4 Engineering and Science

Simon says that design is about「changing existing situations into preferred ones.」But what do we mean by「preferred」situations? In political systems, this may be highly subjective. In engineered systems, it may be much more objective. A political leader may prefer a situation where all immigrants are kept out, even when there is no objective evidence that this makes anything better for anyone. Engineers, by contrast, are often called on to defend their preferences with objective measures, such as lower cost or reduced energy consumption. Simon's「preferred situations」are open. But it is not uncommon in popular culture to assume that engineers primarily optimize preexisting designs. A somewhat silly joke underscores this point:

Question : What is the difference between an optimist, a pessimist, and an engineer?

Answer : An optimist sees a glass half full. A pessimist sees a glass half empty. An engineer sees a glass that is twice as big as it needs to be.

This joke plays on our preconception that engineers prefer whatever costs less. Many engineered systems, however, are「preferred」despite lacking any objective measures showing them to be better than preceding「existing situations.」Apple's iPhone, for example, did not make phone calls better than its Nokia predecessors, and its battery life was distinctly shorter. And it certainly didn't cost less! It was「preferred」because of nonobjective properties. It was fundamentally a creative contribution to humanity, not an optimization. And yet it was most certainly an engineered artifact.

When using the phrase「sciences of the artificial」for the creation and study of human-made phenomena, Simon laments the pejorative connotations of the term「artificial,」saying「our language seems to reflect man's deep distrust of his own products.」Arguably, distrust of the products of nature is equally justified, as suggested by the poem 「Unnatural」 by Stephen Dunn. But as a father of teenagers with iPhones, I can attest that distrust of the artificial is real. Trusted or not, there is no question that smartphones are transformative. The iPhone (and its subsequent competitors), together with other recent innovations in wireless communications and computer systems, enable us to carry nearly all of human published information in our pockets. To call this「transformative」seems like an extraordinary understatement. It is much more a triumph of engineering,「the sciences of the artificial,」than of the sciences of the natural. Yet there is little, if any, invention in the iPhone. Nearly every important aspect of the phone existed already in other products when it was introduced. The iPhone is much more the result of design than either invention or discovery.

UNNATURAL

I'm sure Nature has disapproved of me for years, as if it had overheard one of my silent screeds against it, and my insistence that only the artificial has a real shot at becoming more than we started with, designed, revised, something completely itself. If it could speak, Nature might say it contains lilies, the strange beauty of swamps, the architectural art of spiders, the many et ceteras that make the world the world. Nothing man-made can compete, Nature might say. Oh Nature has been known to go on and on. And if it wanted to push things further, it could cite our sleek perfection of bombs and instruments of torture, our nature so human we hide behind words that disguise and justify. But that's as generous as I want to be in giving Nature its say. I've seen it randomly play its violence card — natural, no-motive crimes with hail and rain and vicious winds, taking out, say, trailer courts and playing fields and homes for the elderly. So I want to be heard and overheard, this time for real, out loud, in fact right in Nature's face, to say I prefer the artifice in what's called artificial, the often concealed skill involved, without which we'd have no accurate view of ourselves, or of lilies in the pond.

— Stephen Dunn

Yet in current Western culture, it seems that most people respect an inventor more than an engineer and a scientist more than an inventor. Colin Macilwain, in an article in Nature , attributes to William Wulf, former president of the U.S. National Academy of Engineering, the following statement:

There is a general attitude among the scientific community that science is superior to engineering. (Macilwain, 2010)

This attitude spills out from the scientific community to the general culture. We use the term「rocket scientist」for extremely smart people, although most of what the people who put together the space program do is engineering. Macilwain goes on,

Wulf attributes this partly to the「linear」model of innovation, which holds that scientific discovery leads to technology, which in turn leads to human betterment. This model is as firmly entrenched in policy-makers' minds as it is intellectually discredited. As any engineer will tell you, innovations, such as aviation and the steam engine, commonly precede scientific understanding of how things work.

It is hard to point to any scientific discovery that led to the iPhone, in the sense that every scientific discovery it depends on was already in widespread use in other products. Nevertheless, it is easy to find evidence that popular culture assumes that this linear model of innovation is in fact how things work. For example, About.com, an advertising-funded website centered around articles on a huge variety of subjects, collects reader commentary. On the question of「Engineer vs Scientist - What's the Difference?」some of the reader answers are: [5]

Scientists are the ones who create the theories, engineers are the ones who implement them. They compliment [sic] each other…

Science is a lot of high level theory and engineering is implementation and optimization.

Engineers deal with math, efficiency and optimization while Scientist [sic] deal with「what is possible.」

Engineers trained [sic] for Using tools, where Scientists are trained for Making them.

Scientists develop theories and work to verify them, Engineers search in these theories to「optimize」things in real life.

A scientist invents a law and an engineer applies it.

Scientist for invention of new theories [sic]. Engineers for applying those theories for piratical [sic] applications.

These views are clearly not authoritative, but rather are reflective of popular perception. Note the contrast between the style of this website and that of Wikipedia. This one is a portal for individual wisdom (and stupidity), whereas Wikipedia is a portal for collective wisdom.

Kuhn, a highly regarded historian of science and a philosopher, in his 1962 book, The Structure of Scientific Revolutions , echoed what Wulf claimed was the「general attitude among the scientific community,」stating that certain kinds of scientific measurement tasks are「hack work to be relegated to engineers or technicians」(Kuhn, 1962). To Kuhn, clearly engineers were a rung down the ladder from scientists. But like his repeated reference in the same text to scientists as「men,」we can forgive this disparaging remark about engineers because at the time he was writing, this view was standard in contemporary culture and had a strong element of truth.

Kuhn addressed the question of what is science, stating,「to a very great extent the term ‘science' is reserved for fields that do progress in obvious ways.」But, he points out, many fields progress in obvious ways:

Part of our difficulty in seeing the profound differences between science and technology must relate to the fact that progress is an obvious attribute of both fields.

Kuhn rejects the pervasive idea that the progress of science is toward some Platonic truth:

We may … have to relinquish the notion, explicit or implicit, that changes of paradigm carry scientists and those who learn from them closer and closer to the truth.

If truth is not the goal, then what gives「progress」its directionality? Kuhn postulates that science may actually have no goal, an observation that he recognizes will be difficult for many people to swallow.

We are all deeply accustomed to seeing science as the one enterprise that draws constantly nearer to some goal set by nature in advance.

He then draws an analogy between the progress of science and Darwin's theory of evolution:

The Origin of Species recognized no goal set either by God or nature.

The lack of a goal for science may be a shock, but for technology, it seems easier to accept. It is hard to postulate any ultimate Platonic「truth」of technology, any goal that when reached finishes the field. Technology progresses if once it is known how to make certain things, this knowledge is not forgotten.

In a 1984 book, the philosopher John Searle supports Wulf and Kuhn about this twentieth-century view of science:

「Science」has become something of an honorific term, and all sorts of disciplines that are quite unlike physics and chemistry are eager to call themselves「sciences.」A good rule of thumb to keep in mind is that anything that calls itself「science」probably isn't — for example, Christian science, or military science, and possibly even cognitive science or social science. (Searle, 1984, p. 11)

Spencer Klaw, in his 1968 book, The New Brahmins — Scientific Life in America , writes about「the awe that scientists now inspire,」where

science has become a form of established religion, and scientists its priests and ministers. (Klaw, 1968, p. 12)

Many disciplines seek to emulate the methods of science, hoping for similar payoffs. The「scientific method,」where a hypothesis is formed and experiments are designed to attempt to falsify the hypothesis, is useful in many disciplines that have little connection with natural science. But the value of the scientific method is often not as great in these nonsciences. Referring to social science, Searle observes,「the methods of the natural sciences have not given the kind of payoff in the study of human behavior that they have in physics and chemistry」(Searle, 1984, p. 71).

Popper, before Kuhn, stressed that the core of the scientific method is falsifiability. A theory or postulate is scientific only if it is falsifiable, according to Popper. To be falsifiable, at least the possibility of an empirical experiment that could disprove the theory must exist. For example, the postulate that「all swans are white」is not supported by any number of observations of white swans. But the postulate is falsifiable because an experiment may find a black swan. Hence, it is a scientific theory, albeit a false one.

Kuhn rejects Popper's conclusion that a scientific theory is rejected by falsification, arguing that even in the face of evidence against it, a theory will not be rejected until a replacement theory is invented:

[T]he act of judgment that leads scientists to reject a previously accepted theory is always based upon more than a comparison of that theory with the world. The decision to reject one paradigm is always simultaneously the decision to accept another, and the judgment leading to that decision involves the comparison of both paradigms with nature and with each other. (Kuhn, 1962, pp. 77–88)

Kuhn is saying that even if an experiment seems to falsify a hypothesis, scientists will not reject the hypothesis until they have a replacement hypothesis. He says,「If any and every failure to fit were ground for theory rejection, all theories ought to be rejected at all times.」

Popper's emphasis on using experiments to falsify hypotheses is healthy. Well-constructed experiments undermine astrology, phrenology, and many other pseudosciences. But as Kuhn points out, experimental evidence is always subject to interpretation. If there is no new paradigm aligning with the experiments, then the experimental results are more likely to be viewed as errors than falsifications.

Experiments are also useful in the「sciences of the artificial.」Engineers and computer scientists do perform experiments but not usually with an eye toward falsification or to compare against nature. The mere fact that you do experiments does not make you a scientist.

In its narrower usage, as reflected by the Merriam-Webster definition previously quoted, the word「science」refers to the study of nature, not to the study or creation of artificial artifacts. Under this interpretation, many of the disciplines that call themselves a「science,」including computer science, are not, even if they do experiments and use the scientific method.

To be sure, beginning with the information technology revolution in the 1990s, the role of engineering has been changing. I believe that this is because digital technology and software have created an explosion of possibilities in the「sciences of the artificial.」There is nothing natural about being able to communicate instantaneously with another person nearly anywhere on the planet. There is nothing natural about being able to see inside the human body. There is nothing natural about being able to carry all of human published information in your pocket. These are all the results of engineering more than science. More important, they are creative products, not inevitable consequences of scientific discovery.

Nevertheless, science still captures our imaginations and delivers spectacular results. The announcement on February 11, 2016, of the detection of gravitational waves emitted by colliding black holes, for example, got a great deal of press (see, e.g., the New York Times article by Overbye [2016]). Gravitational waves were predicted by Einstein more than a century ago, but detecting them has turned out to be astonishingly difficult. The announced detection was accomplished by the Laser Interferometer Gravitational-Wave Observatory (LIGO), at a cost of approximately $1.1 billion. The detected wave lasted one fifth of a second, and analysis indicates that it was produced by a collision between two black holes a billion light years away. This style of science is unlikely to have the practical consequences that early twentieth-century science had. It is「pure science,」in that it seeks knowledge for its own sake.

As might be expected, the high cost of this project has drawn some criticism. Horgan (2016) subtitled his column that reported this result in Scientific American

Was the gravitational-wave experiment worth its $1.1-billion cost if it merely confirms that Einstein was right?

In his article, he quotes chemist Ashutosh Jogalekar, who blogs as Curious Wavefunction:

Some sources are already calling the putative finding one of the most important discoveries in physics of the last few decades. Let me not mince words here: if that is indeed the case, then physics is in bad shape.

Horgan goes on:

In an email to me, a historian of technology was more blunt:「So a 100 year old theory has been confirmed experimentally—big whup. Did anyone think Einstein was wrong? There wasn't any controversy, was there? Was anyone credible claiming that spacetime isn't curved, or that black holes don't exist? I can get that this was quite an experimental trick and technological feat. But this isn't doing anything to convince me that public funds spent on this stuff wouldn't be better spent on medical research. Or clean fuels, or any number of things that would apply scientific expertise toward justice or the alleviation of human suffering.

The acknowledgment that this experiment was「quite an experimental trick and technological feat」is interesting. It raises the question, is the contribution of LIGO science or engineering? The basic method used, laser interferometry, has been understood by scientists as a way to measure gravitational waves since the 1970s. But building a system with adequate sensitivity was not easy.

Given that Einstein's model predicted gravitational waves 100 years ago, that there seems to be no controversy among scientists about the correctness of this prediction, and that the laser interferometry technique for measuring gravitational waves has been known for decades, it may appear that no new science resulted from the $1.1 billion investment. But it is probably not the validation of the existence of gravitational waves that is really the scientific contribution, but rather the demonstration of a new modality for observing events in the universe that were previously invisible to us. Specifically, this experiment has given the first observation of two black holes merging. That such events occur is perhaps not surprising, but most certainly intellectual value can be found in the first demonstration of a new kind of telescope into the universe that is capable of observing such events.

So instead, we should probably view the $1.1 billion as an investment in the engineering of a new device that can now enable a new form of astronomical observation. And the device is quite a triumph of engineering.

Let me try to explain the magnitude of the engineering challenge that the LIGO team faced. First, two detectors were built 3,000 kilometers apart so that the difference in time of arrival of gravitational waves at the two detectors would provide an indication of the direction of the source, and so that entirely independent observations could corroborate each other. Building two detectors can't be more than twice as hard as building one, so this was not the biggest challenge.

Each detector consists of an L-shaped ultra-high-vacuum cavity 4 kilometers long on each side (this alone is not easy to build; see figure 1.6 ). It uses laser interferometry to measure extremely slight distortions in space-time caused by passing gravitational waves; these distortions change the distance between the two ends of the 4-km cavity ever so slightly, by much less than the diameter of a proton! By measuring this change in distance, once all other possible causes for the change in distance have been eliminated, one can infer that the change in distance was caused by a passing gravitational wave distorting space-time. To minimize spurious causes for changes in distance, each detector has to be completely isolated from sources of vibration such as seismic events and human activity such as automotive traffic. Even the most minor such vibration would render the instrument useless.

It is hard to make the case that a gravitational wave telescope will improve (or even affect) the human condition in any tangible way. Nevertheless, the project may in fact have practical and tangible impact by contributing improvements in engineering methods. The ability to detect such extremely small variations in distance surely has applications elsewhere.

Figure 1.6 LIGO gravitational wave detector in Livingston, Louisiana. [Courtesy Caltech/MIT/LIGO Laboratory.]

NASA, whose main mission (I believe) is space exploration in the name of science, frequently uses their contributions to technology development as further justification for the expenditure on space exploration. They claim contributions to light-emitting diodes (LEDs), infrared ear thermometers, artificial limbs, ventricular assist devices, anti-icing systems for aircraft, safety grooving on highways, improved automotive tires, chemical detectors, land mine removal, firefighter gear, and many other technologies (NASA, 2016). To me, this reads as a substantial contribution to technology, irrespective of the contribution to science.

Assuming that LIGO is a triumph, who is the hero? The article announcing the measurement of gravitational waves in Physical Review Letters , published on February 11, 2016, has 1,019 authors (Abbott et al., 2016). The author list occupies 5 of the 16 pages of the article. It is hard to identify an「Einstein」from this list. According to the Boston Globe , Rainer Weiss, now a Professor Emeritus at MIT, is credited by many scientists with being the mastermind of the project, over significant protests from Weiss, who demurs that many people contributed a great deal (Moskowitz, 2016). Assuming Weiss is right, the LIGO project is a form of collective rather than individual wisdom, much like a Wikipedia article. And it is likely that most of these authors would self-identify as「scientists」and not as「engineers.」To me, most if not all of these 1,019 authors are engineers as well as scientists, defying Platonicity.

An engineered artifact such as an iPhone is similarly a form of collective wisdom. It is impossible to identify all the individuals who contributed significant technical content to the iPhone, but I'm sure it is many more than 1,019.

In a famous essay, Leonard Edward Read (1898–1983), libertarian and founder of the Foundation for Economic Education (FEE), accounted for the technical contributions required to make a humble wooden pencil (Read, 1958). Written from the point of view of the pencil, it starts with,「Not a single person on the face of this earth knows how to make me.」He then chronicles the processes and materials that go into fabricating a pencil:

My family tree begins with what in fact is a tree, a cedar of straight grain that grows in Northern California and Oregon. Now contemplate all the saws and trucks and rope and the countless other gear used in harvesting and carting the cedar logs to the railroad siding. Think of all the persons and the numberless skills that went into their fabrication: the mining of ore, the making of steel and its refinement into saws, axes, motors; the growing of hemp and bringing it through all the stages to heavy and strong rope…

He goes on to explain how the wood is milled, kiln dried, and tinted; how the graphite is mined and then mixed with clay and sulfonated tallow; how the lacquer paint is made from castor beans and castor oil; how the label is made with carbon black mixed with resins; how the metal is mined and refined; and how the eraser is made from rape seed oil, sulfur chloride, rubber, pumice, and cadmium sulfide.

And an iPhone is much more complicated than a pencil. Evidently, even Steve Jobs wouldn't know how to make an iPhone (or even a pencil). In a reference to the「invisible hand」of the economist Adam Smith (1723–1790), Read continues:

There is a fact still more astounding: The absence of a master mind, of anyone dictating or forcibly directing these countless actions which bring me into being. No trace of such a person can be found. Instead, we find the invisible hand at work.

Such an engineered artifact is an embodiment of collective wisdom even more extreme than Wikipedia, where at least a log is kept of the individual contributions.

Although we can't even trace the forces behind the invisible hand, widespread recognition exists that many of these forces are driven by people's technical skills. Cultivating such talent is a prerequisite for a modern economy. Today, policymakers and much of the public recognize the value in Science, Technology, Engineering, and Mathematics (STEM) education. This term bundles together a broad set of technical disciplines. It still puts Science first, but this may be as much about being able to pronounce the acronym as it is about relative priorities. Indeed, Liana Heitin blogs that STEM was originally SMET, which perhaps better reflected perceived priorities but was not so euphonious (Heitin, 2015).

Much of the political motivation in STEM may be pragmatic; it's more about being able to get jobs than it is about intellectual search. But we may be underestimating the intellectual search that is intrinsic in the「sciences of the artificial.」Without the engineering tour-de-force of the LIGO project, we would not have humankind's first gravitational telescope. Maybe this telescope will reveal other colliding black holes and other phenomena that may help us better understand the origin of the universe. So indeed, sometimes engineering does precede science rather than the other way around.

We see many other indicators of a shifting attitude toward technology and engineering. In the twentieth century, an「institute of technology」would be viewed as primarily a vocational school rather than a center of intellectual activity. MIT and Caltech changed that notion, and we are even starting to see「technical high schools」emerge as much more than vocational training.

Technology and engineering are distinctly not about discovering preexisting, disembodied truths. They are about creating things, processes, and ideas that never before existed. Pursuit of the Platonic Good, the preexisting, fixed world of Forms, is no longer what is driving humanity forward. We are instead creating knowledge and facts that never before existed, embodied or not.

In the next chapter, I focus on the relationship between discovery and invention. A key theme of that chapter is to understand the role of models in engineering and science. My essential claim is that models are invented, and when those models are modeling physical phenomena, the corresponding physical phenomena, not the models, are discovered. And even those physical phenomena may be brand new, as was the case with the transistor.

[5] http://chemistry.about.com/od/educationemployment/fl/Engineer-vs-Scientist-Whats-the-Difference.htm , updated June 29, 2015, retrieved March 1, 2016.

1.4 工程和科学

西蒙认为，设计就是「将现有情况转变为优选情况」。但是我们所说的「优选」情况是什么意思呢？在政治体系中，这可能是非常主观的。在工程系统中，其可能更加客观。一个政治领袖可能更喜欢将所有的移民拒于门外的局面，即使没有客观证据表明这样做会给任何人带来什么好处。相比之下，工程师则常常被要求以客观的标准来实现他们所希望的「优选」情况，例如降低成本或降低能耗等。西蒙所说的「优选情况」是开放性的。但在大众文化中，认为工程师主要是优化现有设计的看法并不少见。下面这个有些幽默的笑话恰好强调了这一点：

问：乐观者、悲观者和工程师之间有什么区别吗？

答：乐观者看到的是一个半满的玻璃杯。悲观者看到的是一个半空的玻璃杯。而工程师看到的则是玻璃杯比实际需要大了一倍。

这个笑话源于我们脑子里对工程师的成见，即工程师喜欢成本更低的那些产品。尽管缺乏任何客观的衡量标准表明工程系统比「现有的情况」要好，但是许多工程系统仍被认为是「优选的」。例如，苹果手机并没有比诺基亚手机更好用，电池续航时间还明显更短，而且价格也不便宜！人们说苹果手机是「优选的」手机，是因为其具有一些非客观的属性。从根本上说，它是对人类的一种创造性贡献，而不是一种优化。然而，它无疑是一件工程制品。

当使用「人工科学」一词来指称创造和研究人工制品的时候，西蒙为「人工」一词的贬义含义感到惋惜，他说：「我们的语言似乎反映了人类对自己产品的极度不信任。」可以说，对自然产物的不信任同样合理，正如下面的这首诗所暗示的那样。但是，作为一位拥有苹果手机的青少年的父亲，我可以证明对人工制品的不信任是真实存在的。不管是否可信，毫无疑问，智能手机是变革性的人工制品。苹果手机（及其后来的竞争对手）以及最近在无线通信和计算机系统方面的其他创新，使得我们能够将几乎所有人类曾经发布的几乎所有信息都装在口袋里。将其称为「变革性的」似乎太过于轻描淡写了。这是工程学 ——「人工科学」的胜利，而不是自然科学的胜利。然而，我们不得不承认，苹果手机里几乎没有任何新的发明。当苹果手机上市的时候，它的每一项重要功能几乎已经存在于其他产品中了。苹果手机更多是设计的结果，而不是发明或发现。

非自然

斯蒂芬·邓恩

我确信这些年来，自然早就不再喜欢我了，

似乎它无意中听到了我对它的一些沉默而冗长的心声。

我坚信只有人工技艺才能真的丰富造物主最初创造、设计及修正的世界。

如果自然能够开口讲话，它也许会说，

瞧！那娇媚的百合、凄美的沼泽还有神奇的蜘蛛网，

就是这一切构成了世界的本来面目，

这是任何人工技艺都无法比拟的。

自然就是这么周而复始地运行着。

如果自然想要再说些严厉的字眼儿，

它可能会举出人工技艺的种种劣迹，

看看人类制造出的光滑完美的炸弹吧，

还有那些折磨人的酷刑工具。

我们的本性是如此人性，

我们隐藏在伪装和辩护的言辞背后。

我们对自然总是充满溢美之词。

但是，我在慷慨地赞美自然的同时，

也会指出它的冷漠。

看看它的那些暴力行为吧，

冰雹、大雨和狂风

足以顷刻间破坏拖车营地、运动场以及老年人的家园。

我这次真的要面对自然大声说出我的心声，

真心希望自然能够听到我的话语。

我想说，我更喜欢那些人工技艺。

那些通常隐藏着的技巧。

没有它们，人类无法真正地认知自我，

也无法欣赏自然的鬼斧神工。

然而，当今的西方文化中有这样一种司空见惯的现象，大多数人似乎更尊重发明家而不是工程师，更尊重科学家而不是发明家。科林·麦基尔文在《自然》杂志的一篇文章中，将此归因于美国国家工程院前院长威廉·伍尔夫，声明如下：

科学界普遍认为科学优于工程。（麦基尔文，2010）

这种态度从科学界蔓延到一般文化领域。我们常用「火箭科学家」这个词形容非常聪明的人，尽管大多数太空计划的参与者所做的都是工程。麦基尔文继续说：

伍尔夫认为此现象在一定意义上归因于创新的「线性」创新模式。该模式认为，科学发现会导致技术的进步，而技术进步反过来又会推动人类的发展。这种模式在决策者的头脑中根深蒂固，就如同它不被知性地信任一样。正如任何一位工程师都会告诉你的那样，诸如航空和蒸汽机等创新，通常都早于对事物如何运行的科学理解。

很难具体指出是哪一项科学发现最终促成了苹果手机的出现，因为它所依赖的每一项科学发现都已经在其他产品中得到了广泛的应用。然而，我们很容易找到足够的证据，证明流行文化认为这种线性创新模式实际上就是事物的运作方式。例如，About.com 是一个由广告资助的网站，其围绕着各种各样的主题收集读者的评论。在其中一项关于「工程师和科学家 —— 区别是什么？」的问卷调查中，一些读者给出如下回答：科学家是创造理论的人，工程师是将理论运用于实践的人。他们简直是在互相恭维（原文如此）……

科学是许多高层次的理论，而工程则是实现和优化。

工程师处理数学、效率和优化，而科学家处理「什么是可能的」。

工程师受过使用工具的训练，而科学家受过制造工具的训练。

科学家创造理论并努力去验证理论，工程师在这些理论中不断地探索以「优化」现实生活中的事物。

科学家发明法则，而工程师则应用法则。

科学家发明新的理论，工程师将这些理论运用于实际。

上述这些观点显然并不具有权威性，而是在一定程度上反映了大众的普遍看法。请读者对比一下这个网站和维基百科的风格。显然，这个网站是个体智慧（和愚昧）的入口，而维基百科是集体智慧的门户。

库恩是一位备受尊敬的科学史学家和哲学家，他在 1962 年出版的《科学革命的结构》一书中呼应了伍尔夫关于「科学界的普遍态度」的观点，并指出某些类型的科学测量任务是「降级交给工程师或技术人员去做的苦差」（库恩，1962）。对于库恩来说，工程师显然要低科学家一等。但就像他在同一篇文章中反复提到科学家也是「人」一样，我们姑且原谅他对工程师的这种轻蔑言论，因为在他写作的时候，这种观点在当时的文化中正处于主流地位，并且具有很强的真实性。

库恩在谈及什么是科学的问题时说：「‘科学'一词在很大程度上专门用来指那些以明显的方式取得进展的领域。」但是，他又指出，许多领域的进展都是显而易见的：

我们之所以很难看到科学和技术之间的深刻差异，其中的部分原因一定与这一事实有关：进步是这两个领域都有的一个明显特征。

库恩拒绝接受一种普遍认可的观点 —— 科学的进步正朝着某种柏拉图式的真理发展：

我们可能…… 必须放弃这样一种观念，无论这种观念是显性的还是隐性的，即范式的变化使科学家和那些向他们学习的人越来越接近真理了。

如果真理不是目标，那么是什么赋予了「进步」的方向性？库恩假设科学也许实际上就没有什么目标。库恩认识到，许多人很难接受这一观察结果。

我们都深深地习惯于把科学看作一项不断向大自然预先设定的目标靠拢的伟大事业。

然后，他进一步把科学的进步和达尔文的进化论做了一个类比：

《物种的起源》不承认任何由上帝或自然设定的目标。

科学缺乏目标可能会令人感到震惊，但对于技术而言，这似乎更容易接受，因为我们很难假设任何终极的、柏拉图式的技术「真理」，也很难假设任何在达成目标时就会结束的领域。一旦人们知道如何来做某些事情，这种知识就不会被遗忘，技术就会进步。

哲学家约翰·塞尔在 1984 年出版的一本书中支持伍尔夫和库恩关于 20 世纪科学的观点：

「科学」已经成为一个令人崇敬的术语了，各种不同于物理学和化学的学科都渴望称自己为「科学」。一个很好的经验法则就是，任何自称「科学」的东西都可能不是「科学」—— 例如，基督教科学、军事科学，甚至是认知科学或社会科学等。（塞尔，1984:11）

斯宾塞·克劳在他 1968 年出版的《新婆罗门 —— 美国的科学生活》（The New Brahmins: Scientific Life in Americ）一书中写到了「科学家现在所激发的敬畏」：

科学已经成为国教的一种形式，而科学家则是其神父和牧师。（克劳，1968:12）

许多学科试图效仿科学的方法，希望得到类似的回报。提出一个假设并设计实验试图证伪该假设的「科学方法」，这对许多与自然科学几乎没有联系的学科是有用的。但是，在这些非科学的领域中，科学方法的价值往往并不那么大。塞尔在提到社会科学时指出，「自然科学的研究方法在研究人类行为的方面并没有带来类似于物理学和化学那样的回报」（塞尔，1984:71）。

在库恩之前，波普尔强调科学方法的核心是可证伪性。波普尔认为，一个理论或假设只有在可证伪的情况下才是科学的。要证明是可证伪的，至少应存在一种实证性实验的可能性，以证明这一理论或假设是不成立的。例如，「所有天鹅都是白色的」这个假设是无法通过任何观察到的白天鹅的数量来得到支持的。但是，这个假设是可证伪的，因为某些实验可能会发现一只黑天鹅。因此，尽管它是一个错误的理论，却是一个科学的理论。

库恩驳斥了波普尔关于科学理论会被证伪否定的结论，并认为，即使面对反驳这个科学理论的证据，一个理论也不应该被否定，直到一个作为替代的理论被发明出来：

导致科学家做出拒绝一个先前已接受的理论的判断行为，总是建立在将这个理论与现实世界进行比较的基础之上。拒绝接受一种范式的决定总是同时伴随着决定接受另一种范式，而导致这一决定的判断涉及两种范式与自然以及它们彼此的比较。（库恩，1962:77-88）

库恩旨在表明，即便是一个实验似乎证伪了一个假设，科学家也不会立刻抛弃这个假设，除非他们已经拥有一个用于替代的假设。他认为：「如果有任何不相符之处都是否定理论的理由，那么所有的理论都应永远被否定。」

波普尔强调用实验来证伪假设是有益的这一观点。因为精心设计的实验可以揭露占星术、颅相学以及其他许多伪科学。但是，正如库恩所指出的那样，实验证据总是取决于对它们的解释。如果没有与实验证据相一致的新范式，那么实验结果更有可能被视为是错误的，而并非证明为假。

实验在「人工科学」中也起着十分重要的作用。工程师和计算机科学家确实会进行各种各样的实验，但是，他们通常不会着眼于证伪，或者与大自然做比较。简言之，你开展实验的这一事实并不能使你成为一名科学家。

正如之前《韦氏大词典》中的定义所反映的「科学」一词的狭义含义，科学指的是对大自然的研究，而非对人工制品的研究或创造。按照这样的解释，许多自称「科学」的学科，包括计算机科学在内，即使它们进行实验并使用科学方法，也不能称为科学了。

可以肯定，从 20 世纪 90 年代的信息技术革命开始，工程学的作用就一直在变。我认为这是因为数字技术和软件在「人工科学」中创造了巨大的可能性。现在，不管一个人在地球的哪个角落，他几乎都能与另一个人进行即时交流，这一点儿都不自然。能够对人体内部进行观察也不是自然界的一件事情。把人类发布过的所有信息都装进你的口袋也并非大自然的事情。这些都是工程而不是科学的结果。更重要的是，它们是创新性的产品，而不是科学发现的必然结果。

尽管如此，科学仍然抓住了我们的想象力，并为人类带来令人震惊的结果。例如，2016 年 2 月 11 日，有关探测到黑洞碰撞所产生的引力波的消息被大量报道（参见欧弗拜 2016 年在《纽约时报》发表的文章）。爱因斯坦早在一个多世纪前就预言了引力波的存在，但要探测到它却是异常困难的。该报道所宣布的探测工作是由激光干涉引力波天文台（LIGO）完成的，该项目共耗资约 11 亿美元。探测到的引力波仅持续了五分之一秒，后续的分析表明其是由 10 亿光年以外的两个黑洞碰撞产生的。这种风格的科学不太可能产生 20 世纪初科学所带来的实际成效。它属于「纯科学」，因为它追求知识本身。

不出所料，这一项目投入的高昂成本招致了一些批评之声。2016 年，霍根在《科学美国人》杂志的专栏中以如下副标题报道了这一结果：

如果引力波实验仅仅证实了爱因斯坦是正确的，那么它是否值得 11 亿美元的巨额投入？

在文章中，他引用了化学家阿斯托什·乔加莱卡的一段话，其博客为奇怪的波函数（Curious Wavefunction）：

一些消息源已经称这一公认的发现是物理学近几十年来最重要的发现之一。请允许我在这里直言不讳地说：如果情况真是如此，那么物理学的发展可太糟糕了。

霍根继续写道：

在写给我的一封电子邮件中，一位技术史学家更加直言不讳地说：「因此，一个有着 100 年历史的理论已经在实验中得到证实 —— 这就是巨大的成功。有人认为爱因斯坦错了吗？这并没有产生任何争议，不是吗？有没有人确信地声称时空不是弯曲的，或者黑洞是不存在的？我认为这是一个相当具有实验性的技巧和技术壮举。但是，这并不能让我相信，花费在这件事情上的公共资金并不比将其用在医疗研究，或清洁燃料，或任何能将科学的专业知识应用于正义或减轻人类痛苦的事情上更有价值。」

承认这一实验是「一个相当具有实验性的技巧和技术壮举」是十分有趣的。它引发了一个问题，激光干涉引力波天文台的贡献到底属于科学还是工程？自 20 世纪 70 年代以来，科学家已经把激光干涉测量作为测量引力波的一种方法。然而要建立一个具有足够灵敏的系统其实并非易事。

鉴于爱因斯坦的模型在 100 年前就预言了引力波，科学家似乎对这一预测的正确性没有任何争议，而且测量引力波的激光干涉测量技术早已在几十年前就已为人所知了，这 11 亿美元的巨额投入似乎并没有带来任何新的科学成果。但是，真正的科学贡献可能并不是证实了引力波的存在，而是证明了一种观测宇宙中我们以前看不到的事件的新模式。具体来说，这个实验第一次给出对两个黑洞碰撞合并的观测结果。这类事件的发生也许并不能令人感到惊讶，但可以肯定的是，我们可以在一种能够观测到此类事件的新型望远镜的首次亮相中发现它的学术价值。

因此，或许我们应该把 11 亿美元视为对一种新装置工程的投资，它现在可以使一种新的天文观测形式成为可能。因此，可以说，这个装置是工程上的一次巨大胜利。

这里，我来简要解释一下激光干涉引力波天文台工作团队面临的巨大工程挑战。首先，两个探测器相距 3 000 公里，这样引力波到达两个探测器的时间差就可以指示出波源的方向，由此，两个完全独立的观测就可以相互确证了。建造两个探测器的难度并不会超过建造一个探测器的两倍，所以这并不是最大的挑战。

每个探测器由一个 L 形的超高真空腔体组成，每一端长 4 公里（仅此一项就是不容易建造的，如图 1.6 所示）。它用激光干涉技术测量由引力波通过时引起的时空中极其微小的扭曲。这些扭曲使 4 公里的真空腔两端之间的距离发生了非常微小的变化，比质子的直径还要小得多！通过测量这个距离的变化，且一旦消除了所有其他可能引起距离变化的因素，人们就可以推断出距离的变化是由一个穿过的引力波扭曲时空所引起的。为了尽量消除可能引起距离变化的干扰因素，每个探测器都必须与诸如地震等振动源以及诸如车辆交通等人类活动完全隔离。因为即便是最轻微的振动也会使这些仪器变得毫无价值。

很难证明引力波望远镜会以任何切实的方式改善（甚至影响）人类的生活状况。尽管如此，该项目实际上可能会对改进工程方法产生实际和具体的影响。这种能够探测如此微小距离变化的能力，肯定在其他地方也能得到应用。

图 1.6 激光干涉引力波天文台安装的引力波探测器。地点在路易斯安那州利文斯顿，加州理工学院 / 麻省理工学院 / 激光干涉引力波天文台实验室。

美国航空航天局（NASA）的主要任务（我相信）是以科学的名义进行空间探索，并经常以其对技术发展的贡献作为空间探索经费支出的理由。NASA 声称对发光二极管（LED）、红外线耳式温度计、假肢、心室辅助装置、飞机防结冰系统、高速公路上的安全凹槽、改进的汽车轮胎、化学探测器、排雷、消防员装备和许多其他技术都做出了贡献（美国航空航天局，2016）。在我看来，这是对技术的重大贡献，而不是对科学的贡献。

假设激光干涉引力波天文台的工作是一个胜利，那么谁才是真正的英雄？2016 年 2 月 11 日发表在《物理评论快报》上宣布测量引力波的文章共有 1019 位作者（阿博特等，2016）。作者列表占了这篇文章 16 页中的 5 页的篇幅。人们很难从这份冗长的名单中找出一个「爱因斯坦」。据《波士顿环球报》的报道，现为麻省理工学院名誉教授的雷纳·韦斯被许多科学家认为是该项目的策划者。但是，韦斯本人对此提出了不同意见。他反驳说，许多人都为此做出了巨大的贡献（莫斯科维茨，2016）。假设韦斯是对的，那么激光干涉引力波天文台项目像维基百科中的词条一样，是集体智慧而非个体智慧的一种体现。而且，这些作者中的大多数很可能会自称「科学家」，而非「工程师」。在我看来，这 1 019 位作者中的绝大多数（如果不是全部的话）既是工程师，也是科学家，因为他们都在挑战柏拉图主义。

像苹果手机这样的人工制品同样是一种集体智慧的体现。我们不可能逐一确定所有为苹果手机贡献了重要技术要素的个体进行逐个确定，但我肯定这些人员的数量一定远远超过 1 019 这个数字。

在一篇著名的文章中，自由主义者、经济教育基金会（FEE）创始人伦纳德·爱德华·里德（1898 —1983）解释了制造一支普通的木质铅笔所需的技术要素（里德，1958）。文章是从铅笔的视角来写的，文章这样开始：「地球上没有一个人知道我是如何被制作出来的。」然后，作者记录了制作铅笔的整个过程和所需的全部材料：

我的家谱得从一棵树算起，一棵生长在加利福尼亚州北部俄勒冈州的挺拔的雪松。现在仔细想想要砍伐雪松原木并将其运抵铁路线所需的锯子、卡车、绳子和无数的其他工具。再想想整个制造过程中包含的所有人力和无数的技能：矿石的开采、钢铁的炼制以及将它们精加工为锯片、斧子、发动机，还有麻的生长以及如何将麻制成沉重而坚固的绳子……

他接着解释了木材是如何被研磨、烘干和着色的；如何开采石墨，然后又与黏土和磺化油脂混合；如何由蓖麻子和蓖麻油制成油漆；标签是如何用炭黑与树脂混合制成的；金属是如何被开采和提炼的；以及橡皮擦是如何由菜籽油、氯化硫、橡胶、浮石和硫化镉制成的。

可想而知，苹果手机的制造要比铅笔复杂得多。显然，就连史蒂夫·乔布斯也不知道如何制造苹果手机（甚至是铅笔）。在提到经济学家亚当·斯密（1723 —1790）「看不见的手」的说法时，里德这样写道：

还有一件事就更令人称奇了：并没有一个主宰者发号施令，或强制性地指挥我们产生无数的行动。我们一点儿也找寻不到这样一个人物存在的迹象。相反，我们发现，是一只看不见的手在发挥作用。

这样的人工制品甚至需要比维基百科还要极端的集体智慧，因为维基百科至少还保存了个人贡献的记录。

尽管我们无法追踪看不见的手背后的力量，但人们普遍认识到，这些力量中有许多是由人们的技术技能驱动的。培养这样的人才是现代经济的先决条件。今天，决策者和许多公众已经认识到科学、技术、工程和数学（四者的首字母缩略词为 STEM）教育的巨大价值。这个术语融合了一组广泛的技术学科。但是，读者也许已经注意到，该缩略词仍然将科学放在第一位，也许更多是为了便于发音以及它相对的优先度吧。的确，利亚娜·海廷在她的博客中写道，STEM 最初是 SMET，这或许更好地反映了人们理解的优先度，但又不必显得那么高调（海廷，2015）。

提出 STEM 缩略词的政治动机可能是非常实际的，它更多是关于是否能找到工作，而非知识探索。但是我们可能低估了「人工科学」中内在的知识探索的因素。如果没有激光干涉引力波天文台项目的工程杰作，我们就不会有人类第一台引力望远镜。也许这台望远镜将有助于我们揭示其他的黑洞碰撞，以及其他可能帮助我们更好地理解宇宙起源的现象。因此，有的时候工程确实先于科学，而不是科学先于工程。

一些迹象表明，人们对技术和工程的态度正在发生重大转变。20 世纪，人们认为「技术学院」与职业学校没什么区别，并不是智力活动的中心。麻省理工学院和加州理工学院让人们改变了这种观念。我们甚至开始看到许多「技术高职学校」的出现，它们绝不只是进行一些职业培训。

技术和工程显然并非要发现预先无形存在的那些真理，它们是被用来创造从未存在过的事物、过程和想法的。对柏拉图式的善的追求，即那个预先存在的、固定型相的世界，不再是推动人类进步的动力。相反，我们正在创造以前从未存在的、已被或尚未被揭示的知识和事实。

在下一章，我将重点讨论发现和发明的关系。这一章的一个关键主题是理解模型在工程和科学中的作用。我的基本主张是，模型是被发明出来的，而且当这些模型在建模物理现象时，相应的那些物理现象而不是这些模型就会被发现。这些物理现象甚至可能是全新的，就像晶体管一样。

## 0201. Inventing Laws of Nature

· · · in which I argue that models are invented, not discovered; that engineers and scientists use models in complementary, almost opposite ways; that all models are wrong, but some are useful; and that the use of models can slow as well as advance technological progress by establishing a backdrop of unknown knowns, by forcing increased specialization, and by requiring humans to assimilate new paradigms.

0201 发明自然法则

在本章，我将阐述：1）模型是被发明的，而不是被发现的；2）工程师和科学家以互补的却又几乎相反的方式使用模型；3）所有模型都是错的，但有些是有用的；4）模型的使用可以通过建立未知知识的背景、强制提升专业化程度以及要求人类吸收新的范式，来减缓或促进技术的进步。

### 2.1 The Unknown Knowns

Drawn by its provocative title, I recently read Inventing Nature, a wonderful book by Andrea Wulf (Wulf, 2015). Wulf's book tells the story of Alexander von Humboldt (1769–1859), a remarkable Prussian about whom I had previously known nothing except that Humboldt county and Humboldt Redwoods State Park in California, along with numerous other places and things, had been named after him. Wulf boldly states,「Humboldt gave us our concept of nature itself.」Easing somewhat my embarrassment at my ignorance, she goes on,「The irony is that Humboldt's views have become so self-evident that we have largely forgotten the man behind them.」Further easing my embarrassment, Sandra Nichols (2006), in an article titled「Why was Humboldt forgotten in the United States?」reassures me that I am not alone. Nichols postulates many reasons for our collective amnesia, but to me the most poignant is「shifts in scholarship,」where「the search for a comprehensive view of science was soon set aside in favor of specialization.」In Germany, Humboldt and his brother Wilhelm have most definitely not been forgotten. The Humboldt University of Berlin is named after the two of them, and the brother, Wilhelm, is credited with establishing the「Humboldtian model of higher education,」which integrates teaching in the arts and sciences with research. This is a defining principle of all top universities today.

In her claim that Alexander von Humboldt「invented nature,」Wulf shows us that scientific truths can come into existence and then become part of the human psyche, background knowledge that we accept with such tenacity that we no longer think of them as scientific truths. They just are. Wulf summarizes Humboldt's breakthrough:

Humboldt revolutionized the way we see the natural world. He found connections everywhere. Nothing, not even the tiniest organism, was looked at on its own.「In this great chain of causes and effects,」Humboldt said,「no single fact can be considered in isolation.」

Wulf credits Humboldt with being the first scientist to show evidence of human-induced climate change, for founding the field of ecology, and for articulating the first modern notion of「nature」itself. The most astonishing part of this story is that it never occurred to me that the connectedness of nature was not just a simple self-evident truth. It is so widely accepted today that it fades into the background of our basic instinct, along with notions of time and causality. Wulf explains the prevailing scientific thought at Humboldt's time:

Inventions such as telescopes and microscopes revealed new worlds and with them a belief that the laws of nature could be discovered.

But Wulf points out that these laws of nature were understood one phenomenon at a time, as in Newton's laws of motion governing a falling object. Connectedness fell victim to reductionism.

Connectedness faded from our conscious approach to science into the unconscious, part of an unseen background, an unknown known. US Secretary of Defense Donald Rumsfeld, at a Department of Defense news briefing in 2002, made the following often quoted statement:

· · · as we know, there are known knowns; there are things we know we know. We also know there are known unknowns; that is to say we know there are some things we do not know. But there are also unknown unknowns—the ones we don't know we don't know. And if one looks throughout the history of our country and other free countries, it is the latter category that tend to be the difficult ones [sic]. (Rumsfeld, 2002)

The Slovenian philosopher Slavoj Žižek pointed out that Rumsfeld didn't mention an obvious fourth category of knowledge, the「unknown knowns.」These are the things we know but don't know that we know, which Žižek says is「precisely the Freudian unconscious」(Žižek, 2004). The interconnectedness of nature was, until I read Wulf's book, one of my unknown knowns. I didn't know that I knew that. Now I do, and thanks to Wulf, I also now realize that this「truth」that I know was not always known. She credits Humboldt with making it known.

Our unknown knowns bias our thinking. Thomas Kuhn, in his 1964 book The Structure of Scientific Revolutions , disrupted the prevailing view of science as「development-by-accumulation」(Kuhn, 1962). Instead of an accretion of discovered facts about the world, a scientific discipline is founded on a「paradigm,」a conceptual framework that practitioners use, often unknowingly, to interpret observations and develop theories. Kuhn argued that these paradigms make scientific understanding necessarily subjective.

Observation and experience can and must drastically restrict the range of admissible scientific belief, else there would be no science. But they cannot alone determine a particular body of such belief. An apparently arbitrary element, compounded of personal and historical accident , is always a formative ingredient of the beliefs espoused by a given scientific community at a given time. [emphasis added]

Kuhn's「arbitrary element」often takes the form of unknown knowns. A paradigm becomes so widely accepted and strongly held that its subjects no longer know it is there. They accept the paradigm as truth. As argued by Kant, the order we perceive in the world is shaped by our mind, which provides the distorting lens through which we perceive it. We impose order on nature rather than the other way around.

Kuhn's central claim is that scientific revolution, the truly momentous advances that occur from time to time, come about through paradigm shifts rather than through accretion of knowledge. The notion of scientific truth is therefore subjective, defined more by consensus of a scientific community than by Plato's ideal disembodied truth. An obvious corollary is that a paradigm is invented more than discovered.

Kuhn's position was highly controversial. It went very much against the grain of the prevailing philosophy of science, best articulated by Popper, which was about seeking objective truths. In 1965, a colloquium convened in London drew together many of the most prominent thinkers on the philosophy of science to respond to Kuhn's thesis. Imre Lakatos, a Hungarian philosopher of mathematics and science, and co-editor of the proceedings from the colloquium, wrote,「 in Kuhn's view scientific revolution is irrational, a matter for mob psychology 」(Lakatos, 1970, emphasis in the original). He goes on to criticize the notion of a「paradigm shift,」writing that it is

a mystical conversion which is not and cannot be governed by rules of reason and which falls totally within the realm of the (social) psychology of discovery. Scientific change is a kind of religious change. [emphasis in the original]

Despite these objections, Kuhn's notion of governing paradigms is useful for understanding the evolution of scientific thought. It is even more useful for understanding technology, where paradigms can be more obviously subjective.

In our modern technological world, our lives are governed by paradigms that are more obviously invented rather than discovered. These paradigms shape our understanding of the world, becoming unknown knowns. Consider, for example, the fact that in music and performing arts, it used to be that performer and observer had to be in the same room at the same time. Today, we can use Spotify and Hulu, among others, to carry much of the world's music and theater in our pockets, to be enjoyed whenever and wherever we choose. Most of us alive today have been able to listen to music without being in the same room with the musicians. This fact has changed the very meaning of the word「music」in ways that we don't notice. Think, for example, about the meaning of the phrase「my music.」What would that have meant to a citizen of the nineteenth century, before Edison?

I was once telling my wife that a colleague at Berkeley, Miki Lustig, was leading a charge to teach many students, staff, and faculty at Berkeley about amateur radio, and to help them prepare to take the test to become licensed to operate amateur radios. My wife asked me why one would want to operate an amateur radio. The question had never occurred to me, and off the cuff, the best answer I could come up with was,「So they can communicate with anyone around the world.」She asked me,「Why don't they just send email?」I saw a collision of paradigms, less momentous than the collision of two black holes, but nevertheless notable. Being able to communicate instantaneously with anyone around the world has become a background fact, an unknown known, a part of the technological paradigm through which we understand and manage our daily lives.

Figure 2.1 Dilbert, an iconic nerd, in a cartoon by Scott Adams. [DILBERT c 1995 Scott Adams. Used by permission of UNIVERSAL UCLICK. All rights reserved.]

Paradigms change. Kuhn's scientific paradigms change relatively infrequently, and the changes can be quite disruptive to a scientific community. In The Structure of Scientific Revolutions , Kuhn quotes Max Planck:

A new scientific truth does not triumph by convincing its opponents and making them see the light, but rather because its opponents eventually die, and a new generation grows up that is familiar with it.

The same thing happens with technological paradigms. Witness how much of modern technology becomes inaccessible to an aging brain. Our kids accept technological truths that are incomprehensible to older people. In fact, I believe that the pace of technological progress today is more limited by the inability of humans to absorb new paradigms than it is by any physical limitations of the technology.

Kuhn is generous to scientists whose paradigms are later supplanted by better paradigms:

· · · those once current views of nature were, as a whole, neither less scientific nor more the product of human idiosyncrasy than those current today.

· · · If these out-of-date beliefs are to be called myths, then myths can be produced by the same sorts of methods and held for the same sorts of reasons that now lead to scientific knowledge.

We should be similarly generous to humans whose technological paradigms become obsolete, rather than thinking of them as luddites or dinosaurs. I would say to my kids,「Don't worry, you too someday will be a dinosaur.」

Despite similarities, technological paradigms differ from scientific ones in significant ways. Technological paradigms are today much more diverse than scientific paradigms, reflecting immaturity of the field and rapid change. Kuhn argues that scientific paradigms are incommensurable. One paradigm cannot be understood or judged through the conceptual framework and terminology of the other. I will show in chapter 3 that this is less the case for technological paradigms, which may be layered in such a way as to interoperate. Nevertheless, incommensurable paradigms do arise, and it becomes necessary to build a metaparadigm within which to compare technological paradigms. I will attempt to do that through the notion of modeling.

Science, technology, and engineering are all built on models. Models are artifacts in the conceptual framework of a paradigm. Newton's second law, for example, is a model of the motion of an object subjected to a force. It takes the form of an equation, specifically equation (4096) on page 14 , which has meaning in the paradigm of Newton's and Leibniz's calculus, the concept of force, and the Newtonian notion of time and space. If you studied physics in high school, you probably got brainwashed sufficiently that the concepts of force, time, and space are among your unknown knowns. But objectively, Newton gave no physical explanation for these concepts. Instead, he built a self-consistent and self-referential model where each of these concepts is defined in terms of the others, if defined at all.

Every engineered design is similarly a model, which can be as simple as a prototype of a physical shape or as complex as a million lines of code. Each such model has a meaning, a semantics , only within some modeling paradigm. And the modeling paradigm is all too often an unknown known, never articulated or consciously chosen. I will attempt now to break the logjam that is created by failing to recognize these unknown knowns.

2.1 未知的已知

受其颇具煽动性的标题吸引，我最近读了安德烈娅·武尔夫所著的《发明自然》一书（武尔夫，2015）。武尔夫在书中讲述了有关亚历山大·冯·洪堡（1769-1859）的故事。洪堡是一位杰出的普鲁士人，之前除了听说过用他的名字命名的加利福尼亚州洪堡县和洪堡红杉州立公园以及其他许多地方和东西之外，我对他就知之甚少了。武尔夫大胆地评论说：「洪堡给了我们关于自然本身的概念。」她的评论缓解了我因自己的无知而产生的尴尬，她接着说：「颇具讽刺意味的是，洪堡的观点已经如此不言自明，以至我们基本上已经忘了提出这些观点的这个人。」在一篇题为「为什么洪堡在美国被遗忘？」的文章中，桑德拉·尼科尔斯（2006）的观点进一步消除了我的尴尬，让我再次确信自己其实并不孤单，还有其他人和我的想法一样。尼科尔斯为我们的集体健忘症假定了很多原因。但是，对我来说，最令人感到心酸的是「学术上的转变」，即「对科学的全面观点的研究很快就被搁置一边，转而支持专业化」。在德国，洪堡和他的哥哥威廉肯定没有被遗忘。柏林洪堡大学是以他们两人的名字命名的。他的哥哥威廉被誉为「洪堡式高等教育模式」的创立者，该模式将文理学科中的教学与研究结合起来。这是当今所有顶尖大学的基本原则。

武尔夫声称亚历山大·冯·洪堡「发明了自然」，她向我们表明，科学真理可以存在，然后成为人类精神的一部分。我们如此坚定地接受了这些背景知识，以至我们不再将它们视为科学真理。然而，它们就是科学真理。武尔夫用下面这段话总结了洪堡的成就：

洪堡彻底改变了我们看待自然世界的方式。他认为联系无处不在。没有任何东西是孤立存在的，即使是最小的有机体，也不是孤立的。「在这个巨大的因果链中，」洪堡说，「我们不应孤立地考虑其中的任何一个事实。」

武尔夫称赞说，洪堡是第一位证明人类活动导致气候变化的科学家，他创立了生态学领域，并阐明了「自然」本身的第一个现代概念。这个故事最令人惊讶的地方在于，我从来没有想到，大自然的连通性不再是一个简单的理所当然的真理。现在，人们已经如此广泛地接受了这种观念，以至它与时间和因果关系的概念一道逐渐融入我们直觉的背景中。武尔夫解释了洪堡时代盛行的科学思想：

诸如望远镜和显微镜这样的发明，它们揭示了人类尚不了解的新世界，并且使人类相信自然法则是可以被发现的。

但是，武尔夫指出，这些自然法则一次只能被理解为一种现象，就像支配下落物体的牛顿运动定律一样。连通性成为还原论的牺牲品。

连通性从我们对科学的有意识方法中逐渐消失，进而进入无意识中，成为一个看不见的大背景的一部分，一个未知的已知。2002 年，美国国防部长唐纳德·拉姆斯菲尔德在国防部新闻发布会上发表了以下这段被广泛引用的声明：

…… 如我们所知，存在一些已知的已知，有些事物我们知道我们是知道的；我们也知道存在一些已知的未知，也就是说，我们知道有一些事物我们是不知道的。但也存在一些未知的未知 —— 那些我们不知道我们还不知道的事物。纵观我们国家和其他那些自由国家的历史，我们就会发现后者往往是最难的一类。（拉姆斯菲尔德，2002）

斯洛文尼亚哲学家斯拉沃伊·齐泽克指出，拉姆斯菲尔德没有提到显而易见的第四类知识，即「未知的已知」。它指的是那些我们不知道其实我们已经知道的事物。齐泽克说，「正像弗洛伊德的无意识一样」（齐泽克，2004）。直到我读了武尔夫的书以后，大自然的连通性才成为我的未知的已知之一。我过去不知道我已经知道了。多亏了武尔夫，我现在也意识到我所知道的「真理」并不总是为人所知，她相信正是洪堡使其为人所知的。

我们的未知的已知导致我们的思想产生了许多偏见。托马斯·库恩在他 1964 年出版的《科学革命的结构》一书中，打破了普遍流行的「积累式发展」（库恩，1962）科学观。库恩认为，一门科学学科是建立在「范式」的基础之上的，而非建立在已经发现的关于世界的事实积累之上。这是一种概念性框架，实践者常常在不知不觉中使用它来解释观察到的现象，并发展各种理论。库恩认为，这些范式使我们对科学的理解必然带有主观性。

观察和经验可以而且一定会大幅限制可接受科学信念的发展范围，否则就不会有科学。但它们无法单独决定这种信念的某一特定主体。一个明显的任意性因素，混合了个人和历史的偶然性，常常成为一个特定科学群体在特定时期所崇尚的信念的形成要素。

库恩所说的「任意性因素」往往是以未知的已知这种形式存在的。一种范式被如此广泛地接受，并获得强烈的支持，以至接受它的主体不再能体会到它的存在，这些主体认为范式即真理。正如康德所言，我们在世界上所感知到的秩序是由我们的头脑塑造的，我们的头脑为我们提供了感知世界的歪曲的透镜。我们把秩序强加给自然，而不是反之。

库恩的核心主张认为，科学革命，也就是不时发生的真正重大的科学进步，是通过范式的转换而不是知识的积累实现的。因此，科学真理的概念是主观的，其是由科学界的共识而不是柏拉图式理想的无形真理所定义的。由此，就可以得出一个明显的推论 —— 范式多是被发明的而非被发现的。

库恩的观点备受争议。这与当时流行的科学哲学观点背道而驰，也就是波普尔清楚地表达过的寻求客观真理。1965 年，在伦敦召开的一次学术研讨会上，许多最杰出的科学哲学家齐聚一堂并对库恩的观点做出了回应。匈牙利数学和科学哲学家伊姆雷·拉卡托什担任研讨会论文集的共同编辑，他写道，「在库恩看来，科学革命是非理性的，是群氓心理下的肆意行为」（拉卡托什，1970）。他接着又批评了库恩的「范式转换」的概念，并写道：

一种不受也不可能受理性规则支配的神秘转变，完全属于（社会）发现心理学的范畴。科学变革类似于一种宗教革命。

尽管存在这些异议，但是库恩的支配范式概念对于理解科学思想的演变还是有用的。对于理解工程技术来说，库恩的观点甚至更有价值，因为在工程技术中范式可能会显得更加主观。

在现代科技的世界里，我们的生活被一些范式支配。这些范式更明显是被发明出来的，而不是被发现的。这些范式塑造了我们对世界的理解，成为未知的已知。举个例子，过去我们要听音乐或观看表演，就必须和表演者共处在相同的时空里。而今天，我们可以使用诸如 Spotify 音乐服务平台和 Hulu 视频网站等服务平台，它们能够把世界上大部分音乐和剧院里演出的剧目装在我们的口袋里，让我们随时随地都可以欣赏。今天，我们中的大多数人已无须到现场就能听音乐了。这一事实不经意地改变了「音乐」这个词的含义。例如，让我们来想想「我的音乐」这个短语的含义吧。在爱迪生发明留声机之前，这个词对于 19 世纪的人们意味着什么呢？

有一次，我告诉我的妻子，伯克利大学的一位同事米基·卢斯蒂格正在负责一门课程，教伯克利大学的学生、行政人员和教职人员学习业余无线电知识，并帮助他们准备获得业余无线电台使用资格的考试。

我妻子问我为什么那些人要使用业余无线电台。可是，我从来没有想过这个问题。我想了想，我能想到的最好的答案是：「这样他们就可以和世界上的任何人进行交流了。」她又问我：「他们为什么不直接发电子邮件呢？」我看到不同范式的相互碰撞。当然，这种碰撞没有两个黑洞的碰撞那么严重，但仍值得我们注意。能够与世界各地的任何人进行即时交流已经成为一个不争的事实，是一个未知的已知，是我们理解和支配日常生活的技术范式的一部分。

图 2.1 斯科特·亚当斯漫画中的呆伯特，一个标志性的书呆子。（呆伯特 ©1995，斯科特·亚当斯。UNIVERSAL UCLICK 授权使用。保留所有权利。）

范式经常会发生改变。库恩的科学范式变化相对较少，但这些变化可能会对科学界造成相当大的破坏。在《科学革命的结构》一书中，库恩引用了马克斯·普朗克的话：

一个新的科学真理并不是通过说服对手并让他们看到真理之光而获得胜利的，而是因为它的对手最终会死去，而熟悉它的新一代人会成长起来。

1-2-3『上面的这段话，在 N 多个地方看到过，新范式的胜利是因为坚守老范式的那些科学家最终死去了。做一张任意卡片。（2021-10-24）』—— 已完成

同样的事情也发生在技术范式上。让我们来看看有多少现代科技让老化的大脑根本无法领悟。我们的孩子当然能够很快接受老年人无法理解的技术真理。事实上，我认为当今技术进步的步伐更多地受到人类无法吸收新范式的限制，而非技术本身存在的任何限制。

库恩对那些曾经持有的范式被后来更好的范式取代的科学家说出了以下的慷慨之词：

…… 总的来说，那些曾经流行的自然观与今天流行的自然观相比，无论在科学性还是人文性方面都毫不逊色。

…… 如果这些过时的信念可以被称为神话，那么可以用同样的方法制造神话，并以同样的理由坚持这些神话，而这些理由现在导致了科学知识的产生。

我们应该同样慷慨地对待那些生活在过时的技术范式时代的人，而不应把他们当作卢德派分子或恐龙。我会对我的孩子们说：「别担心，有一天你也会变成恐龙的。」

尽管有相似之处，但是，技术范式与科学范式在许多重要的方面的确存在差异。如今，技术范式要远比科学范式更加多样，这反映了该领域发展的不成熟和快速变化。库恩认为，不同的科学范式之间是不可通约的。一种范式不能以另一种范式的概念体系和术语加以理解或判断。然而，技术范式不存在这种情形，因为技术范式是以互操作的方式进行分层的。我将在第 3 章进行说明。然而，不可通约的范式确实出现了，因此有必要建立一个元范式，并在该范式中比较不同的技术范式。我将尝试通过建模的概念达成这一目标。

科学、技术和工程都是建立在模型之上的。模型是范式概念框架中的组件。例如，牛顿第二运动定律是物体在受力作用下的运动模型。它的形式是一个方程，具体来说就是方程（4 096）。它在牛顿和莱布尼茨微积分的范式中，在力的概念以及牛顿的时间和空间概念中都有意义。如果你在高中学过物理，那么你可能已经被彻底洗脑了，以至力、时间和空间的概念都成为你未知的已知。但从客观上来说，牛顿并没有对这些概念做出实质性的解释。相反，他建立了一个自我一致和自我参照的模型。如果说他下了什么定义的话，就是其中的每个概念都是以其他概念来定义的。

每个工程设计都类似于一个模型，它可以像一个物理形状的原型那样简单，也可以像一百万行代码那样复杂。每个这样的模型只有在某种建模的范式中才有一个含义，或者说一个语义。建模范式往往是一个未知的已知，从未被清晰地表达或有意识地选择过。现在，我将尝试打破由于没有认识到这些未知的已知而造成的困难局面。

### 2.2 Models of Nature

Merriam-Webster's online dictionary has no fewer than 14 definitions of the word「model.」Only a few of these are relevant to how models are used in science and engineering:

4 a usually miniature representation of something; also: a pattern of something to be made

5 an example for imitation or emulation

· · ·

7 archetype

· · ·

11 a description or analogy used to help visualize something (as an atom) that cannot be directly observed

12 a system of postulates, data, and inferences presented as a mathematical description of an entity or state of affairs; also: a computer simulation based on such a system.

The first of these definitions is a concrete model, a material object in the physical world, whereas the last two are abstract models, where any material realization, for example, as ink on paper, is incidental. The two in the middle could be either concrete or abstract. Both abstract and concrete models help humans grasp concepts. Both kinds of models are created by humans. Models, therefore, can serve as a way for humans to record and communicate concepts.

For Aristotle, concepts about the world arise from the common properties of particular things (see figure 2.2 ). Particular things can serve as models for the family of things that fit the concept or as models for the concept itself. The concept of a horse, for example, is a generalization formed from the observation of a few horses. A plastic figurine in the shape of horse, such as the one being printed in figure 2.3 , can serve as a concrete model of a horse. Note that the model need not itself be a horse. A concrete model is a physical thing that captures some essence of the things being modeled.

The notion of a concrete model connects naturally to another of Merriam-Webster's definitions,「one who is employed to display clothes or other merchandise.」Consider the model in the poster shown in figure 2.4 . That model was presumably employed to display something, but interestingly, the merchandise being advertised by this poster, cologne, is not shown on the poster. The model instead was employed to be an exemplar of a「sexy human male」(to be sure, I'm talking about the one in the poster, not the one in the reflection). The model (a human) was employed to serve as a model (an archetype) of a sexy human male. The purpose of such a model is to sell cologne to an individual (perhaps the one in the reflection) by evoking an image of how attractive he might become by wearing such cologne.

Platonic Forms, according to Plato, exist independent of humans, as disembodied truths. A Platonic sphere is perfect. The physical world provides no such sphere. It does not and cannot exist as a physical object. Any physical embodiment of a sphere will be made of some material composed of atoms and molecules. No matter how smoothly polished it is, the surface of the sphere will not match the Platonic concept, but rather will have dents and undulations and a fuzziness imposed by the quantum mechanical impossibility of pinning down the location or boundary of the electrons that make up the atoms. Where and what is the surface? Without a surface, we cannot talk about a surface area, but a Platonic sphere should have a surface that is exactly equal to 4 πr 2 , where r is the radius. But the notion of surface has no rigorous basis in physics at the atomic scale.

Figure 2.2 Plato and Aristotle in a detail of The School of Athens, a fresco by Raffaello Sanzio da Urbino (Raphael) in the Vatican. Aristotle is on the right, gesturing toward the earth, indicating that knowledge arises from the study of things, whereas Plato, on the left, gestures toward the heavens, indicating that knowledge is discovery of Forms that exist in an ideal, disembodied world, independent of humans.

So in what sense does the Platonic sphere exist independent of humans? It does not exist in the physical world. We can construct a mathematical model of a sphere, but this is still a human construction not a disembodied truth. For example, we can give a mathematical model of a sphere as follows. A sphere with radius r centered at coordinates (0, 0, 0) in a Cartesian coordinate system is the set of points ( x , y , z ) that satisfy

It is no accident that there is nothing sexy about such a Platonic model.

Figure 2.3 A model of a horse being printed by a 3D printer. [Photo by Ben Zhang, courtesy of the photographer.]

Figure 2.4 Aspirational self-portrait of the author.

The mathematical model of equation (2048) is a human construction, given in the language of algebra and the Cartesian three-dimensional model of space. It can be viewed as an imperfect (i.e., wrong) model of things in the physical world that resemble spheres. Those things in the physical world can be viewed as models of a mental concept of a sphere, as can the equation. But nowhere is there any direct evidence of a human-independent existence of the Platonic Ideal sphere. The mathematical model is not a Platonic Form, but rather at best a model of a Platonic Form, existing within a modeling paradigm (algebra and Cartesian space). There are many other ways to model a sphere mathematically, and as I will discuss in chapter 9 , every such way has limitations. So even an abstract model is a shadow on the wall. Even if it is just a shadow on the wall, it will be more faithful to a Platonic Form of a sphere than any physical model could be. It may be the best representation accessible to us of the Platonic Ideal.

A concrete model of a horse is shown in figure 2.3 being printed by a 3D printer. That printer accepts as input a file containing another kind of model of a horse. Specifically, the file uses a language called STL (for STereoLithography) that is widely used to specify three-dimensional shapes. The STL language was created in 1987 by 3D Systems, headquartered in Rock Hill, South Carolina, a company that makes and sells 3D printers.

A model of a horse in STL is an abstract model. It is based on a paradigm for modeling three-dimensional shapes in terms of two-dimensional facets that share edges. An example of an extremely simple STL model is shown in figure 2.5 . The STL text on the left specifies the pyramid shape at the upper right. It consists of four triangles that form the outer boundary of the object. The vertices of the four triangles are given in a three-dimensional Cartesian coordinate system.

To fully understand the text in the figure, one needs to first assimilate the paradigm on which STL is based. If you will forgive a brief nerd storm, that paradigm is of three-dimensional tessellations of two-dimensional facets, together with rules such as the right-hand rule, which determines which side of a facet is inside versus outside the shape. If you had studied computer graphics, the previous sentence would be easy to read. Otherwise, probably not.

The STL file for the horse being printed in figure 2.3 is much more complicated than the pyramid, so I will not attempt to show it to you here. It is meant to be read by machines not by humans. The horse model is rendered from the STL file at the lower right in figure 2.5 , where if you look closely, you can see the two-dimensional facets that define the shape. Such a model of a horse is sometimes called a virtual prototype because it serves the same purpose as a physical prototype, but it does not have a physical form.

Models are expressed in some physical medium. The concrete model of a horse in figure 2.3 is a three-dimensional printed plastic prototype. The physical medium is plastic as assembled by a 3D printer. An abstract model of the same design might be a mathematical formula describing its shape, like equation (2048), or an STL file such as that in figure 2.5 . This abstract model can be sent to a 3D printer to produce the concrete model. Abstract models also have physical form in the sense that equation (2048) is ink on a page (or pixels on a screen) and an STL file is aligned magnetic iron molecules on a disk or electric charges in a computer memory, but their physical form is incidental. When an abstract model is converted from one physical form to another, for example, into your mental state when you read equation (2048), or when you copy an STL file from one computer to another, we do not end up with two models. It is still just one model, albeit in two or more physical representations. The ontology of an abstract model is independent of its physical embodiment.

Figure 2.5 Three-dimensional shape specified in STL.

Concrete models are exemplars in physical form of a class, whereas abstract models are abstractions of a class. The possibilities for expressive media are much richer for abstract models than for concrete models because they are less constrained by the physical world. STL, in fact, can specify shapes that cannot exist in the physical world, with overlapping facets or facets that do not share edges. Modeling languages are abstract not concrete. They yield more readily to human creativity. Moreover, they invite invention, and even paradigm shifts. A well-chosen modeling language enables elegant expression of complex designs.

Both concrete and abstract models can be used for analysis. A physical prototype of a component, for example, can be used to determine whether the part that it models will fit properly within its housing. But abstract models offer much richer possibilities for analysis. If the modeling medium, the language in which the models are expressed, has a rigorous semantics, then the model may be subject to automated analysis. A computer program can determine whether the component will fit within its housing without ever having to construct a physical prototype.

Figure 2.6 shows a prototype, a concrete model, of an incandescent lightbulb made with a carbonized bamboo filament. This prototype was made in Thomas Edison's lab in Menlo Park, New Jersey. According to The Edison Papers Project (2016), Edison initially tried to make lamps with platinum wire filaments because the metal has a high melting point. But he discovered that when heated in air, the metal would change its structure, weakening the filament, and the melting point would drop. He solved this problem by putting the filament in a vacuum bulb.

Edison was well known for a style of invention that I will call prototype and test . To find a material for the filament that would produce a reasonable amount of light with a reasonable voltage and lifespan, Edison tried many alternatives. Although his starting point, platinum, worked reasonably well in a vacuum, platinum is an expensive precious metal. Edison's platinum bulbs were likely to be too expensive to become commercial successes. Also from The Edison Papers Project (2016),

He turned to carbon and experimented with some cotton threads, different kinds of paper and cardboard, various woods, and then with a few long fiber plant materials before settling on bamboo. Later he had a worldwide search conducted to see if he could find a better long fiber plant as he did not hold the key patents on artificial fibers, which were beginning to prove better.

This is an Aristotelian approach to solving a problem: experiment with materials and infer their properties from observation. The problem he was trying to solve was how to use electricity to generate light. As a side effect of this engineering work, he did some science, discovering a property of the natural world. Specifically, he found that a naturally occurring metal, platinum, when heated in air, changes its structure.

Figure 2.6 Prototype from Thomas Edison's shop of an incandescent lightbulb with a carbon filament. [Image by Terren - Edison Light Bulb, licensed under the Creative Commons Attribution 2.0 Generic license. Lightened by the author. Original from Wikimedia Commons.]

Bamboo filament lightbulbs went into production in 1882 and about six years later were supplanted with tungsten filament bulbs. Both of these styles require operating in a vacuum, otherwise the filament will burn, melt, or otherwise quickly degrade. Edison's discovery that heated metals degrade in air and do not degrade in a vacuum, a scientific fact, became central to the development of a practical lightbulb, an engineering invention.

Thomas Edison used an abstract model of what happens in an incandescent lightbulb, in addition to the physical prototypes. Specifically, he used Ohm's law, first published by Georg Simon Ohm in 1827. Ohm's law relates the current i through a resistor to the voltage v across the resistor by

where the proportionality constant R is called the resistance . The resistance, which has units of ohms in honor of Georg Ohm, is a property of the material used to make the resistor and the geometry of the resistor. A lightbulb filament is a resistor, and in Edison's day, the resistance of a filament would have been determined empirically.

Because of its resistance, the filament heats up, and it is because of the heat that the filament generates light. Platinum conducts electricity easily, which means that its resistance is low. Carbon-based materials, such as bamboo fibers, have much higher resistance. At a fixed voltage v , therefore, the current that flows through a platinum filament will be much higher than the current that flows through a bamboo filament. The low resistance of platinum is therefore another disadvantage, along with its high cost. To accommodate the higher currents that result from low resistance, Edison would have had to use thicker copper wires to deliver electricity to the lightbulbs, driving up system cost.

Ohm's law is an abstract model. Unlike the model in figure 2.6 , there is nothing physical about this model. It nevertheless represents the「essence of things」and yet, in a true Aristotelian manner, was likely derived by Ohm from observation and measurement rather than from fundamental truths.

Ohm's law can be viewed as a law of nature, in which case it must be true of any electrical circuit. Alternatively, we can view Ohm's law as the definition of「resistance」and「resistor.」Under the latter interpretation, any device is a resistor if the current that flows through it is proportional to the voltage across it (i.e., if its behavior conforms with the model given in equation [1024]).

The distinction between these two interpretations is subtle but important. First, note that there is an implicit assumption in equation (1024) that we are talking about the current i and voltage v at an instant in time. In almost all electrical circuits, the current and voltage vary with time. For a lightbulb, the current and voltage are both zero when the light switch is turned off and are nonzero when the switch is on, so clearly there is a dependence on time.

A key question now becomes whether the resistance R should also vary with time. It turns out that neither platinum nor bamboo will satisfy equation (1024) with a constant value of resistance. In fact, the resistance varies with the temperature of the material, and the temperature depends on the current. If the filament starts out cold, then as current flows through it, the material will heat up and its resistance will increase. If the filament heats up too much, then the material melts and resistance becomes infinite (no current flows). Hence, the current depends not only on the voltage now, at an instant in time, but also on the history of the voltage and current at earlier times. How long the lightbulb has been on will affect its temperature and hence the current.

So it won't work to fix the resistance R to be constant. We have to let it vary with time. But then we have a conundrum. If R is an empirically determined value, then Ohm's law becomes a tautology! It is trivially true of every electrical circuit. At any instant in time, the resistance is

which is just a rearrangement of equation (1024). Every electrical circuit with nonzero voltage and current trivially satisfies Ohm's law by simply using R as defined in equation (512) as the definition of the resistance. This defines the resistance at time t to be whatever value makes Ohm's law true! Surely Georg Ohm did not get a basic electrical unit named after him for discovering a tautology. So this cannot be the right interpretation.

One resolution of this conundrum is that the notion of a resistor is a Platonic Ideal Form. A resistor is a device that at all times satisfies equations (1024) and (512) with a constant resistance R . But there is no such device in the physical world. At a minimum, every known material has a resistance that depends on temperature. Moreover, most every known material heats up as current flows through it. [1]

Besides temperature, other physical effects, specifically inductance and capacitance , ensure that physical materials do not exactly obey Ohm's law with a constant R . These effects introduce memory and dynamics in the system. For example, inductance is the tendency for current that is flowing to keep flowing, even if the voltage drops to zero. A material with nonzero inductance will take some time to adjust the current to a new voltage. During that time, it will not satisfy Ohm's law with the same fixed constant R . All materials, in practice, have some nonzero inductance, even if small. [2]

In fact, no physical object is a resistor. Because no physical object obeys Ohm's law, how can we take this to be a law of nature? Plato's allegory of the cave states that human perception is limited to shadows of reality, but it appears that physical objects are but shadows of the Platonic Ideal Form of a resistor. This Platonic Form is not only inaccessible to humans, it is also inaccessible to nature!

As a consequence, Ohm's law is either trivial or wrong. I see no choice but to conclude that Ohm's law is a human-constructed model, not a fundamental truth about nature. It did not exist as a fundamental truth before Georg Ohm because no physical object in the world obeys it. To the extent that it is a fundamental truth, it is so because we declare it to be so. We define a「resistor」to be a physical object whose behavior is reasonably closely modeled by Ohm's equation, and we define the resistance to be the ratio of voltage across that object to current through that object. An ideal resistor, which does not exist in nature, does not in fact exist at all except in the human mind. Ohm's law was invented, not discovered.

Figure 2.7 Drilling through a map. [Photo by Rusi Mchedlishvili, courtesy of the photographer.]

[1] An exception occurs when some materials, called superconductors , are cooled below a critical threshold where they enter a superconductive state, where the resistance becomes exactly zero. But the temperatures required are extremely cold. In 1987, Georg Bednorz and K. Alex Müller got the Nobel Prize in Physics for discovering a「high temperature superconductor.」Their ceramic compound exhibited superconductivity at the「high」temperature of −243.15 degrees Celsius or −405.67 degrees Fahrenheit. As of this writing, the highest temperature at which superconductivity has been observed is about −70° C (−94° F ), still extremely cold, and even then only at extremely high pressures. No practical lightbulb could be expected to work only at such temperatures and pressures.

[2] An imperfect analogy might help the reader if the reader has not studied electricity. An electric current can be visualized as water flowing down a sluice or channel that is tilted. The degree of tilt is analogous to the voltage. The rate of water flow is analogous to the current. A smaller channel will have a higher resistance than a larger channel (the smaller channel lets through less water for a given tilt). Inductance is analogous to the tendency of water that is flowing to keep flowing (it has inertia). If water is flowing down a tilted sluice and you suddenly flatten the sluice, removing the tilt, the water will not instantly stop flowing. This analogy is imperfect for several reasons. Electric current does not have inertia, or at least not much, and inductance is a property of the channel not the current. But it nevertheless provides a nice visual analogy that can be used to get the basic idea.

2.2 大自然的模型

韦氏在线词典对「模型」一词至少有 14 种定义。其中只有少数与模型在科学和工程中的应用有关：

4 通常是某个事物的缩影，也就是要制作的某个事物的模式；

5 模仿或仿制的例子；

……

7 原型；

……

11 一种描述或类比，用来帮助将无法直接观察到的事物（如原子）形象化；

12 一个由假设、数据和推论组成的系统，其被表示为一个实体或事态的数学描述；也是基于这种系统的计算机模拟。

第一个定义是一个具体的模型，是物理世界中的一个物质对象。而最后两个是抽象的模型，就后两者而言，诸如纸上的墨水等任何物质实现都是偶然的。而中间的其他两个则可以是具体的模型，也可以是抽象的模型。抽象模型和具体模型都有助于人类掌握概念。这两种模型都是人类创造的。因此，模型可以作为人类记录和交流概念的一种方式。

对于亚里士多德来说，关于世界的概念来自特定事物的共同属性（见图 2.2）。特定的事物可以作为符合这个概念的一系列事物的模型，也可以作为这个概念本身的模型。例如，马的概念是通过观察几匹马得出的一种概括性概念。一个外形为马的塑料雕像，如图 2.3 所示，就可以作为马的具体模型。请读者注意，模型本身并不需要是一匹真实的马。一个具体的模型是一个能够捕捉被建模事物的某些本质的实际存在。

1-2-3『此时又想到了斯科特的《模型思维》，视频课也收集好了。这本书一定要研读完。（2021-10-24）』—— 未完成

一个有关具体模型的概念与《韦氏大词典》中的另一个定义联系在一起，即「受雇去展示衣服或其他商品的人」，如图 2.4 所示海报中的模型。这个模型大概是被用来展示某个品牌的香水的，然而，有趣的是，海报所宣传的商品「古龙水」并没有出现在海报中。相反，这个模型被用来代表一个「魅力男子」的经典形象（当然，我指的是海报上的那个人，而不是镜子中反射出来的那个人）。该模型（一个人）被用作一个代表魅力男子形象的模型（原型）。这样一个模型的目的是通过唤起某些人「自己喷了古龙水会变得多么有魅力」的遐想，而将古龙水卖给这些人（也许就是镜子里的这个人）。

图 2.2 《雅典学院》是拉斐尔在梵蒂冈创作的一幅壁画。亚里士多德站在右边，手心向着地球，表示知识源于对事物的研究。而柏拉图站在左边，手指向天空，表明知识是对存在于一个理想的、无形的且独立于人类世界的型相的发现。

图 2.3 一个由 3D 打印机打印的马的模型。［张奔（Ben Zhang）供图，致谢。］

图 2.4 作者梦寐以求的自画像。

柏拉图认为，柏拉图型相作为无形的真理独立于人类而存在。柏拉图式的球体是理想的，但是，我们在物理世界中找不到这种理想的球体。它不是也不可能作为一个物理对象而存在。球体的任何物理形式都将是一些由原子和分子构成的物质组成的。无论它被打磨得多么光滑，球体的表面都不会符合柏拉图式的理想球体概念，任何球体表面都会有波动不平的痕迹，以及由于构成原子的电子的位置或边界所具有的量子力学的不可确定性造成的模糊性。表面到底在哪里？表面是什么？如果没有一个表面，我们就不能谈论表面积的问题，但是一个柏拉图式的球体应该有一个正好等于 4πr2 的表面积，其中 r 是球的半径。然而，在原子的尺度上，表面的概念并没有严格的物理学基础。

那么柏拉图式的球体在何种意义上独立于人类而存在呢？结论是它并不存在于物理世界之中。我们可以建立一个球体的数学模型，但是，它仍然是一个人类的构造，而不是无形的真理。例如，我们可以给出一个球体的数学模型。在笛卡儿的坐标系中，以坐标 (0, 0, 0) 为圆心、r 为半径的球体是满足如下条件的点 (x, y, z) 的集合。

毫无疑问，这样一个柏拉图式的模型一点儿都不令人着迷。

方程（2 048）的数学模型是人类用代数语言和笛卡儿空间三维模型构造的。它可以被视为物理世界中事物的、类似球体的不理想（即错误）模型。物理世界中的这些东西可以被视为球体的心理概念模型，就像方程一样。但是，没有任何直接证据表明，柏拉图式的理想球体是独立于人类而存在的。数学模型并不是柏拉图型相，充其量不过是柏拉图型相的模型，存在于建模范式（代数和笛卡儿空间）之中。还有许多其他的方式可以用数学方法建模一个球体，正如我将在第 9 章中讨论的那样，每种方法都有其局限性。所以即使是一个抽象的模型也只是墙上的影子罢了。当然，即使只是墙上的一个影子，它也比任何物理模型更接近一个柏拉图式的球体。它可能是我们所能得到的柏拉图式理想的最佳代表。

图 2.3 所示的是由 3D 打印机打印出来的马的具体模型。该打印机以包含马的模型的另一类文件作为输入。具体来说，该文件使用了一种被称为 STL 的语言（STereoLithography，光固化立体造型术的缩写），其被广泛运用于描述并建立三维形状。STL 语言是由总部设在南卡罗来纳州罗克希尔的 3D 系统公司在 1987 年创建的，这是一家家生产和销售 3D 打印机的公司。

用 STL 语言建立的马的模型是一个抽象模型。它是一个基于共享边的二维面来建模三维形状的范式。图 2.5 给出了一个非常简单的 STL 模型的例子。左边的 STL 文本描述了右上角的金字塔形状。它由四个构成物体外边界的三角形组成。在一个三维笛卡儿坐标系中，给出了这四个三角形的顶点。

要完全理解图中的文本，首先需要明白 STL 所基于的范式。如果你愿意原谅一场短暂的技术呆子头脑风暴，那就请继续阅读下面这段内容。这个范式就是二维平面的三维镶嵌，以及诸如右手定则之类的规则，右手定则决定了一个面的哪一边位于形状的内部而不是外部。如果你学过计算机图形学的话，上面的内容就很容易理解，否则，就可能有些难度。

打印图 2.3 所示马的 STL 文件要比金字塔复杂得多，所以我不打算在这里继续阐述了。它注定是由机器而不是人类来阅读的。马的模型是由图 2.5 右下角的 STL 文件来呈现的。如果读者仔细观察的话，就可以看到定义这个形状的二维平面。这种马的模型有时被称为虚拟原型，因为它的用途与物理原型相同，只是它没有物理形式。

模型是以某些物理介质来呈现的。图 2.3 中马的具体模型是一个三维打印的塑料原型。物理介质是由 3D 打印机用来打印组装的塑料。同一设计的抽象模型可以是描述其形状的数学公式，如方程（2 048）也可以是图 2.5 所示的 STL 文件。这个抽象模型可以被发送到 3D 打印机生成具体的模型。从某种意义上说，抽象模型也具有物理形式，如方程（2 048）是页面上的墨迹（或屏幕上的像素），而 STL 文件是排列在磁盘上的磁性铁分子或计算机内存中的电荷。但是，它们的物理形式是偶然性的。当抽象模型从一种物理形式转换为另一种物理形式的时候，例如，当你读取方程（2 048）时，或者当你将 STL 文件从一台计算机复制到另一台计算机时，我们最终得到的并不是两个模型。

图 2.5 用 STL 制作的 3D 模型。

这仍然只是一个模型，尽管有两个或更多的物理表示。抽象模型的本体论独立于其物理具象。

具体模型是某个类的一些物理形式范例，而抽象模型是某个类的一些抽象。对于抽象模型来说，其表现媒介的可能性要比具体模型丰富得多，因为它们很少受到物理世界的限制。事实上，STL 文件可以建立物理世界中不存在的形状，如一组重叠的平面或不共享边的平面。建模语言是抽象的，而非具体的，它们更容易激发人类的创造力。此外，它们还会带来发明，甚至是范式的转换。设计人员精心选择的建模语言能够优雅地表达设计。

具体模型和抽象模型都可以用于分析。例如，可以使用组件的物理原型来确定它所建模的组件是否适合其外壳。但是，抽象模型为分析提供了更丰富的可能性。如果建模媒介（用于表达模型的语言）具有严格的语义，那么模型可能会进行自动分析。计算机程序可以确定一个组件是否适合其外壳，而无须构建物理原型。

图 2.6 是用碳化竹灯丝制成的白炽灯泡的原型，它是一个具体的模型。这个原型是在新泽西州门洛帕克的托马斯·爱迪生实验室制作的。根据爱迪生论文计划（2016），爱迪生最初尝试用铂丝制作灯丝，因为这种金属具有很高的熔点。但后来他发现，当在空气中加热这种金属时，它的结构会发生改变，这削弱了灯丝的功能且使其熔点降低。最后，他通过把灯丝装在真空灯泡里解决了这个问题。

爱迪生以一种我们称为原型 — 测试的发明风格闻名于世。为了找到一种能产生适量的光、有稳定的电压和使用寿命的灯丝材料，爱迪生做了许多尝试。虽然在最初，金属铂在真空状态下也能很好地工作，然而铂是一种昂贵的贵金属，爱迪生制作的铂金灯泡很可能因为太过昂贵而无法在商业上取得成功。以下内容同样来自爱迪生论文计划（2016）：

图 2.6 托马斯·爱迪生的白炽灯泡和碳化竹灯丝原型。（特伦 - 爱迪生灯泡公司供图，知识共享署名许可 2.0 授权。作者对原文进行了删减，原文来自维基共享资源。）

他转向了碳类材料，并尝试使用一些棉线、不同种类的纸和纸板以及各种木材做实验，然后还试过几根长纤维植物材料，最终选定了竹子。后来，他在全球范围内进行了一次大搜索，以确定是否能找到更好的长纤维植物，那时他还没有获得人造纤维的关键专利，而这些人造纤维将被证实是更好的材料。

爱迪生的方法是一种亚里士多德式的问题解决方法：用材料进行实验，并从观察中推断出不同材料的特质。他试图解决的问题是如何用电来产生光。作为这项工程的辅助性工作，他也做了一些科学工作，结果竟然发现了自然界的一种特性。具体来说，他发现自然界中存在的金属铂在空气中被加热时其结构会发生改变。

竹丝灯泡于 1882 年投入生产，大约 6 年后被钨丝灯泡取代。这两种类型的灯丝都需要在真空中工作，否则灯丝会燃烧、熔化或迅速降解。爱迪生发现加热的金属在空气中会降解，在真空中则不会，这一科学事实是一项工程发明，并成为开发实用灯泡的核心支撑。

除了物理原型，托马斯·爱迪生还使用了白炽灯泡工作过程中涉及的抽象模型。具体来说，他使用了欧姆定律。该定律由乔治·西蒙·欧姆在 1827 年首次发表。欧姆定律把通过电阻的电流 i 与电阻器两端的电压 v 联系起来。

i = v/R（1 024）

其中的比例常数 R 为阻值。阻值的单位是欧姆，这样命名是为了纪念乔治·欧姆。阻值是用来制作电阻器的材料及电阻器几何形状的一种性质。灯泡的灯丝是电阻，在爱迪生的时代，灯丝的阻值是靠经验推算出来的。

因为阻值的存在，所以灯丝可以被加热，而正是因为灯丝被加热，它也才会发光。金属铂容易导电，这意味着它的阻值很低。诸如竹纤维等碳基材料则具有高得多的阻值，因此，在固定的电压 v 下，流经铂丝的电流要比流经竹丝的电流大得多。因此，金属铂除了成本很高，低阻值也是它的一个缺点。为了应对低电阻产生的高电流，爱迪生将不得不使用更粗的铜线向灯泡供电，从而推高了系统成本。

欧姆定律是一个抽象模型。与图 2.6 中所示的模型不同，该模型没有任何物理特性。尽管如此，它仍然代表了「事物的本质」。然而，如果我们以一种真正的亚里士多德的方式来解释的话，该定律就很可能是欧姆从观察和测量中得出的，而不是从基本真理中得出的。

欧姆定律可以被视为一条自然法则，在这种情况下，它对任何电路必须都成立。换言之，我们可以把欧姆定律看作「阻值」和「电阻」的定义。根据后一种解释，如果流经它的电流与它两端的电压成正比，那么任何装置都是一个电阻［也就是说，其行为是否符合方程（1 024）给出的模型］。

这两种解释之间的区别十分微妙，但很重要。首先，请注意，在方程（1 024）中有一个隐含的假设，即我们所讨论的是瞬时的电流 i 和电压 v。在几乎所有的电路中，电流和电压都是随时间的变化而变化的。对于一个灯泡来说，电流和电压在电灯开关断开时都为零，而当灯泡的开关接通时，电流和电压都不是零，所以很明显，电流和电压的变化都与时间有关。

现在的一个关键性问题是，阻值 R 是否也会随着时间的变化而变化。结果表明，铂和竹丝都不满足表示恒定阻值的方程（1 024）。事实上，这些材料的阻值会随着材料温度的变化而变化，其温度又取决于电流。如果灯丝一开始是冷却的，那么当电流流过它的时候，灯丝的材料就会变热，其阻值就会增大。如果灯丝过热，材料就会熔化，阻值就会变得无穷大（没有电流流动）。因此，在某一时刻，电流不仅取决于当前的电压，也取决于电压和电流在前期的状况。灯泡点亮的时间会影响它的温度，从而也会影响电流。

所以，把阻值 R 固定为常数是行不通的。我们必须让它随时间的变化而变化。但在此时，我们会遇到一个难题。如果阻值 R 是一个根据经验确定的值，那么欧姆定律就变成了一个恒真的命题！也就是说，每个电路都是如此。在任何瞬间，电阻都等于电压除以电流：

R = v/i（512）

这不过是方程（1 024）的另一种形式。通过简单地将方程（512）中的 R 作为阻值的定义，每一个非零电压和非零电流的电路就都应满足欧姆定律。这就将 t 时刻的阻值定义为使得欧姆定律成立的任何值！当然，乔治·欧姆并没有因为发现了一个恒真命题而获得一个以他的名字命名的基本电子元件。所以，这不可能是正确的解释。

解决这个难题的一个办法在于，将电阻的概念作为一种柏拉图式的理想型相。电阻是一个在任何时候都能满足方程（1 024）和（512）且具有恒定阻值 R 的器件。但是在物理世界里没有这样的器件。至少，每一种已知材料的阻值都会受到温度变化的影响。此外，大多数已知的材料都会在电流流过时发热。除温度以外的其他物理效应，特别是电感和电容，都会确保物理材料不可能完全以常数 R 来遵守欧姆定律。这些效应在系统中带入了记忆和动力学。例如，即使电压降到零，电感也是电流持续流动的趋势。非零电感的材料需要一些时间才能将电流调整到新的电压。在此期间，它不能以同样规定不变的常数 R 来满足欧姆定律。

实际上，所有材料都带有非零的电感，即使很小。事实上，没有任何物理对象是电阻，因为没有任何物理对象可以遵循欧姆定律，那么我们又怎么能把欧姆定律当作一条自然法则呢？在柏拉图的关于洞穴的寓言中，人类的感知局限于现实的影子，但物理对象似乎只是电阻的柏拉图式理想型相的影子。这种柏拉图式的型相是人类无法接触的，也是大自然无法接触的！

因此，欧姆定律要么是微不足道的，要么就是错误的。我不得不得出这样的结论 —— 欧姆定律是一个人类构建的模型，而不是关于自然的基本真理。在乔治·欧姆提出欧姆定律之前，它并不作为一个基本存在，因为世界上没有任何物理对象遵守它。在某种程度上，它之所以能够成为一个真理，是因为我们宣称它是真理。我们将「电阻」定义为一个物理对象，其行为与欧姆定律的方程所建模的行为非常接近，我们将阻值定义为该对象两端的电压与通过该对象的电流的比值。除了在人的头脑中，自然界中并不存在一个理想的电阻。因此，欧姆定律是被发明的，不是被发现的。

### 2.3 Models Are Wrong

Modeling is central to every scientific and engineering enterprise. Solomon Wolf Golomb (1932–2016), who has written eloquently about the use of models in science and engineering, emphasizes understanding the distinction between a model and thing being modeled. He famously stated,「You will never strike oil by drilling through the map」(Golomb, 1971). A map is a model. The territory is the thing being modeled. You should drill through the territory, not the map.

For both scientists and engineers, the「thing being modeled」is typically an object, process, or system in the physical world. [3] Let us call the thing being modeled the target of the model. The fidelity of a model is the degree to which it emulates the target.

When the target is a physical object, process, or system, the model fidelity is never perfect. Box and Draper (1987) state,「essentially, all models are wrong, but some are useful.」The model in figure 2.4 is not useful (at least not to me). Ohm's law, in contrast, is quite useful. It models certain physical devices, such as Edison's lightbulb filaments. Although it models them imperfectly, Edison used this model to understand that a bamboo filament was a better choice than a platinum filament in a lightbulb.

A useful model has to have a purpose, and the fidelity of the model needs to be evaluated against that purpose. Ohm's law, as a model for a lightbulb, will tell Edison how much current will flow through the filament, but it will not tell him how much light will be generated. A different model is needed for that purpose.

Note that a model may be「useful」in ways that are not practical or mercenary. Merriam-Webster defines「useful」as「helping to do or achieve something.」That「something」may be further intellectual inquiry or pure science. That is, a model may be useful because it explains or predicts a phenomenon even if there is no practical application for that phenomenon. Einstein's model of gravitational waves is useful because, among other things, it suggests a way to observe the collision of black holes, as done by LIGO, even if we have no practical use for colliding black holes.

When using models, it is important to apply them only within their regime of applicability, which is limited for all models. Ohm's law, by itself, will not be applicable to a resistor that has melted. Gravitational waves are not useful when studying the interactions of subatomic particles. [4]

Models are generally more useful when their fidelity is higher. So how do we get good model fidelity? We have two different mechanisms available to us. We can either choose (or invent) a model that is faithful to the target, or we can choose (or invent) a target that is faithful to the model. The former is the essence of what a scientist does. The latter is the essence of what an engineer does. Both require assuming that the target is operating within some regime of applicability of the model.

Edison was a quintessential engineer of his time. In selecting a lightbulb filament (a target), among other properties (durability, tolerance for high temperature), Edison needed a filament that was well modeled by Ohm's law. Suppose that Edison had chosen instead a filament that was well modeled by a different law known as Faraday's law of induction. This choice would have resulted in a poor lightbulb. If you will indulge me a brief nerd storm, I will attempt to explain why.

As I pointed out before, inductance is the tendency for current that is flowing to keep flowing, even if the voltage drops to zero. An inductor is a device that resists changes in current, as opposed to a resistor, which simply resists current. By analogy, a resistor is like a lazy person and an inductor is like a stubborn person. It takes more effort to get a lazy person to work for you and to keep him working, whereas once a stubborn person is working at something, that person will keep working at it (like me with this book). A person may be both lazy and stubborn, just as a physical device may have both resistance and inductance.

In one of the simpler forms of Faraday's law, the current i and voltage v of an inductor are related by [5]

where the constant L is called the inductance. [6] This equation states that the voltage v ( t ) at time t is proportional to the rate of change of current i at time t , where the proportionality constant is L . This means that if the current changes rapidly, the voltage is high. Vice versa, if the voltage is high, the current changes rapidly.

According to Wikipedia, Electromagnetic induction was discovered independently by Michael Faraday in 1831 and Joseph Henry in 1832. Faraday was the first to publish the results of his experiments. (Retrieved March 15, 2016)

We might be tempted to change「discovered」to「invented」on the Wikipedia page, but that would not be quite right. The word「discovered」is correct for induction but not for equation (256). Equation (256) is an invention. It is an idealized model, and just like Ohm's law, no physical object perfectly obeys it (with constant L ). As a model, therefore, it is wrong, but it is extremely useful.

Kuhn (1962) takes a stand on the relationship between discovery and invention, stating,「Discovery and invention are inseparable because the theory to explain the discovery must occur for the discovery to occur.」The discovery that a current that is flowing tends to keep flowing (inductance) and that this property is accentuated in certain devices (inductors) is inextricably linked to the model represented in equation (256), in the sense that some form of this model has to be understood to recognize the discovery. This link between discovery and invention, Kuhn says, also makes it much more difficult to pinpoint a discovery, assigning it to a particular person at a particular time:

· · · the sentence,「Oxygen was discovered,」misleads by suggesting that discovering something is a single simple act assimilable to our usual (and also questionable) concept of seeing. That is why we so readily assume that discovering, like seeing or touching, should be unequivocally attributable to an individual and to a moment in time. But the latter attribution is always impossible, and the former often is as well. (Kuhn, 1962, p. 55)

Discoveries never occur at an instant in time and are rarely properly attributable to an individual. The messiness with the discovery of the transistor effect, leading to a Nobel Prize, years after the transistor had been patented as an invention, underscores this point.

Let me illustrate how Edison might have used the model of inductance in equation (256). Suppose that he had chosen as a lightbulb filament an inductor like those in figure 2.8 . The first problem he would have run into is that these filaments would not have generated any light. But this would only be the start of his problems. Suppose for simplicity that L = 1 henry. [7] Suppose that we now apply a constant voltage of one volt to the lightbulb. By equation (256), the rate of change of current becomes

This has units of amps per second. It means that for every second that passes, the current increases by one amp. If the current is initially zero when we turn on the lightbulb, then after 10 seconds, the current will be 10 amps. After one minute, the current will be 60 amps. After one hour, the current will be 3,600 amps. After a few days, the house will have burned down, the transformer on the power pole outside the house will have blown up, and the electric bill will have become more than the cost of a college education. Edison would not have been able to sell us more than one such lightbulb. [8]

I have already concluded that both Ohm's law and Faraday's law are wrong, in the sense that no physical object obeys either law exactly. But a bamboo fiber in a vacuum bulb comes pretty close to obeying Ohm's law, and a coil of copper around an iron core, as on the left in figure 2.8 , comes pretty close to obeying Faraday's law. However, in both cases, the model is wrong.

Edison was an engineer, but he also made contributions to science, and he relied heavily on experimentation, as many scientists do. To a scientist, the value of a model lies in how well its properties match those of a target, typically an object found in nature. The value of Ohm's and Faraday's laws lies in how well they describe the properties of some object under study. But to an engineer such as Edison, the value of an object, say a bamboo fiber, lies in how well its properties match a model, in this case, Ohm's law. Edison understood enough about electricity to know that an inductive filament would be of no use. Instead, he knew that he needed a filament for which Ohm's law was a faithful model (and that also generated light), and he went about the task of finding a filament (a target) for that model.

Figure 2.8 A few mostly hand-made inductors. [Image by「me,」licensed under CC BY-SA 3.0. Original available at: https://commons.wikimedia.org/w/index.php?curid=1534586 .]

According to Popper's philosophy of science, a scientific model, a「theory,」must be falsifiable to be scientific. Under this principle, Ohm's and Faraday's laws are either unscientific or false. If the laws are tautologies, then they are not falsifiable, and if not, then no physical object obeys them, so they are false. Ohm's and Faraday's laws are useful not true .

In what Simon might have called the「sciences of the natural,」to distinguish them from the「sciences of the artificial,」a scientist is, by definition, given the target. It exists in nature. Such a scientist constructs models to help understand the target. An engineer, in contrast, constructs targets to emulate the properties of a model. An engineer uses or invents models for things that do not exist and then tries to construct physical objects (targets) for which the models are reasonably faithful. For an engineer, a model provides a design and the target is the implementation . The task is to find an implementation that is faithful to the model.

These two uses of models are complementary. Engineers and scientists will typically use models both ways. Edison spent a great deal of effort characterizing the electrical properties of all sorts of natural materials before settling on bamboo fibers. Good engineering requires doing good science. And at least for experimental science, good science requires doing good engineering, as we saw in the last chapter with the LIGO gravitational wave detector.

In both cases, the models are wrong. In engineering, a model is useful if we can find an implementation that is reasonably faithful to the model. In science, a model is useful if it is reasonably faithful to a target given to us by nature. A scientist asks,「Can I make a model for this thing?」An engineer asks,「Can I make a thing for this model?」

Models are human constructions. Modeling paradigms are also human constructions. Therefore, both are subject to creativity. They are invented not discovered. Because an engineer constructs models for things that do not yet exist, there is much more room for creativity than for a scientist, at least one focusing on the sciences of the natural, who is stuck crafting models for things that already exist. Moreover, I claim that digital technology has smashed open the possibilities for what could exist, so the room for creativity is vast indeed. I examine how digital technology does this in the next chapter.

3 The「thing being modeled」can also be another model. I will examine that issue later in chapter 3 .

4 Penrose (1989) speculates that gravitational waves may in fact be implicated in certain subatomic quantum mechanical phenomena, but as of this writing, there is no experimental corroboration for this thesis and no wide support among physicists.

5 Messerschmitt's law (see footnote on page 2) probably becomes overly conservative when the equation uses calculus, as this one does. I suspect that this equation will drop my readership by more than half, but I will nevertheless stick to the numbering scheme previously established.

6 The units of the inductance L are called「henries」after Joseph Henry. It is customary to use the symbol L for inductance.

7 One henry is actually a very large inductance, but it makes the math simpler and therefore will damage my readership less than a more reasonable choice of, say, one millihenry.

8 Most household circuits in the United States have fuses that trip, interrupting the current, when the current exceeds 15 or 20 amps, so this scenario would not play out this way in your house. Also, the voltage supplied in a household circuit is much larger, typically 170 volts at its peak in the United States (see Lee and Varaiya [2011] sidebar on page 11 for an explanation of household electric power). Hence, during the time that the voltage is 170 volts, the current will increase at a rate of 170 amps per second, which means it will reach 15 amps in 11 milliseconds. At this point, it will trip the fuse, leaving you in the dark. So the bulb would operate for only 11 milliseconds.

2.3 模型是错误的

建模是每一项科学和工程工作的核心。所罗门·沃尔夫·格伦布（1932-2016）曾撰写过关于在科学和工程中应用模型的一篇精彩文章，他强调理解模型和正在被建模的事物之间的区别特别重要。他有一句名言：「通过在地图上钻孔，你永远不会找到石油。」（格伦布，1971）地图就是模型，而土地是被建模的对象。显而易见，你应该在土地上钻井，而不是在地图上（如图 2.7 所示）。

对于科学家和工程师来说，「被建模的事物」通常是物理世界中的一个对象、过程或系统。让我们把被建模的事物称为模型的目标物。模型的保真度就是它模仿目标物的接近程度。

图 2.7 在地图上钻孔。（这张照片由摄影师鲁西·姆切德利什维利提供。）

当目标物是物理对象、过程或系统的时候，模型的保真度永远不会是理想的。博克斯和德雷珀（1987）曾指出：「从本质上讲，所有的模型都是错误的，但有些是有用的。」图 2.4 中给出的模型并没有什么用（至少对我而言是如此）。相反，欧姆定律却是非常有用的模型。它对某些物理装置进行了建模，如爱迪生的灯丝。虽然所建立的模型还不够理想，但它让爱迪生明白竹丝比金属铂丝更适合用来制作灯泡。

一个有用的模型必须有一个目的，并且模型的保真度应该根据这个目的进行评估。作为灯泡的模型，欧姆定律可以告诉爱迪生会有多少电流流过灯丝，但它不会明确告知爱迪生该模型能够产生多少光。为此，我们还需要另一个不同的模型。

请注意，模型可能在不实际或不产生实际效果的方面是「有用的」。《韦氏大词典》对「有用」的定义是「帮助做某事或达成某事」。「某事」可能指的是进一步的知识探索或纯科学。也就是说，一个模型可能是有用的，因为它解释或预测了一种现象，即使它没有对应于这种现象的实际应用。即使我们对黑洞碰撞没有实际应用，爱因斯坦的引力波模型也很有用，因为它提出了一种观察黑洞碰撞的方法，就像激光干涉引力波天文台所做的那样。

在使用模型时，在其适用的范围内应用它们是非常重要的。所有模型都有其适用范围。欧姆定律本身不适用于已经熔化的电阻。引力波在研究亚原子量子的相互作用时也是无用的。模型的保真度越高，它们通常就会越有用。那么，我们如何才能获得良好的保真度呢？我们可以有两种可用的不同机制。我们可以选择（或发明）一个高度符合于目标对象的模型，也可以选择（或发明）一个高度符合于模型的目标对象。前者是科学家工作的本质，后者是工程师工作的本质。两者都要求假设目标对象在模型的某个适用范围内运作。

爱迪生是他那个时代的一名杰出的工程师。在选择灯泡的灯丝（一个目标对象）时，除了耐用性、耐高温性等特性之外，爱迪生还需要一种能由欧姆定律很好地模拟的灯丝。假设爱迪生选择了一种人们熟知的法拉第电磁感应定律所模拟的灯丝，那么这种选择一定会生产出一个非常糟糕的灯泡。请允许我再次进行一场简短的技术呆子风暴，以解释其中的原因。

正如我之前指出的那样，即使电压降为零，电感仍然会维持电流的流动趋势。电感是一种能够抵抗电流变化的装置，而电阻只是一种能够抵抗电流的装置。打个比方，电阻就像一个懒惰的人，而电感就像一个固执的人。要想让一个懒惰的人为你工作并持续工作需要更多的努力，而一个固执的人一旦做了某件事，他就会一直做下去（就像我写这本书一样）。一个人可能既懒惰又固执，就像一个物理装置可能既有电阻又有电感一样。

在法拉第定律的一种较简单的表现形式中，电感的电流 i 和电压 v 具有如下关系：

其中，常数 L 被称作感应系数（即电感值）。这个方程表明，t 时刻的电压 v 与电流 i 的变化率成正比，其中比例常数为 L。这意味着，如果电流变化很快，电压就会升高；反之，如果电压高，电流就会变化很快。

根据维基百科的解释：

电磁感应是由迈克尔·法拉第在 1831 年以及约瑟夫·亨利在 1832 年分别独立发现的。法拉第是第一个公布这个实验结果的人。（2016 年 3 月 15 日检索）

我们可能会试图把维基百科页面上的「发现」改为「发明」，但这并不完全正确。「发现」一词用于电磁感应是正确的，但不适用于方程（256）。方程（256）是一项发明，就像欧姆定律一样。这个方程也是一个理想化的模型，没有物理对象能够完全遵循它（L 为常数）。因此，作为一个模型而言其是错误的，但又是非常有用的。

库恩（1962）就发现和发明之间的关系阐明了自己的观点，他认为「发现和发明是分不开的，因为解释发现的理论必须出现，才能使这个发现真正出现」。正在流动的电流趋向于保持流动（感应系数），以及某些装置（电感）会呈现这一特性的发现，与方程（256）中所表示的模型不可分割地联系在一起。从某种意义上说，必须理解这一模型的某种形式才能认识这一发现。库恩说，发现和发明之间的这种联系，也使得人们很难准确地确定一个发现是谁在什么时候发现的：

……「氧气是被发现的」这句话极大地误导了我们，因为它认为发现某种东西是一种简单的行为，与我们通常（我对此同样表示质疑）所理解的「看」的概念类似。这就是为什么我们如此轻易地认为，发现，就像看或触摸一样，应该明确地归属于某个人和某个时刻。然而，后一种归因总是不可能的，前一种也经常是不可能的。（库恩，1962:55）

发现从来不会在瞬间发生，也很少能完全归因于某个人。晶体管效应的发现获得了诺贝尔奖，这一发现的混乱情况在晶体管作为一项发明而获得专利的数年后更为显著。

让我来解释一下爱迪生可能是如何使用方程（256）中的电感模型的。假设他选择了如图 2.8 所示的电感作为灯泡的灯丝。他遇到的第一个问题就是这种灯丝不会产生任何光。但这只是问题的开始。为了简单起见，假设 L=1 亨利，并假设我们现在给灯泡施加 1 伏特的恒定电压，那么根据方程（256），电流的变化率为：

它的单位是每秒的安培数。这意味着每经过一秒，电流就会增加 1 安培。如果我们接通灯泡时的最初电流为零，那么 10 秒之后，电流将变为 10 安培；1 分钟以后，电流将达到 60 安培；1 小时后，电流将达到 3 600 安培；过不了几天，整栋房子就会被烧毁，房子外面电线杆上的变压器也会爆炸，而电费也将会超过读大学的学费。这样，爱迪生卖给我们的灯泡就不可能超过一个。我已经得出结论 —— 欧姆定律和法拉第定律都是错误的，因为没有任何物理对象能够完全遵守这两条定律。但是，真空灯泡中的竹纤维非常接近遵守欧姆定律，而铁芯周围的铜线圈（如图 2.8 所示）则非常接近遵守法拉第定律。然而，即便是在这两种情况下，模型也是错误的。

图 2.8 几个手工制作的电感。［图片由「我」提供，并获得 CC BY-SA（署名 - 非商业性使用 - 相同方式共享协议文本）3.0. 授权。原图片网址 https://commons.wikimedia.org/w/index.php?curid=1534586。］

爱迪生是一名工程师，但他对科学也做出了巨大贡献。他和许多科学家一样，非常依赖实验。对于科学家来说，模型的价值在于它的特性与目标物（通常是在自然界中发现的对象）属性的匹配程度。欧姆定律和法拉第定律的价值在于它们描述研究对象属性的准确程度。但是，对于像爱迪生这样的工程师来说，一种对象的价值（如竹纤维）取决于它的属性与模型（这里就是欧姆定律）的匹配程度。爱迪生对电有足够的了解，他知道感应灯丝是没用的。相反，他知道他需要一根以欧姆定律为相符模型的灯丝（并且还能产生光），于是，他开始为这个模型寻找一根灯丝（一个目标物）。

根据波普尔的科学哲学，一个科学模型，或者是一种「理论」，在科学上必须是可证伪的。按照这一原则，欧姆定律和法拉第定律要么是不科学的，要么是错误的。如果定律是恒真命题，那么它们是不可证伪的。如果定律不是恒真命题，那么在现实中就没有任何物理对象会遵守它们，所以它们是错误的。欧姆定律和法拉第定律是有用但不正确的。

为了有别于「人工科学」，在西蒙所说的「自然科学」中，科学家根据定义被赋予了这个目标物，其存在于自然界中。这样的科学家建立模型，帮助人们理解该目标物。相比之下，工程师则构建目标物模拟一个模型的特性。工程师为不存在的事物使用或发明模型，然后尝试构造出高度符合于模型的物理对象（目标物）。对于工程师来说，模型提供了一种设计，而目标物是其实现。任务在于，要找到一个高度符合于该模型的实现。

这两种模型的使用是互补的。工程师和科学家通常会以这两种方式使用模型。爱迪生花费了大量精力来研究各种天然材料的电特性，之后才选定竹纤维。因此，好的工程要以好的科学为基础。至少对于实验科学来说，好的科学研究需要好的工程来配合，正如我们在上一章提到的激光干涉引力波天文台的工作一样。

但是，很遗憾，在这两种情形下模型都会是错的。在工程中，如果我们能够找到一个高度符合于模型的实现，那么该模型就是有用的。在科学中，如果一个模型高度符合于大自然给我们的一个目标物，那么这个模型是有用的。科学家常常会问这样的问题：「我能为这个东西构造一个模型吗？」工程师则会问：「我可以为这个模型做点儿什么吗？」

模型是由人类所构造的，建模的范式也是由人类构造的。因此，二者都受制于人类的创造力。它们都是被发明的，而不是被发现的。因为工程师会为尚不存在的事物构造模型，所以和专注于自然科学的科学家相比，他们的创造力空间更大。原因在于，科学家常常被困于为已经存在的事物构造模型。此外，我认为数字技术已经为一切的可能存在打开了可能性，创造力的空间确实是巨大的。我将在下一章分析数字技术是如何做到这一点的。

## 0301. Models of Models of Models of Models of Things

· · · in which I argue that in engineering, models are stacked many layers deep, with the design of each layer affecting the designs both above and below it; and that the engineering use of models enables creativity because the layering of models distances designers from the physical constraints of the realization. Digital technology, particularly, has, in effect, mostly removed any meaningful physical constraints from a broad class of engineered systems. Innovation, therefore, is less limited by the physics of the technology than it is by our human imagination and ability to assimilate new paradigms.

0301 事物之模型之模型之模型

我认为：1）工程中的模型是深度层叠的，并且每一层的设计都会影响上、下相邻两层的设计；2）而且模型的工程运用能激活创造性，这是因为模型的分层使设计者能够摆脱现实的物理约束。实际上，特别是数字技术已经在很大程度上消除了一大类工程系统中任何有意义的物理约束。因此，可以说，人类的想象力和吸收新范式的能力是限制创新的因素，而不是技术本身的因素。

### 3.1 Technological Tapestries

Consider the engineer's question,「Can I make a thing for this model?」Suppose that the answer is「yes」for a broad class of models. For example, technology today gives us the ability to make networks of electrically controlled switches, where closing one switch can cause another switch to open or close. A semiconductor chip is such a network, where the switches are realized as transistors and the network consists of wires that connect the transistors. The medium in which such a network is crafted is the silicon and metal of semiconductors, a physical medium.

Once the answer to the question is「yes, we can make the thing」for networks of switches, then networks of switches become a medium for making models. This medium has its own paradigm, much like Kuhn's scientific paradigms. Just as a scientist uses a paradigm to construct a model of a thing, so does an engineer. The paradigm gives the conceptual framework within which to understand the model.

So what can we build with networks of switches? The network of switches paradigm is quite an expressive one. With just two states for each switch, on and off, it might not seem so expressive, but it turns out that we can interconnect such switches to perform logic functions corresponding to natural language words such as「and,」「or,」and「not.」We can interconnect those logic functions to compare and manipulate strings of bits that represent text and to perform arithmetic on numbers represented in binary. In fact, networks of switches are capable of enormously rich manipulation of any information that is representable as sequences of zeros and ones. It is no accident that transistors functioning as binary switches are the linchpins of information technology.

Once we have the ability to perform arithmetic, we open up the possibility of using another paradigm for design, namely, arithmetic expressions. This paradigm is distinctly different from the network of switches paradigm, but models in the arithmetic expression paradigm are implementable as models in the network of switches paradigm. So if an engineer has a model consisting of arithmetic operations on binary numbers and again asks the question,「Can I make a thing for this model,」then again the answer is「yes.」To realize the「thing,」however, the arithmetic model needs to be first translated into a network of switches model, which then in turn is translated into a silicon chip. Arithmetic expressions become a virtual medium, not directly physical, but translatable into something physical through one level of indirection. This is my first example of transitive models.

It turns out that we can do much more with networks of switches. We can make memory, which stores binary patterns. For example, a bank balance of $256 can be represented by the binary pattern 0000000100000000. There are 16 bits in this representation. It is possible to design a network of 96 switches that can store this number indefinitely. If a customer deposits $16, representable by the binary number 0000000000010000, then a network of switches can add the two numbers, getting 0000000100010000, the binary representation for the number 272. It can then update the memory with the new balance. We can start to see the glimmer of how a computer banking system can emerge from networks of switches.

But thinking about a computer banking system as a network of switches is not practical. For one thing, the number of switches actually required will be vastly more than I've indicated above, and the operations that need to be performed are vastly more complex. A bank will not hire an engineer to wire together transistors, which realize the switches, to make a computer banking system. Instead, the bank will hire an engineer who will write software that will be translated by a computer into a binary pattern that will control a machine that is ultimately composed of a network of transistors. This engineer need not know anything about how to craft a transistor, nor how to perform binary arithmetic using networks of switches, nor how to organize networks of switches to make memories.

In fact, there are many layers of models between the bank engineer and the physical realization. The bank application, a computer program represented as a sequence of letters, numbers, and punctuation, is in fact a model of a model, which in turn is a model of another model, which in turn is yet another model of a model, until ultimately we get down to a model of a thing. Each of these layers of modeling has a paradigm, and each paradigm is a human invention. Only the lowest level physics is given to us by nature.

In this chapter, I will attempt to articulate why such layering of paradigms is so powerful and how the layers turn paradigms into a creative medium that other engineers can use to realize their models. You may come at this with the preconception that these layers of paradigms will be dry, fact-laden technologies, intricate and boring at the same time. But they are not. They are shaped by what is physically possible, but particularly with digital technology, it turns out that so much is possible that they are much more shaped by the personalities and idiosyncrasies of the engineers who create them.

Educators all too often belie the personality of the technology. They present technology as Platonic facts about the world that must be mastered. This is how the educators learned about it. But the creators of the technology did not learn it that way. They invented it, and like literature and art, their inventions reflect the predilections of the creators and the (technological) culture in which they lived. The culture in which they lived was, in turn, defined by the inventions of others. Technology is not a collection of Platonic truths that have always been lurking in the background, waiting to be discovered, but is rather a rich sociological tapestry of ideas created by human inventors. It is shaped by those humans, and had a different set of humans created it, including more women, for example, the technology would unquestionably be different.

I will defer many details to the next two chapters, where I attempt to capture the paradigms and cultures that have manifested in hardware and software technology. In this chapter, I keep a high-level view.

3.1 技术的分层

让我们先来看一看工程师给出的一个问题：「我可以为这个模型做点儿什么吗？」假定对于一大类模型来说，该答案是「是的」。例如，今天的技术使我们能够构造电气控制的开关网络。在这个网络中，闭合一个开关会导致另一个开关断开或闭合。半导体芯片就是这样的网络，其中的开关就是晶体管，网络是由连接这些晶体管的线路组成的。制作该类网络的介质是硅金属半导体，它是一种物理介质。

一旦这个问题的答案是「是的，我们可以」，那么开关网络就变成了构造模型的媒介。就如同库恩的科学范式一样，这种媒介也有它自己的范式。正如科学家使用范式来构建事物的模型一样，工程师也使用范式来构建事物的模型。范式提供了理解模型的概念框架。

那么，我们可以建立什么样的开关网络呢？开关网络的范式是颇具表达力的。每个开关只有两种状态 —— 开（导通）和关（截止），它看起来不那么有表达力，但事实证明，我们可以将这些开关连接起来，以执行与自然语言相对应的逻辑功能，例如「与」、「或」和「非」。我们可以将这些逻辑功能互联起来，以比较和操作表示文本的位串，并对二进制表示的数字执行算术运算。事实上，开关网络能够对任何可以表示为 0、1 序列的信息进行极其丰富的操作。作为二进制开关的晶体管能成为信息技术的关键，这并非偶然。

一旦我们拥有了执行算术运算的能力，我们就有可能开启另一种设计范式 —— 算术表达式。这一范式与开关网络的范式有着明显的不同，但算术表达式范式中的模型与开关网络范式中的模型一样具有可实现性。因此，如果一个工程师有一个由二进制数的算术运算组成的模型，并且再次回到这个问题 ——「我可以为这个模型做点儿什么吗？」，那么答案依然会是「是的」。然而，要实现「做点儿什么」的愿望，首先需要将算术模型转换为一个开关网络模型，然后将其转换为硅芯片。由此，算术表达式就变成了一种虚拟的媒介，它并非直接就是物理的，但可以通过一个间接层转换到某个物理介质。这是我要解释的第一个传递性模型的例子。

事实证明，我们可以用开关网络做更多的事情。我们可以用它创建存储器，存储二进制模式。例如，256 美元的银行余额可以用二进制模式 0000000100000000 来表示。这种二进制表示法共有 16 位。我们可以设计一个由 96 个开关组成的网络，其可以存储银行无限多的数据。如果客户存入账户 16 美元，该数据可以用二进制模式 0000000000010000 来表示，随后，开关网络可以将这两个数进行相加，并得到一个二进制数 0000000100010000，这个二进制数表示十进制数 272。然后，它可以用新的银行余额更新存储器。我们可以看到计算机银行系统是如何从开关网络中慢慢浮现而出的。

但是，把计算机银行系统看作一个开关网络是不现实的想法。首先，它实际所需的开关数量比我前面给出的例子要多得多，同时，所需执行的操作也要复杂得多。银行不会雇用一名工程师来连接实现开关功能的晶体管，以构建一个计算机银行系统。相反，银行会聘请一名工程师编写软件，这些软件将被计算机翻译为二进制模式，从而控制最终由晶体管构成的机器。这位工程师不需要知道如何制造一个晶体管，也不需要知道如何使用开关网络进行二进制运算，更不需要知道如何组织开关网络来制造一块存储器。

事实上，在银行系统的工程师和最终的计算机银行系统之间有许多模型层次。银行的应用，一个由字母、数字和标点符号组成的计算机程序，实际上是另一个模型的模型，另一个模型又是第三个模型的模型，以此类推，直到我们最终向下到达某个事物的模型。每个建模层次都有一个范式，而且每个范式都是由人类发明的。只有最低层的物理实体是大自然给予我们的。

在本章中，我试图阐明为什么分层的范式会如此强大，以及这些层次如何将范式转化为其他工程师可以用来实现其模型的创造性媒介。此时，你可能会带有成见地认为，这些范式层是枯燥的和充满事实的技术，同时也是复杂的和无聊的。然而，事实并非如此。它们是由物理上的可能性塑造的，尤其是有了数字技术之后，事实证明，它们更可能带有缔造者（工程师）的个性和气质的深深印迹。

教育工作者往往不承认技术的个性。他们把技术描述为人们必须掌握的关于世界的柏拉图式的事实。这就是教育家学习它的方式。但是，技术的创造者并不是以这种方式来学习的。他们发明了技术，就像文学和艺术是被发明的一样。他们的发明反映了创造者的个人偏好，以及他们所处的（技术）文化环境。反过来，他们所处的文化环境又为其他人的发明所定义。技术不是一直潜伏在幕后等待被发现的柏拉图式真理的集合，而是由人类发明家创造的丰富的社会学思想的结晶。它是由这些人塑造的，并且是由一群不同的人创造出来的，其中包括很多女性。因此，技术无疑会有所不同。

我将把许多细节推到接下来的两章中进行阐述。在这两章中，我将尝试捕捉在硬件和软件技术中表现出来的范式和文化。而在本章中，我主要是给出一个高层次的观点。

### 3.2 Complexity Simplified

Engineering of simple systems, like Edison's lightbulb, can be carried out with a prototype-and-test approach. But this approach breaks down as systems get more complex. With more complex systems, the use of models becomes much more important.

Complexity is a difficult concept to pin down. Roughly speaking, something is complex when it strains our human minds to comprehend it. Complexity is therefore a relation between an artifact or a concept and a human observer.

One source of complexity is large numbers of parts. The human brain has difficulty keeping in mind simultaneously more than a few distinct components. In the early days of the telephone network, for example, extensive human studies conducted by Bell Labs determined that people could reliably keep seven numbers in short-term memory but not more. So telephone numbers were constructed with seven digits.

Computers have no such difficulty. They can easily keep billions of numbers「in mind」simultaneously. Computers, therefore, become both a source of complexity for us (we can't understand what they are doing with all those numbers) and a way to help us manage complexity (we delegate to them our memory).

Consider the horse model shown being 3D printed in figure 2.3 . The virtual prototype shown in figure 2.5 has more than 23,000 triangular facets. Each facet is specified by nine numbers, so the STL file that defines the virtual prototype contains more than 207,000 numbers represented by more than 46 million bits. Yet my laptop computer generates from these numbers the graphic image shown in the figure, complete with simulated lighting, in less than one second. I can interactively rotate that graphical image to examine all sides of the horse with no noticeable delay for the computer to re-render and re-simulate the lighting at each angle. The rendering of the image requires millions of arithmetic computations on the numbers that represent the vertices of the 23,000 triangles.

It is harder to design a complex system using Edison's prototype-and-test approach because there are so many more possible configurations to try. Nevertheless, prototypes and tests on those prototypes continue to play a major role in engineering today. A modern prototype of an electrical device is shown in figure 3.1 and reported in Choi et al. (2001). This is a transistor of a type called a FinFET, invented at Berkeley by Jeff Bokor, Tsu-Jae King, Chenming Hu, and their students. The prototype shown in the figure, made in 2001, uses the same principles as the field-effect transistor (FET) patented by Julius Lilienfeld (Lilienfeld, 1930).

The innovation in this transistor is its structure, which is more vertical than its predecessors in integrated circuits. Its vertical structure enables many more of these transistors to be packed into a given area of a silicon chip.

I would like to emphasize the dimensions indicated in the figure. The「fin」on the FinFET is 20 nanometers wide. There are one billion nanometers in a meter, so this is quite small indeed.

Figure 3.1 Prototype of a modern transistor. [Courtesy of Tsu-Jae King-Liu.]

Consider the implications of being able to realize a transistor that is so small. A modest sized silicon chip is about one centimeter squared. How many 20-nm squares fit in one centimeter squared? Shall I pause for you to do the calculation?

Pause.

OK, hopefully you got the same answer I did, which is 2.5 × 10 11 , or 250 billion! This is a square centimeter:

It is hard to imagine fitting 250 billion distinct human-made objects into the space above.

As of 2017, nobody has made a chip with 250 billion transistors (yet), in part, because a chip includes many other things besides transistors, such as wires to connect the transistors. Also, each transistor needs some space around it to separate it from neighboring transistors. So how many transistors can a chip have in practice?

Intel makes a family of microprocessor chips that they call their Haswell line using 22-nm FinFETs. You may have such a chip in your computer. Figure 3.2 shows a portion of a silicon wafer containing several such chips. A「fab」is a high-tech factory that produces such wafers and then cuts them into individual chips and packages them for inclusion in a computer. Each chip in the figure occupies 1.77 centimeters squared, nearly twice as big as the square shown above, and has 1.4 billion transistors (Shimpi, 2013). This is far fewer than 250 billion, but it is still a large number. [1]

Much writing about such technology, including what I've written above, has a breathless enthusiasm about the big numbers. But most of us actually have quite a bit of difficulty assigning any meaning to such numbers because they are so much bigger than anything we encounter in daily life. In fact, the point I want to make is that the human brain is incapable of comprehending any design that has 1.4 billion individual components, each with a potentially different function, despite the fact that the human brain has some 100 billion neurons, each of which does more than a transistor!

Each transistor can function as an electronic switch. It has a control input that either turns the switch on or turns it off. It can turn on and off billions of times per second. Billions of transistors switching billions of times per second creates unimaginable potential complexity.

Figure 3.2 Photo of a silicon wafer with several Intel Haswell microprocessor chips. The pin on top is for scale. [Photo by Intel Free Press (Flickr: Haswell Chip), released under a CC BY 2.0 license, via Wikimedia Commons.]

How can we design anything using this technology? Can we use Edison's prototype-and-test style of experimentation? Bokor, King, and Hu probably did some prototyping and testing before getting a single FinFET to work. Even so, it was much harder for them than for Edison simply because of the dimensions involved. It is extremely difficult to sculpt a physical structure 20 nm wide. You can't do this with a hammer and chisel. As a consequence, they would have had to make much more use of models than Edison did.

But more to the point, if you want to design a system based on a silicon chip, would you start your design by assembling and interconnecting transistors? Consider, for example, the system I am using to write this book. I'm using a software package called that converts text that I type into a formatted book that can be distributed electronically or printed. Suppose I want to design such a system. Should I start with a bagful of transistors and start connecting them in various ways to see what they do? Most certainly not.

is an interesting story. It provides me, a book author, with a paradigm for modeling a book. I construct a model of my book in a text editor that contains annotations such as \footnote{Footnote contents} to create a footnote, such as this one. [2] I then run a program to convert the text model into a PDF file, another model of pages to be printed. was created by Leslie Lamport in the early 1980s, when he was at SRI International. Lamport is an astonishingly prolific and influential computer scientist who received the 2013 Turing Award, sometimes called the Nobel Prize of computer science, for his work on distributed software systems. stands for「Lamport's 」and is built on top of , designed in the late 1970s by Donald Knuth from Stanford University, another Turing Award winner. Knuth is most well known for his monumental multi-volume work The Art of Computer Programming , an encyclopedic compendium of algorithms and principles of programming. Vikram Chandra, in his wonderful book about the aesthetics of software, Geek Sublime , said,

If ever there was a person who fluently spoke the native idiom of machines, it is Knuth, computing's great living sage. (Chandra, 2014)

In an article called「Literate Programming,」Knuth argued that software is a literature where code can be written as much to communicate with other human beings as to tell the computer what to do:

Let us change our traditional attitude to the construction of programs: Instead of imagining that our main task is to instruct a computer what to do, let us concentrate rather on explaining to human beings what we want a computer to do. (Knuth, 1984, emphasis in the original)

Knuth created TeX over about 10 years starting in the late 1970s because he found the typography of phototypesetting systems of the day ugly. Today, thousands of people have contributed to and , primarily through a system of packages that support an astonishing variety of document preparation needs. It is a thriving, open-source community where nearly all software is free. Almost as if in homage to Knuth, the code gets read and improved by others. The typography that TeX produces, in my opinion, is better than any commercial word processor that I have encountered. In chapter 5 , I will have much more to say about the human expressiveness of software.

[1] The particular chip shown in figure 3.2 is a「quad-core + GPU」version of the Haswell product, meaning that each chip actually contains five computers, four「cores」that execute your programs and one「graphics processing unit」that manages the rendering of graphics and text on a screen. The GPU is also a computer, albeit a rather specialized one. If you squint at the figure, you can see the dies for each chip, the rectangular repeating pattern. Within each die, you can see four identical patterns; these are the four cores. The GPU is above the four cores. The rest of the chip is probably mostly memory. As of this writing (August 2016), the largest Haswell chip has 5.56 billion transistors, is about 6.6 centimeters squared, and has 18 cores.

[2] Footnote contents

3.2 简化的复杂性

简单系统的工程，如爱迪生的灯泡，可以用一种原型 — 测试的方法来实现。但随着系统变得越来越复杂，这种方法可能会失效。对于更为复杂的系统，模型的使用变得越发重要。

复杂性是一个很难被界定的概念。粗略地说，当一件事迫使我们绞尽脑汁去思考才能理解时，它就是复杂的。因此，复杂性是一种人工制品或一个概念与观察者之间的关系。

复杂性的一个来源是大量的组件。人类的大脑很难同时记住几个不同的组件。例如，在电话网络发展的早期，贝尔实验室对人类的记忆能力进行了大量研究。研究结果表明，人类在短时间内可以可靠地记住 7 个数字，但不能再多了。

所以电话号码是由 7 位数组成的。

计算机没有这样的困难。它们可以很容易同时「记住」数十亿个数字。因此，计算机对我们人类来说既是复杂性的来源（我们无法理解它们在用这些数字做什么），也是帮助我们管理复杂性的一种方法（我们将自己的记忆托付给它们）。

以图 2.3 中 3D 打印的马的模型为例，图 2.5 所示的虚拟模型共有超过 23 000 个三角形平面。每个平面都由 9 个数字指定，因此，定义虚拟模型的 STL 文件中包含了由 4 600 万比特表示的超过 207 000 个数字。然而，我的笔记本电脑可以用这些数字生成图中的图形，并在不到 1 秒钟的时间内完成模拟光线。我还可以在没有明显延迟的情况下交互式旋转该图形，以便计算机重新渲染和重新模拟每个角度的光线。该图像的渲染需要对代表 23 000 个三角形顶点的数字进行数百万次的算术运算。

使用爱迪生的原型 — 测试法设计一个复杂的系统比较困难，因为有太多可能的配置可供尝试。尽管如此，针对原型的这些原型 — 测试方法在今天的工程中仍然扮演着重要的角色。图 3.1 所示的是崔伊等人（2001）报道的电子元件现代原型。这是一种被称为鳍式场效应管（FinFET）的晶体管，是由杰夫·博科尔、金智杰、胡正明和他们的学生在伯克利大学发明的。图中所示的原型是在 2001 年制造的，其原理与朱利叶斯·利林菲尔德申请的场效应晶体管专利具有相同的原理（利林菲尔德，1930）。

这种晶体管的创新之处在于其结构，它比以前的集成电路更加立体。它的垂直结构使得更多的晶体管可以被封装到一个硅芯片的特定区域。

我要强调一下图中所示的几个尺寸大小。鳍式场效应晶体管上的「鳍」的宽度是 20 纳米。我们知道，1 米有 10 亿个纳米，所以这确实是相当小的。

图 3.1 一个现代晶体管的原型。（金智杰供图，致谢。）

让我们来思考一下实现如此小的晶体管的意义。一个中等规模的硅芯片的面积约为 1 平方厘米。想想看，1 平方厘米的硅芯片上能有多少个 20 纳米的小方块呢？我要不要先停下来，等你计算一下呢？

我先暂停一会儿。

好吧，希望你得到的答案和我的一样，那就是 2.5×1011，也就是 2 500 亿！下面这个小方块的面积就是 1 平方厘米：

要把 2 500 亿个不同的人造对象装进上面的空间，这的确令人难以想象。

在 2016 年之前，还没有人制造出拥有 2 500 亿个晶体管的芯片，部分原因是除了晶体管之外，芯片中还包括许多其他的东西，例如连接晶体管的线路。此外，任何两个晶体管之间都需要一定的距离和空间。那么，一个芯片实际上能有多少个晶体管呢？

英特尔公司使用 22 纳米的鳍式场效应晶体管制造了一系列的微处理器芯片，并将它们命名为 Haswell 系列芯片。你的电脑里可能就有这样的一块芯片。图 3.2 给出了包含多个此类芯片的硅芯片的一部分。作为高科技工厂，「晶圆厂」生产这种晶圆，然后将其切割成单个芯片，并将它们安装在计算机中。图中每个芯片的面积是 1.77 平方厘米，几乎是如上所示正方形的两倍，且具有 14 亿个晶体管（辛皮，2013）。这远远少于如前所述的 2 500 亿，但是仍然是一个庞大的数字。图 3.2 这是一张带有多个英特尔 Haswell 微处理器芯片的硅片照片。通过上面的别针可以感受其大小。[照片由英特尔免费媒体（雅虎网络相册：Haswell 芯片）发布，已获得维基共享资源 2.0 授权。]

很多关于这类技术的文章，包括我在上面所写的，都对大的数字有着令人窒息的热情，因为它们比我们在日常生活中遇到的任何东西都要大得多。但实际上，我们大多数人很难给这些庞大的数字赋予任何意义。事实上，我想说明的一点是，尽管人类的大脑有大约 1 000 亿个神经元，且每个神经元的功能都比一个晶体管更复杂，但人类的大脑还是无法理解任何由 14 亿个功能都可能不同的单个组件构成的设计！

每个晶体管都可以作为一个电子开关。它有一个控制输入，可以使得开关导通或截止。它可以在每秒钟开关数十亿次。数十亿计的晶体管以每秒数十亿次的速度进行开关，其结果就是产生了难以想象的潜在复杂性。

我们如何才能利用这项技术设计任何东西呢？我们可以使用爱迪生的原型 — 测试实验风格吗？博科尔、金智杰以及胡正明很可能在成功设计鳍式场效应晶体管之前，的确做了一些原型 — 测试的实验。即便如此，仅仅因为所涉及的尺度，他们的实验也比爱迪生的要困难得多。要雕刻一个 20 纳米的物理结构是非常困难的，你不能用锤子和凿子来做到这一点。因此，与爱迪生相比，他们不得不更多地使用模型。

但是更重要的是，如果你想设计一个基于硅芯片的系统，你会从晶体管的组装和连接开始吗？

例如，我们来看看我用来编写本书的系统。我使用了一个名为 LATEX 的软件包，它能够把我输入的文本转换成可电子分发或打印的格式化书籍。假设我想设计这样一个系统，那么，我是否应该从一堆晶体管开始，以各种方式把它们连接起来，再看看它们能做些什么？肯定不会是这样的。

LATEX 是一个有趣的软件。它为我（一本书的作者）提供了建模图书的范式。我在文本编辑器中构造了我的书的模型，其中包含诸如用 \ footnote {脚注内容} 的注释创建一个脚注。然后，我会运行一个 LATEX 程序，将文本模式的内容转换为一个 PDF 文件 —— 待打印文件的另一种页面模式。LATEX 软件是莱斯利·兰波特 20 世纪 80 年代初在斯坦福国际研究院工作时开发的。兰波特是一位多产且有影响力的计算机科学家。他因在分布式软件系统方面的突出贡献获得 2013 年的图灵奖（有时也被称为诺贝尔计算机科学奖）。LATEX 是「Lamport 的 TEX」的缩写，它以斯坦福大学的另一位图灵奖得主高德纳于 20 世纪 70 年代末设计的 TEX 排版系统为基础。高德纳因他不朽的多卷型巨著《计算机程序设计艺术》而声名显赫。这是一本关于算法和编程原理的百科全书。维克拉姆·钱德拉在他的关于软件美学的著作《极客写作：代码与小说之美》（Geek Sublime）一书中写道：

如果有一个人能流利地说出机器里的方言，那么这个人一定是高德纳 —— 计算机领域的活佛。（钱德拉，2014)

在一篇名为「文学编程」的文章中，高德纳认为，软件是一种文学，在这种文学中，编写的代码不仅可以告诉计算机该做什么，还能用来与他人进行交流：

让我们改变一下我们对构建程序的传统态度：与其设想我们的主要任务是指导计算机去做什么，不如让我们集中精力向人类

解释我们想让计算机做什么。（高德纳，1984）

从 20 世纪 70 年代末开始，高德纳花了大约 10 年创建了 TEX 排版系统，因为他发现当时的照相排字系统的排版实在太难看了。今天，成千上万人已经为 TEX 和 LATEX 软件做出了贡献，主要是通过一个支持各种文档准备需求的软件包系统。它是一个蓬勃发展的开源社区，几乎所有的软件都是免费的。人们阅读并改进其中的代码，这几乎就像是在向高德纳致敬。在我看来，TEX 软件生成的字体比我遇到的任何商业文字处理器的都要好。在第 5 章，我将更多地谈及有关软件的人类表达的内容。

### 3.3 Transitivity of Models

A word processing system, such as the one I'm using to write this book, runs on a microprocessor like that in figure 3.2 , which uses transistors based on the prototype in figure 3.1 . Many levels of modeling exist between the physics of silicon and the word processor. Even more layers can be found between the physics and a system like Wikipedia. Like a pencil, no individual person knows how to make such a system. The fact that such systems exist, however, is a direct consequence of human ingenuity and creativity. Each layer of modeling allows individuals to contribute to the design without knowledge of or concern for how the layers of modeling they are using came about and without knowledge of how the layers of modeling they are creating will be used by other designers.

A few of the layers involved in the construction of a system such as Wikipedia are shown in figure 3.3 . My friend and colleague Alberto Sangiovanni-Vincentelli calls these layers「platforms」(Sangiovanni-Vincentelli, 2007), an apt term because each platform forms a substrate for construction of the models above it. Some of the models above it define platforms for further construction. Sangiovanni-Vincentelli points out that the platforms give designers「freedom from choice.」Below a platform there are many possibilities, offering more choices than any human designer can handle. Above the platform, there are fewer choices to be made. You can design more systems by creating a network of transistors than you can using logic gates (explained in chapter 4 ), for example. But when logic gates provide a suitable platform, the design job becomes much easier if you use logic gates rather than networks of transistors.

Occasionally, one encounters the use of such layers of abstraction in science. But compared with engineering, it is relatively rare, and depth of the layering is much more shallow. Scientists wish to construct models of physical reality, and models of models of physical reality become more suspect simply because they are further from the physical reality.

Figure 3.3 Layers of paradigms.

An example from science where layering of models has been successful is the gas laws developed at the end of the eighteenth century. These laws relate pressure, temperature, volume, and mass of a gas, including Boyle's law, Charles' law, Gay-Lussac's law, and Avogadro's law. These models describe phenomena that are ultimately due to the motion of large numbers of molecules in a gas, but they do not describe the phenomena in terms of the individual molecules. For example, Boyle's law states that at a fixed temperature, the pressure of a gas is inversely proportional to the volume it occupies. So, for example, if you reduce the volume (compress the gas), then pressure will increase. These are useful models of models, where the lower level model is of randomly moving molecules colliding with one another and with the surface of the enclosure.

In biology, arguably the most complex of the natural sciences, some researchers have argued that only through such layering can natural biological systems become comprehensible. Fisher et al. (2011), for example, propose the layers shown in figure 3.4 「to tame complexity of living systems.」They explicitly propose these layers in analogy to computer hardware systems, even naming some of the layers accordingly, such as「bio-logic gates.」The question marks in the figure, however, reveal that this approach is not mature. Biology appears less able to exploit the transitivity of models, compared with engineering, at least so far.

I believe this limitation is quite fundamental. Science cannot benefit as much as engineering from the layering of modeling paradigms. The root of the reason, which I explore more fully in the subsequent chapters, is that engineers build systems to match models rather than models to match systems.

Figure 3.4 Layers of abstraction proposed by Fisher et al. (2011) for synthetic biology.

Even without layering, many phenomena in our physical world (maybe even most phenomena) defy scientific modeling. John Searle has written extensively about the inability of scientific models to address cognitive and social phenomena, for example, even though those phenomena are clearly physical. Recall his claim that「the methods of the natural sciences have not given the kind of payoff in the study of human behavior that they have in physics and chemistry」(Searle, 1984, p. 71). His explanation, to my understanding, is a form of failure of transitivity of models. As an illustrative example, he looks at our inability to predict wars and revolutions in terms of lower level physical phenomena:

Whatever else wars and revolutions are, they involve lots of molecule movements. But that has the consequence that any strict law about wars and revolutions would have to match perfectly with the laws about molecule movements. (Searle, 1984, p. 75)

He points out that we have no laws (in the sense of physical laws) about the occurrence of wars and revolutions, although, ultimately,「wars and revolutions, like everything else, consist of molecule movements.」

It is not that higher level phenomena cannot be explained in terms molecule movements. Some can. Searle cites Boyle's law and Charles' law, which can be shown consistent with models of molecule movements. The relationship is relatively simple and the models become predictive. But not so with wars and revolutions. Wars and revolutions are so distant from molecule movements that no such relationship makes sense.

Searle argues that such relationships are impossible not just difficult. His reason is quite deep and thought provoking. To make his case, he asks us to consider the concept of「money,」which as he points out is「whatever people use and think of as money」(Searle, 1984, p. 78). The fact that this concept is self-referential is a key part of Searle's argument, in that「the concept that names the phenomenon is itself a constituent of the phenomenon.」Money can take the form of printed paper, gold coins, or (today) bits stored in a computer and displayed as numbers on a screen. An attempt to explain money as a neurophysiological phenomenon, Searle says, gets tripped up by the many forms that money can take. As we see money in these various forms, the stimulus on the visual cortex will be completely different. Searle asks how these completely different stimuli could have the same effect on the brain:

[F]rom the fact that money can have an indefinite range of physical forms it follows that it can have an indefinite range of stimulus effects on our nervous systems. But since it can have an indefinite range of stimulus patterns on our visual systems, it would … be a miracle if they all produced exactly the same neurophysiological effect on the brain. (Searle, 1984, p. 80)

So the concept of money must be more than a neurophysiological effect, Searle claims.

[T] here can't be any systematic connections between the physical and the social or mental properties of the phenomenon. (Searle, 1984, p. 78)

The same argument seems to apply to effects that are quite unlike the sociological concept of money, such as face recognition. We recognize our mother's face in a black-and-white picture of her taken before we were born, for example, despite enormous differences in the physical structure of the face and the material nature of a black-and-white photo versus a real face. It seems that Searle would have to conclude that this too is not a neurophysiological effect. But I suspect it is. The human brain has evolved to categorize visual stimuli into discrete bins despite huge variability in the stimulus.

I'm an engineer, not a philosopher, and not a neuroscientist. I can't credibly reject or defend Searle's argument, but frankly I don't need it to reach essentially the same conclusion. I am perfectly willing to accept that nobody will ever establish any meaningful connection between the physical stimulus to the visual system and the sociological concept of money. Even if we could construct the layers of epiphenomena, [3] their relationships would be so complex, or there would be so many layers, that nothing meaningful could ever arise from their connections. The phenomena at the higher levels are emergent phenomena , in that they comprise the lower level phenomena but have their own identity and properties. In later chapters, I will examine the fundamental limits of modeling that make such connections improbable even if the concept of money really is a neurophysiological effect.

But perhaps more interesting, even for some phenomena where we know exactly how to explain how they arise from physical effects, it is not useful to do so. In chapter 5 , I argue that, although software is ultimately electrons sloshing around in silicon, there are so many layers of modeling between the physics and the software that the connection to the physical is practically meaningless.

I claim that a high-level technology such as Wikipedia has little (and declining) meaningful connection with the underlying physical phenomena in semiconductor physics that make it all work. For digital technology, we can in fact trace the connection from Wikipedia all the way down to semiconductor physics. I will do this for you in chapters 4 and 5 . But in doing so, I will show you that there are so many levels of indirection that what happens at the higher level has little meaningful connection with what happens at the lower levels.

Engineers have an advantage over scientists when dealing with layers of models. Natural biological systems and wars and revolutions are givens in our world. Engineered systems are not. For engineered systems, the goal is not to explain them in terms of lower level phenomena. The goal instead is to design them using lower level phenomena. This different goal makes it much easier to exploit the transitivity of models.

Consider synthetic biology, which is concerned with designing artificial biological systems. This field is less focused on explaining naturally occurring systems and more focused on leveraging natural biological pathways to synthesize new systems. In synthetic biology, researchers have embraced layered abstractions to great effect. Endy (2005), for example, argues for using predefined functional modules to create biological systems. Indeed, an engineering discipline such as synthetic biology can more readily use layered abstractions because the models need only to model the systems being created. The bioengineers choose the systems to be modeled, and they choose them in part because they can model them. To be effective, scientific models need to model the systems given to us by nature, which are much more numerous. And we can't choose those. They are given.

In the next two chapters, I will elaborate on the layers in figure 3.3 , with an emphasis on understanding how they came about and with the goal of showing that the specific design of such layers is the creative work of humans, not a collection of God-given facts. But first I would like to spend a little time thinking about how to decide which layer to focus on for any given task.

[3] An epiphenomenon is a phenomenon that can be completely explained in terms of more fundamental phenomena.

3.3 模型的传递性

一个文字处理系统，就像我在写作本书时使用的一样，运行在图 3.2 所示的微处理器上，其使用基于图 3.1 所示原型的晶体管。

在硅物质和文字处理器之间存在着许多建模层次。在物理和维基百科这样的系统之间可以找到更多的层次。就像铅笔一样，没有人知道如何制作这样一个系统。然而，这种系统的存在的确是人类伟大智慧和创造力的直接结果。每个建模层都允许个人对设计做出贡献，而无须了解或关心他们正在使用的建模层是如何产生的，也无须知道他们正在创建的建模层将如何被其他设计人员使用。

图 3.3 给出了构建一个系统（例如维基百科）所涉及的几个层次。我的朋友兼同事阿尔贝托·圣乔瓦尼 — 温琴泰利称这些层次为「平台」（圣乔瓦尼 — 温琴泰利，2007）。这是一个恰当的术语，因为每个平台构成了构造上层模型的基础。上面的一些模型又定义了用于进一步构造的平台。圣乔瓦尼 — 温琴泰利指出，这些平台给了设计人员「选择的自由」。每个平台下面都存在很多种可能性，这些可能性提供的选择比任何设计人员所能处理的都要多。而在平台之上，可做出的选择很少。例如，与使用逻辑门相比，你可以通过创建一个晶体管网络设计更多的系统（将在第 4 章中做出解释）。但是，当逻辑门提供了一个合适的平台时，如果你使用逻辑门而不是晶体管网络，设计工作就会变得容易很多。

图 3.3 范式的分层。

人们偶尔会在科学中遇到这种抽象分层的使用。但与工程相比，科学中的这种情况还是比较少见的，而且也不会出现那么多的层次。科学家希望构建物理现实的模型，然而，物理现实的模型的模型会仅仅因为其离物理现实更远而变得更加令人怀疑。

18 世纪末发展起来的气体定律是模型成功分层的科学的例子。这些定律与气体的压力、温度、体积和质量有关。它们包括玻意耳定律、查理定律、盖 — 吕萨克定律和阿伏伽德罗定律。这些模型描述了最终由气体中大量分子的运动所导致的现象，但它们并没有从单个分子的角度描述这些现象。例如，玻意耳定律指出，在不变的温度下，气体的压力与它所占的体积成反比。因此，如果你要减小气体的体积（压缩气体），气体的压力就会增加。这些都是非常有用的模型的模型，其中较低层次是随机移动的分子之间的相互碰撞以及与外壳表面碰撞的模型。

可以说，生物学是最复杂的自然科学学科。一些研究人员认为，只有通过这样的分层才能使自然生物系统变得容易理解。例如，费希尔等人在 2011 年提出了如图 3.4 所示的层次「以征服生命系统的复杂性」。他们类比计算机硬件系统的分层而明确提出了这些层，甚至相应地命名了其中的一些层，如「生物逻辑门」。然而，图中的问号显示这种方法还不成熟。至少到目前为止，生物学似乎比工程更难利用模型的传递性。

我相信这个限制是非常基础的。科学不能像工程那样从建模范式的分层中获益。原因在于，工程师构建系统来匹配模型，而不是构造模型来匹配系统。我将在后面的章节对此进行更全面的讨论。

图 3.4 费希尔等（2011）为合成生物学提出的抽象层次。

即使没有分层，我们物理世界中的许多现象（甚至也许是大多数现象）也不适合于科学建模。例如，约翰·塞尔写了大量关于科学模型无法处理认知和社会现象的文章，尽管这些现象显然属于物理现象。我们回顾一下他的观点，「自然科学的方法在研究人类行为时并没有像在物理学和化学中那样带来回报」（塞尔，1984:71）。据我的理解，他的解释是模型传递性失败的一种形式。作为一个例证，他从较低层次的物理现象来看待我们无法预测战争和革命的现象：

不管是什么样的战争和革命，它们都会涉及大量的分子运动。其结果是，任何有关战争和革命发生的铁律都必须与分子运动的规律完全一致。（塞尔，1984:75)

他指出，我们没有关于战争和革命发生的规律（从物理规律意义上讲）。尽管最终「战争和革命，和其他一切事物一样，都是由分子运动组成的」。

这并不是说更高层次的现象不能用分子运动来解释。有些现象是可以的。塞尔引用了玻意耳定律和查理定律，这两个定律与分子运动的模型是一致的。这种关系相对简单，而且模型具有预测性。但是，战争和革命并非如此。战争和革命距离分子运动是如此遥远，以至没有任何关联是有意义的。

塞尔认为建立这种关联不仅是困难的，也是不可能的。他给出的理由既深刻又发人深省。为了证明他的观点，他让我们思考一下「货币」这个概念。正如他指出的那样，「货币就是人们所使用和认为是货币的东西」（塞尔，1984:78）。这个概念是自我参照的这一事实，是塞尔观点的关键所在。原因在于，「命名现象的概念本身就是这个现象的组成部分」。货币可以有不同的形式，如纸币、金币或（今天）存储在电脑中并以数字形式显示在屏幕上的比特位。塞尔说，试图将货币解释为一种神经生理学现象的尝试为货币的多种形式所羁绊。因为，当我们看到这些不同形式的货币时，视觉皮层上的刺激会完全不同。塞尔提出问题 —— 这些完全不同的刺激是如何对大脑产生同样的影响的：

从货币可以有范围不定的物理形式这一事实来看，它可以对我们的神经系统产生范围不定的刺激作用。但是，由于它可以给我们的视觉系统带来一种范围不定的刺激模式，如果它们都能对我们的大脑产生完全相同的神经生理效应，那么它会…… 是个奇迹。（塞尔，1984:80）

因此，塞尔认为，货币的概念对我们的大脑不会仅仅是一种神经生理效应。

这种现象的物质和社会或者精神属性之间不可能有任何系统的联系。（塞尔，1984:78）

同样的观点似乎也适用于与货币这一社会学概念截然不同的现象，如人脸识别。例如，我们能够在一张我们出生以前拍摄的黑白照片中认出自己母亲的脸，尽管那时黑白照片上母亲的面容与现在有很大的差异。塞尔似乎必须得出这样的结论 —— 这也不是一种神经生理效应。但是，我怀疑它是。尽管刺激有很大的可变性，但人类大脑已经进化到将视觉刺激归类为不相关联的类别了。

我是工程师，不是哲学家，更不是神经学家。我不能言之凿凿地拒绝或支持塞尔的观点，但坦率地讲，我并不需要它得出本质上相同的结论。我完全愿意接受这一点 —— 没有人会在视觉系统的生理刺激和货币的社会学概念之间建立任何有意义的联系。即使我们能构建出副现象的层次，它们之间的关系也会特别复杂，或者会有很多层次，以至从它们的联系中也不会产生任何有意义的东西。较高层次的现象是涌现现象，它们包含了较低层次的现象，但又有其自身的特征和属性。在后面的章节中，我将探讨建模的基本限制。即便货币的概念确实是一种神经生理学效应，这些限制也会使这种联系变得不可能。

这也许是更为有趣的事实，即使我们清楚地知道如何解释产生于物理效应的一些现象，这样做本身也没什么意义。在第 5 章，我会谈到，尽管软件最终是在硅材料中流动的电子，但是物理效应和软件之间存在着太多的建模层。实际上，这已经使得它们之间的联系变得毫无意义了。

我认为，像维基百科这样的高端技术，与使其运转的半导体物理学中的潜在物理现象几乎没有（而且正在减少）什么有意义的联系。对于数字技术，我们实际上可以将这种关系从维基百科一直追溯到半导体物理学。我将在第 4 章和第 5 章中探究这些问题。但在这个过程中，我将向大家展示，较高层次与较低层次的模型之间存在着许多间接层次，以至高层次上发生的事情与低层次上发生的事情几乎没有什么有意义的联系。

在处理模型的分层时，工程师比科学家有优势。自然生物系统以及战争与革命都是我们的世界赋予的，而工程系统不是。就工程系统而言，工程师的目标不是用较低层次的现象解释它们，而是用较低层次的现象设计它们。这个不同的目标使得利用模型的传递性变得更加容易。

以合成生物学为例，它与设计人工生物系统有关。这一领域较少关注解释自然产生的系统，而更侧重于利用自然生物途径来合成新的系统。在合成生物学中，研究人员采用了分层的抽象概念，并获得了很大的成效。例如，恩迪（2005）主张使用预设的功能模块创建生物系统。实际上，像合成生物学这样的工程学科，可以更容易地使用分层抽象，因为模型只需要对正在创建的系统建模。生物工程师选择要建模的系统，而且他们选择系统的部分依据是他们可以建模这些系统。为了提高效率，科学模型就需要对大自然赋予我们的众多系统进行建模。而且，我们不能选择这些系统，它们是大自然赋予我们的。

在接下来的两章中，我将详细介绍图 3.3 中的这些层，重点在于理解它们是如何产生的，而且我的目的在于说明这些层是人类的创造性工作，而不是上帝给予的事实的集合。但是，我首先还是想先花一点儿时间来思考，对任何给定的任务，如何确定应该关注哪个层。

### 3.4 Reductionism

At the lowest level, a word processor and Wikipedia are electrons sloshing around in silicon and metal, and the programs that make up Wikipedia are models of models of models of · · · models of electrons sloshing around in silicon and metal. It is tempting to fall into a reductionist trap and say that Wikipedia is「nothing but」electrons sloshing around in silicon, but this would grossly misrepresent reality.

A reductionist perspective explains a system at any level of modeling in terms of the level below it. For example, we could explain how a Wikipedia search uses operators in a programming language that compare text, which are realized by comparisons between binary representations of text in machine code, which uses a compare instruction in an instruction set architecture, which is implemented by microarchitecture with an arithmetic logic unit (ALU) that can do comparison, which is made up of logic gates that implement the comparison, which gates are interconnections of transistors, which transistors are three-dimensional structures of doped silicon. This is a terrible explanation of the search function of Wikipedia.

One of the implications of reductionism is that an epiphenomenon has no effect on the phenomena that explain it. The epiphenomena of temperature and pressure of a gas, for example, can be explained in terms of the underlying molecule movements, but molecule movements would exist unchanged even if we had no concepts of temperature and pressure. But this implication is patently false for the layers of figure 3.3 . Only the lowest foundation of these layers, electrons moving an electric field, is given to us by nature. Every other layer is constructed by humankind, often distinctly with an eye toward servicing better the layer above. It is perfectly valid to explain the operation of a logic gate in terms of its role in the design of digital machines and the design of digital machines in terms of the software they are expected to execute. The design of each layer is affected by the layers below and above it.

In the sciences of the natural, if scientists were to use such layers, it would be a teleological leap of faith to claim that higher levels of the stack affect lower ones. How could the existence of a biologic gates abstraction in figure 3.4 affect nature's realization of signaling pathways? In contrast, in the stack of figure 3.3 , it is not farfetched to claim that transistors are pretty good switches to enable Wikipedia.

In fact, designers of physics-based electronics are constantly trying to improve transistors to make them more like ideal switches. Fundamentally, a transistor is not a switch. It is an amplifier. But engineers tune the design of transistors to make them more like switches. For example, when a transistor is off, it is desirable that little current leak through it. This will reduce energy consumption, making it possible to pack more transistors into a small space without generating excessive heat that could melt the silicon. Hence, engineers will tweak the design of the physical structure to reduce leakage. They do this so that Wikipedia can work better. Teleological explanations in this case are perfectly reasonable.

The resemblance, therefore, between the stack of models in figure 3.3 and the one in figure 3.4 is superficial at best. I come back to the point I made in section 2.3 , which is that in science, the value of a model lies in how well its properties match those of the target, whereas in engineering, the value of the target lies in how well its properties match those of the model. If our model of a transistor is a switch, then the most valuable transistors are the ones that most perfectly behave like ideal switches.

With sufficient positivist dogmatic determination, we could still insist on a reductionist approach. Once we are given transistors by the physical electronics engineers, gates by the VLSI design software, a microarchitecture by Intel, an instruction set architecture by Intel, a Java compiler by Oracle, and a library of Java components by the Eclipse Foundation, then we could explain how Wikipedia works in terms of these foundations.

But this is too nerdy even for me. First, these foundations aren't static, so our laboriously constructed explanation could only be valid at an instant. But more important, it vastly understates what Wikipedia really is. At the higher layers of abstraction properties emerge that are difficult if not impossible to explain in terms of the lower level abstractions. An enormous part of the value of Wikipedia lies in its essence as a partnership between technology and culture. I admit a genuine aesthetic delight when I encounter a particularly well-written Wikipedia page and a sense of frustration and gloom when I find a more poorly written page or one that too clearly reflects the views of too few people. A well-written Wikipedia page is difficult to explain in terms of sloshing electrons.

Technology alone does not create a phenomenon such as Wikipedia. Any reductionist explanation of the phenomenon would be naive. In later chapters, I will argue that the failure of reductionism is fundamental and unavoidable in complex technology.

Notice that our layering need not stop at the top of figure 3.3 . The software in Wikipedia is created within the modeling paradigms at the top of the figure, but in large part that technology is molded to support a sociological layer above it. But I am a nerd, and I don't understand people, so I won't try to extend my analysis to those sociological levels. I will leave that to the social scientists.

In the next chapter, I will focus on hardware technologies. I point out that hardware does not last nearly as long as the models of the same hardware. Models and the paradigms on which they are based, despite having no material form, are more durable than the things they model, despite those being physical. I focus on digital technology because as we move up from the physical layer (silicon chips), we quickly get extremely expressive media capable of realizing enormously complex and intricate models. The expressiveness of these media unleashes the creativity of humans, enabling the emergence of such transformative technologies as Wikipedia.

In chapter 5 , I focus on software technologies. Here, I point out that software encodes the paradigms on which it is constructed. This self-scaffolding enables the bootstrapping of truly innovative artifacts, ones that can profoundly affect human culture. In later chapters, I will explain what software cannot do. The door remains open to further creativity.

3.4 还原论

在最低层次上，文字处理器和维基百科都是在硅材料和金属中流动的电子，而构成维基百科的程序是硅材料和金属中流动的电子的模型的模型的模型的模型…… 人们很容易落入还原论的陷阱，于是认为维基百科「除了」是电子在材料硅中流动外什么都不是，但这会极大地歪曲事实。

对于任何建模层的系统，还原论的观点是用其下面的一层来进行解释的。例如，我们可以解释，维基百科的搜索功能是如何使用编程语言中比较文本的操作符的，这些操作符通过比较机器码中的文本二进制表示来实现，机器码使用了某个指令集体系架构中的一条比较指令，指令集体系架构由带有一个可以执行比较操作的算术逻辑单元（ALU）的微体系结构实现，该逻辑单元由实现比较功能的一组逻辑门构成，这些逻辑门是互连的一组晶体管，而晶体管是三维结构的掺杂硅。显然，这是对维基百科搜索功能的一个糟糕解释。

还原论蕴含的一个含义是，一种副现象对解释它的现象没有任何影响。例如，气体的温度和压力的副现象可以用潜在的分子运动来解释，但是，即便我们不了解温度和压力的概念，分子运动也不会发生改变。然而，对于图 3.3 所示的这些层来说，这一含义显然是错误的。只有这些层的最低层，即移动电场的电子，是自然界赋予我们的。其他的每一层都是由人类构建的，而且其目的通常是更好地服务于上层。以逻辑门在数字机器设计中的作用来解释逻辑门的操作，以及用数字机器所要执行的软件来解释数字机器的设计，都是非常有效的，因为每一层的设计都要受到其下面以及上面层的影响。

在自然科学中，如果科学家想要使用这样的层，那么声称栈中更高的层影响其中较低的层将是一次信念的目的论飞跃。图 3.4 中生物门的存在如何影响自然界的信号通路的实现？相比之下，如果认为图 3.3 的栈中，晶体管是启动维基百科的很好的开关，这样的观点就不会让人觉得牵强了。

事实上，基于物理电子学的设计者一直在努力改进晶体管，使其更像理想的开关。从根本上讲，晶体管并不是开关，而是一个放大器。然而，工程师们对晶体管的设计进行了不断调整，使它们更像开关。例如，当晶体管处于截止状态时，通过它的泄漏电流应该非常小。这样可以减少能耗，这使得将更多的晶体管封装到一个小空间而不产生可能融化硅材料的过多热量成为可能。因此，工程师将会调整物理结构的设计，以减少电流的泄漏。他们这样做是为了让维基百科更好地运行。在这种情况下，有目的论的解释是完全合理的。

因此，图 3.3 与图 3.4 所示模型栈的相似之处充其量只是表面的。

我现在要重申一下我在 2.3 节提出的观点 —— 在科学中，模型的价值取决于它的特性与目标物属性的匹配程度，而在工程中，目标物的价值在于它的属性与模型特性的匹配程度。如果我们的晶体管模型是一个开关，那么最有价值的晶体管会是那些表现得最像理想开关的晶体管。

尽管我们有着坚持实证主义教条的决心，但是我们仍然可以坚持一种还原论的方法。一旦我们得到了物理电子工程师设计的一些晶体管、超大规模集成电路软件设计的一些逻辑门、英特尔设计的微体系结构以及指令集体系架构、甲骨文开发的 Java 编译器、Eclipse 基金会的 Java 组件库，我们就可以用这些基础来解释维基百科是如何工作的。

但是，这些解释对我来说太过于呆子气了。首先，这些基础并不是静态的，所以我们费力构建的解释只会在瞬间有效。而更重要的是，这种解释大大低估了维基百科存在的真正意义。在抽象的更高层次，出现了一些很难（如果不是不可能的话）用较低层次的抽象来解释的属性。从本质上说，维基百科使技术和文化达成一种伙伴关系。这在很大程度上就是维基百科的价值所在。我承认，当我看到一个写得特别好的维基百科页面时，我确实感到一种真正的审美上的愉悦；而当我看到一个写得很糟糕的页面，或者过于清晰地反映太少人的观点的页面时，我会感到非常沮丧和郁闷。一个写得好的维基百科页面很难用流动的电子来解释。

技术本身并不能创造出像维基百科这样的现象。对该类现象进行任何简化的解释都是幼稚的。在后面的章节中，我将说明，还原论的失败是复杂技术中不可避免的基本问题。

请注意，我们的分层不需要止步于在图 3.3 所示的顶部层次。

维基百科中的软件是在该图顶部的建模范式中被创建的。但在很大程度上，技术是为了支撑其上的社会学层次才被建模的。我只是个技术呆子，我不了解人，所以我不会试图把我的分析扩展到那些社会学层次。我把这个任务留给社会科学家。

在下一章，我将重点介绍硬件技术。我认为，硬件的生命力并没有该硬件的模型那么持久。尽管没有物质的形式，但是模型和它们所基于的范式比它们所建模的事物具有更持久的生命力。我之所以关注数字技术，是因为当我们从物理层（硅芯片）开始向上时，我们很快就会得到极具表现力的媒介，其可以实现极其复杂的模型。这些媒介的表现力释放了人类的创造力，并促成了像维基百科这样的变革性技术的出现。

在第 5 章，我将聚焦于软件技术。在这里，我需要指出，软件对构建它的范式进行编码。这种自我支撑能激发真正的创新力，并创造出那些能够对人类文化产生深远影响的真正的创新产品。在后面的章节，我将阐释软件的局限性。进一步创新的大门依然敞开着。
