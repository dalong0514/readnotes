## 记忆时间

## 卡片

### 0101. 反常识卡 —— 

这本书的主题核心，就是最大的反常识卡，并且注意时间脉络。

### 0201. 术语卡 —— 

根据反常识，再补充三个证据 —— 就产生三张术语卡。

### 0202. 术语卡 —— 

### 0203. 术语卡 —— 

### 0301. 人名卡 —— Toby Segaran

[Toby Segaran | Experiments in electronics, data, art, cocktails and physics](https://kiwitobes.com/)

[Toby Segaran - O'Reilly Media](https://www.oreilly.com/pub/au/2972)

Toby Segaran, 1979-。本书作者，数据挖掘领域的大牛。是 Genstruct 公司的软件开发主管，这家公司涉足计算生物领域，他本人的职责是设计算法，并利用数据挖掘技术来辅助了解药品机理。Toby Segaran 还为其他几家公司和数个开源项目服务，帮助它们从收集到的数据当中分析并发掘价值。除此以外，Toby Segaran 还建立了几个免费的网站应用，包括流行的 tasktoy 和 Lazybase。他非常喜欢滑雪与品酒，其博客地址是 blog.kiwitobes.com，现居于旧金山。

著作有：《Beautiful Data》、《Programming the Semantic Web》和《Programming Collective Intelligence》。

2『已下载书籍「2020017Programming_Collective_Intelligence」、「2020056Beautiful_Data」、「2020057Programming_the Semantic_Web」。』

### 0401. 金句卡 —— 

最后根据他写的非常震撼的话语 —— 产生一张金句卡。

### 0501. 任意卡 —— 

最后还有一张任意卡，记录个人阅读感想。

## 模板

### 1. 逻辑脉络

用自己的话总结主题，梳理逻辑脉络，也就是这本书整个地图里这一章所在的节点。

### 2. 摘录及评论

## 前言

本书以机器学习与计算统计为主题背景，专门讲述如何挖掘和分析 Web 上的数据和资源，如何分析用户体验、市场营销、个人品味等诸多信息，并得出有用的结论，通过复杂的算法来从 Web 网站获取、收集并分析用户的数据和反馈信息，以便创造新的用户价值和商业价值。全书内容翔实，包括协作过滤技术（实现关联产品推荐功能）、集群数据分析（在大规模数据集中发掘相似的数据子集）、搜索引核心技术（爬虫、索引、査询引繁、Pagerank 算法等）、搜索海量信息并进行分析统计得出结论的优化算法、贝叶斯过滤技术（垃圾邮件过滤、文本过滤）、用决策树技术实现预测和决策建模功能、社交网络的信息匹配技术、机器学习和人工智能应用等。本书是 Web 开发者、架构师、应用工程师等的绝佳选择。

大家不时地抱怨：为什么不能让浏览器像客户端应用那样具有丰富的表现？为什么每次打开链接都要傻傻地等着空白页面消失？直到有一天，Tim O'Reil 向世人宣告了一个新的概念 —— Web2.0。于是，忽如一夜春风来，大大小小的 Web2.0 应用如雨后春笋般不断涌现，互联网又迈向了一个新的时代。

Web2.0 使互联网变得异彩纷呈：来自不同地域的人们可以随时修改别人写过的文字，这就是维基；你有任何想法或观点都可以尽情地表达并欢迎别人评论，这就是博客；甚至连网页上出现的广告也都是与我们当前所关注的内容密切相关，这就是 Google Adsense 所有这一切，都带给我们不同于以往的全新感受。但是，这些应用究竟是怎样实现的？隐藏在它们背后的原理到底是什么？怎样让我们的 Web2.0 程序变得更加聪明，更加贴心呢？译者相信，本书必定能够为大家逐一解开素绕在心中的这些谜团。

本书以 Web2.0 的核心价值观 —— 集体智慧作为出发点，探讨了各种能够让 Web2.0 程序变得更为智能的算法及其应用。这些算法大多来自机器学习和计算统计领域，其中的一些算法非常普及，而另一些则属于目前相当前沿的课题。它们包括了过滤器、聚类算法、支持向量机、遗传編程、优化技术，以及非常著名的 Pagerank 算法，等等。将如此众多的优秀算法有效应用于互联网领域，并构造出具有智能特征的 Web2.0 应用，应该是本书的一大亮点，同时，这也使本书有别于以往我们所见到过的任何一本纯粹介绍 Web2.0 技术与概念的书籍。不仅如此，本书还提供了大量可供运行的示例代码，这些代码具有很好的复用性只要稍加修改就可以用于实际的应用系统之中。书中代码还大最使用了许多时下流行的开放 API，这些 API 来自于 Yahoo!、eBay、FaceBook 等众多热门的 Web2.0 网站，这使得本书在保有实用价值的同时又不失时效性。

为了便于读者阅读理解，特在此附上本书翻译过程中整理提取的中英文术语对照表。下表所包含的多为专业领域的技术术语。其中部分术语在不同的文献中往往有不同的译法。本书为了统一，选择了比较常见的译法，如 clustering 可译作「聚类」或「聚集」，此处我们选择了「聚类」。类似的还有 k-nearest neighbors、cross-product、dot-product，等等。另一部分术语，虽有固定译法，但我们结合上下文，采用了更为贴切的翻译。如 computationally intensive 常被译为「计算密集的」，而在此处，我们采用「计算量很大的」。类似的还有 data- Intensive、solution、crawl，等等。此外还有一部分术语，在当下的中文文献中并没有明确的公认译法，因而我们在书中给出了参考翻译，以供大家商榷。如 collective intelligence 被译为「集体智慧」，list comprehension 被译为「列表推导式」，等等。

无论是有意还是无意，越来越多投身于互联网的人们已经制造出了相当多的数据，这给了我们无数潜在的机会来洞悉用户体验、商业营销、个人偏好和通常所谓的人类行为（human behavior）。本书向大家介绍了一个新兴的领域，称为集体智慧（collective intelligence）。这领域涵盖了诸多方法，借助这些方法我们可以从众多 Web 站点处（这些站点的名字或许你曾经有所耳闻）提取到值得关注的重要数据；借助这些方法我们还可以从使用自己应用程序的用户那里搜集信息，并对我们所掌握的数据进行分析和理解。本书的目的是要带领你超越以数据库为后端的简单应用系统，并告诉你如何利用自己和他人每天搜集到的信息来编写更为智能的程序。

列表推导式。列表推导式（list comprehension）是一种方便简洁的语法形式，我们可以利用它将一个列表经过滤后转换成另一个列表，也可以利用它将函数应用于列表中的元素。列表推导式以如下形式书写：[表达式 for 变量 in 列表] 或者 [表达式 for 变量 in 列表 f 条件]。

```
In [17]: l1 = range(10)
In [18]: l1
Out[18]: range(0, 10)
In [19]: print([v*10 for v in l1 if v > 5])
[60, 70, 80, 90]
```

本书中频繁地使用了列表推导式，因为要将一个函数应用于整个列表，或是別除不需要的列表项时，这种表达方法非常简练。列表推导式的另一种常见用法是与 dict 构造函数结合在一起使用。上述代码将会建立一个字典，以原先的列表作为键，以每个列表项乘以 10 作为值。

```
In [20]: dict([(v, v*10) for v in l1])
Out[20]: {0: 0, 1: 10, 2: 20, 3: 30, 4: 40, 5: 50, 6: 60, 7: 70, 8: 80, 9: 90}
```

1『列表推导式太方便了，直接对列表进行过滤，过滤的方式 2 个，一是后面的条件判断，二是前面的表达式，关键表达式还可以使用函数，哈哈；更强的是其与字典的结合使用，列表推导式作为参数传递给 dict() 函数，推导式的列表作为字典的键，推导式的值作为字典的值。但是注意，表达式里「键-值」要括号起来，dict([(x, x*10) for x in l2 if x>2])。』

开放的 API。用于将集体智慧合成起来的算法需要来自许多用户的数据。除机器学习的算法外，本书还论及了许多开放的 Web APIs（应用编程接口）。这些 API 允许我们通过特殊的协议对来自相应 Web 站点的数据进行访问；我们可以编写程序将数据下载下来并加以处理。这些数据通常是由站点的使用者来提供的，我们可以从中挖掘出新的内涵来。有的时候，我们可以用现成的 Python 库来访问这些 API；而有时，如果没有现成的库，那么最为直接的做法莫过于创建自己的接口来访问数据，为此我们须要利用 Python 提供的内建库将数据下载下来，并对 XML 加以解析。此处列出了一系列提供开放 API 的 Web 站点，我们将在本书中陆续接触到这些站点。

Delicio us，一个社会型书签应用系统（social bookmarking application），其开放的 API 允许你根据标签（tag）或特定的用户来下载链接；Kayak，一个提供 API 的旅游网站，你可以利用 API 在自己的程序中集成针对航班和旅馆的搜索；ebay，一个提供 API 的在线交易站点，允许你査询当前正在出售的货品；Hot or Not，一个评分与交友的网站，提供 API 对人员进行搜索，并获取其评分及个人资料；Akismet，一种用于对协作型垃圾信息进行过滤的 API。

通过对来自单一源的数据进行处理，对来自多个源的数据进行组合，甚至通过将外部信息与自有系统的用户输入信息加以组合，我们可以构造出大量的潜在应用。对人们在不同网站以各种不同方式产生的数据加以充分利用的能力，便是构建集体智慧的一个基本要素。如果你想寻找更多的提供开放 API 的 Web 站点，不妨从访问 Programmable Web 开始。

3『[ProgrammableWeb - APIs, Mashups and the Web as Platform](https://www.programmableweb.com/)』

各章概览。本书的每个算法都来源于某一现实的问題，希望这些问题能够很容易地被广大读者所理解。笔者将尝试尽量避开那些要求大量领域知识的问题，而将焦点集中在那些虽不失复杂性，但对大多数涉足者而言却又是简单易懂的问题上。

第 1 章，集体智慧导言。本章解释了藴藏于机器学习背后的概念，并解释了如何将其应用于诸多不同的领域以及如何利用它对搜集自许多不同人群的数据进行分析，并从中得出新的结论。

第 2 章，提供推荐。本章介绍协作型过滤（collaborative filtering）技术，这项技术被许多在线零售商用来向顾客推荐商品或媒体。本章中有一节介绍了如何向一个社会型书签服务网站的用户提供推荐链接，还介绍了如何根据 Movielens 所提供的数据集构筑一个影片推荐系统。

第 3 章，发现群组。本章基于第 2 章中给出的某些观点，介绍了两种不同的聚类方法，利用这些方法，我们可以在一个大数据集中自动找出具有相似特征的群组。本章还演示了如何利用聚类算法从一组颇受欢迎的博客之中寻找群组，以及利用聚类算法根据某个社会型网站的用户意愿去寻找群组。

第 4 章，搜索与排名。本章描述了构成一个搜索引擎的各个不同组成部分，它们包括：爬虫程序（crawler）、素引程序（indexer），以及査询引擎（query engine）。本章介绍了以来自外部网站的链接信息为依据给网页打分的 Pagerank 算法，还向你展示了如何构建神经网络，借此获知与不同结果相关联的关键词。

第 5 章，优化。本章介绍了优化算法，设计这些算法的目的，是为了对问题的数百万个可能的题解进行搜索，并从中选出最优解来。书中利用示例演示了这些算法的各种不同用法，包括为一群去往相同地点的旅客寻找最佳航班，寻求为学生安排宿舍的最佳方案，以及给出交又线数量最小的网络布局。

第 6 章，文档过滤。本章向读者演示了贝叶斯过滤，这一方法被广泛应用于许多免费的和商业的垃圾信息过滤系统中，用于根据单词类型及出现在文档中的其他特征对文档进行自动分类。我们将其应用于一组 RSS 搜素结果，以此来说明对内容项的自动分类过程。

第 7 章，决策树建模。本章介绍了决策树，我们不仅将它作为一种预测方法，而且还用它来为决策过程进行建模。本章中出现的第一棵决策树是根据假想的服务器日志数据构建而成的，我们利用它来预测用户是否有可能成为付费订户（premium subscriber）。本章的另一个例子则使用了来自真实 Web 站点的数据，用以对住房价格和来自 Hot or Not 网站的「热度」（hotness）评价进行建模。

第 8 章，构建价格模型。本章解决的是数值预测问题而非分类问题，期间用到了 k - 最近邻技术，并且还用到了第 5 章中的优化算法。我们将这些方法与 ebay API 结合在一起构造出一个系统，能够根据拍卖品的一组属性，预测出最终的拍卖价格。

第 9 章，高阶分类：核方法与 SVM。本章向读者介绍了如何利用支持向量机（support-vector machines）对在线约会网站的用户进行匹配，以及如何将其用于针对专业交友网站的好友信息搜索。支持向量机是一项非常高阶的技术，本章将之与其他方法进行了对比。

第 10 章，导找独立特征。本章介绍了一种相对较新的技术，称为非负矩阵因式分解：(non-negative matrix factorization），我们利用这项技术在数据集中寻找独立的特征。对许多数据集而言，其中所包含的内容都是可以借助一组独立特征的组合被重新构造出来的，而这些特征是我们事先不知道的，非负矩阵因式分解的思路便是要寻找这些特征。在本章中，我们利用一组新闻报道说明了该项技术的使用；期间，通过新闻故事来寻找其中的主题，一篇给定的新闻故事中会包含一个或多个这样的主题。

第 11 章，智能进化。本章介绍了遗传编程（genetic programming）的概念，这是一组非常复杂的技术，它超出了优化的范畴。并且，这项技术实际上借鉴了进化的思想，它是通过自动构造算法的方式来解决特定问题的。我们通过一个简单的游戏来说明这项技术的应用。在游戏中，计算机最初只是一个学艺不精的初级选手，但是随着游戏的不断进行，它会通过逐步改进其所拥有的代码来提升自己的技能。

第 12 章，算法总结。本章回顾了书中所讲述的所有机器学习算法及统计算法，并将它们与一组人为设计的问题做了对比。这将有助于我们理解算法的工作原理，并形象地说明每种算法划分数据的方法。

附录 A，第三方函数库。给出了有关本书所用的第三方库的信息，例如在哪里可以找到这些第三方库，以及如何进行安装；附录 B，数学公式。包含了一部分数学公式及其说明，以及本书通篇引入的、以代码形式描述的诸多数学概念。

## 01. 集体智慧导言

### 1. 逻辑脉络

集体智慧。为了创造新的想法，而将一群人的行为、偏好或思想组合在一起。机器学习背后的概念，并解释了如何将其应用于诸多不同的领域以及如何利用它对搜集自许多不同人群的数据进行分析，并从中得出新的结论。

### 2. 摘录及评论

上述这两家公司有何共同之处呢？它们都使用了先进的算法将来自不同人群的数据加以组合，进而得出新的结论，并创造出新的商机。这种信息采集能力，以及对其加以解释的计算能力已经激发起很多巨大的协作型商机，并且加深了对用户和顾客更好的理解。这样的例子现在比比皆是 —— 约会网站希望帮助人们更快的找到他们的最佳拍档，预测机票价格变化的公司如芹春笋般不断涌现，为了创造更有针对性的广告，几乎每个人都想更好地了解他们的顾客。

上面提到的，仅仅是集体智慧（collective intelligence）这一令人振奋的新兴领域中少数几个典型的例子，层出不穷的新服务意味着每天都会有新的商机涌现出来。笔者相信，理解机器学习和统计方法在许多不同领域里都会变得愈加重要，而这一点在针对海量信息的解释和组织方面尤为突出（全世界的人们正在不断创造这些信息）。人们使用集体智慧这一术语已有十多年之久，随着新型通信技术的出现，这一术语也变得日趋流行和重要。尽管这样的表达也许会让人联想到群体意识或超自然现象，但当技术人员使用这一词汇时，其含义通常是指：为了创造新的想法，而将一群人的行为、偏好或思想组合在一起。

当然，集体智慧的出现可能要早于 Internet。为了从全无关系的一群人中搜集、组合和分析数据，我们不一定要借助于 Web。完成这项工作的一种最为基础的方法，便是使用调査问卷或普査。从一大群人中搜集的答案可以使我们得出关于群组的统计结论：组中的个体成员将会被忽视。从独立的数据提供者那里得出新的结论，是集体智慧所真正关注的。

这里有一个众所周知的例子，是关于金融市场的。在金融市场里，价格并不是由某个个体或某种协作力量所决定的，它是由许多独立个体的交易行为所共同决定的，所有人的行为都建立在这样一种信念基础之上：他们相信当前的交易会为他们带来最大的利益。尽管乍看这似乎违背直觉，但在未来的市场上，大量的参与者都是根据他们对未来价格的信心而进行契约交易的，这样的市场在价格预测的效果方面，往往被认为要比独立进行预测的专家们表现得更好。这是因为，市场将知识、经验和成百上千人的意志组织在一起，形成了一种不依赖个人观点的预测。

尽管寻求集体智慧的方法在 Internet 之前就已经存在，但自从有了 Internet 之后，从数千甚至数百万网民中搜集信息的能力为人们提供了许多新的可能。一直以来，人们都在利用 Internet 来购买所需、搜索信息、寻求娱乐，以及架设自己的 b 站点。所着这些行为都可以得到监控，并且不必要求用户放下手头的工作来接受询问，而可以借由监控得到的信息提取出有价值的结论，有大量的方法可以用来对这些信色进行加工和解释。这里有 2 个重要的例子，分别体现了两种彼此对立的做法。

1『维基百科和 Google。』

虽然 Wikipedia 是一个巨大的资源库，而且也是展现集体智慧的一个令人印象深刻的例子，但它的存在很大程度上要归功于提供内容的用户，而非软件中的那些智能算法。本书的焦点并不在于提供内容的用户，而在于算法，这其中就包括了 Google 的 Pagerank 算法，该算法会搜集用户的数据，对数据进行计算分析，并从中创造出可以增强用户体验的新信息。在获得的这些数据当中，有一部分是明确搜集而来的，比如向用户询问与评价网页级别相关的问题。另一部分则是偶然搜集得到的，比如观察用户的购买行为。对于这两种情况，重要的不仅是搜集和显示信息，还包括以一种智能化的方式对这些信息加以处理，并产生出新的信息来。

本书将告诉你如何利用开放的 API 来搜集数据，同时还会讨论到各种机器学习算法和统计方法。将二者结合起来，就可以借助集体智慧的相关方法，对由自己编写的应用程序搜集得到的数据进行分析；同时，也可以从其他地方搜集数据，并对数据进行试验。

机器学习是人工智能（AI, artificial intelligence）领域中与算法相关的一个子域，它允许计算机不断地进行学习。大多数情况下，这相当于将一组数据传递给算法，并由算法推断出与这些数据的属性相关的信息 —— 借助这些信息，算法就能够预测出未来有可能会出现的其他数据。这种预测是完全有可能的，因为几乎所有的非随机数据中，都会包含这样或那样的「模式」（patterns），这些模式的存在使机器得以据此进行归纳。为了实现归纳，机器会利用它所认定的出现于数据中的重要特征对数据进行「训练」，并借此得到一个模型。

为了理解模型得到的过程，我们来看另外一个复杂领域 —— 电子邮件过滤中的一个简单例子。假定我们收到了大量包含「online pharmacy」单词的垃圾邮件。对人而言，我们可以很轻松地识别出其中的模式，并快速确知任何含有「online pharmacy」单词的信息都是垃圾邮件，应该将其直接移到垃圾箱中。这就是归纳 一一 事实上，我们已经建立起了一个关于垃圾邮件的智力模型。当我们将多条这样的信息报告为垃圾邮件之后，专门设计用以过滤垃圾邮件的机器学习算法应该有能力做出同样的归纳来。

有许多不同的机器学习算法，所有算法都各有所长，适应于不同类型的问题。有些算法，比如决策树，非常的直观，通过眼睛观察就可以完全理解机器执行的推导过程。另有一些算法，比如神经网络，则像一个黑盒，它们虽然也给出最终的结果，但通常要复现蕴含在这些结果背后的推导过程则是非常困难的。

许多机器学习算法都很倚仗数学和统计学。根据笔者早些时候给出的定义，我们甚至可以认为，简单的相关性分析和回归都是机器学习的基本形式。本书并没有假定读者具备许多统计学方面的知识，所以笔者会尝试尽可能直观地解释所用到的统计学知识。

机器学习并非没有缺点。机器学习算法受限于其在大量模式之上的归纳能力，而一个模式如果不同于算法先前所曾见到过的任何其他模式，那么它很有可能会被「误解」。人类拥有大量的文化知识及经验可以借鉴；不仅如此，人们还具备一种非凡的能力，即：当对新的信息进行决策时，人们能够从中识别出相似的信息来，而机器学习方法却只能凭借已经见过的数据进行归纳，而且归纳的方式受到很大的限制。

我们将在本书中见到的垃圾邮件过滤方法，是以单词或单词组合的出现为依据的，至于这些单词的含义及句式结构，则根本未予考虑。尽管在理论上，构造一个考虑语法的算法是可行的，但在现实中却很少这样做，这是因为为此付出的努力与算法的改进相比很不成比例。理解单词的含义及单词与个人生活的相关性所要求掌握的信息，远比垃圾邮件过滤算法中所能访问到的现有信息还要多。

另外，尽管在解决问题的倾向性上各有不同，但是所有机器学习算法都有过度归纳的可能性。就如生活中的大多数事情一样，基于少数示例的强归纳很少是完全精确的。我们的确有可能会收到友人寄来的一封重要邮件，里面包含「online pharmacy」的字样。在这种情况下，我们须要告诉算法这不是垃圾邮件，或许算法可以作出判断，将来自某位好友的邮件判定为可以接收。究其本质，许多机器学习算法在新信息到来之时都是能够持续进行学习的。

当前 Internet 上有大量站点正在不断地从广大用户当中搜集数据，并利用机器学习和统计方法从中获益。Google 是其中的佼佼者 —— 它不仅可以利用 Web 链接对网页进行排名，而且当其广告被不同的用户点击时，它会持续搜集信息，这使得 Google 可以更加有效地进行广告定位。在第 4 章中，我们将了解到搜索引擎和 Pagerank 算法，这是 Google 排名系统的重要组成部分。其他的例子还包括带有推荐系统的 Web 站点。如 Amazon 和 Netflix 这样的站点，它们利用人们的购买或租赁信息来确定人或物品的相似程度，然后再根据买卖历史来给出推荐。另有一些站点，比如 Pandora 和 Last.fm，则可以利用我们对不同乐队和歌曲的评价来建立定制的广播电台，其中包含了网站认为我们会喜欢的音乐。第 2 章将会讨论构建推荐系统的方法。

市场预测也是集体智慧的一种形式。这其中最为有名的一个例子莫过于 [Hollywood Stock Exchange](https://www.hsx.com/)，在那里人们可以进行涉及影片和影星的模拟股票交易。我们可以按照影片的当前价格买卖股票，其对应的价值相当于电影实际首次票房收入的百万分之一。因为价格是通过交易行为来设定的，所以价值不由任何一个个体所决定，而是由群体的行为来确定的，股票的当前价格可以看作是整个群体对电影票房收入数字的预测。通常而言，由 Hollywood Stock Exchange 所给出的预测往往要优于某位专家所给出的预测。某些交友网站，比如 eHarmony，利用从参与者那里搜集而来的信息确定交友的最佳配对。尽管这些公司对他们所采用的匹配算法守口如瓶，但是任何一种成功的匹配算法很可能都会涉及一个持续不断的求值过程 —— 算法会反复判断选定的匹配成功与否。

生物工艺学。人类在测序技术和筛选技术（sequencing and screening technology）上的进步已经创造出了许多不同种类的海量数据，比如 DNA 序列、蛋白质结构、化合物筛选及 RNA 表达。为了找到能进一步理解生物进程的模式，机器学习技术被广泛应用于所有这些类型的数据之中；金融欺诈侦测。信用卡公司一直都在寻找侦测交易是否存在欺诈行为的新方法。最终，他们使用了像神经网络和归纳逻辑这样的技术，对交易行为进行检验，并捕获不正当的使用方法；机器视觉。出于军事或监控的目的，从摄像机中进行图片解析是一个活跃的研究领域。许多机器学习技术被用来自动侦测入侵者、辨别车辆，或者识别人脸。尤其值得注意的是无人监控技术的使用，比如能从大数据集中发现有趣特征的独立组元分析技术。

产品市场化。长期以来，对人口统计资料及其发展趋势的理解被认为是一种艺术而不是科学。最近人们在消费者数据搜集能力方面的增长，为机器学习技术打开了机会之门，比如聚类方法，就能很好地理解存在于市场中的自然划分，并能更好地预测未来的趋势；供应链优化。许多企业通过其供应链的有效运行及精确预测不同区域的产品需求，来节省数以百万计的成本投入。构造供应链的方法非常多，影响需求的潜在因素也非常多。优化和学习技术时常被用来分析这些数据集；股票市场分析。自从有了股票市场，人们就一直在尝试利用数学方法来赚取更多的钱。随着参与股市的股民变得越来越有经验，对大量数据进行分析并采用先进技术来侦测模式已经变得很有必要了；国家安全。全世界的政府机构都在搜集海量信息，对这些数据的分析过程要求计算机对模式进行检测，并将之与潜在的威胁联系起来。

上述这些仅仅是人们现在大量使用机器学习的典型个案。既然有越来越多的信息被制造出来已是大势所趋，那么有越来越多的领域将依赖于机器学习和统计技术并不是没有可能的，因为信息扩张的规模已经超出了人们利用旧有方法进行处理的能力。每天可以获得的新信息有多少，显然就会有多少更多的可能性。一旦你掌握了一点机器学习的算法，你就会发现它们的应用随处可见。

## 02. 提供推荐

### 1. 逻辑脉络

介绍协作型过滤（collaborative filtering）技术，这项技术被许多在线零售商用来向顾客推荐商品或媒体。介绍了如何向一个社会型书签服务网站的用户提供推荐链接，还介绍了如何根据 Movielens 所提供的数据集构筑一个影片推荐系统。

数据用字典存储；通过「欧几里徳距离」和「皮尔逊相关度」两种方法可以计算相似度评价值；

### 2. 摘录及评论

为了开始集体智慧之旅，本章即将告诉大家，如何根据群体偏好来为人们提供推荐。有许多针对于此的应用，如：在线购物中的商品推荐、热门网站的推荐，以及帮助人们寻找音乐和影片的应用。本章将告诉你如何构筑一个系统，用以寻找具有相同品味的人，并根据他人的喜好自动给出推荐。

也许在使用如 Amazon 这样的在线购物网站之前，你已经接触过某些推荐类引擎了。Amazon 会对所有购物者的购买习惯进行追踪，并在你登录网站时，利用这些信息将你可能会喜欢的商品推荐给你。Amazon 甚至还能够向你椎荐你可能会喜欢的影片，即便你此前也许只从该网站购买过书籍。还有一些在线的音乐会售票代理站点，它们会查看你以前观看演出的历史，并提醒你即将到来的演出，不定这些演出是值得一看的。又比如像 reddit.com 这样的站点，它会让你对其他 web 站点的链接进行投票，然后利用投票结果推荐你也许会感兴趣的其他链接。

从这些例子中，你可以看到我们能使用许多同的方式来搜集兴趣偏好。有时候，这些数据可能来自于人们购的物品，以有关些物品的评价信息，这些评价可能会被表达成「是 / 否」之类的投表决，或者是从 1 到 5 的评价值中，我们将对这些形色各异的表达方法进行考查，以便能够利用一组算法对其进行处理。

我们知道，要想了解商品、影片或娱乐性网站的推荐信息，最没有技术含量的方法莫过于向朋友们询问。我们也知道，这其中有一部分人的品味会比其他人的高一些，通过观察这些人是否通常也和我们一样喜欢同样的东西，可以逐渐对这些情况有所了解。不过随着选择越来越多，要想通过询问一小群人来确定我们想要的东西，将会变得越来越不切实际，因为他们可能并不了解所有的选择。这就是为什么人们要发展出一套被称为协作型过滤（collaborative filtering）的技术。

一个协作型过滤算法通常的做法是对一大群人进行搜索，并从中找出与我们品味相近的一小群人。算法会对这些人所偏爱的其他内容进行考查，并将它们组合起来构造出一个经过排名的推荐列表。有许多不同的方法可以帮助我们确定哪些人与自己的品味相近，并将他们的选择组合成列表。本章将择其一二详加介绍。

术语：「协作型过滤」是 David Goldberg 1992 年在施乐帕克研究中心（Xerox PARC）的一篇题为《Using collaborative filtering to weave an information tapestry》的论文中首次使用的。他设计了一个名 Tapestry 的系统，该系统允许人们根据自己对文档感兴趣的程度为其添加标注，并利用这一信息为他人进行文档过滤。时下，有数以百计的 Web 站点都在采用这样那样的协作型过滤算法，这些算法所要处理的内容涉及电影、音乐、书籍、交友、购物网站、播客服务（podcast）、文章，甚至还有幽默笑话。

2『已下载论文「2020012Using_collaborative_filtering_to_weave_an_information_tapestry」，存储于 Zotero。』

我们要做的第一件事情，是寻找一种表达不同人及其偏好的方法。在 Python 中，达到这目的的一种非常简单的方法是使用一个嵌套的字典。上述字典使用从 1 到 5 的评分，以此来体现包括本人在内的每位影评者对某一给定影片的喜爱程度。不管偏好是如何表达的，我们需要一种方法来将它们对应到数字。假如我们正在架设一个购物网站，不妨用数字 1 来代表有人过去曾购买过某件商品，用数字 0 来代表未曾购买过任何商品。而对于一个新闻故事的投票网站，我们可以分别用数字  -1、0 和 1 来表达「不喜欢」、「没有投票」、「喜欢」，如表 2-1 所示。

1『

把书里的字典做成一个函数 critics，函数不传递参数直接返回一个字典，在 ipython 里直接载入函数即可交互。

```
In [13]: from  recommendations import rec
In [14]: critics = critics()
In [17]: critics['Lisa Rose']
In [18]: critics['Lisa Rose']['Lady in the Water']
```

』

对于算法试验和范例演示而言，使用字典是很方便的。我们可以很容易地对字典进行査询和修改。尽管可以将相当数量的人员偏好信息置于字典内（即内存中），但对于一个规模巨大的数据集而言，也许我们还是会希望将其存入数据库中。

寻找相近的用户。搜集完人们的偏好数据之后，我们须要有一种方法来确定人们在品味方面的相似程度。为此，我们可以将每个人与所有其他人进行对比，并计算他们的相似度评价值。有若干种方法可以达到此目的，介绍两套计算相似度评价值的体系：欧几里徳距离和皮尔逊相关度。

计算相似度评价值的一个非常简单的方法是使用欧几里德距离评价方法。它以经过人们一致评价的物品为坐标轴，然后将参与评价的人绘制到图上，并考査他们彼此间的距离远近，如图 2-1 所示；该图显示了处于「偏好空间」中人们的分布状况。Toby 在 Snakes 轴线和 Dupree 轴轴线上所标示的数值分别是 4.5 和 1.0。两人在「偏好空间」中的距离越近，他们的兴趣偏好就越相似。因为这张图是二维的，所以在同一时间内你只能看到两项评分，但是这一规则对于更多数量的评分项而言也是同样适用的。

为了计算图上 Toby 和 Lasalle 之间的距离，我们可以计算出毎一轴向上的差值，求平方后再相加，最后对总和取平方根。在 Python 中，我们可以利用函数 pow (n,2) 对某数求平方，并使用 sqrt 函数求平方根。上述算式可以计算出距离值，偏好越相似的人，其距离就越短。不过，我们还需要一个函数，来对偏好越相近的情况给出越大的值。为此，我们可以将函数值加 1（这样就可以避免遇到被零整除的错误了），并取其倒数；这一新的函数总是返回介于 0 到 1 之间的值，返回 1 则表示两人具有一样的偏好。我们将前述知识结合起来，就可以构造出用来计算相似度的函数了。

```
In [1]: from recommendations import critics
In [2]: from recommendations import sim_distance
In [3]: critics = critics()
In [6]: sim_distance(critics, 'Michael Phillips', 'Claudia Puig')
Out[6]: 0.5714285714285714
```

除了欧几里德距离，还有一种更复杂一些的方法可以用来判断人们兴趣的相似度，那就是皮尔逊相关系数。该相关系数是判断两组数据与某一直线拟合程度的一种度量。对应的公式比欧几里德距离评价的计算公式要复杂，但是它在数据不是很规范（normalized）的时候（比如，影评者对影片的评价总是相对于平均水平偏离很大时），会倾向于给出更好的结果。为了形象地展现这一方法，我们可以在图上标示出两位评论者的评分情况，如下页图 2-2 所示。Mick Lasalle 为《Superman》评了 3 分，而 Gene Seymour 则评了 5 分，所以该影片被定位在图中的（3,5) 处。

在图上，我们还可以看到一条直线。因其绘制原则是尽可能地靠近图上的所有坐标点，故而被称作最佳拟合线（best-fit line）。如果两位评论者对所有影片的评分情况都相同，那么这条直线将成为对角线，并且会与图上所有的坐标点都相交，从而得到一个结果为 1 的理想相关度评价。对于如上图所示的情况，由于评论者对部分影片的评分不尽相同，因而相关系数大约为 0.4 左右。图 2-3 展现了一个有着更高相关系数的例子，约为 0.75。

在采用皮尔逊方法进行评价时，我们可以从图上发现一个值得注意的地方，那就是它修正了「夸大分值」（grade inflation）的情况。在这张图中，虽然 Jack Matthews 总是倾向于给出比 Lisa Rose 更高的分值，但最终的直线仍然是拟合的，这是因为他们两者有着相对近似的偏好。如果某人总是倾向于给出比另一个人更高的分值，而二者的分值之差又始终保持一致，则他们依然可能会存在很好的相关性。此前提到过的欧几里德距离评价方法，会因为个人的评价始终比另一个人的更为「严格」（从而导致评价始终相对偏低），而得出两者不相近的结论，即使他们的品味很相似也是如此。而这一行为是否就是我们想要的结果，则取决于具体的应用场景。

1『向量的方向和长度。两个向量虽然长度相差很大，但方向差不多，其实相关性还是很高。但是如果能讲所有向量的长度调整为差不多大，那么「欧几里德距离」模型也能反应出真实情况。』

皮尔逊相关度评价算法首先会找出两位评论者都曾评价过的物品，然后计算两者的评分总和与平方和，并求得评分的乘积之和。最后，算法利用这些计算结果计算出皮尔逊相关系数，如下列代码中粗体部分所示。不同于距离度量法，这一公式不是非常的直观，但是通过除以将所有变量的变化值相乘后得到的结果，它的确能够告诉我们变量的总体变化情况。

为了使用这一公式，请新建一个与 recommendations.py 中的 sim_ distance 函数有同样签名的函数。该函数将返回一个介于 -1 与 1 之间的数值。值为 1 则表明两个人对每一样物品均有着完全一致的评价。与距离度量法不同，此处我们无须为达到正确的比率而对这一数值进行变换。现在，我们可以试着求一下图 2-3 中的相关评价值了。

1『我另建了一个函数 pear_distance()。』

```
In [2]: import recommendations as reco
In [3]: critics = reco.critics()

In [4]: reco.sim_distance(critics, 'Michael Phillips', 'Claudia Puig')
Out[4]: 0.5714285714285714
In [5]: reco.pear_distance(critics, 'Michael Phillips', 'Claudia Puig')
Out[5]: 1.0

In [6]: reco.sim_distance(critics, 'Lisa Rose', 'Gene Seymour')
Out[6]: 0.14814814814814814
In [7]: reco.pear_distance(critics, 'Lisa Rose', 'Gene Seymour')
Out[7]: 0.39605901719066977
```

应该选用哪一种相似性度量方法。我们在此处已经介绍了两种不同的度量方法，但实际上，还有许多方法可以衡量两组数据间的相似程度。使用哪一种方法最优，完全取决于具体的应用。如果你想看看哪种方法能够获得更好的实际效果，皮尔逊、欧几里德距离，或者任何其他方法，都是值得一试的。本章剩余部分出现的函数均有一个可选的相似性参数，该参数指向一个实际的算法函数。这可以使针对算法的实验变得更为容易：我们可以指定 sim_pearson 或 sim_distance 作为相似性参数的取值。我们还可以使用许多其他的函数，如 Jaccard 系数或曼哈顿距离算法，作为相似度计算函数，只要它们满足如下条件：拥有同样的函数签名，以一个浮点数作为返回值，其数值越大代表相似度越大。

为评论者打分。既然我们已经有了对两个人进行比较的函数，下面我们就可以编写函数，根据指定人员对每个人进行打分，并找出最接近的匹配结果了。在本例中，我们对找寻与自己有相似品味的影评者很感兴趣，因为这样我们就知道在选择影片时应该采纳谁的建议了。请将该函数加入 recommendations.py 中，以得到一个人员的有序列表，这些人与某个指定人员具有相近的品味；该函数利用了 Python 的列表推导式，采用先前定义过的某种距离度量算法，将自身和字典中的其他每一位用户都进行了比较。然后，函数返回排序结果中的前 n 项。调用该方法并传入自己的姓名，将得到一个有关影评者及其相似度评价值的列表。

```
In [1]: import recommendations as rec
In [3]: rec.topMatches(rec.critics(), 'Toby', 3)
Out[3]:
[(0.9912407071619299, 'Lisa Rose'),
 (0.9244734516419049, 'Mick LaSalle'),
 (0.8934051474415647, 'Claudia Puig')]

In [6]: from recommendations import sim_distance

In [7]: rec.topMatches(rec.critics(), 'Toby', 3, similarity=sim_distance)
Out[7]:
[(0.3076923076923077, 'Mick LaSalle'),
 (0.2857142857142857, 'Michael Phillips'),
 (0.23529411764705882, 'Claudia Puig')]
```

推荐物品。找到一位趣味相投的影评者并阅读他所撰写的评论固然不错，但现在我们真正想要的不是这些，而是一份影片的推荐。当然，我们也可以査找与自己品味最为相近的人，并从他所喜欢的影片中找出一部自己还未看过的影片，不过这样做太随意了（permissive）。有时，这种方法可能会有问题：评论者还未对某些影片做过评论，而这些影片也许就是我们所喜欢的。还有一种可能是，我们会找到一个热衷某部影片的古怪评论者，而根据 topMatches 所返回的结果，所有其他的评论者都不看好这部影片。

为了解决上述问题，我们须要通过一个经过加权的评价值来为影片打分，评论者的评分结果因此而形成了先后的排名。为此，我们须要取得所有其他评论者的评价结果，借此得到相似度后，再乘以他们为毎部影片所给的评价值。表 2-2 给出了这一方法的执行过程。

表中列出了每位评论者的相关度评价值，以及他们对三部影片（《The Night Listener》、《Lady in the Water）》和《Just My Luck》）的评分情况（我们还不曾参与评分）。以 S.x 打头的列给出了乘以评价值之后的相似度。如此一来，相比于与我们不相近的人，那些与我们相近的人将会对整体评价值拥有更多的贡献。总计一行给出了所有加权评价值的总和。

我们也可以选择利用总计值来计算排名，但是我们还须要考虑到，一部受更多人评论的影片会对结果产生更大的影响。为了修正这一向题，我们须要除以表中名为 Sim.Sum 的那一行，它代表了所有对这部电影有过评论的评论者的相似度之和。由于每个人都对影片《The Night Listener》进行了评论，因此我们用总计值除以全部相似度之和。而对于影片《Lady in the Water》而言，Puig 并未做过评论，因此我们将这部影片的总计值除以所有其他人的相似度之和。表中最后一行给出了相除的结果。下列代码反映了上述过程，非常的简单易懂，并且它对欧几里德距离评价或皮尔逊相关度评价都是适用的。

上述代码循环遍历所有位于字典 prefs 中的其他人。针对每一次循环，它会计算由 person 参数所指定的人员与这些人的相似度。然后它会循环遍历所有打过分的项。以黑体显示的代码行说明了每一项的最终评价值的计算方法 一一 用毎一项的评价值乘以相似度，并将所得乘积累加起来。最后，我们将每个总计值除以相似度之和，借此对评价值进行归一化处理，然后返回一个经过排序的结果。这样，我们就可以找到自己接下来应该要看的电影了。

```
In [1]: import recommendations as rec

In [3]: rec.getRecommendations(rec.critics(), 'Toby')
Out[3]:
[(3.3477895267131017, 'The Night Listener'),
 (2.8325499182641614, 'Lady in the Water'),
 (2.530980703765565, 'Just My Luck')]
 
 In [4]: rec.getRecommendations(rec.critics(), 'Toby', rec.sim_distance)
Out[4]:
[(3.5002478401415877, 'The Night Listener'),
 (2.7561242939959363, 'Lady in the Water'),
 (2.461988486074374, 'Just My Luck')]
```

此处，我们不仅得到了一个经过排名的影片列表，而且还推测出了自己对每部影片的评价情况。根据这份结果，我们可以决定自己究竟要不要观看其中的某部影片，还是最好干脆什么也别看。有赖于具体的应用，假如无法满足某一用户给出的标准，我们也可以决定不给予建议。你会发现，选择不同的相似性度量方法，对结果的影响是微乎其微的。

现在，我们已经建立起了一个完整的推荐系统，它适用于任何类型的商品或网络链接。我们所要做的全部事情就是：建立一个涉及人员、物品和评价值的字典，然后就可以借此来为任何人提供建议了。在本章的后续章节中，你将会看到如何利用 del.icio.us API 来获取真实数据，进而向人们推荐 Web 站点。

匹配商品。现在，我们已经知道了如何为指定人员寻找品味相近者，以及如何向其推荐商品的方法，但是假如我们想了解哪些商品是彼此相近的，那又该如何做呢？也许我们曾经在购物网站上遇到过这种情形，尤其是当网站还没有收集到关于用户的足够信息时。图 2-4 显示了 Amazon 网站上有关《Programming Python》一书的局部网页。在这种情况下，我们可以通过査看哪些人喜欢某一特定物品，以及这些人喜欢哪些其他物品来决定相似度。事实上，这和我们此前用来决定人与人之间相似度的方法是一样的 一一 只须要将人员与物品对换即可。因此，假如我们将 XX 换成 XX 就可以复用以前所写的方法了。将执行这一转换过程的函数加入 recommendations.py 中：

```
def transformPrefs(prefs):
    result={} 
    for person in prefs:
        for item in prefs[person]:
            result.setdefault(item,{})
            # Flip item and person 
            result[item][person]=prefs[person][item] 
    return result

```

现在，调用以前曾经用过的 topmatches 函数，得到一组与《Superman Returns》最为相近的影片：

```
movies=rec.transformPrefs(rec.critics)
rec.topMatches(movies,'Superman Returns') 

recommendations.getRecommendations(movies,'Just My Luck') 
[(4.0, 'Michael Phillips'), (3.0, 'Jack Matthews')]
```

请注意：在本例中，实际存在着一些相关评价值为负的情况，这表明那些喜欢影片《Superman Returns》的人，存在不喜欢《Just My Luck》的倾向，如图 2-5 所示。上面我们示范了为某部影片提供相关影片的推荐，不仅如此，我们甚至还可以为影片推荐评论者。例如，也许我们正在考虑邀请谁和自己一起参加某部影片的首映式。

将人和物对调并不总是会得到有价值的结果，但是大多数情况下，这将有助于我们作出有意义的对比。为了向不同的个体推荐商品，在线零售商可能会收集人们的购买历史。将商品与人进行对调 一一 正如我们此前所做的那样 一一 可以令零售商找到购买某些商品的潜在客户。这对于他们为了清仓处理某些商品而在市场营销投入方面制定的规划，也许是很有助益的。这种做法的另一个潜在用途是，在专门推荐链接的网站上，这样做可以确保新出现的链接，能够被那些最有可能对它产生兴趣的网站用户找到。



