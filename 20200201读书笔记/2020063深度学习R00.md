## 记忆时间

参考：伊恩·古德费洛.(2017).深度学习.(赵申剑,黎彧君.译).人民邮电出版社 => xxxx

## 读书大法

### 第一步：确定是一本什么类型的书

问：

[图片-书籍封面]

请介绍下这本书籍，越详细越好

GPT-4（2023-10-11）

这本书名为「Deep Learning」（深度学习），作者是 Ian Goodfellow、Yoshua Bengio 和 Aaron Courville。这本书是深度学习领域的经典教材，被广大研究者和学生所推崇。

内容简介：

这本书详细介绍了深度学习的基础知识、核心概念以及最新的研究进展。书中从最基础的线性代数、概率和信息论开始，逐步深入到更复杂的主题，如前馈深度网络、正则化、优化、卷积网络、序列模型和生成模型。

特点：

1、全面性：这本书涵盖了深度学习的各个方面，从基础到高级，适合初学者和专家。

2、理论与实践结合：不仅提供了理论知识，还给出了实际的算法和模型，以及如何实现和应用它们的建议。

3、权威性：三位作者都是深度学习领域的权威人物，他们的研究工作为这个领域的发展做出了重要贡献。

4、应用领域：书中不仅涉及基础的研究内容，还探讨了深度学习在自然语言处理、计算机视觉、语音识别等多个应用领域的实践。

总之，这本书为那些希望深入了解深度学习的读者提供了宝贵的资源，无论是学生、研究者还是从业者，都可以从中受益。

问：

我有一定的计算机基础，并且有 Python 基础知识，但不具有深度学习相关的知识。如果我想要研读并吃透这本书，请给我列出具体的阅读计划，并说明理由，越详细越好

当然可以！为了更好地理解和研究这本「Deep Learning」书籍，您可以按照以下的阅读计划进行：

GPT-4（2023-10-11）

1、理论基础。

线性代数、概率和信息论：深度学习的核心概念建立在这些数学基础之上。首先从这些章节开始，确保您对这些概念有深入的了解。

2、深度学习基础。

前馈深度网络：了解深度学习模型的基本构建块和工作原理。

正则化：学习如何防止模型过拟合。

优化：深入理解如何训练深度学习模型。

3、高级内容。

卷积网络：针对图像数据的特殊模型。

序列模型：用于处理时间序列数据或文本数据。

生成模型：学习如何生成新的、之前未见过的数据。

4、实践与应用。

根据书中的指导和示例，实践实现一些模型。

深入研究深度学习在自然语言处理、计算机视觉和语音识别等领域的应用。

理由：

建立坚实的基础：深度学习是一个复杂的领域，所以首先确保理解其基础理论是非常重要的。通过首先学习线性代数、概率和信息论，您可以为后续的学习打下坚实的基础。

分步骤学习：从基础到高级，逐步深入。这样可以确保您在进入高级主题之前已经充分理解了基础内容。

实践加深理解：理论知识和实践相结合是最好的学习方式。通过亲自实现和应用模型，您可以更深入地理解深度学习的工作原理。

最后，这本书中可能会提到很多与您之前未接触过的概念。建议您在阅读的过程中，不断地做笔记，并时常回顾，以加深对各个概念的理解。同时，利用网络资源，如相关的博客、教程或研究论文，来辅助您的学习也是一个很好的方法。祝您学习愉快！

问：

以下{}中的内容是对个人文集、个人专著、个人编著和集体编撰四大类的定义，请根据该定义判断本书属于哪一类，并说明理由。

{
图书分为个人文集、个人专著、个人编著与集体编撰四大类。个人文集指由一位作者独立完成的著作，但章节之间关联松散，先读哪一篇，后读哪一篇，影响不大。个人专著指由一位作者为主独立完成的著作，章节之间紧密相合，前后呼应。在实际操作中，亦常见多位作者，如作者邀请师友弟子，贡献其中的一两章，或者两位好友合著一本。这类书依然属于个人专著。个人编著指由一位作者编写而成的著作。常见的有两类情况：一类是评述某个领域的既有成果，典型如各学科或领域中的教科书；另一类是凭借个人品位挑选他人作品，如沈德潜编写《古诗源》，收录唐代之前的经典诗歌七百余首。集体编撰指由多位作者共同编写的著作，典型如各类辞书与各个学科或领域中的手册，再如医学领域的临床循证治疗指南、工程领域的各类行业标准。
}

GPT-4（2023-10-14）

根据所给定义，这本「Deep Learning」书籍属于「集体编撰」。

理由：

本书是由 Ian Goodfellow、Yoshua Bengio 和 Aaron Courville 三位作者共同完成的。

根据定义中的描述，集体编撰指由多位作者共同编写的著作。本书正是由多位作者共同撰写的，因此符合集体编撰的定义。

### 第二步：确定应用阅读技法的次序

参考第 9 章的介绍。先翻到 P199 页。对于学术专著，发现建议应用阅读的技法的次序是：结构阅读、抽样阅读、文本细读、主题阅读。

结构阅读（P118 页）

作者使用的认知方式是什么？

问：

以下{}中的内容为人类 9 种认知方式的定义，请根据该定义判断本书使用了哪些认知方式，并说明理由，如果你知道本书内容的话请列举书中的案例辅助说明。

{
思想实验：作者构造了怎样的思想实验？这个思想实验是作者第一次发明，还是基于历史上已有的思想实验发明的？这个思想实验和你头脑中的常识有什么不同？给你提供了什么样的反常识？仿照作者的这个思想实验，你可以用它来批判什么观点？

符号思考：作者使用的是像数学符号一样精确的符号，还是非精确、模糊的符号？这些符号之间建立联系了吗？是可以运算的还是不可以运算的？假如能够运算，可以得出什么结果？假如不能运算，作者用这些符号表征了什么现象？模仿作者的符号可以应用到哪些领域？

实验科学：作者设计了什么类型的实验？是严格意义上的实验，还是宽松的准实验？作者的实验设计是自己发明的新方法，还是业界通用的方法？作者的实验假设是否存在备择假设？作者的实验证据和实验结论之间证明了什么关系？是因果关系，还是相关关系，或者其他关系？作者的实验是否能够脱离实验室环境，应用到更广的范围？

计算模拟：作者提出了一个什么样的计算模型？模拟了什么现象、什么事物？作者的计算模型使用了真实的编程语言，还是非真实的编程语言？支持作者计算模型的实际证据是什么？作者的计算模型能够解释别人已有的相关研究和数据吗？

田野调查：作者是进行实地的、一手的田野调查，还是基于资料进行二手的田野调查？作者进行田野调查的时候去了多久，待了多长时间？在此之前，作者熟悉还是不熟悉调查对象？作者在田野调查的时候，得出了什么结论？这个结论有什么解释价值？能够对哪些现象进行解释？

幽默叙事：这个幽默的营造语句和关键语句是什么？这个幽默与人类的什么基本需求相关？这个幽默是否可笑？如果可笑，为什么可笑？如果不可笑，为什么不可笑？模仿作者的幽默，可以做什么样的改写？

故事叙事：故事内核或者说最小故事是什么？这个故事的「故事性」强吗？为什么？这个故事的主人翁是谁？故事发生在什么时间、地点？先后经历了哪些事件？事件一是什么？事件二是什么？...事件 n 是什么？这个故事涉及人性的深层次问题吗？假如要模仿作者写一个故事，你该如何写？

文采美感：作者给了你什么样的意象和感觉？作者的字词、句子、篇章有哪些可以学习和模仿的地方？作者唤醒了你什么样的情绪？

视觉美感：作者的作品展现了什么样的形象？模仿作者的视觉设计，你可以应用到什么领域？作者唤醒了你什么样的情绪？
}

GPT-4（2023-10-14）

根据我对「Deep Learning」这本书的了解，以下是该书中使用的人类认知方式及对应的说明和案例：

符号思考：

使用：这本书大量使用了数学符号，这些符号是精确的。

联系：这些符号之间确实建立了联系，并且是可以运算的。

案例：例如，在描述神经网络的反向传播算法时，会使用链式法则等数学符号进行推导。

计算模拟：

使用：这本书提到了许多计算模型，如各种神经网络结构。

案例：例如，当介绍卷积神经网络（CNN）时，会详细描述其计算模型并展示如何模拟图像分类等任务。

总结：该书主要使用了符号思考和计算模拟两种认知方式。

抽样阅读（P100 页）

概率抽样：简单随机抽样、等距抽样、整群抽样和分层抽样；非概率抽样：专家抽样、便利抽样、配额抽样和雪球抽样。

文本细读（P68 页）

主题阅读：参考附录即可（P411 页）

### 第四步：边读边写卡片

参考第 9 章的介绍。再次翻到 P199 页。对于大众科普，发现建议卡片大法的重点是：新知卡、术语卡、图示卡。

### 第五步：从卡片到文章与图书

要学会把作者的知识产权转变为个人的知识产权。

## 卡片

### 0101. 新知卡

新知卡，是有什么理论模型、推断证据、故事或行动，挑战了你的既有认知。新知卡的信息结构是：已知 + 新知 + 例子。「已知」建议挑选大众或自己以前的观念或掌握的知识；「新知」建议挑选自己更新之后的新知。「例子」建议使用自己日常生活中碰到过的事情，这样更容易记忆。新知卡举例如下：

{
已知：通过熟人找工作更容易。

新知：社会学家马克·格兰诺维特的弱联系理论告诉我们，在大多数人寻找工作的过程中，弱联系的那些人起到的作用最大。

例子：读本科时，我的第一份实习工作是一个统计论坛上素未谋面的朋友介绍的。
}

请通过文档提炼一张新知卡，新知的主题是：「认识到人类的认知可以是科学研究而不光是哲学思辩的对象还不到 150 年」。尽可能多的列举文档中的例子，并将例子具体展开。开始前请先重新阐述任务。

#### 1.1 新知卡 —— XXXX

已知：在过去，人们普遍认为人类的认知是哲学思辩的对象，而非科学研究的领域。

新知：然而，近 150 年来，科学家们开始将人类的认知视为科学研究的对象。这一转变的起点可以追溯到 19 世纪末的心理学的诞生，特别是威廉·詹姆斯的开创性工作。

例子：

1、威廉·詹姆斯是心理学的奠基人之一，他的研究使我们开始将人类的认知视为科学研究的对象。他的著作《心理学原理》是第一本系统性地研究人类认知的科学著作，它开启了认知科学的新篇章。

2、在 20 世纪，认知科学的发展进一步推动了我们对人类认知的科学研究。例如，艾伦·图灵的工作，他提出了「图灵测试」，这是一个判断机器是否具有人类智能的测试，这个测试的提出，使我们开始思考人类认知的本质和可能性。

3、另一个例子是诺姆·乔姆斯基的生成语法理论，他的理论挑战了我们对人类语言认知的理解，使我们开始从科学的角度研究语言的本质（页码：9）。

参考：约翰·R.安德森.(2012).认知心理学及其启示.(裕林，程瑶，周海燕，译).人民邮电出版社 => 0101. 认知的科学

唯一编码：202305292046

打印备注：2023-05-29

### 0201. 术语卡

术语卡记录的是阅读中出现过的陌生术语或概念，有时候是学术词汇，有时候是作者发明的黑话。如果不是作者首创的术语，建议找到最原始的论文或者资料，查询谁首先提出了这个术语，分辨哪些是作者真正意义上的原创贡献，哪些是作者改善前人研究，哪些是作者故意曲解他人术语。一旦养成这种习惯，你的独立思考能力就会增强。术语卡常见的信息结构是：「标题 + 定义 + 解释 + 例子」。试举如下：

{
标题：什么是执行意图？

定义：它是一种制订计划的方式。认知心理学家彼得·戈尔维策将「我要减肥十斤」这种制订计划的方式称为「目标意图」，将使用「如果...那么...」（if...then...）的句式来制订计划的方式称为「执行意图」。

解释：执行意图通过在大脑中提前规划执行计划的时间、地点，从而更易引发行动。

例子：你可以将「我要多运动」改写为「如果到了每天傍晚 5 点，那么我就去操场跑步」。前者是目标意图，后者是执行意图。
}

请结合以下内容提炼一张标题为{机器学习}的术语卡，尽可能多的列举内容中的例子，并将例子具体展开。开始前请先重新阐述任务。

#### 2.1 术语卡 —— 机器学习

定义：

机器学习是一种人工智能（AI）技术，使计算机能够从数据中自动地学习和改进。它旨在让计算机拥有从原始数据中提取模式的能力，而不需要硬编码知识。

解释：

1、知识获取：不同于传统的硬编码（hard-code）方法或知识库（knowledge base）方法，机器学习算法可以从数据中自动提取知识。

2、数据表示：机器学习算法的性能在很大程度上依赖于数据的表示（representation）。不同的特征表示会影响算法的性能。

3、决策能力：机器学习可以处理现实世界的问题，并能做出看似主观的决策。

例子：

1、逻辑回归（Logistic Regression）：这是一种简单的机器学习算法，用于分类问题。例如，在医疗领域，逻辑回归可以用于判断产妇是否适合剖腹产。系统并不直接检查患者，而是依据医生提供的各种特征（如是否存在子宫疤痕）来做出预测。

2、朴素贝叶斯（Naive Bayes）：另一个简单的机器学习算法，主要用于分类。它可以用来区分垃圾电子邮件和合法电子邮件。

3、数据表示的影响：逻辑回归在判断产妇是否适合剖腹产时，如果输入数据是 MRI（核磁共振）扫描而不是医生的正式报告，那么其预测能力会受到影响。因为 MRI 扫描的单一像素与分娩过程中的并发症之间的相关性非常小。

4、表示的选择：在计算机科学和日常生活中，数据表示（如阿拉伯数字和罗马数字）会对运算速度产生影响。同样，在机器学习中，合适的数据表示会极大地影响算法的性能。

参考：伊恩·古德费洛.(2017).2020063深度学习.(赵申剑,黎彧君.译).人民邮电出版社 => 0101 引言

唯一编码：202311020020

打印备注：2023-11-02

原文：

一些人工智能项目力求将关于世界的知识用形式化的语言进行硬编码（hard-code）。计算机可以使用逻辑推理规则来自动地理解这些形式化语言中的声明。这就是众所周知的人工智能的知识库（knowledge base）方法。然而，这些项目最终都没有取得重大的成功。其中最著名的项目是 Cyc（Lenat and Guha，1989）。Cyc 包括一个推断引擎和一个使用 CycL 语言描述的声明数据库。这些声明是由人类监督者输入的。这是一个笨拙的过程。人们设法设计出足够复杂的形式化规则来精确地描述世界。例如，Cyc 不能理解一个关于名为 Fred 的人在早上剃须的故事（Linde，1992）。它的推理引擎检测到故事中的不一致性：它知道人体的构成不包含电气零件，但由于 Fred 正拿着一个电动剃须刀，它认为实体 ——「正在剃须的 Fred」（FredWhileShaving）含有电气部件。因此，它产生了这样的疑问 —— Fred 在刮胡子的时候是否仍然是一个人。

依靠硬编码的知识体系面临的困难表明，AI 系统需要具备自己获取知识的能力，即从原始数据中提取模式的能力。这种能力称为机器学习（machine learning）。引入机器学习使计算机能够解决涉及现实世界知识的问题，并能做出看似主观的决策。比如，一个称为逻辑回归（logistic regression）的简单机器学习算法可以决定是否建议剖腹产（Mor-Yosef et al.，1990）。而同样是简单机器学习算法的朴素贝叶斯（naive Bayes）则可以区分垃圾电子邮件和合法电子邮件。

这些简单的机器学习算法的性能在很大程度上依赖于给定数据的表示（representation）。例如，当逻辑回归用于判断产妇是否适合剖腹产时，AI 系统不会直接检查患者。相反，医生需要告诉系统几条相关的信息，诸如是否存在子宫疤痕。表示患者的每条信息称为一个特征。逻辑回归学习病人的这些特征如何与各种结果相关联。然而，它丝毫不能影响该特征定义的方式。如果将病人的 MRI（核磁共振）扫描而不是医生正式的报告作为逻辑回归的输入，它将无法做出有用的预测。MRI 扫描的单一像素与分娩过程中并发症之间的相关性微乎其微。

在整个计算机科学乃至日常生活中，对表示的依赖都是一个普遍现象。在计算机科学中，如果数据集合被精巧地结构化并被智能地索引，那么诸如搜索之类的操作的处理速度就可以成指数级地加快。人们可以很容易地在阿拉伯数字的表示下进行算术运算，但在罗马数字的表示下，运算会比较耗时。因此，毫不奇怪，表示的选择会对机器学习算法的性能产生巨大的影响。图 1.1 展示了一个简单的可视化例子。

#### 2.2 术语卡 —— 深度学习

定义：

深度学习是人工智能（AI）的一个子领域，专注于让计算机从经验中学习并根据层次化的概念体系来理解世界。每个复杂的概念都通过与某些相对简单的概念之间的关系来定义。补充：深度学习是机器学习的一种，是机器学习的子类。

解释：

1、层次化的概念体系：通过构建较简单的概念来学习复杂概念。

2、从经验学习：避免由人类来给计算机形式化地指定它需要的所有知识。

例子：

1、多层感知机（MLP）。MLP 是深度学习模型的典型例子，它是一个将一组输入值映射到输出值的数学函数。该函数由许多较简单的函数复合而成，每一层提供了输入的新表示。

2、图像识别。在图像识别中，深度学习模型通过组合较简单的概念（例如角和轮廓）来表示图像中人的概念。第一层识别边缘，第二层识别角和轮廓，以此类推，直到识别出复杂对象。

3、语音识别。用于识别人们所说的话，处理诸如口音这样的复杂变量。从原始声波数据中提取有用的信息是非常复杂的。

4、国际象棋和深蓝。深蓝（Deep Blue）是 IBM 的国际象棋系统，1997 年击败了世界冠军 Garry Kasparov。国际象棋系统是一个较为「朴素和形式化」的环境，不需要深度学习来理解复杂的现实世界。

挑战与困难：

1、非形式化的知识：对于很多直观的、非形式化的任务（如面部识别、语音识别），传统的方法很难解决。

2、表示学习：如何从原始数据中提取高层次、抽象的特征是非常困难的。

独特视角：

1、多步骤的计算机程序：深度学习可以被看作是学习一个多步骤的计算机程序，其中每一层都是一组并行执行的指令。

2、状态信息：深度学习模型不仅仅用于理解输入，还存储了状态信息，这有助于模型组织其处理过程。

参考：伊恩·古德费洛.(2017).2020063深度学习.(赵申剑,黎彧君.译).人民邮电出版社 => 译者序/0101 引言

唯一编码：202311020033

打印备注：2023-11-02

原文：

译者序：

作者在书中写到：「人工智能的真正挑战在于解决那些对人来说很容易执行、但很难形式化描述的任务，比如识别人们所说的话或图像中的脸。对于这些问题，我们人类往往可以凭直觉轻易地解决」。为了应对这些挑战，他们提出让计算机从经验中学习，并根据层次化的概念体系来理解世界，而每个概念通过与某些相对简单的概念之间的关系来定义。由此，作者给出了深度学习的定义：「层次化的概念让计算机构建较简单的概念来学习复杂概念。如果绘制出表示这些概念如何建立在彼此之上的一幅图，我们将得到一张‘深’（层次很多）的图。由此，我们称这种方法为 AI 深度学习（deep learning）」。

引言：

01

在人工智能的早期，那些对人类智力来说非常困难、但对计算机来说相对简单的问题得到迅速解决，比如，那些可以通过一系列形式化的数学规则来描述的问题。人工智能的真正挑战在于解决那些对人来说很容易执行、但很难形式化描述的任务，如识别人们所说的话或图像中的脸。对于这些问题，我们人类往往可以凭借直觉轻易地解决。

针对这些比较直观的问题，本书讨论一种解决方案。该方案可以让计算机从经验中学习，并根据层次化的概念体系来理解世界，而每个概念则通过与某些相对简单的概念之间的关系来定义。让计算机从经验获取知识，可以避免由人类来给计算机形式化地指定它需要的所有知识。层次化的概念让计算机构建较简单的概念来学习复杂概念。如果绘制出表示这些概念如何建立在彼此之上的图，我们将得到一张「深」（层次很多）的图。基于这个原因，我们称这种方法为 AI 深度学习（deep learning）。

AI 许多早期的成功发生在相对朴素且形式化的环境中，而且不要求计算机具备很多关于世界的知识。例如，IBM 的深蓝（Deep Blue）国际象棋系统在 1997 年击败了世界冠军 Garry Kasparov（Hsu，2002）。显然国际象棋是一个非常简单的领域，因为它仅含有 64 个位置并只能以严格限制的方式移动 32 个棋子。设计一种成功的国际象棋策略是巨大的成就，但向计算机描述棋子及其允许的走法并不是这一挑战的困难所在。国际象棋完全可以由一个非常简短的、完全形式化的规则列表来描述，并可以容易地由程序员事先准备好。

具有讽刺意义的是，抽象和形式化的任务对人类而言是最困难的脑力任务之一，但对计算机而言却属于最容易的。计算机早就能够打败人类最好的国际象棋选手，但直到最近计算机才在识别对象或语音任务中达到人类平均水平。一个人的日常生活需要关于世界的巨量知识。很多这方面的知识是主观的、直观的，因此很难通过形式化的方式表达清楚。计算机需要获取同样的知识才能表现出智能。人工智能的一个关键挑战就是如何将这些非形式化的知识传达给计算机。

02

显然，从原始数据中提取如此高层次、抽象的特征是非常困难的。许多诸如说话口音这样的变差因素，只能通过对数据进行复杂的、接近人类水平的理解来辨识。这几乎与获得原问题的表示一样困难，因此，乍一看，表示学习似乎并不能帮助我们。

深度学习（deep learning）通过其他较简单的表示来表达复杂表示，解决了表示学习中的核心问题。

深度学习让计算机通过较简单的概念构建复杂的概念。图 1.2 展示了深度学习系统如何通过组合较简单的概念（例如角和轮廓，它们反过来由边线定义）来表示图像中人的概念。深度学习模型的典型例子是前馈深度网络或或多层感知机（multilayer perceptron，MLP）。多层感知机仅仅是一个将一组输入值映射到输出值的数学函数。该函数由许多较简单的函数复合而成。我们可以认为不同数学函数的每一次应用都为输入提供了新的表示。

图 1.2 深度学习模型的示意图。计算机难以理解原始感观输入数据的含义，如表示为像素值集合的图像。将一组像素映射到对象标识的函数非常复杂。如果直接处理，学习或评估此映射似乎是不可能的。深度学习将所需的复杂映射分解为一系列嵌套的简单映射（每个由模型的不同层描述）来解决这一难题。输入展示在可见层（visible layer），这样命名的原因是因为它包含我们能观察到的变量。然后是一系列从图像中提取越来越多抽象特征的隐藏层（hidden layer）。因为它们的值不在数据中给出，所以将这些层称为「隐藏层」；模型必须确定哪些概念有利于解释观察数据中的关系。这里的图像是每个隐藏单元表示的特征的可视化。给定像素，第 1 层可以轻易地通过比较相邻像素的亮度来识别边缘。有了第 1 隐藏层描述的边缘，第 2 隐藏层可以容易地搜索可识别为角和扩展轮廓的边集合。给定第 2 隐藏层中关于角和轮廓的图像描述，第 3 隐藏层可以找到轮廓和角的特定集合来检测特定对象的整个部分。最后，根据图像描述中包含的对象部分，可以识别图像中存在的对象（经 Zeiler and Fergus（2014）许可引用此图）

学习数据的正确表示的想法是解释深度学习的一个视角。另一个视角是深度促使计算机学习一个多步骤的计算机程序。每一层表示都可以被认为是并行执行另一组指令之后计算机的存储器状态。更深的网络可以按顺序执行更多的指令。顺序指令提供了极大的能力，因为后面的指令可以参考早期指令的结果。从这个角度上看，在某层激活函数里，并非所有信息都蕴涵着解释输入的变差因素。表示还存储着状态信息，用于帮助程序理解输入。这里的状态信息类似于传统计算机程序中的计数器或指针。它与具体的输入内容无关，但有助于模型组织其处理过程。

03

总之，这本书的主题 —— 深度学习是通向人工智能的途径之一。具体来说，它是机器学习的一种，一种能够使计算机系统从经验和数据中得到提高的技术。我们坚信机器学习可以构建出在复杂实际环境下运行的 AI 系统，并且是唯一切实可行的方法。深度学习是一种特定类型的机器学习，具有强大的能力和灵活性，它将大千世界表示为嵌套的层次概念体系（由较简单概念间的联系定义复杂概念、从一般抽象概括到高级抽象表示）。图 1.4 说明了这些不同的 AI 学科之间的关系。图 1.5 展示了每个学科如何工作的高层次原理。

### 0301. 人名卡

请为约翰·R.安德森（John R. Anderson）写一份 500-1000 字的小传。要求包括他的姓名全称、生卒年份、教育背景、工作经历、主要身份、家庭网络、社会关系、人生重要节点以及重要成果，着重介绍其重要成果和著作，请参考维基百科的信息，并给出链接。

#### 3.1 人名卡 —— XXXX

标题：约翰·R.安德森（John R. Anderson）

小传：

约翰·R. 安德森（John Robert Anderson，1947-）是一位杰出的认知心理学家和人工智能研究员，他的研究对于理解人类认知过程产生了深远影响。安德森的理论和模型已经被广泛应用于教育、人机交互和认知心理疗法等领域。

约翰·R. 安德森于 1947 年 1 月 27 日出生在加拿大温哥华。他在 1968 年毕业于加拿大不列颠哥伦比亚大学，获得数学和物理的学士学位。1972 年，他在斯坦福大学获得心理学博士学位。毕业后，他加入卡内基梅隆大学（CMU）任教，并在那里度过了他的大部分职业生涯。

安德森是 CMU 认知心理学和人工智能研究的核心人物，他的贡献主要集中在认知建模和智能教育系统的设计与研究。他开发的「ACT-R」认知建模框架，为认知心理学家研究人类复杂认知行为提供了一种强大的工具。他还是 CMU "LearnLab" 的联合创始人，这是一个研究人类学习过程的实验室，它使用科技手段，如智能教学系统，以提高学习效率。

他的主要著作有《人类认知的适应性性质》（The Adaptive Character of Thought, 1990）、《认知的规则》（Rules of the Mind, 1993）等，这些著作在认知心理学界产生了广泛的影响。

安德森在生活中是一位爱好广泛的人，他喜欢徒步、攀岩和滑雪等户外活动。他与妻子 Lynne Reder 共同生活，Lynne 也是一位在 CMU 任职的心理学教授。

在科研领域，安德森的贡献得到了广泛认可，他是美国国家科学院的院士，获得过多项重要奖项，包括美国心理学会的「杰出科学贡献奖」。

约翰·R. 安德森以其深入的研究和实践，为我们理解和改善人类认知提供了宝贵的资源。他的工作已经超越了学术领域的边界，影响了教育政策的制定和技术产品的设计。他的 ACT-R 理论以及研究人类学习的 LearnLab 为人们理解复杂认知过程以及改进教育方法提供了极为宝贵的资源。

至于他的人生重要节点，除了他的教育背景和职业生涯之外，他在 2004 年获得了杰出贡献奖，以表彰他在心理学领域的杰出贡献，尤其是在认知科学领域。他的贡献在诸多方面都得到了认可，这包括他对人工智能的研究，尤其是他对认知建模的创新工作。

总的来说，约翰·R. 安德森是一位杰出的认知心理学家和人工智能研究员，他的研究和理论在认知科学、教育和人机交互等领域产生了深远影响。尽管他已经离开了教室和实验室，但他的贡献和影响力仍然深远，他的工作仍然是当前认知科学研究的重要参考。

约翰·R. 安德森与冯特、佛洛依德、巴甫洛夫以及赫伯特·西蒙并列被评为人类历史上「50 位最伟大的心理学思想家」之一，他是最年轻的一位。

参考：[John Robert Anderson (psychologist) - Wikipedia](https://en.wikipedia.org/wiki/John_Robert_Anderson_(psychologist))

唯一编码：202305292311

打印备注：2023-05-29

### 0401. 金句卡

最后根据他写的非常震撼的话语——产生一张金句卡。

#### 4.1 金句卡 —— XXXX

### 0501. 基础卡

基础卡是最为基础的卡片，用于记录一些基础性事实、观点、故事等。基础卡常见的信息结构是：「标题 + 内容 + 评论」。「标题」指的是对卡片内容简明扼要的概括，类似卡片助记词，帮助你更好地记忆；「内容」指的是卡片正文，你可将阅读心得写成内容 + 评论或心得或想法或收获。基础卡举例如下：

{
标题：读《听听那冷雨》

内容：惊蛰一过，春寒加剧。先是料料峭峭，继而雨季开始，时而淋淋漓漓，时而渐渐沥沥，天潮潮地湿湿，即连在梦里，也似乎把伞撑着。而就凭一把伞，躲过一阵潇潇的冷雨，也躲不过整个雨季。连思想也都是潮润的。每天回家，曲折穿过金门街到厦门街迷宫式的长巷短巷，雨里风里，走入靠靠令人更想入非非。想这样子的台北凄凄切切完全是黑白片的味道，想整个中国整部中国的历史无非是一张黑白片子，片头到片尾，一直是这样下着雨的。

评论：余光中散文名篇《听听那冷雨》堪称白话文范文，将中文之美用到了极致，开篇「料料峭峭」「淋淋漓满」「渐渐沥沥」「凄凄切切」，又「天潮潮」「地湿湿」「潮润润」，又「惊蛰一过」「泰寒加剧」「雨季开始」。从头读到尾，毫不采板。
}

请结合以下内容提炼一张标题为{金属和非金属的判断指标}的基础卡。开始前请先重新阐述任务。

#### 5.1 基础卡 —— 深度学习经历的三次浪潮

内容：

1、1940-1960 年，深度学习的雏形出现在控制论（cybernetics）中。

2、1980-1990 年，深度学习以联结主义（connectionism）为代表。

3、2006 年至今，深度学习之大复兴。

唯一编码：202311020040

打印备注：2023-11-02

评论：

参考：伊恩·古德费洛.(2017).2020063深度学习.(赵申剑,黎彧君.译).人民邮电出版社 => 译者序

原文：

作者指出：「一般认为，到目前为止深度学习已经经历了三次发展浪潮：20 世纪 40 年代到 60 年代深度学习的雏形出现在控制论（cybernetics）中，20 世纪 80 年代到 90 年代深度学习以联结主义（connectionism）为代表，而从 2006 年开始，以深度学习之名复兴」。

## 作者简介

Ian Goodfellow，谷歌公司（Google）的研究科学家，2014 年蒙特利尔大学机器学习博士。他的研究兴趣涵盖大多数深度学习主题，特别是生成模型以及机器学习的安全和隐私。Ian Goodfellow 在研究对抗样本方面是一位有影响力的早期研究者，他发明了生成式对抗网络，在深度学习领域贡献卓越。

Yoshua Bengio，蒙特利尔大学计算机科学与运筹学系（DIRO）的教授，蒙特利尔学习算法研究所（MILA）的负责人，CIFAR 项目的共同负责人，加拿大统计学习算法研究主席。Yoshua Bengio 的主要研究目标是了解产生智力的学习原则。他还教授「机器学习」研究生课程（IFT6266），并培养了一大批研究生和博士后。

Aaron Courville，蒙特利尔大学计算机科学与运筹学系的助理教授，也是 LISA 实验室的成员。目前他的研究兴趣集中在发展深度学习模型和方法，特别是开发概率模型和新颖的推断方法。Aaron Courville 主要专注于计算机视觉应用，在其他领域，如自然语言处理、音频信号处理、语音理解和其他 AI 相关任务方面也有所研究。

## 译者序 —— 青山遮不住，毕竟东流去

深度学习这个术语自 2006 年被正式提出后，在最近 10 年得到了巨大发展。它使人工智能（AI）产生了革命性的突破，让我们切实地领略到人工智能给人类生活带来改变的潜力。2016 年 12 月，MIT 出版社出版了 Ian Goodfellow、Yoshua Bengio 和 Aaron Courville 三位学者撰写的《Deep Learning》一书。三位作者一直耕耘于机器学习领域的前沿，引领了深度学习的发展潮流，是深度学习众多方法的主要贡献者。该书正应其时，一经出版就风靡全球。

该书包括 3 个部分，第 1 部分介绍基本的数学工具和机器学习的概念，它们是深度学习的预备知识。第 2 部分系统深入地讲解现今已成熟的深度学习方法和技术。第 3 部分讨论某些具有前瞻性的方向和想法，它们被公认为是深度学习未来的研究重点。因此，该书适用于不同层次的读者。我本人在阅读该书时受到启发良多，大有裨益，并采用该书作为教材在北京大学讲授深度学习课程。

这是一本涵盖深度学习技术细节的教科书，它告诉我们深度学习集技术、科学与艺术于一体，牵涉统计、优化、矩阵、算法、编程、分布式计算等多个领域。书中同时也蕴含了作者对深度学习的理解和思考，处处闪烁着深刻的思想，耐人回味。第 1 章关于深度学习的思想、历史发展等论述尤为透彻而精辟。

作者在书中写到：「人工智能的真正挑战在于解决那些对人来说很容易执行、但很难形式化描述的任务，比如识别人们所说的话或图像中的脸。对于这些问题，我们人类往往可以凭直觉轻易地解决」。为了应对这些挑战，他们提出让计算机从经验中学习，并根据层次化的概念体系来理解世界，而每个概念通过与某些相对简单的概念之间的关系来定义。由此，作者给出了深度学习的定义：

层次化的概念让计算机构建较简单的概念来学习复杂概念。如果绘制出表示这些概念如何建立在彼此之上的一幅图，我们将得到一张「深」（层次很多）的图。由此，我们称这种方法为 AI 深度学习（deep learning）」

1-3『吴恩达的机器学习课里，提到 Tom Mitchell 对深度学习的定义：A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.（2021-02-10）』

作者指出：「一般认为，到目前为止深度学习已经经历了三次发展浪潮：20 世纪 40 年代到 60 年代深度学习的雏形出现在控制论（cybernetics）中，20 世纪 80 年代到 90 年代深度学习以联结主义（connectionism）为代表，而从 2006 年开始，以深度学习之名复兴」。

谈到深度学习与脑科学或者神经科学的关系，作者强调：「如今神经科学在深度学习研究中的作用被削弱，主要原因是我们根本没有足够的关于大脑的信息作为指导去使用它。要获得对被大脑实际使用算法的深刻理解，我们需要有能力同时监测（至少是）数千相连神经元的活动。我们不能够做到这一点，所以我们甚至连大脑最简单、最深入研究的部分都还远远没有理解」。值得注意的是，我国有些专家热衷倡导人工智能与脑科学或认知学科的交叉研究，推动国家在所谓的「类脑智能」等领域投入大量资源。且不论我国是否真有同时精通人工智能和脑科学或认知心理学的学者，至少对交叉领域，我们都应该怀着务实、理性的求是态度。唯有如此，我们才有可能在这一波人工智能发展浪潮中有所作为，而不是又成为一群观潮人。

作者进一步指出：「媒体报道经常强调深度学习与大脑的相似性。的确，深度学习研究者比其他机器学习领域（如核方法或贝叶斯统计）的研究者更可能地引用大脑作为参考，但大家不应该认为深度学习在尝试模拟大脑。现代深度学习从许多领域获取灵感，特别是应用数学的基本内容如线性代数、概率论、信息论和数值优化。尽管一些深度学习的研究人员引用神经科学作为重要的灵感来源，然而其他学者完全不关心神经科学」。的确，对于广大青年学者和一线的工程师来说，我们是可以完全不用因为不懂神经（或脑）科学而对深度学习、人工智能踯躅不前。数学模型、计算方法和应用驱动才是我们研究人工智能的可行之道。深度学习和人工智能不是飘悬在我们头顶的框架，而是立足于我们脚下的技术。我们诚然可以从哲学层面或角度来欣赏科学与技术，但过度地从哲学层面来研究科学问题只会导致一些空洞的名词。

关于人工神经网络在 20 世纪 90 年代中期的衰落，作者分析到：「基于神经网络和其他 AI 技术的创业公司开始寻求投资，其做法野心勃勃但不切实际。当 AI 研究不能实现这些不合理的期望时，投资者感到失望。同时，机器学习的其他领域取得了进步。比如，核方法和图模型都在很多重要任务上实现了很好的效果。这两个因素导致了神经网络热潮的第二次衰退，并一直持续到 2007 年」。「其兴也悖焉，其亡也忽焉」。这个教训也同样值得当今基于深度学习的创业界、工业界和学术界等警醒。

我非常荣幸获得人民邮电出版社王峰松先生的邀请来负责该书的中文翻译。我是 2016 年 7 月收到王先生的邀请，但那时我正忙于找工作，无暇顾及。然而，当我和我的学生讨论翻译事宜时，他们一致认为这是一件非常有意义的事情，表达愿意来承担。译稿是由我的四位学生赵申剑、黎彧君、符天凡和李凯独立完成的。申剑和天凡是二年级的硕士生，而李凯和彧君则分别是二年级和三年级的直博生。虽然他们在机器学习领域都还是新人，其知识结构还不全面，但是他们热情高涨、勤于学习、工作专注、执行力极强。他们通过重现书中的算法代码和阅读相关文献来加强理解，在不到三个月的时间就拿出了译著的初稿，之后又经过自校对、交叉校对等环节力图使译著保持正确性和一致性。他们自我协调、主动揽责、相互谦让，他们的责任心和独立工作能力让我倍感欣慰，因而得以从容。

由于我们无论是中文还是英文能力都深感有限，译文恐怕还是有些生硬，我们特别担心未能完整地传达出原作者的真实思想和观点。因此，我们强烈地建议有条件的读者去阅读英文原著，也非常期待大家继续指正译著，以便今后进一步修订完善。我恳请大家多给予 4 位译者以鼓励。请把你们对译著的批评留给我，这是我作为他们的导师必须要承担的，也是我对王峰松先生的信任做出的承诺。

当初译稿基本完成时，我们决定把它公开在 GitHub 上，希望通过广大读者的参与来完善译稿。令人惊喜的是，有上百位热心读者给予了大量富有建设性的修改意见，其中有 20 多位热心读者直接帮助润色校对（详见中文版致谢名单）。可以说，这本译著是大家共同努力的结晶。这些读者来自一线的工程师和在校的学生，从中我领略到了他们对深度学习和机器学习领域的挚爱。更重要的是，我感受到了他们开放、合作和奉献的精神，而这也是推动人工智能发展不可或缺的。因此，我更加坚定地认为中国人工智能发展的希望在于年青学者，唯有他们才能让我国人工智能学科在世界有竞争力和影响力。

江山代有人才出，各领风骚数十年！

张志华代笔

2017 年 5 月 12 日于北大静园六院